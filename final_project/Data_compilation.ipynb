{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compilation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code consolidates seperate .csv data files sourced from the internet into one data frame, drops certain observations and fills NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "##############################################################################\n",
    "#Define help fuunctions to load data\n",
    "##############################################################################\n",
    "\n",
    "#This is a dictioary that maps selected country names to JHU format\n",
    "country_dictionary = {\n",
    "                      #United States\n",
    "                      \"United States of America\" : \"US\", \n",
    "                      \"U.S.\" : \"US\",\n",
    "                      \"United States\" : \"US\",\n",
    "                      \"USA\" : \"US\",\n",
    "\n",
    "                      #United Kingdom\n",
    "                      \"UK\" : \"United Kingdom\",\n",
    "                      \n",
    "                      #Others\n",
    "                      \"Republic of Korea\" : \"Korea, South\",\n",
    "                      \"Russian Federation\" : \" Russia\",\n",
    "                      \"Iran (Islamic Republic of)\" : \"Iran\",\n",
    "                      \"Bolivia (Plurinational State of)\":\"Bolivia\",\n",
    "                      \"Republic of North Macedonia\" : \"North Macedonia\",\n",
    "                      \"CÃ´te d'Ivoire\" : \"Cote d'Ivoire\",\n",
    "                      \"Congo\" : \"Congo (Brazzaville)\",\n",
    "                      \"Taiwan\" : \"Taiwan*\",\n",
    "                      \"UAE\": \"United Arab Emirates\"}\n",
    "\n",
    "#define a function that renames country names to JHU format\n",
    "def rename_countries(x, y, country_dictionary = None):\n",
    "    \n",
    "    #delete possible spaces \" \" at the end of a string, if applicable\n",
    "    a = y\n",
    "    \n",
    "    #apply the dictionary-based remap, if applicable\n",
    "    if not(country_dictionary is None):\n",
    "        a = a.replace(country_dictionary)\n",
    "    \n",
    "    #loop through the list of country names and assign matches\n",
    "    for x_str in x:\n",
    "        bool_list = np.vectorize(lambda z: z.find(x_str)>=0)(y)\n",
    "        \n",
    "        if (np.sum(bool_list) > 1):\n",
    "            if np.sum(np.vectorize(lambda z: x_str == z)(a)) != 1:\n",
    "                print(\"Error: Multiple Matches\")\n",
    "                break\n",
    "                #return\n",
    "        else:\n",
    "            a[bool_list] = x_str\n",
    "    return a\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#Load data into a big data frame\n",
    "##############################################################################\n",
    "    \n",
    "#create list of files\n",
    "import os\n",
    "path = \"./Raw Data\"\n",
    "file_list = list(filter(lambda x: ('.csv' in x) and not('JHU_recent_mortality_by_country' in x), os.listdir(path)))\n",
    "\n",
    "#load target variable\n",
    "jhu = pd.read_csv(path+\"/JHU_recent_mortality_by_country.csv\", \n",
    "                  converters = {\"Case-Fatality\": lambda x: float(x.strip(\"%\"))/100})\n",
    "\n",
    "#loop through list of files in directory\n",
    "for file_name in file_list:\n",
    "    \n",
    "    #load current file\n",
    "    who = pd.read_csv(path+\"/\"+file_name, encoding = \"latin-1\").iloc[:,:2]\n",
    "    who.rename(columns={who.columns[0]: \"Country\" }, inplace=True)\n",
    "    \n",
    "    #delete possible spaces \" \" at the end and beginning of a string, if applicable\n",
    "    who[\"Country\"] = np.vectorize(lambda z: z.rstrip().lstrip())(who[\"Country\"])\n",
    "    \n",
    "    #remap for values encoded as \"<0.1\", if applicable\n",
    "    if type(who.iloc[0,1]) == str:\n",
    "        who.iloc[:,1] = who.iloc[:,1].replace({\"<0.1\" : \"0.05\"}).astype(float)\n",
    "\n",
    "    #apply country remapping function\n",
    "    who[\"Country\"] = rename_countries(jhu[\"Country\"], who[\"Country\"], country_dictionary)\n",
    "    \n",
    "    #append to master data base\n",
    "    jhu = jhu.merge(who, on =\"Country\", how = \"left\")\n",
    "\n",
    "del(who, file_name, file_list, country_dictionary, path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#Drop small countries\n",
    "##############################################################################\n",
    "\n",
    "def drop_countries(data = jhu, quantile_threshold = 0.4):\n",
    "    \n",
    "    data[\"Population\"] = data[\"Population\"].fillna(0)\n",
    "    quantile = np.quantile(data[\"Population\"], quantile_threshold)\n",
    "    data = data.loc[ data[\"Population\"] > quantile ]\n",
    "    return data\n",
    "\n",
    "jhu = drop_countries(data = jhu, quantile_threshold = 0.4)\n",
    "\n",
    "#drop population column\n",
    "jhu = jhu.drop(\"Population\",axis = 1)\n",
    "\n",
    "##############################################################################\n",
    "#Handle NAs\n",
    "##############################################################################\n",
    "\n",
    "#function that drops every country that has less than half of  the data available\n",
    "def drop_NA(data = jhu, country_thresh = 0.5, var_thresh = 0.7):\n",
    "    \n",
    "    #delete countries with too many NAs\n",
    "    bool_vec = (1 - np.apply_along_axis(lambda x: np.sum(np.isnan(x)), 1, data.iloc[:,1:])/data.iloc[:,1:].shape[1])>=country_thresh\n",
    "    a = data.loc[bool_vec]\n",
    "    \n",
    "    #delete variables with too many NAs\n",
    "    bool_vec = (1 - np.apply_along_axis(lambda x: np.sum(np.isnan(x)), 0, data.iloc[:,1:])/data.iloc[:,1:].shape[0])>=var_thresh\n",
    "    a = a.loc[:, np.append(True,bool_vec)]\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "#drop NAs for countries that has less than half of  the data available\n",
    "jhu = drop_NA(country_thresh = 0.9, var_thresh = 0.8)\n",
    "\n",
    "\n",
    "def fill_NA(input_data = jhu, dev = 0.5, statistics = \"median\", method = \"OLS\"):\n",
    "    \n",
    "    from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    data = np.array(input_data.iloc[:,2:])\n",
    "    \n",
    "    #list of variables in data with NAs\n",
    "    var_list = np.arange(data.shape[1])[np.apply_along_axis(lambda x: np.sum(np.isnan(x)), 0, data) >= 1]\n",
    "    \n",
    "    if method == \"OLS\":\n",
    "        reg_method = LinearRegression(fit_intercept = False)\n",
    "    else:\n",
    "        reg_method = HuberRegressor(fit_intercept = False)\n",
    "    \n",
    "    if statistics == \"mean\":\n",
    "        average = np.mean\n",
    "        disp = np.std\n",
    "    else:\n",
    "        from scipy import stats\n",
    "        average = np.median\n",
    "        disp = stats.median_absolute_deviation\n",
    "        \n",
    "        \n",
    "    #loop through variables containing NAs\n",
    "    for i in var_list:\n",
    "        \n",
    "        #indices corresponding to test observation indices\n",
    "        test_indx = np.where( np.isnan(data[:,i]) )[0]\n",
    "        \n",
    "        #(preliminary) indices corresponding to train observation indices\n",
    "        train_indx = np.where( ~(np.isnan(data[:,i])))[0]\n",
    "        \n",
    "        #indices corresponding to variables\n",
    "        var_indx = np.where(np.apply_along_axis(lambda x: np.sum(np.isnan(x)) == 0, 0, data[test_indx,:]))[0]\n",
    "        \n",
    "        #test set of X-variables and y-variables\n",
    "        X_test = data[test_indx,:][:,var_indx] \n",
    "        indx_temp = np.where(np.apply_along_axis(lambda x: np.sum(np.isnan(x)) == 0, 1, data[train_indx,:][:, var_indx]))[0]\n",
    "        \n",
    "        #define train set for OLS regression\n",
    "        X_train = data[train_indx,:][:, var_indx][indx_temp,:]\n",
    "        y_train = data[train_indx,i][indx_temp]\n",
    "    \n",
    "        #standardize training and testing data\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True).fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True).fit(y_train.reshape(-1,1))\n",
    "        y_train = scaler.transform(y_train.reshape(-1,1))\n",
    "        \n",
    "        #perform OLS regression\n",
    "        reg = reg_method.fit(X_train, y_train)\n",
    "        reg_pred = scaler.inverse_transform(reg.predict(X_test)).ravel()\n",
    "        y_train = scaler.inverse_transform(y_train.reshape(-1,1)).ravel()\n",
    "        \n",
    "        #prune results if they deviate too much\n",
    "        lower, upper = average(y_train)-dev*disp(y_train), average(y_train)+dev*disp(y_train)\n",
    "        reg_pred[lower > reg_pred] = lower\n",
    "        reg_pred[upper < reg_pred] = upper\n",
    "        \n",
    "        #fill NAs\n",
    "        data[test_indx, i] = reg_pred\n",
    "\n",
    "    input_data.iloc[:,2:] = data\n",
    "    return input_data\n",
    "\n",
    "#fill NAs\n",
    "jhu = fill_NA(input_data = jhu, dev = 0.5, statistics = \"median\", method = \"OLS\")\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#Export data\n",
    "##############################################################################\n",
    "\n",
    "jhu.to_csv(\"raw_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
