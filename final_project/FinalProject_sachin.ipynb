{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "*Please fill out the relevant cells below according to the instructions. When done, save the notebook and export it to PDF, upload both the `ipynb` and the PDF file to Canvas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members\n",
    "\n",
    "*Group submission is highly encouraged. If you submit as part of group, list all group members here. Groups can comprise up to 5 students.*\n",
    "\n",
    "* Adam Applegate\n",
    "* Beatrix Brahms\n",
    "* \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Interactions\n",
    "\n",
    "### Preparation (3pts)\n",
    "\n",
    "Review the paper [The Kernel Interaction Trick: Fast Bayesian Discovery of Pairwise Interactions in High Dimensions](https://arxiv.org/abs/1905.06501) by Agrawal et al. (2019). Start with the general concepts and then go into the finer details.\n",
    "\n",
    "When you feel comfortable with the content, answer the following questions:\n",
    "\n",
    "1. Why does the Gaussian scale mixture prior promote sparsity of the regression coefficients $\\theta$?\n",
    "2. What are the required properties of the model in Eq. (3) that allow it to be rewritten in the form of Eq. (6)?\n",
    "3. What are the conceptual and practical limitation of the approach?\n",
    "\n",
    "**Hint:** Some of the answers may require parsing the relevant references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** Based on Griffin and Brown (2017), hierarchical priors in Bayesian regression are dependent on the size of the coefficients, where the hyperparameters control for shrinkage of coefficients similar to a penalty term. In particular, a small estimated variance in coefficients would enforce some shrinkage and likely yield a sparser model. The Gaussian scale mixture is in fact just a special case of hierarchical priors, in which $\\tau$ and $\\Sigma_\\tau$ control the shrinkage of $\\theta$. \n",
    "\n",
    "**2** This result is possible due to the Proposition 4.1 in Agrawal et al (2019). The function $\\Phi_2$ is designed such that it can be rewritten as a GP, namely the GP $g = \\theta^T\\Phi_2$. Then, the equivalence is completed by using the covariance $k_\\tau(x^{(i)},x^{(j})=\\Phi_2(x^{(i)})\\Sigma_\\tau\\Phi_2(x^{(j)})$ for $g\\sim GP(0,k_\\tau)$. Based on the weight-space view of GP from Rasmussen and Williams (2006), for any draw $g|\\tau\\sim N(0,k_\\tau)$, there exists a parameter vector $\\theta$ such that $g=\\theta^T\\Phi_2$. This completes the re-parametrization from Equation (3) to (6). \n",
    "\n",
    "**3** In the discussion of Priors for Related Predictors in Chipman (1996), one practical instance in which the strong hierarchy property would fail is in atmospheric sciences. A key relation is $log(Y)=log(A)+BC$, in which the interaction term $BC$ would not satisfy strong hierarchy, and thus could not be properly modeled using this approach. One conceptual limitation of the approach is the use of pairwise interactions. On one hand, the dimension of the parameter space is increased from $p$ to $\\frac{p(p+1)}{2}$, which could be extremely computationally expensive when $p$ is not even that large; on the other hand, there may be instances that involve higher-order polynomial interactions, and thus this model of at-most pairwise interactions could be too limited in its scope. In addition, the runtime is cubic and memory is quadraic with respect to the sample size $N$, which is as good or worse than other sampling methods it is compared to (NAIVE, WOODBURY, and FULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code adaptation (3pts)\n",
    "\n",
    "The method SKIM from chapter 6 has been implemented in jax/Numpyro [here](https://pyro.ai/numpyro/examples/sparse_regression.html). Review the code and recognize how the theoretical concepts of the Kernel Interaction Trick and the specific features of SKIM have been implemented. Then copy the code to this notebook and modify it so that you can execute the provided test example inline. Confirm that you get a result comparable to theirs.\n",
    "\n",
    "The last step of their example analysis (sampling from the posterior with the method `sample_theta_space`) often returns `nan`s. It also reports the posterior for all $\\theta$ (active and inactive ones), and only for one sample at a time. That's really clunky. Modify this function to produce flat posteriors samples from the MCMC (with an arbitrary length of samples) but only for the active direct and pairwise interaction terms. Visualize the posterior from the example with `corner`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application (4pts)\n",
    "\n",
    "COVID-19 dominates the news, with many countries still reporting rising case numbers. One surprising fact is that the mortality rate (i.e. the fraction of the infected who have died, also called **case-fatality ratio**) differs *a lot* between countries, from 15% to less than 1%. Find out which features (such as age distribution, population health indices, economic factors, COVID-specific factors ...) influences that rate.\n",
    "\n",
    "This task has three parts:\n",
    "\n",
    "* Think about what possible effects there could be.\n",
    "* Find suitable data for as many countries as possible in public data archives. Combine them into a master data set.\n",
    "* Perform the inference.\n",
    "\n",
    "You will probably need to iterate and refine along the way. Explain your reasoning about the kinds of features you decided to include in your analysis. Then report the most important direct and pairwise interactions. Visualized the posterior samples with `corner`.\n",
    "\n",
    "**Note:** This is an exploratory study. If your approach is sound, but the data don't show firm trends, partial points will be awarded. Include your final data compilation as a separate file with your submission.\n",
    "\n",
    "**Hints:** \n",
    "\n",
    "* Start [here](https://coronavirus.jhu.edu/data/mortality).\n",
    "* Don't forget to standardize the data by subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "import jax\n",
    "from jax import vmap\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "import corner\n",
    "\n",
    "def dot(X, Z):\n",
    "    return np.dot(X, Z[..., None])[..., 0]\n",
    "\n",
    "\n",
    "# The kernel that corresponds to our quadratic regressor. (According to prop 6.1)\n",
    "def kernel(X, Z, eta1, eta2, c, jitter=1.0e-6):\n",
    "    eta1sq = np.square(eta1)\n",
    "    eta2sq = np.square(eta2)\n",
    "    k1 = 0.5 * eta2sq * np.square(1.0 + dot(X, Z))\n",
    "    k2 = -0.5 * eta2sq * dot(np.square(X), np.square(Z))\n",
    "    k3 = (eta1sq - eta2sq) * dot(X, Z)\n",
    "    k4 = np.square(c) - 0.5 * eta2sq\n",
    "    if X.shape == Z.shape:\n",
    "        k4 += jitter * np.eye(X.shape[0])\n",
    "    return k1 + k2 + k3 + k4\n",
    "\n",
    "\n",
    "# Most of the model code is concerned with constructing the sparsity inducing prior.\n",
    "def model(X, Y, hypers):\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    # S ??? - like a sparsity coeff? \n",
    "    S, P, N = hypers['expected_sparsity'], X.shape[1], X.shape[0]\n",
    "\n",
    "    # sample variables from p. 18\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(hypers['alpha3']))\n",
    "    phi = sigma * (S / np.sqrt(N)) / (P - S)\n",
    "    eta1 = numpyro.sample(\"eta1\", dist.HalfCauchy(phi))\n",
    "\n",
    "    msq = numpyro.sample(\"msq\", dist.InverseGamma(hypers['alpha1'], hypers['beta1']))\n",
    "    xisq = numpyro.sample(\"xisq\", dist.InverseGamma(hypers['alpha2'], hypers['beta2']))\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "\n",
    "    lam = numpyro.sample(\"lambda\", dist.HalfCauchy(np.ones(P)))\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    # sample observation noise\n",
    "    var_obs = numpyro.sample(\"var_obs\", dist.InverseGamma(hypers['alpha_obs'], hypers['beta_obs']))\n",
    "\n",
    "    # compute kernel (as in proposition 6.1)\n",
    "    kX = kappa * X\n",
    "    k = kernel(kX, kX, eta1, eta2, hypers['c']) + var_obs * np.eye(N)\n",
    "    assert k.shape == (N, N)\n",
    "\n",
    "    # sample Y according to the standard gaussian process formula\n",
    "    numpyro.sample(\"Y\", dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=k),\n",
    "                   obs=Y)\n",
    "\n",
    "    \n",
    "    \n",
    "# I guess broadly corresponds to Section 5 of the paper??\n",
    "\n",
    "# Compute the mean and variance of coefficient theta_i (where i = dimension) for a\n",
    "# MCMC sample of the kernel hyperparameters (eta1, xisq, ...).\n",
    "# Compare to theorem 5.1 in reference [1].\n",
    "def compute_singleton_mean_variance(X, Y, dimension, msq, lam, eta1, xisq, c, var_obs):\n",
    "    P, N = X.shape[1], X.shape[0]\n",
    "\n",
    "    probe = np.zeros((2, P))\n",
    "    probe = jax.ops.index_update(probe, jax.ops.index[:, dimension], np.array([1.0, -1.0]))\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    vec = np.array([0.50, -0.50]) ## a = (1/2, -1/2)\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.dot(mu, vec)\n",
    "\n",
    "    var = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    var = np.matmul(var, vec)\n",
    "    var = np.dot(var, vec)\n",
    "\n",
    "    return mu, var\n",
    "\n",
    "\n",
    "# Compute the mean and variance of coefficient theta_ij for a MCMC sample of the\n",
    "# kernel hyperparameters (eta1, xisq, ...). Compare to theorem 5.1 in reference [1].\n",
    "def compute_pairwise_mean_variance(X, Y, dim1, dim2, msq, lam, eta1, xisq, c, var_obs):\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    P, N = X.shape[1], X.shape[0]\n",
    "\n",
    "    probe = np.zeros((4, P))\n",
    "    probe = jax.ops.index_update(probe, jax.ops.index[:, dim1], np.array([1.0, 1.0, -1.0, -1.0]))\n",
    "    probe = jax.ops.index_update(probe, jax.ops.index[:, dim2], np.array([1.0, -1.0, 1.0, -1.0]))\n",
    "    \n",
    "    \n",
    "    # compute eta2 and kappa from p. 18 \n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    # ?? compute a bunch of matrices w/ kernels ??\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    vec = np.array([0.25, -0.25, -0.25, 0.25]) ## ?? not sure why not (-1/2, 1/2, -1, 1) ??\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.dot(mu, vec)\n",
    "\n",
    "    var = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    var = np.matmul(var, vec)\n",
    "    var = np.dot(var, vec)\n",
    "\n",
    "    return mu, var\n",
    "\n",
    "\n",
    "# Sample coefficients theta from the posterior for a given MCMC sample.\n",
    "# The first P returned values are {theta_1, theta_2, ...., theta_P}, while\n",
    "# the remaining values are {theta_ij} for i,j in the list `active_dims`,\n",
    "# sorted so that i < j.\n",
    "def sample_theta_space(X, Y, active_dims, msq, lam, eta1, xisq, c, var_obs): #(section B.5) ?\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    # and number of active dimensions? \n",
    "    P, N, M = X.shape[1], X.shape[0], len(active_dims)\n",
    "    \n",
    "    # the total number of coefficients we return\n",
    "    num_coefficients = P + M * (M - 1) // 2\n",
    "\n",
    "    probe = np.zeros((2 * P + 2 * M * (M - 1), P))\n",
    "    vec = np.zeros((num_coefficients, 2 * P + 2 * M * (M - 1)))\n",
    "    start1 = 0\n",
    "    start2 = 0\n",
    "\n",
    "    for dim in range(P):\n",
    "        probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 2, dim], np.array([1.0, -1.0]))\n",
    "        vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 2], np.array([0.5, -0.5]))\n",
    "        start1 += 2\n",
    "        start2 += 1\n",
    "\n",
    "    for dim1 in active_dims:\n",
    "        for dim2 in active_dims:\n",
    "            if dim1 >= dim2:\n",
    "                continue\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim1],\n",
    "                                         np.array([1.0, 1.0, -1.0, -1.0]))\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim2],\n",
    "                                         np.array([1.0, -1.0, 1.0, -1.0]))\n",
    "            vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 4],\n",
    "                                       np.array([0.25, -0.25, -0.25, 0.25]))\n",
    "            start1 += 4\n",
    "            start2 += 1\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.sum(mu * vec, axis=-1)\n",
    "\n",
    "    covar = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    covar = np.matmul(vec, np.matmul(covar, np.transpose(vec)))\n",
    "    L = np.linalg.cholesky(covar)\n",
    "\n",
    "    # sample from N(mu, covar)\n",
    "    sample = mu + np.matmul(L, onp.random.randn(num_coefficients))\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "# Helper function for doing HMC inference\n",
    "def run_inference(model, args, rng_key, X, Y, hypers):\n",
    "    start = time.time()\n",
    "    kernel = NUTS(model)\n",
    "    mcmc = MCMC(kernel, args.num_warmup, args.num_samples, num_chains=args.num_chains,\n",
    "                progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True)\n",
    "    mcmc.run(rng_key, X, Y, hypers)\n",
    "    mcmc.print_summary()\n",
    "    print('\\nMCMC elapsed time:', time.time() - start)\n",
    "    return mcmc.get_samples()\n",
    "\n",
    "\n",
    "# Get the mean and variance of a gaussian mixture\n",
    "def gaussian_mixture_stats(mus, variances):\n",
    "    mean_mu = np.mean(mus)\n",
    "    mean_var = np.mean(variances) + np.mean(np.square(mus)) - np.square(mean_mu)\n",
    "    return mean_mu, mean_var\n",
    "\n",
    "\n",
    "# Create artificial regression dataset where only S out of P feature\n",
    "# dimensions contain signal and where there is a single pairwise interaction\n",
    "# between the first and second dimensions.\n",
    "def get_data(N=20, S=2, P=10, sigma_obs=0.05):\n",
    "    assert S < P and P > 1 and S > 0\n",
    "    onp.random.seed(0)\n",
    "\n",
    "    X = onp.random.randn(N, P)\n",
    "    # generate S coefficients with non-negligible magnitude\n",
    "    W = 0.5 + 2.5 * onp.random.rand(S)\n",
    "    # generate data using the S coefficients and a single pairwise interaction\n",
    "    Y = onp.sum(X[:, 0:S] * W, axis=-1) + X[:, 0] * X[:, 1] + sigma_obs * onp.random.randn(N)\n",
    "    Y -= np.mean(Y)\n",
    "    Y_std = np.std(Y)\n",
    "\n",
    "    assert X.shape == (N, P)\n",
    "    assert Y.shape == (N,)\n",
    "\n",
    "    return X, Y / Y_std, W / Y_std, 1.0 / Y_std\n",
    "\n",
    "\n",
    "# Helper function for analyzing the posterior statistics for coefficient theta_i\n",
    "def analyze_dimension(samples, X, Y, dimension, hypers):\n",
    "    vmap_args = (samples['msq'], samples['lambda'], samples['eta1'], samples['xisq'], samples['var_obs'])\n",
    "    mus, variances = vmap(lambda msq, lam, eta1, xisq, var_obs:\n",
    "                          compute_singleton_mean_variance(X, Y, dimension, msq, lam,\n",
    "                                                          eta1, xisq, hypers['c'], var_obs))(*vmap_args)\n",
    "    mean, variance = gaussian_mixture_stats(mus, variances)\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# Helper function for analyzing the posterior statistics for coefficient theta_ij\n",
    "def analyze_pair_of_dimensions(samples, X, Y, dim1, dim2, hypers):\n",
    "    vmap_args = (samples['msq'], samples['lambda'], samples['eta1'], samples['xisq'], samples['var_obs'])\n",
    "    mus, variances = vmap(lambda msq, lam, eta1, xisq, var_obs:\n",
    "                          compute_pairwise_mean_variance(X, Y, dim1, dim2, msq, lam,\n",
    "                                                         eta1, xisq, hypers['c'], var_obs))(*vmap_args)\n",
    "    mean, variance = gaussian_mixture_stats(mus, variances)\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_theta_space_trial(X, Y, active_dims, msq, lam, eta1, xisq, c, var_obs, N_samps, dim_pair_arr): #(section B.5) ?\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    # and number of active dimensions? \n",
    "    P, N, M = X.shape[1], X.shape[0], len(active_dims)\n",
    "    \n",
    "    # the total number of coefficients we return\n",
    "    num_coefficients = P + M * (M - 1) // 2\n",
    "\n",
    "    probe = np.zeros((2 * P + 2 * M * (M - 1), P))\n",
    "    vec = np.zeros((num_coefficients, 2 * P + 2 * M * (M - 1)))\n",
    "    start1 = 0\n",
    "    start2 = 0\n",
    "\n",
    "    for dim in range(P):\n",
    "        probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 2, dim], np.array([1.0, -1.0]))\n",
    "        vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 2], np.array([0.5, -0.5]))\n",
    "        start1 += 2\n",
    "        start2 += 1\n",
    "\n",
    "    for dim1 in active_dims:\n",
    "        for dim2 in active_dims:\n",
    "            if dim1 >= dim2:\n",
    "                continue\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim1],\n",
    "                                         np.array([1.0, 1.0, -1.0, -1.0]))\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim2],\n",
    "                                         np.array([1.0, -1.0, 1.0, -1.0]))\n",
    "            vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 4],\n",
    "                                       np.array([0.25, -0.25, -0.25, 0.25]))\n",
    "            start1 += 4\n",
    "            start2 += 1\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.sum(mu * vec, axis=-1)\n",
    "\n",
    "    covar = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    covar = np.matmul(vec, np.matmul(covar, np.transpose(vec)))\n",
    "    L = np.linalg.cholesky(covar)\n",
    "    \n",
    "    #print(\"mu\" + str(mu))\n",
    "    #print(\"cov\" + str(covar))\n",
    "    \n",
    "    # sample from N(mu, covar)\n",
    "    sample = mu + np.matmul(L, onp.random.randn(num_coefficients))\n",
    "    \n",
    "        ####### ~~~~~~~~~~~~~ CHANGES~~~~~~~~~~~~~~~~~~~\n",
    "    print(\"NUM of DIM: \" + str(P))\n",
    "    print(\"Num of all Thetas: \" + str(len(mu)))\n",
    "    # sample from active dims only? \n",
    "    all_active_dims = active_dims + dim_pair_arr\n",
    "    mu_active = np.array([mu[i] for i in all_active_dims])\n",
    "    \n",
    "    cov_active = []\n",
    "    for j in all_active_dims:\n",
    "        cov_act_j = [covar[j][i] for i in all_active_dims]\n",
    "        #print(cov_act_j)\n",
    "        cov_active.append(cov_act_j)\n",
    "    cov_active = onp.array(cov_active)\n",
    "    \n",
    "    print(\"mu_act\" + str(mu_active))\n",
    "    print(\"cov_act\" + str(cov_active))\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    samps = numpyro.distributions.MultivariateNormal(loc = onp.array(mu_active), \n",
    "                                                     covariance_matrix = cov_active).sample(rng_key, sample_shape = (1, N_samps))\n",
    "\n",
    "    samps_new = onp.reshape(samps, (N_samps, len(all_active_dims)))\n",
    "    \n",
    "    return samps_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args, hypers):\n",
    "    #X, Y, expected_thetas, expected_pairwise = get_data(N=args.num_data, P=args.num_dimensions,\n",
    "    #                                                    S=args.active_dimensions)\n",
    "    \n",
    "    Y = np.array(df.iloc[:,0])\n",
    "    X = np.array(df.iloc[:,1:])\n",
    "\n",
    "    # do inference\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    samples = run_inference(model, args, rng_key, X, Y, hypers)\n",
    "\n",
    "    # compute the mean and square root variance of each coefficient theta_i\n",
    "    means, stds = vmap(lambda dim: analyze_dimension(samples, X, Y, dim, hypers))(np.arange(args.num_dimensions))\n",
    "    num_dims = len(means)\n",
    "    #print(\"Coefficients theta_1 to theta_%d used to generate the data:\" % args.active_dimensions, expected_thetas)\n",
    "    #print(\"The single quadratic coefficient theta_{1,2} used to generate the data:\", expected_pairwise)\n",
    "    active_dimensions = []\n",
    "\n",
    "    for dim, (mean, std) in enumerate(zip(means, stds)):\n",
    "        # we mark the dimension as inactive if the interval [mean - 3 * std, mean + 3 * std] contains zero\n",
    "        lower, upper = mean - 1.0 * std, mean + 1.0 * std\n",
    "        inactive = \"inactive\" if lower < 0.0 and upper > 0.0 else \"active\"\n",
    "        if inactive == \"active\":\n",
    "            active_dimensions.append(dim)\n",
    "        print(\"[dimension %02d/%02d]  %s:\\t%.2e +- %.2e\" % (dim + 1, args.num_dimensions, inactive, mean, std))\n",
    "\n",
    "    print(\"Identified a total of %d active dimensions; expected %d.\" % (len(active_dimensions),\n",
    "                                                                        args.active_dimensions))\n",
    "\n",
    "    # Compute the mean and square root variance of coefficients theta_ij for i,j active dimensions.\n",
    "    # Note that the resulting numbers are only meaningful for i != j.\n",
    "    if len(active_dimensions) > 0:\n",
    "        dim_pairs = np.array(list(itertools.product(active_dimensions, active_dimensions)))\n",
    "        means, stds = vmap(lambda dim_pair: analyze_pair_of_dimensions(samples, X, Y,\n",
    "                                                                       dim_pair[0], dim_pair[1], hypers))(dim_pairs)\n",
    "        # print(dim_pairs)\n",
    "        dim_pair_arr = []\n",
    "        dim_pair_index = num_dims -1\n",
    "        dim_pair_name = []\n",
    "        for dim_pair, mean, std in zip(dim_pairs, means, stds):\n",
    "            dim1, dim2 = dim_pair\n",
    "            if dim1 >= dim2:\n",
    "                continue\n",
    "            dim_pair_index += 1  \n",
    "            lower, upper = mean - 3.0 * std, mean + 3.0 * std\n",
    "            if not (lower < 0.0 and upper > 0.0):\n",
    "                dim_pair_arr.append(dim_pair_index)\n",
    "                dim_pair_name.append('%d and %d'%(dim1 + 1, dim2 + 1))\n",
    "                format_str = \"Identified pairwise interaction between dimensions %d and %d: %.2e +- %.2e\"\n",
    "                print(format_str % (dim1 + 1, dim2 + 1, mean, std))\n",
    "        print(dim_pair_arr)\n",
    "        print(dim_pair_name)\n",
    "        # Draw a single sample of coefficients theta from the posterior, where we return all singleton\n",
    "        # coefficients theta_i and pairwise coefficients theta_ij for i, j active dimensions. We use the\n",
    "        # final MCMC sample obtained from the HMC sampler.\n",
    "        N_samps = 100\n",
    "        thetas = sample_theta_space_trial(X, Y, active_dimensions, samples['msq'][-1], samples['lambda'][-1],\n",
    "                                            samples['eta1'][-1], samples['xisq'][-1], hypers['c'], \n",
    "                                            samples['var_obs'][-1], N_samps, dim_pair_arr)\n",
    "        print(\"Active_dimensions: \" + str(active_dimensions))\n",
    "        #print(\"Single posterior sample theta:\\n\", thetas)\n",
    "        all_active_dimensions = active_dimensions + dim_pair_arr\n",
    "        labels = ['dim '+str(i) for i in active_dimensions]\n",
    "        for n in range(len(dim_pair_name)):\n",
    "            labels.append('dim ' + dim_pair_name[n])\n",
    "        fig = corner.corner(thetas, labels = labels);\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ON COVID DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case-Fatality</th>\n",
       "      <th>Human Development Index (HDI)</th>\n",
       "      <th>Population median age (years)</th>\n",
       "      <th>Adult mortality rate</th>\n",
       "      <th>Life expectancy at birth (years)</th>\n",
       "      <th>Mortality rate attributed to exposure to unsafe WASH services (per 100 000 population) (SDG 3.9.2)</th>\n",
       "      <th>Population proportion over 60 (%)</th>\n",
       "      <th>Current health expenditure (CHE) per capita in US$</th>\n",
       "      <th>UHC index of service coverage (SCI)</th>\n",
       "      <th>Cases per 1M population</th>\n",
       "      <th>Urban population (% of total population)</th>\n",
       "      <th>diabetes_prevalence</th>\n",
       "      <th>hospital_beds_per_100k</th>\n",
       "      <th>cvd_death_rate</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Tests/ 1M pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191215</td>\n",
       "      <td>1.203150</td>\n",
       "      <td>0.865347</td>\n",
       "      <td>-0.415850</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>-0.576234</td>\n",
       "      <td>1.790465</td>\n",
       "      <td>3.962344</td>\n",
       "      <td>1.091062</td>\n",
       "      <td>2.754711</td>\n",
       "      <td>0.907303</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>-0.023778</td>\n",
       "      <td>-0.742498</td>\n",
       "      <td>2.019030</td>\n",
       "      <td>0.671197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.534257</td>\n",
       "      <td>1.203150</td>\n",
       "      <td>1.175225</td>\n",
       "      <td>-1.051761</td>\n",
       "      <td>1.120574</td>\n",
       "      <td>-0.576234</td>\n",
       "      <td>0.119199</td>\n",
       "      <td>1.100189</td>\n",
       "      <td>1.288382</td>\n",
       "      <td>2.073479</td>\n",
       "      <td>0.959909</td>\n",
       "      <td>-0.893201</td>\n",
       "      <td>-0.114475</td>\n",
       "      <td>-0.986940</td>\n",
       "      <td>1.225108</td>\n",
       "      <td>0.499712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.225284</td>\n",
       "      <td>0.961579</td>\n",
       "      <td>1.628975</td>\n",
       "      <td>-1.227652</td>\n",
       "      <td>1.316638</td>\n",
       "      <td>-0.581976</td>\n",
       "      <td>0.171357</td>\n",
       "      <td>0.643761</td>\n",
       "      <td>0.959516</td>\n",
       "      <td>2.566817</td>\n",
       "      <td>0.362907</td>\n",
       "      <td>-0.750738</td>\n",
       "      <td>0.137898</td>\n",
       "      <td>-1.062809</td>\n",
       "      <td>1.013720</td>\n",
       "      <td>1.474719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.534257</td>\n",
       "      <td>1.013811</td>\n",
       "      <td>1.219493</td>\n",
       "      <td>-0.997641</td>\n",
       "      <td>1.330643</td>\n",
       "      <td>-0.570492</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>1.333646</td>\n",
       "      <td>0.696423</td>\n",
       "      <td>1.106240</td>\n",
       "      <td>0.823833</td>\n",
       "      <td>-0.753587</td>\n",
       "      <td>1.242031</td>\n",
       "      <td>-1.291539</td>\n",
       "      <td>1.178186</td>\n",
       "      <td>0.306799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.765986</td>\n",
       "      <td>1.196621</td>\n",
       "      <td>1.330164</td>\n",
       "      <td>-0.984111</td>\n",
       "      <td>1.092565</td>\n",
       "      <td>-0.570492</td>\n",
       "      <td>-0.291404</td>\n",
       "      <td>1.390868</td>\n",
       "      <td>1.091062</td>\n",
       "      <td>3.347087</td>\n",
       "      <td>1.632596</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>1.107958</td>\n",
       "      <td>-1.048059</td>\n",
       "      <td>1.460354</td>\n",
       "      <td>1.621932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-1.018928</td>\n",
       "      <td>0.289098</td>\n",
       "      <td>0.201323</td>\n",
       "      <td>-0.185839</td>\n",
       "      <td>0.266293</td>\n",
       "      <td>-0.518813</td>\n",
       "      <td>-0.284746</td>\n",
       "      <td>-0.557400</td>\n",
       "      <td>-0.092856</td>\n",
       "      <td>-0.695878</td>\n",
       "      <td>-2.030720</td>\n",
       "      <td>0.930325</td>\n",
       "      <td>0.303518</td>\n",
       "      <td>-0.354086</td>\n",
       "      <td>-0.470704</td>\n",
       "      <td>-0.539635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.710330</td>\n",
       "      <td>-1.127683</td>\n",
       "      <td>-1.115658</td>\n",
       "      <td>2.560758</td>\n",
       "      <td>-1.680346</td>\n",
       "      <td>0.824832</td>\n",
       "      <td>-0.357988</td>\n",
       "      <td>-0.579536</td>\n",
       "      <td>-0.882135</td>\n",
       "      <td>-0.726423</td>\n",
       "      <td>-1.398110</td>\n",
       "      <td>-1.594119</td>\n",
       "      <td>-0.445715</td>\n",
       "      <td>0.581003</td>\n",
       "      <td>-1.022397</td>\n",
       "      <td>-0.586538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.606965</td>\n",
       "      <td>-1.734876</td>\n",
       "      <td>-1.259530</td>\n",
       "      <td>1.004804</td>\n",
       "      <td>-1.106157</td>\n",
       "      <td>1.921567</td>\n",
       "      <td>-0.208174</td>\n",
       "      <td>-0.617534</td>\n",
       "      <td>-1.868734</td>\n",
       "      <td>-0.726423</td>\n",
       "      <td>-1.925370</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>-0.997781</td>\n",
       "      <td>-0.476164</td>\n",
       "      <td>-1.050487</td>\n",
       "      <td>-0.602008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.551683</td>\n",
       "      <td>-1.636941</td>\n",
       "      <td>-1.370201</td>\n",
       "      <td>1.491885</td>\n",
       "      <td>-1.288217</td>\n",
       "      <td>1.037288</td>\n",
       "      <td>-0.355769</td>\n",
       "      <td>-0.614397</td>\n",
       "      <td>-1.408321</td>\n",
       "      <td>-0.726423</td>\n",
       "      <td>-2.101614</td>\n",
       "      <td>-0.990076</td>\n",
       "      <td>-0.603448</td>\n",
       "      <td>-0.098634</td>\n",
       "      <td>-1.087411</td>\n",
       "      <td>-0.611902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.761451</td>\n",
       "      <td>-0.944873</td>\n",
       "      <td>-1.436603</td>\n",
       "      <td>1.911316</td>\n",
       "      <td>-1.554304</td>\n",
       "      <td>1.416265</td>\n",
       "      <td>-0.360208</td>\n",
       "      <td>-0.598580</td>\n",
       "      <td>-0.947909</td>\n",
       "      <td>-0.720869</td>\n",
       "      <td>-0.877023</td>\n",
       "      <td>-0.990076</td>\n",
       "      <td>-0.327415</td>\n",
       "      <td>-0.038267</td>\n",
       "      <td>-0.937810</td>\n",
       "      <td>-0.592988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case-Fatality  Human Development Index (HDI)  \\\n",
       "0        0.191215                       1.203150   \n",
       "1        2.534257                       1.203150   \n",
       "2        2.225284                       0.961579   \n",
       "3        2.534257                       1.013811   \n",
       "4        2.765986                       1.196621   \n",
       "..            ...                            ...   \n",
       "63      -1.018928                       0.289098   \n",
       "64       1.710330                      -1.127683   \n",
       "65      -0.606965                      -1.734876   \n",
       "66       0.551683                      -1.636941   \n",
       "67      -0.761451                      -0.944873   \n",
       "\n",
       "    Population median age (years)  Adult mortality rate  \\\n",
       "0                        0.865347             -0.415850   \n",
       "1                        1.175225             -1.051761   \n",
       "2                        1.628975             -1.227652   \n",
       "3                        1.219493             -0.997641   \n",
       "4                        1.330164             -0.984111   \n",
       "..                            ...                   ...   \n",
       "63                       0.201323             -0.185839   \n",
       "64                      -1.115658              2.560758   \n",
       "65                      -1.259530              1.004804   \n",
       "66                      -1.370201              1.491885   \n",
       "67                      -1.436603              1.911316   \n",
       "\n",
       "    Life expectancy at birth (years)  \\\n",
       "0                           0.714440   \n",
       "1                           1.120574   \n",
       "2                           1.316638   \n",
       "3                           1.330643   \n",
       "4                           1.092565   \n",
       "..                               ...   \n",
       "63                          0.266293   \n",
       "64                         -1.680346   \n",
       "65                         -1.106157   \n",
       "66                         -1.288217   \n",
       "67                         -1.554304   \n",
       "\n",
       "    Mortality rate attributed to exposure to unsafe WASH services (per 100 000 population) (SDG 3.9.2)  \\\n",
       "0                                           -0.576234                                                    \n",
       "1                                           -0.576234                                                    \n",
       "2                                           -0.581976                                                    \n",
       "3                                           -0.570492                                                    \n",
       "4                                           -0.570492                                                    \n",
       "..                                                ...                                                    \n",
       "63                                          -0.518813                                                    \n",
       "64                                           0.824832                                                    \n",
       "65                                           1.921567                                                    \n",
       "66                                           1.037288                                                    \n",
       "67                                           1.416265                                                    \n",
       "\n",
       "    Population proportion over 60 (%)  \\\n",
       "0                            1.790465   \n",
       "1                            0.119199   \n",
       "2                            0.171357   \n",
       "3                            0.145833   \n",
       "4                           -0.291404   \n",
       "..                                ...   \n",
       "63                          -0.284746   \n",
       "64                          -0.357988   \n",
       "65                          -0.208174   \n",
       "66                          -0.355769   \n",
       "67                          -0.360208   \n",
       "\n",
       "    Current health expenditure (CHE) per capita in US$  \\\n",
       "0                                            3.962344    \n",
       "1                                            1.100189    \n",
       "2                                            0.643761    \n",
       "3                                            1.333646    \n",
       "4                                            1.390868    \n",
       "..                                                ...    \n",
       "63                                          -0.557400    \n",
       "64                                          -0.579536    \n",
       "65                                          -0.617534    \n",
       "66                                          -0.614397    \n",
       "67                                          -0.598580    \n",
       "\n",
       "    UHC index of service coverage (SCI)  Cases per 1M population  \\\n",
       "0                              1.091062                 2.754711   \n",
       "1                              1.288382                 2.073479   \n",
       "2                              0.959516                 2.566817   \n",
       "3                              0.696423                 1.106240   \n",
       "4                              1.091062                 3.347087   \n",
       "..                                  ...                      ...   \n",
       "63                            -0.092856                -0.695878   \n",
       "64                            -0.882135                -0.726423   \n",
       "65                            -1.868734                -0.726423   \n",
       "66                            -1.408321                -0.726423   \n",
       "67                            -0.947909                -0.720869   \n",
       "\n",
       "    Urban population (% of total population)  diabetes_prevalence  \\\n",
       "0                                   0.907303             0.961667   \n",
       "1                                   0.959909            -0.893201   \n",
       "2                                   0.362907            -0.750738   \n",
       "3                                   0.823833            -0.753587   \n",
       "4                                   1.632596            -0.890352   \n",
       "..                                       ...                  ...   \n",
       "63                                 -2.030720             0.930325   \n",
       "64                                 -1.398110            -1.594119   \n",
       "65                                 -1.925370             0.015713   \n",
       "66                                 -2.101614            -0.990076   \n",
       "67                                 -0.877023            -0.990076   \n",
       "\n",
       "    hospital_beds_per_100k  cvd_death_rate  GDP per capita  Tests/ 1M pop  \n",
       "0                -0.023778       -0.742498        2.019030       0.671197  \n",
       "1                -0.114475       -0.986940        1.225108       0.499712  \n",
       "2                 0.137898       -1.062809        1.013720       1.474719  \n",
       "3                 1.242031       -1.291539        1.178186       0.306799  \n",
       "4                 1.107958       -1.048059        1.460354       1.621932  \n",
       "..                     ...             ...             ...            ...  \n",
       "63                0.303518       -0.354086       -0.470704      -0.539635  \n",
       "64               -0.445715        0.581003       -1.022397      -0.586538  \n",
       "65               -0.997781       -0.476164       -1.050487      -0.602008  \n",
       "66               -0.603448       -0.098634       -1.087411      -0.611902  \n",
       "67               -0.327415       -0.038267       -0.937810      -0.592988  \n",
       "\n",
       "[68 rows x 16 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "raw_data = pd.read_csv('raw_data.csv')\n",
    "df = raw_data.copy()\n",
    "\n",
    "country = df[df.columns[[0]]] # save countries\n",
    "df.drop(df.columns[0], axis=1, inplace=True) # drop countries\n",
    "df[df.columns] = StandardScaler().fit_transform(df) # scale\n",
    "# df.iloc[:,0] = StandardScaler().fit_transform(df.iloc[:,0].to_numpy().reshape(-1,1)) # scale\n",
    "\n",
    "# df = df.loc[:,['Population median age (years)', 'Cases per 1M population', 'diabetes_prevalence', 'Tests/ 1M pop']]\n",
    "# df = df.iloc[:30,:]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup hyperparameters\n",
    "# hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 10),\n",
    "#           'alpha1': 3.0, 'beta1': 1.0,\n",
    "#           'alpha2': 3.0, 'beta2': 1.0,\n",
    "#           'alpha3': 1.0, 'c': 1.0,\n",
    "#           'alpha_obs': 3.0, 'beta_obs': 1.0}\n",
    "\n",
    "hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 2),\n",
    "          'alpha1': 0.26872577050471647, \n",
    "          'alpha2': 4.818866884657901, \n",
    "          'alpha3': 6.812836016637205, \n",
    "          'alpha_obs': 49.093191654133754, \n",
    "          'beta1': 1.2942745182532156, \n",
    "          'beta2': 0.21267247881371867, \n",
    "          'beta_obs': 3.3406960438157594, \n",
    "          'c': 2.751017838090896}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-fd0ecc9e7688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnumpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_host_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a7fd7d412402>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, hypers)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# do inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrng_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# compute the mean and square root variance of each coefficient theta_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-86f87e277a40>\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(model, args, rng_key, X, Y, hypers)\u001b[0m\n\u001b[1;32m    205\u001b[0m     mcmc = MCMC(kernel, args.num_warmup, args.num_samples, num_chains=args.num_chains,\n\u001b[1;32m    206\u001b[0m                 progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True)\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nMCMC elapsed time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             states_flat, last_state = self._single_chain_mcmc(rng_key, init_state, init_params,\n\u001b[0;32m-> 1197\u001b[0;31m                                                               args, kwargs, collect_fields)\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36m_single_chain_mcmc\u001b[0;34m(self, rng_key, init_state, init_params, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minit_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             init_state = self.sampler.init(rng_key, self.num_warmup, init_params,\n\u001b[0;32m-> 1070\u001b[0;31m                                            model_args=args, model_kwargs=kwargs)\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                              ' `potential_fn`.')\n\u001b[1;32m    506\u001b[0m         \u001b[0;31m# Find valid initial params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             init_params, is_valid = find_valid_initial_params(rng_key, self._model,\n\u001b[1;32m    509\u001b[0m                                                               \u001b[0minit_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1479\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    assert numpyro.__version__.startswith('0.2.4')\n",
    "    parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "#     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "#     parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "#     parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "#     parser.add_argument(\"--num-data\", nargs='?', default=100, type=int)\n",
    "#     parser.add_argument(\"--num-dimensions\", nargs='?', default=20, type=int)\n",
    "#     parser.add_argument(\"--active-dimensions\", nargs='?', default=3, type=int)\n",
    "#     parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "    \n",
    "    parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=5000, type=int)\n",
    "    parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "    parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "    parser.add_argument(\"--num-data\", nargs='?', default=68, type=int)\n",
    "    parser.add_argument(\"--num-dimensions\", nargs='?', default=16, type=int)\n",
    "    parser.add_argument(\"--active-dimensions\", nargs='?', default=8, type=int)\n",
    "    parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "    #args = parser.parse_args() \n",
    "    args = parser.parse_args(args=[])  #68, 50, 5, 68, 16, 3, 'cpu'\n",
    "\n",
    "    numpyro.set_platform(args.device)\n",
    "    numpyro.set_host_device_count(args.num_chains)\n",
    "\n",
    "    main(args, hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus challenge (2pts extra):\n",
    "\n",
    "Find another application (e.g. from your area of research) where the kernel-interaction method is directly applicable, or could be applied with some modification. Describe the application for a statistically knowledgeable but non-expert audience (think: your peers in SML 515). In particular, explain why the sparse interaction ansatz is justified. Then demonstrate the use with a suitable data set of your own choice.\n",
    "\n",
    "**Note:** If your description is convincing, but you don't find any data or it doesn't lead to conclusive results, partial points will be awarded. Make sure that you have permission to use the data and include it as separate file in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 245)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as onp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fxdata3 = pd.read_csv('fxdata3.csv')\n",
    "# fxdata4 = pd.read_csv('fxdata4.csv')\n",
    "fxdata5 = pd.read_csv('fxdata5.csv', header=0)\n",
    "# fxdata10 = pd.read_csv('fxdata10.csv')\n",
    "\n",
    "df = fxdata5.copy()\n",
    "target_col = 'EURGBP_log_RealVol'\n",
    "df['Target_' + target_col] = df[target_col].copy()\n",
    "cols = df.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('Target_' + target_col)))\n",
    "df = df[cols].set_index('Date')\n",
    "\n",
    "\n",
    "df = df.iloc[-252:,:]\n",
    "df[::5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 245)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in df.columns[1:]:\n",
    "    df[c] = (df[c] - df[c].mean()) / df[c].std()\n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 10),\n",
    "          'alpha1': 0.27126163430537936, \n",
    "            'alpha2': 8.54749838434074, \n",
    "         'alpha3': 0.903895331940715, \n",
    "         'alpha_obs': 1.5417239333242043, \n",
    "         'beta1': 0.8507152602802248, \n",
    "         'beta2': 0.10195933547631165, \n",
    "         'beta_obs': 0.1328785334645342, \n",
    "         'c': 0.1529779179024281}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'expected_sparsity': max(1.0, args.num_dimensions // 10),\n",
    "              'alpha1': list(range(1,4)), \n",
    "              'alpha2': list(range(1,4)), \n",
    "              'alpha3': list(range(1,4)), \n",
    "              'alpha_obs': list(range(10,50,10)), \n",
    "              'beta1': list(range(1,4)), \n",
    "              'beta2': list(range(1,4)), \n",
    "              'beta_obs': list(range(1,4)), \n",
    "              'c': list(range(2))}\n",
    "\n",
    "n_params = len(param_grid)\n",
    "param_names = [_.lower() for _ in list(param_grid.keys())]\n",
    "param_values = list(param_grid.values())\n",
    "mdls = pd.DataFrame(onp.stack(onp.meshgrid(*param_values)).T.reshape(-1,n_params), columns=param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_sparsity': 24,\n",
       " 'alpha1': 1,\n",
       " 'alpha2': 1,\n",
       " 'alpha3': 1,\n",
       " 'alpha_obs': 10,\n",
       " 'beta1': 1,\n",
       " 'beta2': 1,\n",
       " 'beta_obs': 1,\n",
       " 'c': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mdl in mdls.iterrows():\n",
    "    \n",
    "    hypers = mdl.to_dict()\n",
    "\n",
    "    try:\n",
    "        if __name__ == \"__main__\":\n",
    "            assert numpyro.__version__.startswith('0.2.4')\n",
    "            parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "        #     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "        #     parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "        #     parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "        #     parser.add_argument(\"--num-data\", nargs='?', default=100, type=int)\n",
    "        #     parser.add_argument(\"--num-dimensions\", nargs='?', default=20, type=int)\n",
    "        #     parser.add_argument(\"--active-dimensions\", nargs='?', default=3, type=int)\n",
    "        #     parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "            parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "            parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "            parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "            parser.add_argument(\"--num-data\", nargs='?', default=252, type=int)\n",
    "            parser.add_argument(\"--num-dimensions\", nargs='?', default=245, type=int)\n",
    "            parser.add_argument(\"--active-dimensions\", nargs='?', default=25, type=int)\n",
    "            parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "            #args = parser.parse_args() \n",
    "            args = parser.parse_args(args=[])\n",
    "\n",
    "            numpyro.set_platform(args.device)\n",
    "            numpyro.set_host_device_count(args.num_chains)\n",
    "\n",
    "            main(args, hypers)\n",
    "\n",
    "    except RuntimeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypers = {'expected_sparsity': max(1.0, args.num_dimensions // 10),\n",
    "#  'alpha1': 1,\n",
    "#  'alpha2': 1,\n",
    "#  'alpha3': 1,\n",
    "#  'alpha_obs': 10,\n",
    "#  'beta1': 1,\n",
    "#  'beta2': 1,\n",
    "#  'beta_obs': 1,\n",
    "#  'c': 0}\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#             assert numpyro.__version__.startswith('0.2.4')\n",
    "#             parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "#         #     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "#         #     parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "#         #     parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "#         #     parser.add_argument(\"--num-data\", nargs='?', default=100, type=int)\n",
    "#         #     parser.add_argument(\"--num-dimensions\", nargs='?', default=20, type=int)\n",
    "#         #     parser.add_argument(\"--active-dimensions\", nargs='?', default=3, type=int)\n",
    "#         #     parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "#             parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "#             parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "#             parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "#             parser.add_argument(\"--num-data\", nargs='?', default=252, type=int)\n",
    "#             parser.add_argument(\"--num-dimensions\", nargs='?', default=245, type=int)\n",
    "#             parser.add_argument(\"--active-dimensions\", nargs='?', default=25, type=int)\n",
    "#             parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "#             #args = parser.parse_args() \n",
    "#             args = parser.parse_args(args=[])\n",
    "\n",
    "#             numpyro.set_platform(args.device)\n",
    "#             numpyro.set_host_device_count(args.num_chains)\n",
    "\n",
    "#             main(args, hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
