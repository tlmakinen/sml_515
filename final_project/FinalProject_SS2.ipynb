{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "*Please fill out the relevant cells below according to the instructions. When done, save the notebook and export it to PDF, upload both the `ipynb` and the PDF file to Canvas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members\n",
    "\n",
    "*Group submission is highly encouraged. If you submit as part of group, list all group members here. Groups can comprise up to 5 students.*\n",
    "\n",
    "* Adam Applegate\n",
    "* Beatrix Brahms\n",
    "* \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Interactions\n",
    "\n",
    "### Preparation (3pts)\n",
    "\n",
    "Review the paper [The Kernel Interaction Trick: Fast Bayesian Discovery of Pairwise Interactions in High Dimensions](https://arxiv.org/abs/1905.06501) by Agrawal et al. (2019). Start with the general concepts and then go into the finer details.\n",
    "\n",
    "When you feel comfortable with the content, answer the following questions:\n",
    "\n",
    "1. Why does the Gaussian scale mixture prior promote sparsity of the regression coefficients $\\theta$?\n",
    "2. What are the required properties of the model in Eq. (3) that allow it to be rewritten in the form of Eq. (6)?\n",
    "3. What are the conceptual and practical limitation of the approach?\n",
    "\n",
    "**Hint:** Some of the answers may require parsing the relevant references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** Based on Griffin and Brown (2017), hierarchical priors in Bayesian regression are dependent on the size of the coefficients, where the hyperparameters control for shrinkage of coefficients similar to a penalty term. In particular, a small estimated variance in coefficients would enforce some shrinkage and likely yield a sparser model. The Gaussian scale mixture is in fact just a special case of hierarchical priors, in which $\\tau$ and $\\Sigma_\\tau$ control the shrinkage of $\\theta$. \n",
    "\n",
    "**2** This result is possible due to the Proposition 4.1 in Agrawal et al (2019). The function $\\Phi_2$ is designed such that it can be rewritten as a GP, namely the GP $g = \\theta^T\\Phi_2$. Then, the equivalence is completed by using the covariance $k_\\tau(x^{(i)},x^{(j})=\\Phi_2(x^{(i)})\\Sigma_\\tau\\Phi_2(x^{(j)})$ for $g\\sim GP(0,k_\\tau)$. Based on the weight-space view of GP from Rasmussen and Williams (2006), for any draw $g|\\tau\\sim N(0,k_\\tau)$, there exists a parameter vector $\\theta$ such that $g=\\theta^T\\Phi_2$. This completes the re-parametrization from Equation (3) to (6). \n",
    "\n",
    "**3** In the discussion of Priors for Related Predictors in Chipman (1996), one practical instance in which the strong hierarchy property would fail is in atmospheric sciences. A key relation is $log(Y)=log(A)+BC$, in which the interaction term $BC$ would not satisfy strong hierarchy, and thus could not be properly modeled using this approach. One conceptual limitation of the approach is the use of pairwise interactions. On one hand, the dimension of the parameter space is increased from $p$ to $\\frac{p(p+1)}{2}$, which could be extremely computationally expensive when $p$ is not even that large; on the other hand, there may be instances that involve higher-order polynomial interactions, and thus this model of at-most pairwise interactions could be too limited in its scope. In addition, the runtime is cubic and memory is quadraic with respect to the sample size $N$, which is as good or worse than other sampling methods it is compared to (NAIVE, WOODBURY, and FULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code adaptation (3pts)\n",
    "\n",
    "The method SKIM from chapter 6 has been implemented in jax/Numpyro [here](https://pyro.ai/numpyro/examples/sparse_regression.html). Review the code and recognize how the theoretical concepts of the Kernel Interaction Trick and the specific features of SKIM have been implemented. Then copy the code to this notebook and modify it so that you can execute the provided test example inline. Confirm that you get a result comparable to theirs.\n",
    "\n",
    "The last step of their example analysis (sampling from the posterior with the method `sample_theta_space`) often returns `nan`s. It also reports the posterior for all $\\theta$ (active and inactive ones), and only for one sample at a time. That's really clunky. Modify this function to produce flat posteriors samples from the MCMC (with an arbitrary length of samples) but only for the active direct and pairwise interaction terms. Visualize the posterior from the example with `corner`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application (4pts)\n",
    "\n",
    "COVID-19 dominates the news, with many countries still reporting rising case numbers. One surprising fact is that the mortality rate (i.e. the fraction of the infected who have died, also called **case-fatality ratio**) differs *a lot* between countries, from 15% to less than 1%. Find out which features (such as age distribution, population health indices, economic factors, COVID-specific factors ...) influences that rate.\n",
    "\n",
    "This task has three parts:\n",
    "\n",
    "* Think about what possible effects there could be.\n",
    "* Find suitable data for as many countries as possible in public data archives. Combine them into a master data set.\n",
    "* Perform the inference.\n",
    "\n",
    "You will probably need to iterate and refine along the way. Explain your reasoning about the kinds of features you decided to include in your analysis. Then report the most important direct and pairwise interactions. Visualized the posterior samples with `corner`.\n",
    "\n",
    "**Note:** This is an exploratory study. If your approach is sound, but the data don't show firm trends, partial points will be awarded. Include your final data compilation as a separate file with your submission.\n",
    "\n",
    "**Hints:** \n",
    "\n",
    "* Start [here](https://coronavirus.jhu.edu/data/mortality).\n",
    "* Don't forget to standardize the data by subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "import jax\n",
    "from jax import vmap\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "import corner\n",
    "\n",
    "def dot(X, Z):\n",
    "    return np.dot(X, Z[..., None])[..., 0]\n",
    "\n",
    "\n",
    "# The kernel that corresponds to our quadratic regressor. (According to prop 6.1)\n",
    "def kernel(X, Z, eta1, eta2, c, jitter=1.0e-6):\n",
    "    eta1sq = np.square(eta1)\n",
    "    eta2sq = np.square(eta2)\n",
    "    k1 = 0.5 * eta2sq * np.square(1.0 + dot(X, Z))\n",
    "    k2 = -0.5 * eta2sq * dot(np.square(X), np.square(Z))\n",
    "    k3 = (eta1sq - eta2sq) * dot(X, Z)\n",
    "    k4 = np.square(c) - 0.5 * eta2sq\n",
    "    if X.shape == Z.shape:\n",
    "        k4 += jitter * np.eye(X.shape[0])\n",
    "    return k1 + k2 + k3 + k4\n",
    "\n",
    "\n",
    "# Most of the model code is concerned with constructing the sparsity inducing prior.\n",
    "def model(X, Y, hypers):\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    # S ??? - like a sparsity coeff? \n",
    "    S, P, N = hypers['expected_sparsity'], X.shape[1], X.shape[0]\n",
    "\n",
    "    # sample variables from p. 18\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(hypers['alpha3']))\n",
    "    phi = sigma * (S / np.sqrt(N)) / (P - S)\n",
    "    eta1 = numpyro.sample(\"eta1\", dist.HalfCauchy(phi))\n",
    "\n",
    "    msq = numpyro.sample(\"msq\", dist.InverseGamma(hypers['alpha1'], hypers['beta1']))\n",
    "    xisq = numpyro.sample(\"xisq\", dist.InverseGamma(hypers['alpha2'], hypers['beta2']))\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "\n",
    "    lam = numpyro.sample(\"lambda\", dist.HalfCauchy(np.ones(P)))\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    # sample observation noise\n",
    "    var_obs = numpyro.sample(\"var_obs\", dist.InverseGamma(hypers['alpha_obs'], hypers['beta_obs']))\n",
    "\n",
    "    # compute kernel (as in proposition 6.1)\n",
    "    kX = kappa * X\n",
    "    k = kernel(kX, kX, eta1, eta2, hypers['c']) + var_obs * np.eye(N)\n",
    "    assert k.shape == (N, N)\n",
    "\n",
    "    # sample Y according to the standard gaussian process formula\n",
    "    numpyro.sample(\"Y\", dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=k),\n",
    "                   obs=Y)\n",
    "\n",
    "    \n",
    "    \n",
    "# I guess broadly corresponds to Section 5 of the paper??\n",
    "\n",
    "# Compute the mean and variance of coefficient theta_i (where i = dimension) for a\n",
    "# MCMC sample of the kernel hyperparameters (eta1, xisq, ...).\n",
    "# Compare to theorem 5.1 in reference [1].\n",
    "def compute_singleton_mean_variance(X, Y, dimension, msq, lam, eta1, xisq, c, var_obs):\n",
    "    P, N = X.shape[1], X.shape[0]\n",
    "\n",
    "    probe = np.zeros((2, P))\n",
    "    probe = jax.ops.index_update(probe, jax.ops.index[:, dimension], np.array([1.0, -1.0]))\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    vec = np.array([0.50, -0.50]) ## a = (1/2, -1/2)\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.dot(mu, vec)\n",
    "\n",
    "    var = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    var = np.matmul(var, vec)\n",
    "    var = np.dot(var, vec)\n",
    "\n",
    "    return mu, var\n",
    "\n",
    "\n",
    "# Compute the mean and variance of coefficient theta_ij for a MCMC sample of the\n",
    "# kernel hyperparameters (eta1, xisq, ...). Compare to theorem 5.1 in reference [1].\n",
    "def compute_pairwise_mean_variance(X, Y, dim1, dim2, msq, lam, eta1, xisq, c, var_obs):\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    P, N = X.shape[1], X.shape[0]\n",
    "\n",
    "    probe = np.zeros((4, P))\n",
    "    probe = jax.ops.index_update(probe, jax.ops.index[:, dim1], np.array([1.0, 1.0, -1.0, -1.0]))\n",
    "    probe = jax.ops.index_update(probe, jax.ops.index[:, dim2], np.array([1.0, -1.0, 1.0, -1.0]))\n",
    "    \n",
    "    \n",
    "    # compute eta2 and kappa from p. 18 \n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    # ?? compute a bunch of matrices w/ kernels ??\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    vec = np.array([0.25, -0.25, -0.25, 0.25]) ## ?? not sure why not (-1/2, 1/2, -1, 1) ??\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.dot(mu, vec)\n",
    "\n",
    "    var = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    var = np.matmul(var, vec)\n",
    "    var = np.dot(var, vec)\n",
    "\n",
    "    return mu, var\n",
    "\n",
    "\n",
    "# Sample coefficients theta from the posterior for a given MCMC sample.\n",
    "# The first P returned values are {theta_1, theta_2, ...., theta_P}, while\n",
    "# the remaining values are {theta_ij} for i,j in the list `active_dims`,\n",
    "# sorted so that i < j.\n",
    "def sample_theta_space(X, Y, active_dims, msq, lam, eta1, xisq, c, var_obs): #(section B.5) ?\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    # and number of active dimensions? \n",
    "    P, N, M = X.shape[1], X.shape[0], len(active_dims)\n",
    "    \n",
    "    # the total number of coefficients we return\n",
    "    num_coefficients = P + M * (M - 1) // 2\n",
    "\n",
    "    probe = np.zeros((2 * P + 2 * M * (M - 1), P))\n",
    "    vec = np.zeros((num_coefficients, 2 * P + 2 * M * (M - 1)))\n",
    "    start1 = 0\n",
    "    start2 = 0\n",
    "\n",
    "    for dim in range(P):\n",
    "        probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 2, dim], np.array([1.0, -1.0]))\n",
    "        vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 2], np.array([0.5, -0.5]))\n",
    "        start1 += 2\n",
    "        start2 += 1\n",
    "\n",
    "    for dim1 in active_dims:\n",
    "        for dim2 in active_dims:\n",
    "            if dim1 >= dim2:\n",
    "                continue\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim1],\n",
    "                                         np.array([1.0, 1.0, -1.0, -1.0]))\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim2],\n",
    "                                         np.array([1.0, -1.0, 1.0, -1.0]))\n",
    "            vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 4],\n",
    "                                       np.array([0.25, -0.25, -0.25, 0.25]))\n",
    "            start1 += 4\n",
    "            start2 += 1\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.sum(mu * vec, axis=-1)\n",
    "\n",
    "    covar = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    covar = np.matmul(vec, np.matmul(covar, np.transpose(vec)))\n",
    "    L = np.linalg.cholesky(covar)\n",
    "\n",
    "    # sample from N(mu, covar)\n",
    "    sample = mu + np.matmul(L, onp.random.randn(num_coefficients))\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "# Helper function for doing HMC inference\n",
    "def run_inference(model, args, rng_key, X, Y, hypers):\n",
    "    start = time.time()\n",
    "    kernel = NUTS(model)\n",
    "    mcmc = MCMC(kernel, args.num_warmup, args.num_samples, num_chains=args.num_chains,\n",
    "                progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True)\n",
    "    mcmc.run(rng_key, X, Y, hypers)\n",
    "    mcmc.print_summary()\n",
    "    print('\\nMCMC elapsed time:', time.time() - start)\n",
    "    return mcmc.get_samples()\n",
    "\n",
    "\n",
    "# Get the mean and variance of a gaussian mixture\n",
    "def gaussian_mixture_stats(mus, variances):\n",
    "    mean_mu = np.mean(mus)\n",
    "    mean_var = np.mean(variances) + np.mean(np.square(mus)) - np.square(mean_mu)\n",
    "    return mean_mu, mean_var\n",
    "\n",
    "\n",
    "# Create artificial regression dataset where only S out of P feature\n",
    "# dimensions contain signal and where there is a single pairwise interaction\n",
    "# between the first and second dimensions.\n",
    "def get_data(N=20, S=2, P=10, sigma_obs=0.05):\n",
    "    assert S < P and P > 1 and S > 0\n",
    "    onp.random.seed(0)\n",
    "\n",
    "    X = onp.random.randn(N, P)\n",
    "    # generate S coefficients with non-negligible magnitude\n",
    "    W = 0.5 + 2.5 * onp.random.rand(S)\n",
    "    # generate data using the S coefficients and a single pairwise interaction\n",
    "    Y = onp.sum(X[:, 0:S] * W, axis=-1) + X[:, 0] * X[:, 1] + sigma_obs * onp.random.randn(N)\n",
    "    Y -= np.mean(Y)\n",
    "    Y_std = np.std(Y)\n",
    "\n",
    "    assert X.shape == (N, P)\n",
    "    assert Y.shape == (N,)\n",
    "\n",
    "    return X, Y / Y_std, W / Y_std, 1.0 / Y_std\n",
    "\n",
    "\n",
    "# Helper function for analyzing the posterior statistics for coefficient theta_i\n",
    "def analyze_dimension(samples, X, Y, dimension, hypers):\n",
    "    vmap_args = (samples['msq'], samples['lambda'], samples['eta1'], samples['xisq'], samples['var_obs'])\n",
    "    mus, variances = vmap(lambda msq, lam, eta1, xisq, var_obs:\n",
    "                          compute_singleton_mean_variance(X, Y, dimension, msq, lam,\n",
    "                                                          eta1, xisq, hypers['c'], var_obs))(*vmap_args)\n",
    "    mean, variance = gaussian_mixture_stats(mus, variances)\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# Helper function for analyzing the posterior statistics for coefficient theta_ij\n",
    "def analyze_pair_of_dimensions(samples, X, Y, dim1, dim2, hypers):\n",
    "    vmap_args = (samples['msq'], samples['lambda'], samples['eta1'], samples['xisq'], samples['var_obs'])\n",
    "    mus, variances = vmap(lambda msq, lam, eta1, xisq, var_obs:\n",
    "                          compute_pairwise_mean_variance(X, Y, dim1, dim2, msq, lam,\n",
    "                                                         eta1, xisq, hypers['c'], var_obs))(*vmap_args)\n",
    "    mean, variance = gaussian_mixture_stats(mus, variances)\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_theta_space_trial(X, Y, active_dims, msq, lam, eta1, xisq, c, var_obs, N_samps, dim_pair_arr): #(section B.5) ?\n",
    "    # Here X is the design matrix with N x p dimensions\n",
    "    # read off dimensions P and N\n",
    "    # and number of active dimensions? \n",
    "    P, N, M = X.shape[1], X.shape[0], len(active_dims)\n",
    "    \n",
    "    # the total number of coefficients we return\n",
    "    num_coefficients = P + M * (M - 1) // 2\n",
    "\n",
    "    probe = np.zeros((2 * P + 2 * M * (M - 1), P))\n",
    "    vec = np.zeros((num_coefficients, 2 * P + 2 * M * (M - 1)))\n",
    "    start1 = 0\n",
    "    start2 = 0\n",
    "\n",
    "    for dim in range(P):\n",
    "        probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 2, dim], np.array([1.0, -1.0]))\n",
    "        vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 2], np.array([0.5, -0.5]))\n",
    "        start1 += 2\n",
    "        start2 += 1\n",
    "\n",
    "    for dim1 in active_dims:\n",
    "        for dim2 in active_dims:\n",
    "            if dim1 >= dim2:\n",
    "                continue\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim1],\n",
    "                                         np.array([1.0, 1.0, -1.0, -1.0]))\n",
    "            probe = jax.ops.index_update(probe, jax.ops.index[start1:start1 + 4, dim2],\n",
    "                                         np.array([1.0, -1.0, 1.0, -1.0]))\n",
    "            vec = jax.ops.index_update(vec, jax.ops.index[start2, start1:start1 + 4],\n",
    "                                       np.array([0.25, -0.25, -0.25, 0.25]))\n",
    "            start1 += 4\n",
    "            start2 += 1\n",
    "\n",
    "    eta2 = np.square(eta1) * np.sqrt(xisq) / msq\n",
    "    kappa = np.sqrt(msq) * lam / np.sqrt(msq + np.square(eta1 * lam))\n",
    "\n",
    "    kX = kappa * X\n",
    "    kprobe = kappa * probe\n",
    "\n",
    "    k_xx = kernel(kX, kX, eta1, eta2, c) + var_obs * np.eye(N)\n",
    "    k_xx_inv = np.linalg.inv(k_xx)\n",
    "    k_probeX = kernel(kprobe, kX, eta1, eta2, c)\n",
    "    k_prbprb = kernel(kprobe, kprobe, eta1, eta2, c)\n",
    "\n",
    "    mu = np.matmul(k_probeX, np.matmul(k_xx_inv, Y))\n",
    "    mu = np.sum(mu * vec, axis=-1)\n",
    "\n",
    "    covar = k_prbprb - np.matmul(k_probeX, np.matmul(k_xx_inv, np.transpose(k_probeX)))\n",
    "    covar = np.matmul(vec, np.matmul(covar, np.transpose(vec)))\n",
    "    L = np.linalg.cholesky(covar)\n",
    "    \n",
    "    #print(\"mu\" + str(mu))\n",
    "    #print(\"cov\" + str(covar))\n",
    "    \n",
    "    # sample from N(mu, covar)\n",
    "    sample = mu + np.matmul(L, onp.random.randn(num_coefficients))\n",
    "    \n",
    "        ####### ~~~~~~~~~~~~~ CHANGES~~~~~~~~~~~~~~~~~~~\n",
    "    print(\"NUM of DIM: \" + str(P))\n",
    "    print(\"Num of all Thetas: \" + str(len(mu)))\n",
    "    # sample from active dims only? \n",
    "    all_active_dims = active_dims + dim_pair_arr\n",
    "    mu_active = np.array([mu[i] for i in all_active_dims])\n",
    "    \n",
    "    cov_active = []\n",
    "    for j in all_active_dims:\n",
    "        cov_act_j = [covar[j][i] for i in all_active_dims]\n",
    "        #print(cov_act_j)\n",
    "        cov_active.append(cov_act_j)\n",
    "    cov_active = onp.array(cov_active)\n",
    "    \n",
    "    print(\"mu_act\" + str(mu_active))\n",
    "    print(\"cov_act\" + str(cov_active))\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    samps = numpyro.distributions.MultivariateNormal(loc = onp.array(mu_active), \n",
    "                                                     covariance_matrix = cov_active).sample(rng_key, sample_shape = (1, N_samps))\n",
    "\n",
    "    samps_new = onp.reshape(samps, (N_samps, len(all_active_dims)))\n",
    "    \n",
    "    return samps_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args, hypers):\n",
    "    #X, Y, expected_thetas, expected_pairwise = get_data(N=args.num_data, P=args.num_dimensions,\n",
    "    #                                                    S=args.active_dimensions)\n",
    "    \n",
    "    Y = np.array(df.iloc[:,0])\n",
    "    X = np.array(df.iloc[:,1:])\n",
    "\n",
    "    # do inference\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    samples = run_inference(model, args, rng_key, X, Y, hypers)\n",
    "\n",
    "    # compute the mean and square root variance of each coefficient theta_i\n",
    "    means, stds = vmap(lambda dim: analyze_dimension(samples, X, Y, dim, hypers))(np.arange(args.num_dimensions))\n",
    "    num_dims = len(means)\n",
    "    #print(\"Coefficients theta_1 to theta_%d used to generate the data:\" % args.active_dimensions, expected_thetas)\n",
    "    #print(\"The single quadratic coefficient theta_{1,2} used to generate the data:\", expected_pairwise)\n",
    "    active_dimensions = []\n",
    "\n",
    "    for dim, (mean, std) in enumerate(zip(means, stds)):\n",
    "        # we mark the dimension as inactive if the interval [mean - 3 * std, mean + 3 * std] contains zero\n",
    "        lower, upper = mean - 1. * std, mean + 1. * std\n",
    "        inactive = \"inactive\" if lower < 0.0 and upper > 0.0 else \"active\"\n",
    "        if inactive == \"active\":\n",
    "            active_dimensions.append(dim)\n",
    "        print(\"[dimension %02d/%02d]  %s:\\t%.2e +- %.2e\" % (dim + 1, args.num_dimensions, inactive, mean, std))\n",
    "\n",
    "    print(\"Identified a total of %d active dimensions; expected %d.\" % (len(active_dimensions),\n",
    "                                                                        args.active_dimensions))\n",
    "\n",
    "    # Compute the mean and square root variance of coefficients theta_ij for i,j active dimensions.\n",
    "    # Note that the resulting numbers are only meaningful for i != j.\n",
    "    if len(active_dimensions) > 0:\n",
    "        dim_pairs = np.array(list(itertools.product(active_dimensions, active_dimensions)))\n",
    "        means, stds = vmap(lambda dim_pair: analyze_pair_of_dimensions(samples, X, Y,\n",
    "                                                                       dim_pair[0], dim_pair[1], hypers))(dim_pairs)\n",
    "        # print(dim_pairs)\n",
    "        dim_pair_arr = []\n",
    "        dim_pair_index = num_dims -1\n",
    "        dim_pair_name = []\n",
    "        for dim_pair, mean, std in zip(dim_pairs, means, stds):\n",
    "            dim1, dim2 = dim_pair\n",
    "            if dim1 >= dim2:\n",
    "                continue\n",
    "            dim_pair_index += 1  \n",
    "            lower, upper = mean - 1. * std, mean + 1. * std\n",
    "            if not (lower < 0.0 and upper > 0.0):\n",
    "                dim_pair_arr.append(dim_pair_index)\n",
    "                dim_pair_name.append('%d and %d'%(dim1 + 1, dim2 + 1))\n",
    "                format_str = \"Identified pairwise interaction between dimensions %d and %d: %.2e +- %.2e\"\n",
    "                print(format_str % (dim1 + 1, dim2 + 1, mean, std))\n",
    "        print(dim_pair_arr)\n",
    "        print(dim_pair_name)\n",
    "        # Draw a single sample of coefficients theta from the posterior, where we return all singleton\n",
    "        # coefficients theta_i and pairwise coefficients theta_ij for i, j active dimensions. We use the\n",
    "        # final MCMC sample obtained from the HMC sampler.\n",
    "        N_samps = 100\n",
    "        thetas = sample_theta_space_trial(X, Y, active_dimensions, samples['msq'][-1], samples['lambda'][-1],\n",
    "                                            samples['eta1'][-1], samples['xisq'][-1], hypers['c'], \n",
    "                                            samples['var_obs'][-1], N_samps, dim_pair_arr)\n",
    "        print(\"Active_dimensions: \" + str(active_dimensions))\n",
    "        #print(\"Single posterior sample theta:\\n\", thetas)\n",
    "        all_active_dimensions = active_dimensions + dim_pair_arr\n",
    "        labels = ['dim '+str(i) for i in active_dimensions]\n",
    "        for n in range(len(dim_pair_name)):\n",
    "            labels.append('dim ' + dim_pair_name[n])\n",
    "        fig = corner.corner(thetas, labels = labels);\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ON COVID DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case-Fatality</th>\n",
       "      <th>Human Development Index (HDI)</th>\n",
       "      <th>Population median age (years)</th>\n",
       "      <th>Adult mortality rate</th>\n",
       "      <th>Life expectancy at birth (years)</th>\n",
       "      <th>Mortality rate attributed to exposure to unsafe WASH services (per 100 000 population) (SDG 3.9.2)</th>\n",
       "      <th>Population proportion over 60 (%)</th>\n",
       "      <th>Current health expenditure (CHE) per capita in US$</th>\n",
       "      <th>UHC index of service coverage (SCI)</th>\n",
       "      <th>Cases per 1M population</th>\n",
       "      <th>Urban population (% of total population)</th>\n",
       "      <th>diabetes_prevalence</th>\n",
       "      <th>hospital_beds_per_100k</th>\n",
       "      <th>cvd_death_rate</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Tests/ 1M pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191215</td>\n",
       "      <td>1.203150</td>\n",
       "      <td>0.865347</td>\n",
       "      <td>-0.415850</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>-0.576234</td>\n",
       "      <td>1.790465</td>\n",
       "      <td>3.962344</td>\n",
       "      <td>1.091062</td>\n",
       "      <td>2.754711</td>\n",
       "      <td>0.907303</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>-0.023778</td>\n",
       "      <td>-0.742498</td>\n",
       "      <td>2.019030</td>\n",
       "      <td>0.671197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.534257</td>\n",
       "      <td>1.203150</td>\n",
       "      <td>1.175225</td>\n",
       "      <td>-1.051761</td>\n",
       "      <td>1.120574</td>\n",
       "      <td>-0.576234</td>\n",
       "      <td>0.119199</td>\n",
       "      <td>1.100189</td>\n",
       "      <td>1.288382</td>\n",
       "      <td>2.073479</td>\n",
       "      <td>0.959909</td>\n",
       "      <td>-0.893201</td>\n",
       "      <td>-0.114475</td>\n",
       "      <td>-0.986940</td>\n",
       "      <td>1.225108</td>\n",
       "      <td>0.499712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.225284</td>\n",
       "      <td>0.961579</td>\n",
       "      <td>1.628975</td>\n",
       "      <td>-1.227652</td>\n",
       "      <td>1.316638</td>\n",
       "      <td>-0.581976</td>\n",
       "      <td>0.171357</td>\n",
       "      <td>0.643761</td>\n",
       "      <td>0.959516</td>\n",
       "      <td>2.566817</td>\n",
       "      <td>0.362907</td>\n",
       "      <td>-0.750738</td>\n",
       "      <td>0.137898</td>\n",
       "      <td>-1.062809</td>\n",
       "      <td>1.013720</td>\n",
       "      <td>1.474719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.534257</td>\n",
       "      <td>1.013811</td>\n",
       "      <td>1.219493</td>\n",
       "      <td>-0.997641</td>\n",
       "      <td>1.330643</td>\n",
       "      <td>-0.570492</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>1.333646</td>\n",
       "      <td>0.696423</td>\n",
       "      <td>1.106240</td>\n",
       "      <td>0.823833</td>\n",
       "      <td>-0.753587</td>\n",
       "      <td>1.242031</td>\n",
       "      <td>-1.291539</td>\n",
       "      <td>1.178186</td>\n",
       "      <td>0.306799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.765986</td>\n",
       "      <td>1.196621</td>\n",
       "      <td>1.330164</td>\n",
       "      <td>-0.984111</td>\n",
       "      <td>1.092565</td>\n",
       "      <td>-0.570492</td>\n",
       "      <td>-0.291404</td>\n",
       "      <td>1.390868</td>\n",
       "      <td>1.091062</td>\n",
       "      <td>3.347087</td>\n",
       "      <td>1.632596</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>1.107958</td>\n",
       "      <td>-1.048059</td>\n",
       "      <td>1.460354</td>\n",
       "      <td>1.621932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-1.018928</td>\n",
       "      <td>0.289098</td>\n",
       "      <td>0.201323</td>\n",
       "      <td>-0.185839</td>\n",
       "      <td>0.266293</td>\n",
       "      <td>-0.518813</td>\n",
       "      <td>-0.284746</td>\n",
       "      <td>-0.557400</td>\n",
       "      <td>-0.092856</td>\n",
       "      <td>-0.695878</td>\n",
       "      <td>-2.030720</td>\n",
       "      <td>0.930325</td>\n",
       "      <td>0.303518</td>\n",
       "      <td>-0.354086</td>\n",
       "      <td>-0.470704</td>\n",
       "      <td>-0.539635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.710330</td>\n",
       "      <td>-1.127683</td>\n",
       "      <td>-1.115658</td>\n",
       "      <td>2.560758</td>\n",
       "      <td>-1.680346</td>\n",
       "      <td>0.824832</td>\n",
       "      <td>-0.357988</td>\n",
       "      <td>-0.579536</td>\n",
       "      <td>-0.882135</td>\n",
       "      <td>-0.726423</td>\n",
       "      <td>-1.398110</td>\n",
       "      <td>-1.594119</td>\n",
       "      <td>-0.445715</td>\n",
       "      <td>0.581003</td>\n",
       "      <td>-1.022397</td>\n",
       "      <td>-0.586538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.606965</td>\n",
       "      <td>-1.734876</td>\n",
       "      <td>-1.259530</td>\n",
       "      <td>1.004804</td>\n",
       "      <td>-1.106157</td>\n",
       "      <td>1.921567</td>\n",
       "      <td>-0.208174</td>\n",
       "      <td>-0.617534</td>\n",
       "      <td>-1.868734</td>\n",
       "      <td>-0.726423</td>\n",
       "      <td>-1.925370</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>-0.997781</td>\n",
       "      <td>-0.476164</td>\n",
       "      <td>-1.050487</td>\n",
       "      <td>-0.602008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.551683</td>\n",
       "      <td>-1.636941</td>\n",
       "      <td>-1.370201</td>\n",
       "      <td>1.491885</td>\n",
       "      <td>-1.288217</td>\n",
       "      <td>1.037288</td>\n",
       "      <td>-0.355769</td>\n",
       "      <td>-0.614397</td>\n",
       "      <td>-1.408321</td>\n",
       "      <td>-0.726423</td>\n",
       "      <td>-2.101614</td>\n",
       "      <td>-0.990076</td>\n",
       "      <td>-0.603448</td>\n",
       "      <td>-0.098634</td>\n",
       "      <td>-1.087411</td>\n",
       "      <td>-0.611902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.761451</td>\n",
       "      <td>-0.944873</td>\n",
       "      <td>-1.436603</td>\n",
       "      <td>1.911316</td>\n",
       "      <td>-1.554304</td>\n",
       "      <td>1.416265</td>\n",
       "      <td>-0.360208</td>\n",
       "      <td>-0.598580</td>\n",
       "      <td>-0.947909</td>\n",
       "      <td>-0.720869</td>\n",
       "      <td>-0.877023</td>\n",
       "      <td>-0.990076</td>\n",
       "      <td>-0.327415</td>\n",
       "      <td>-0.038267</td>\n",
       "      <td>-0.937810</td>\n",
       "      <td>-0.592988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case-Fatality  Human Development Index (HDI)  \\\n",
       "0        0.191215                       1.203150   \n",
       "1        2.534257                       1.203150   \n",
       "2        2.225284                       0.961579   \n",
       "3        2.534257                       1.013811   \n",
       "4        2.765986                       1.196621   \n",
       "..            ...                            ...   \n",
       "63      -1.018928                       0.289098   \n",
       "64       1.710330                      -1.127683   \n",
       "65      -0.606965                      -1.734876   \n",
       "66       0.551683                      -1.636941   \n",
       "67      -0.761451                      -0.944873   \n",
       "\n",
       "    Population median age (years)  Adult mortality rate  \\\n",
       "0                        0.865347             -0.415850   \n",
       "1                        1.175225             -1.051761   \n",
       "2                        1.628975             -1.227652   \n",
       "3                        1.219493             -0.997641   \n",
       "4                        1.330164             -0.984111   \n",
       "..                            ...                   ...   \n",
       "63                       0.201323             -0.185839   \n",
       "64                      -1.115658              2.560758   \n",
       "65                      -1.259530              1.004804   \n",
       "66                      -1.370201              1.491885   \n",
       "67                      -1.436603              1.911316   \n",
       "\n",
       "    Life expectancy at birth (years)  \\\n",
       "0                           0.714440   \n",
       "1                           1.120574   \n",
       "2                           1.316638   \n",
       "3                           1.330643   \n",
       "4                           1.092565   \n",
       "..                               ...   \n",
       "63                          0.266293   \n",
       "64                         -1.680346   \n",
       "65                         -1.106157   \n",
       "66                         -1.288217   \n",
       "67                         -1.554304   \n",
       "\n",
       "    Mortality rate attributed to exposure to unsafe WASH services (per 100 000 population) (SDG 3.9.2)  \\\n",
       "0                                           -0.576234                                                    \n",
       "1                                           -0.576234                                                    \n",
       "2                                           -0.581976                                                    \n",
       "3                                           -0.570492                                                    \n",
       "4                                           -0.570492                                                    \n",
       "..                                                ...                                                    \n",
       "63                                          -0.518813                                                    \n",
       "64                                           0.824832                                                    \n",
       "65                                           1.921567                                                    \n",
       "66                                           1.037288                                                    \n",
       "67                                           1.416265                                                    \n",
       "\n",
       "    Population proportion over 60 (%)  \\\n",
       "0                            1.790465   \n",
       "1                            0.119199   \n",
       "2                            0.171357   \n",
       "3                            0.145833   \n",
       "4                           -0.291404   \n",
       "..                                ...   \n",
       "63                          -0.284746   \n",
       "64                          -0.357988   \n",
       "65                          -0.208174   \n",
       "66                          -0.355769   \n",
       "67                          -0.360208   \n",
       "\n",
       "    Current health expenditure (CHE) per capita in US$  \\\n",
       "0                                            3.962344    \n",
       "1                                            1.100189    \n",
       "2                                            0.643761    \n",
       "3                                            1.333646    \n",
       "4                                            1.390868    \n",
       "..                                                ...    \n",
       "63                                          -0.557400    \n",
       "64                                          -0.579536    \n",
       "65                                          -0.617534    \n",
       "66                                          -0.614397    \n",
       "67                                          -0.598580    \n",
       "\n",
       "    UHC index of service coverage (SCI)  Cases per 1M population  \\\n",
       "0                              1.091062                 2.754711   \n",
       "1                              1.288382                 2.073479   \n",
       "2                              0.959516                 2.566817   \n",
       "3                              0.696423                 1.106240   \n",
       "4                              1.091062                 3.347087   \n",
       "..                                  ...                      ...   \n",
       "63                            -0.092856                -0.695878   \n",
       "64                            -0.882135                -0.726423   \n",
       "65                            -1.868734                -0.726423   \n",
       "66                            -1.408321                -0.726423   \n",
       "67                            -0.947909                -0.720869   \n",
       "\n",
       "    Urban population (% of total population)  diabetes_prevalence  \\\n",
       "0                                   0.907303             0.961667   \n",
       "1                                   0.959909            -0.893201   \n",
       "2                                   0.362907            -0.750738   \n",
       "3                                   0.823833            -0.753587   \n",
       "4                                   1.632596            -0.890352   \n",
       "..                                       ...                  ...   \n",
       "63                                 -2.030720             0.930325   \n",
       "64                                 -1.398110            -1.594119   \n",
       "65                                 -1.925370             0.015713   \n",
       "66                                 -2.101614            -0.990076   \n",
       "67                                 -0.877023            -0.990076   \n",
       "\n",
       "    hospital_beds_per_100k  cvd_death_rate  GDP per capita  Tests/ 1M pop  \n",
       "0                -0.023778       -0.742498        2.019030       0.671197  \n",
       "1                -0.114475       -0.986940        1.225108       0.499712  \n",
       "2                 0.137898       -1.062809        1.013720       1.474719  \n",
       "3                 1.242031       -1.291539        1.178186       0.306799  \n",
       "4                 1.107958       -1.048059        1.460354       1.621932  \n",
       "..                     ...             ...             ...            ...  \n",
       "63                0.303518       -0.354086       -0.470704      -0.539635  \n",
       "64               -0.445715        0.581003       -1.022397      -0.586538  \n",
       "65               -0.997781       -0.476164       -1.050487      -0.602008  \n",
       "66               -0.603448       -0.098634       -1.087411      -0.611902  \n",
       "67               -0.327415       -0.038267       -0.937810      -0.592988  \n",
       "\n",
       "[68 rows x 16 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "raw_data = pd.read_csv('raw_data.csv')\n",
    "df = raw_data.copy()\n",
    "\n",
    "country = df[df.columns[[0]]] # save countries\n",
    "df.drop(df.columns[0], axis=1, inplace=True) # drop countries\n",
    "df[df.columns] = StandardScaler().fit_transform(df) # scale\n",
    "# df.iloc[:,0] = StandardScaler().fit_transform(df.iloc[:,0].to_numpy().reshape(-1,1)) # scale\n",
    "\n",
    "# df = df.loc[:,['Population median age (years)', 'Cases per 1M population', 'diabetes_prevalence', 'Tests/ 1M pop']]\n",
    "# df = df.iloc[:30,:]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup hyperparameters\n",
    "# hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 10),\n",
    "#           'alpha1': 3.0, 'beta1': 1.0,\n",
    "#           'alpha2': 3.0, 'beta2': 1.0,\n",
    "#           'alpha3': 1.0, 'c': 1.0,\n",
    "#           'alpha_obs': 3.0, 'beta_obs': 1.0}\n",
    "\n",
    "hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 2),\n",
    "          'alpha1': 0.26872577050471647, \n",
    "          'alpha2': 4.818866884657901, \n",
    "          'alpha3': 6.812836016637205, \n",
    "          'alpha_obs': 49.093191654133754, \n",
    "          'beta1': 1.2942745182532156, \n",
    "          'beta2': 0.21267247881371867, \n",
    "          'beta_obs': 3.3406960438157594, \n",
    "          'c': 2.751017838090896}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    assert numpyro.__version__.startswith('0.2.4')\n",
    "    parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "#     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "#     parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "#     parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "#     parser.add_argument(\"--num-data\", nargs='?', default=100, type=int)\n",
    "#     parser.add_argument(\"--num-dimensions\", nargs='?', default=20, type=int)\n",
    "#     parser.add_argument(\"--active-dimensions\", nargs='?', default=3, type=int)\n",
    "#     parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "    \n",
    "    parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=5000, type=int)\n",
    "    parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "    parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "    parser.add_argument(\"--num-data\", nargs='?', default=68, type=int)\n",
    "    parser.add_argument(\"--num-dimensions\", nargs='?', default=16, type=int)\n",
    "    parser.add_argument(\"--active-dimensions\", nargs='?', default=8, type=int)\n",
    "    parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "    #args = parser.parse_args() \n",
    "    args = parser.parse_args(args=[])  #68, 50, 5, 68, 16, 3, 'cpu'\n",
    "\n",
    "    numpyro.set_platform(args.device)\n",
    "    numpyro.set_host_device_count(args.num_chains)\n",
    "\n",
    "    main(args, hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus challenge (2pts extra):\n",
    "\n",
    "Find another application (e.g. from your area of research) where the kernel-interaction method is directly applicable, or could be applied with some modification. Describe the application for a statistically knowledgeable but non-expert audience (think: your peers in SML 515). In particular, explain why the sparse interaction ansatz is justified. Then demonstrate the use with a suitable data set of your own choice.\n",
    "\n",
    "**Note:** If your description is convincing, but you don't find any data or it doesn't lead to conclusive results, partial points will be awarded. Make sure that you have permission to use the data and include it as separate file in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_EURGBP_log_RealVol</th>\n",
       "      <th>AUDJPY_log_ImplVol1d</th>\n",
       "      <th>AUDJPY_log_ImplVol1d_HAR22</th>\n",
       "      <th>AUDJPY_log_ImplVol1d_HAR5</th>\n",
       "      <th>AUDJPY_log_ImplVol1m</th>\n",
       "      <th>AUDJPY_log_ImplVol1m_HAR22</th>\n",
       "      <th>AUDJPY_log_ImplVol1m_HAR5</th>\n",
       "      <th>AUDJPY_log_RealVol</th>\n",
       "      <th>AUDJPY_log_RealVol_HAR22</th>\n",
       "      <th>AUDJPY_log_RealVol_HAR5</th>\n",
       "      <th>...</th>\n",
       "      <th>USDCHF_log_RealVol_HAR5</th>\n",
       "      <th>USDJPY_log_ImplVol1d</th>\n",
       "      <th>USDJPY_log_ImplVol1d_HAR22</th>\n",
       "      <th>USDJPY_log_ImplVol1d_HAR5</th>\n",
       "      <th>USDJPY_log_ImplVol1m</th>\n",
       "      <th>USDJPY_log_ImplVol1m_HAR22</th>\n",
       "      <th>USDJPY_log_ImplVol1m_HAR5</th>\n",
       "      <th>USDJPY_log_RealVol</th>\n",
       "      <th>USDJPY_log_RealVol_HAR22</th>\n",
       "      <th>USDJPY_log_RealVol_HAR5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.382606</td>\n",
       "      <td>-1.113089</td>\n",
       "      <td>-0.857241</td>\n",
       "      <td>-1.390873</td>\n",
       "      <td>-0.807958</td>\n",
       "      <td>-0.843128</td>\n",
       "      <td>-0.941674</td>\n",
       "      <td>-1.359974</td>\n",
       "      <td>-1.043436</td>\n",
       "      <td>-1.518471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972054</td>\n",
       "      <td>-0.897603</td>\n",
       "      <td>-0.796031</td>\n",
       "      <td>-1.299435</td>\n",
       "      <td>-0.627827</td>\n",
       "      <td>-0.758041</td>\n",
       "      <td>-0.916504</td>\n",
       "      <td>-1.135485</td>\n",
       "      <td>-0.941159</td>\n",
       "      <td>-1.437344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>-0.210221</td>\n",
       "      <td>-0.984138</td>\n",
       "      <td>-0.823987</td>\n",
       "      <td>-1.193571</td>\n",
       "      <td>-0.811705</td>\n",
       "      <td>-0.825481</td>\n",
       "      <td>-0.879132</td>\n",
       "      <td>-1.123296</td>\n",
       "      <td>-1.027466</td>\n",
       "      <td>-1.416277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.663547</td>\n",
       "      <td>-0.693473</td>\n",
       "      <td>-0.756117</td>\n",
       "      <td>-1.053805</td>\n",
       "      <td>-0.762690</td>\n",
       "      <td>-0.745066</td>\n",
       "      <td>-0.825872</td>\n",
       "      <td>-0.748236</td>\n",
       "      <td>-0.907765</td>\n",
       "      <td>-1.182811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>-0.445465</td>\n",
       "      <td>-1.366099</td>\n",
       "      <td>-0.866473</td>\n",
       "      <td>-1.247583</td>\n",
       "      <td>-0.702246</td>\n",
       "      <td>-0.804847</td>\n",
       "      <td>-0.800335</td>\n",
       "      <td>-0.443139</td>\n",
       "      <td>-0.976796</td>\n",
       "      <td>-1.053005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422177</td>\n",
       "      <td>-0.933149</td>\n",
       "      <td>-0.769495</td>\n",
       "      <td>-1.000837</td>\n",
       "      <td>-0.582873</td>\n",
       "      <td>-0.729509</td>\n",
       "      <td>-0.714918</td>\n",
       "      <td>-0.071412</td>\n",
       "      <td>-0.863337</td>\n",
       "      <td>-0.786875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>-0.530039</td>\n",
       "      <td>-0.567261</td>\n",
       "      <td>-0.863042</td>\n",
       "      <td>-0.984663</td>\n",
       "      <td>-0.623899</td>\n",
       "      <td>-0.788618</td>\n",
       "      <td>-0.720086</td>\n",
       "      <td>-0.718948</td>\n",
       "      <td>-0.992457</td>\n",
       "      <td>-0.950720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443892</td>\n",
       "      <td>-0.496679</td>\n",
       "      <td>-0.773760</td>\n",
       "      <td>-0.769779</td>\n",
       "      <td>-0.656583</td>\n",
       "      <td>-0.735486</td>\n",
       "      <td>-0.646684</td>\n",
       "      <td>-0.657682</td>\n",
       "      <td>-0.868349</td>\n",
       "      <td>-0.656093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>-0.830431</td>\n",
       "      <td>-0.748562</td>\n",
       "      <td>-0.869974</td>\n",
       "      <td>-0.943429</td>\n",
       "      <td>-0.706986</td>\n",
       "      <td>-0.782303</td>\n",
       "      <td>-0.682762</td>\n",
       "      <td>-0.624565</td>\n",
       "      <td>-0.980799</td>\n",
       "      <td>-0.820193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460334</td>\n",
       "      <td>-0.699712</td>\n",
       "      <td>-0.773667</td>\n",
       "      <td>-0.715646</td>\n",
       "      <td>-0.745540</td>\n",
       "      <td>-0.742096</td>\n",
       "      <td>-0.630552</td>\n",
       "      <td>-0.902153</td>\n",
       "      <td>-0.892822</td>\n",
       "      <td>-0.649630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>1.560493</td>\n",
       "      <td>1.062543</td>\n",
       "      <td>2.012176</td>\n",
       "      <td>1.737380</td>\n",
       "      <td>1.046625</td>\n",
       "      <td>2.119660</td>\n",
       "      <td>1.871731</td>\n",
       "      <td>1.005373</td>\n",
       "      <td>1.925843</td>\n",
       "      <td>1.699374</td>\n",
       "      <td>...</td>\n",
       "      <td>1.667303</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>1.913068</td>\n",
       "      <td>1.277627</td>\n",
       "      <td>0.771120</td>\n",
       "      <td>2.000492</td>\n",
       "      <td>1.379824</td>\n",
       "      <td>0.625076</td>\n",
       "      <td>1.839538</td>\n",
       "      <td>1.211704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>1.482345</td>\n",
       "      <td>1.462119</td>\n",
       "      <td>2.088034</td>\n",
       "      <td>1.559780</td>\n",
       "      <td>1.301858</td>\n",
       "      <td>2.195838</td>\n",
       "      <td>1.684304</td>\n",
       "      <td>0.954699</td>\n",
       "      <td>1.968560</td>\n",
       "      <td>1.348760</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410642</td>\n",
       "      <td>1.150817</td>\n",
       "      <td>1.955618</td>\n",
       "      <td>1.169178</td>\n",
       "      <td>1.142795</td>\n",
       "      <td>2.056242</td>\n",
       "      <td>1.266506</td>\n",
       "      <td>0.924267</td>\n",
       "      <td>1.872261</td>\n",
       "      <td>1.122017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>1.457737</td>\n",
       "      <td>0.657827</td>\n",
       "      <td>2.114822</td>\n",
       "      <td>1.495080</td>\n",
       "      <td>1.262437</td>\n",
       "      <td>2.265042</td>\n",
       "      <td>1.543208</td>\n",
       "      <td>0.938274</td>\n",
       "      <td>2.003941</td>\n",
       "      <td>1.140850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245554</td>\n",
       "      <td>0.746574</td>\n",
       "      <td>1.982081</td>\n",
       "      <td>1.127274</td>\n",
       "      <td>1.266606</td>\n",
       "      <td>2.118647</td>\n",
       "      <td>1.228477</td>\n",
       "      <td>0.988907</td>\n",
       "      <td>1.902658</td>\n",
       "      <td>1.072154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>1.333884</td>\n",
       "      <td>1.320928</td>\n",
       "      <td>2.177116</td>\n",
       "      <td>1.355081</td>\n",
       "      <td>1.314684</td>\n",
       "      <td>2.336491</td>\n",
       "      <td>1.382576</td>\n",
       "      <td>0.618109</td>\n",
       "      <td>2.027932</td>\n",
       "      <td>0.962148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023680</td>\n",
       "      <td>1.125842</td>\n",
       "      <td>2.019867</td>\n",
       "      <td>1.064401</td>\n",
       "      <td>1.247969</td>\n",
       "      <td>2.175101</td>\n",
       "      <td>1.183351</td>\n",
       "      <td>0.935629</td>\n",
       "      <td>1.923112</td>\n",
       "      <td>0.953999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>0.986862</td>\n",
       "      <td>1.119876</td>\n",
       "      <td>2.233125</td>\n",
       "      <td>1.252145</td>\n",
       "      <td>1.050584</td>\n",
       "      <td>2.380010</td>\n",
       "      <td>1.285546</td>\n",
       "      <td>1.175029</td>\n",
       "      <td>2.033922</td>\n",
       "      <td>1.009445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884412</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>2.050862</td>\n",
       "      <td>1.043634</td>\n",
       "      <td>1.091226</td>\n",
       "      <td>2.208847</td>\n",
       "      <td>1.195282</td>\n",
       "      <td>0.975988</td>\n",
       "      <td>1.916278</td>\n",
       "      <td>0.967359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Target_EURGBP_log_RealVol  AUDJPY_log_ImplVol1d  \\\n",
       "Date                                                          \n",
       "2019-12-31                  -0.382606             -1.113089   \n",
       "2020-01-02                  -0.210221             -0.984138   \n",
       "2020-01-03                  -0.445465             -1.366099   \n",
       "2020-01-06                  -0.530039             -0.567261   \n",
       "2020-01-07                  -0.830431             -0.748562   \n",
       "...                               ...                   ...   \n",
       "2020-03-25                   1.560493              1.062543   \n",
       "2020-03-26                   1.482345              1.462119   \n",
       "2020-03-27                   1.457737              0.657827   \n",
       "2020-03-30                   1.333884              1.320928   \n",
       "2020-03-31                   0.986862              1.119876   \n",
       "\n",
       "            AUDJPY_log_ImplVol1d_HAR22  AUDJPY_log_ImplVol1d_HAR5  \\\n",
       "Date                                                                \n",
       "2019-12-31                   -0.857241                  -1.390873   \n",
       "2020-01-02                   -0.823987                  -1.193571   \n",
       "2020-01-03                   -0.866473                  -1.247583   \n",
       "2020-01-06                   -0.863042                  -0.984663   \n",
       "2020-01-07                   -0.869974                  -0.943429   \n",
       "...                                ...                        ...   \n",
       "2020-03-25                    2.012176                   1.737380   \n",
       "2020-03-26                    2.088034                   1.559780   \n",
       "2020-03-27                    2.114822                   1.495080   \n",
       "2020-03-30                    2.177116                   1.355081   \n",
       "2020-03-31                    2.233125                   1.252145   \n",
       "\n",
       "            AUDJPY_log_ImplVol1m  AUDJPY_log_ImplVol1m_HAR22  \\\n",
       "Date                                                           \n",
       "2019-12-31             -0.807958                   -0.843128   \n",
       "2020-01-02             -0.811705                   -0.825481   \n",
       "2020-01-03             -0.702246                   -0.804847   \n",
       "2020-01-06             -0.623899                   -0.788618   \n",
       "2020-01-07             -0.706986                   -0.782303   \n",
       "...                          ...                         ...   \n",
       "2020-03-25              1.046625                    2.119660   \n",
       "2020-03-26              1.301858                    2.195838   \n",
       "2020-03-27              1.262437                    2.265042   \n",
       "2020-03-30              1.314684                    2.336491   \n",
       "2020-03-31              1.050584                    2.380010   \n",
       "\n",
       "            AUDJPY_log_ImplVol1m_HAR5  AUDJPY_log_RealVol  \\\n",
       "Date                                                        \n",
       "2019-12-31                  -0.941674           -1.359974   \n",
       "2020-01-02                  -0.879132           -1.123296   \n",
       "2020-01-03                  -0.800335           -0.443139   \n",
       "2020-01-06                  -0.720086           -0.718948   \n",
       "2020-01-07                  -0.682762           -0.624565   \n",
       "...                               ...                 ...   \n",
       "2020-03-25                   1.871731            1.005373   \n",
       "2020-03-26                   1.684304            0.954699   \n",
       "2020-03-27                   1.543208            0.938274   \n",
       "2020-03-30                   1.382576            0.618109   \n",
       "2020-03-31                   1.285546            1.175029   \n",
       "\n",
       "            AUDJPY_log_RealVol_HAR22  AUDJPY_log_RealVol_HAR5  ...  \\\n",
       "Date                                                           ...   \n",
       "2019-12-31                 -1.043436                -1.518471  ...   \n",
       "2020-01-02                 -1.027466                -1.416277  ...   \n",
       "2020-01-03                 -0.976796                -1.053005  ...   \n",
       "2020-01-06                 -0.992457                -0.950720  ...   \n",
       "2020-01-07                 -0.980799                -0.820193  ...   \n",
       "...                              ...                      ...  ...   \n",
       "2020-03-25                  1.925843                 1.699374  ...   \n",
       "2020-03-26                  1.968560                 1.348760  ...   \n",
       "2020-03-27                  2.003941                 1.140850  ...   \n",
       "2020-03-30                  2.027932                 0.962148  ...   \n",
       "2020-03-31                  2.033922                 1.009445  ...   \n",
       "\n",
       "            USDCHF_log_RealVol_HAR5  USDJPY_log_ImplVol1d  \\\n",
       "Date                                                        \n",
       "2019-12-31                -0.972054             -0.897603   \n",
       "2020-01-02                -0.663547             -0.693473   \n",
       "2020-01-03                -0.422177             -0.933149   \n",
       "2020-01-06                -0.443892             -0.496679   \n",
       "2020-01-07                -0.460334             -0.699712   \n",
       "...                             ...                   ...   \n",
       "2020-03-25                 1.667303              0.810802   \n",
       "2020-03-26                 1.410642              1.150817   \n",
       "2020-03-27                 1.245554              0.746574   \n",
       "2020-03-30                 1.023680              1.125842   \n",
       "2020-03-31                 0.884412              0.978164   \n",
       "\n",
       "            USDJPY_log_ImplVol1d_HAR22  USDJPY_log_ImplVol1d_HAR5  \\\n",
       "Date                                                                \n",
       "2019-12-31                   -0.796031                  -1.299435   \n",
       "2020-01-02                   -0.756117                  -1.053805   \n",
       "2020-01-03                   -0.769495                  -1.000837   \n",
       "2020-01-06                   -0.773760                  -0.769779   \n",
       "2020-01-07                   -0.773667                  -0.715646   \n",
       "...                                ...                        ...   \n",
       "2020-03-25                    1.913068                   1.277627   \n",
       "2020-03-26                    1.955618                   1.169178   \n",
       "2020-03-27                    1.982081                   1.127274   \n",
       "2020-03-30                    2.019867                   1.064401   \n",
       "2020-03-31                    2.050862                   1.043634   \n",
       "\n",
       "            USDJPY_log_ImplVol1m  USDJPY_log_ImplVol1m_HAR22  \\\n",
       "Date                                                           \n",
       "2019-12-31             -0.627827                   -0.758041   \n",
       "2020-01-02             -0.762690                   -0.745066   \n",
       "2020-01-03             -0.582873                   -0.729509   \n",
       "2020-01-06             -0.656583                   -0.735486   \n",
       "2020-01-07             -0.745540                   -0.742096   \n",
       "...                          ...                         ...   \n",
       "2020-03-25              0.771120                    2.000492   \n",
       "2020-03-26              1.142795                    2.056242   \n",
       "2020-03-27              1.266606                    2.118647   \n",
       "2020-03-30              1.247969                    2.175101   \n",
       "2020-03-31              1.091226                    2.208847   \n",
       "\n",
       "            USDJPY_log_ImplVol1m_HAR5  USDJPY_log_RealVol  \\\n",
       "Date                                                        \n",
       "2019-12-31                  -0.916504           -1.135485   \n",
       "2020-01-02                  -0.825872           -0.748236   \n",
       "2020-01-03                  -0.714918           -0.071412   \n",
       "2020-01-06                  -0.646684           -0.657682   \n",
       "2020-01-07                  -0.630552           -0.902153   \n",
       "...                               ...                 ...   \n",
       "2020-03-25                   1.379824            0.625076   \n",
       "2020-03-26                   1.266506            0.924267   \n",
       "2020-03-27                   1.228477            0.988907   \n",
       "2020-03-30                   1.183351            0.935629   \n",
       "2020-03-31                   1.195282            0.975988   \n",
       "\n",
       "            USDJPY_log_RealVol_HAR22  USDJPY_log_RealVol_HAR5  \n",
       "Date                                                           \n",
       "2019-12-31                 -0.941159                -1.437344  \n",
       "2020-01-02                 -0.907765                -1.182811  \n",
       "2020-01-03                 -0.863337                -0.786875  \n",
       "2020-01-06                 -0.868349                -0.656093  \n",
       "2020-01-07                 -0.892822                -0.649630  \n",
       "...                              ...                      ...  \n",
       "2020-03-25                  1.839538                 1.211704  \n",
       "2020-03-26                  1.872261                 1.122017  \n",
       "2020-03-27                  1.902658                 1.072154  \n",
       "2020-03-30                  1.923112                 0.953999  \n",
       "2020-03-31                  1.916278                 0.967359  \n",
       "\n",
       "[63 rows x 145 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as onp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fxdata3 = pd.read_csv('fxdata3.csv')\n",
    "# fxdata4 = pd.read_csv('fxdata4.csv')\n",
    "# fxdata10 = pd.read_csv('fxdata10.csv')\n",
    "fxdata5 = pd.read_csv('fxdata5.csv', header=0)\n",
    "\n",
    "df = fxdata5.copy()\n",
    "df = df.iloc[-64:,:]\n",
    "drop_cols = list(df.columns[df.columns.str.contains('Dummy')])\n",
    "drop_cols = drop_cols + list(df.columns[df.columns.str.contains('LogReturn')])\n",
    "drop_cols = drop_cols + list(df.columns[df.columns.str.contains('Spot')])\n",
    "# drop_cols = drop_cols + list(df.columns[df.columns.str.contains('HAR')])\n",
    "df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "target_col = 'EURGBP_log_RealVol'\n",
    "df['Target_' + target_col] = df[target_col].shift(1).copy()\n",
    "cols = df.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('Target_' + target_col)))\n",
    "df = df[cols].set_index('Date').dropna()\n",
    "df[df.columns] = StandardScaler().fit_transform(df) # scale\n",
    "\n",
    "list(df.columns)\n",
    "\n",
    "df #.iloc[:,41] #89] 62]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 10),\n",
    "#           'alpha1': 3.0, 'beta1': 1.0,\n",
    "#           'alpha2': 3.0, 'beta2': 1.0,\n",
    "#           'alpha3': 1.0, 'c': 1.0,\n",
    "#           'alpha_obs': 50.0, 'beta_obs': 1.0}\n",
    "\n",
    "hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 10),\n",
    "          'alpha1': 0.26872577050471647, \n",
    "          'alpha2': 4.818866884657901, \n",
    "          'alpha3': 6.812836016637205, \n",
    "          'alpha_obs': 49.093191654133754, \n",
    "          'beta1': 1.2942745182532156, \n",
    "          'beta2': 0.21267247881371867, \n",
    "          'beta_obs': 3.3406960438157594, \n",
    "          'c': 2.751017838090896}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'expected_sparsity': max(1.0,args.num_dimensions // 10),\n",
    "#           'alpha1': 0.40097142738801805, \n",
    "#           'alpha2': 0.47483035520083294, \n",
    "#           'alpha3': 19.09608142822879, \n",
    "#           'alpha_obs': 0.9711468316345567, \n",
    "#           'beta1': 1.2402045085927398, \n",
    "#           'beta2': 0.332604268922102, \n",
    "#           'beta_obs': 0.24564582519281306, \n",
    "#           'c': 29.7980082293205}\n",
    "\n",
    "param_grid = {'expected_sparsity': 15.0, #max(1.0, args.num_dimensions // 10),\n",
    "              'alpha1': [0.5]+list(np.arange(5,10,5)), #list(np.arange(0.5,2,0.5)), \n",
    "              'alpha2': [0.5]+list(np.arange(5,10,5)), #list(np.arange(0.5,2,0.5)), \n",
    "              'alpha3': list(np.arange(10,21,5)), \n",
    "              'alpha_obs': [0.5]+list(np.arange(5,10,5)), #list(np.arange(0.5,2,0.5)), \n",
    "              'beta1': [0.5]+list(np.arange(5,10,5)), #list(np.arange(0.5,2,0.5)), \n",
    "              'beta2': [0.5]+list(np.arange(5,10,5)), #list(np.arange(0.5,2,0.5)), \n",
    "              'beta_obs': [0.5]+list(np.arange(5,10,5)), #list(np.arange(0.5,2,0.5)), \n",
    "              'c': [0.5]+list(np.arange(5,10,5))} #list(np.arange(0.5,2,0.5))}\n",
    "\n",
    "n_params = len(param_grid)\n",
    "param_names = [_.lower() for _ in list(param_grid.keys())]\n",
    "param_values = list(param_grid.values())\n",
    "mdls = pd.DataFrame(onp.stack(onp.meshgrid(*param_values)).T.reshape(-1,n_params), columns=param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_sparsity</th>\n",
       "      <th>alpha1</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>alpha3</th>\n",
       "      <th>alpha_obs</th>\n",
       "      <th>beta1</th>\n",
       "      <th>beta2</th>\n",
       "      <th>beta_obs</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     expected_sparsity  alpha1  alpha2  alpha3  alpha_obs  beta1  beta2  \\\n",
       "0                 15.0     0.5     0.5    10.0        0.5    0.5    0.5   \n",
       "1                 15.0     5.0     0.5    10.0        0.5    0.5    0.5   \n",
       "2                 15.0     0.5     5.0    10.0        0.5    0.5    0.5   \n",
       "3                 15.0     5.0     5.0    10.0        0.5    0.5    0.5   \n",
       "4                 15.0     0.5     0.5    15.0        0.5    0.5    0.5   \n",
       "..                 ...     ...     ...     ...        ...    ...    ...   \n",
       "379               15.0     5.0     5.0    15.0        5.0    5.0    5.0   \n",
       "380               15.0     0.5     0.5    20.0        5.0    5.0    5.0   \n",
       "381               15.0     5.0     0.5    20.0        5.0    5.0    5.0   \n",
       "382               15.0     0.5     5.0    20.0        5.0    5.0    5.0   \n",
       "383               15.0     5.0     5.0    20.0        5.0    5.0    5.0   \n",
       "\n",
       "     beta_obs    c  \n",
       "0         0.5  0.5  \n",
       "1         0.5  0.5  \n",
       "2         0.5  0.5  \n",
       "3         0.5  0.5  \n",
       "4         0.5  0.5  \n",
       "..        ...  ...  \n",
       "379       5.0  5.0  \n",
       "380       5.0  5.0  \n",
       "381       5.0  5.0  \n",
       "382       5.0  5.0  \n",
       "383       5.0  5.0  \n",
       "\n",
       "[384 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 1500/1500 [00:26<00:00, 56.04it/s, 15 steps of size 2.01e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    297.53      1.01\n",
      "  lambda[0]      2.47      6.47      0.97      0.01      5.13    775.84      1.00\n",
      "  lambda[1]      3.84     27.39      0.95      0.00      5.24    421.67      1.00\n",
      "  lambda[2]      3.03      7.66      1.00      0.01      6.48    627.94      1.00\n",
      "  lambda[3]      3.13      9.19      0.97      0.00      6.34    595.61      1.00\n",
      "  lambda[4]      2.44      6.81      0.99      0.00      5.01    976.31      1.00\n",
      "  lambda[5]      3.82     14.13      1.02      0.00      7.07    698.25      1.00\n",
      "  lambda[6]      3.20     13.02      0.98      0.00      5.76    658.33      1.00\n",
      "  lambda[7]      3.02      9.79      0.94      0.00      6.05    855.79      1.00\n",
      "  lambda[8]      3.08      8.45      1.04      0.00      6.43    596.92      1.00\n",
      "  lambda[9]      2.46      5.34      1.03      0.00      5.10    785.96      1.00\n",
      " lambda[10]      3.05      9.42      0.95      0.00      5.92    737.64      1.00\n",
      " lambda[11]      2.41      5.91      0.93      0.00      5.03    713.23      1.00\n",
      " lambda[12]      4.92     16.98      1.00      0.00      8.44    461.63      1.01\n",
      " lambda[13]      2.72      8.63      1.03      0.00      4.98    830.07      1.00\n",
      " lambda[14]      3.20     10.76      1.05      0.00      5.65    872.30      1.00\n",
      " lambda[15]      2.32      5.57      0.95      0.00      4.71    811.98      1.00\n",
      " lambda[16]      3.83     21.47      0.98      0.00      6.37    912.94      1.00\n",
      " lambda[17]      2.86      7.08      1.00      0.00      6.00    566.47      1.00\n",
      " lambda[18]      3.10      8.42      0.95      0.00      6.18    642.93      1.00\n",
      " lambda[19]      2.87      8.31      1.05      0.00      6.07    813.73      1.00\n",
      " lambda[20]      3.37     10.74      0.99      0.00      6.80    851.20      1.00\n",
      " lambda[21]      2.69      5.76      1.05      0.01      6.36    366.81      1.00\n",
      " lambda[22]      2.88      9.17      0.98      0.00      5.97    648.34      1.00\n",
      " lambda[23]      3.83     28.38      0.95      0.00      5.78    893.75      1.00\n",
      " lambda[24]      3.58     14.21      1.00      0.00      5.57    751.09      1.00\n",
      " lambda[25]      2.89     10.05      0.93      0.00      5.73    310.30      1.00\n",
      " lambda[26]      3.17     11.49      1.03      0.00      5.94    599.63      1.00\n",
      " lambda[27]      2.91     10.81      0.96      0.00      5.54    654.68      1.00\n",
      " lambda[28]      2.82      8.65      1.00      0.01      5.39    694.75      1.00\n",
      " lambda[29]      3.26     11.06      0.92      0.00      6.35    862.23      1.01\n",
      " lambda[30]      3.92     12.86      1.02      0.00      7.27    715.95      1.00\n",
      " lambda[31]      3.28     11.88      0.99      0.00      5.78    665.58      1.00\n",
      " lambda[32]      3.66     14.32      1.07      0.00      6.46    856.99      1.00\n",
      " lambda[33]      3.14      7.91      1.01      0.00      7.05    685.40      1.00\n",
      " lambda[34]      3.21      9.04      0.98      0.00      6.33    563.35      1.00\n",
      " lambda[35]      3.02      8.24      1.03      0.01      5.85    772.23      1.00\n",
      " lambda[36]      3.84     15.50      1.03      0.01      6.91    625.82      1.00\n",
      " lambda[37]      3.24      8.66      1.05      0.00      6.59    755.32      1.00\n",
      " lambda[38]      3.52     21.12      0.99      0.01      5.87    987.05      1.00\n",
      " lambda[39]      3.30     13.81      0.97      0.01      5.92    895.07      1.00\n",
      " lambda[40]      4.15     17.42      0.92      0.00      6.70    695.20      1.00\n",
      " lambda[41]     33.47    364.20      1.04      0.00     11.55    442.72      1.00\n",
      " lambda[42]      2.79      8.88      0.92      0.00      4.86    710.84      1.00\n",
      " lambda[43]      3.94     20.46      1.00      0.00      6.18    946.29      1.00\n",
      " lambda[44]      2.99      9.32      0.99      0.00      6.09    925.83      1.00\n",
      " lambda[45]      2.53      8.49      0.97      0.00      4.80    755.61      1.00\n",
      " lambda[46]      2.84     10.58      0.95      0.00      4.55    865.22      1.00\n",
      " lambda[47]      2.48      5.24      0.97      0.01      5.51    676.58      1.00\n",
      " lambda[48]      2.62      5.69      0.93      0.00      6.40    880.76      1.00\n",
      " lambda[49]      3.24     11.27      0.97      0.00      5.99    841.87      1.00\n",
      " lambda[50]      3.55     15.28      0.95      0.00      5.47    567.67      1.00\n",
      " lambda[51]      3.78     11.30      1.02      0.00      6.35    782.18      1.00\n",
      " lambda[52]      2.59      6.78      0.99      0.00      4.93   1049.58      1.00\n",
      " lambda[53]      2.93      9.14      0.99      0.00      5.52    565.79      1.00\n",
      " lambda[54]      2.06      3.92      0.99      0.01      4.54    736.32      1.00\n",
      " lambda[55]      3.47     19.91      0.85      0.00      5.31    549.35      1.00\n",
      " lambda[56]      2.94      8.75      0.99      0.00      5.55    853.62      1.00\n",
      " lambda[57]      5.42     16.02      1.03      0.00     10.69    360.85      1.00\n",
      " lambda[58]      2.74      8.85      0.92      0.00      5.31    718.35      1.00\n",
      " lambda[59]      3.89     17.98      1.06      0.00      6.44    507.60      1.00\n",
      " lambda[60]      3.08      9.60      1.05      0.00      5.94    726.29      1.00\n",
      " lambda[61]      2.95      9.49      1.01      0.01      5.47    912.67      1.00\n",
      " lambda[62]   4045.18  75890.91    160.45      0.00   1290.44    564.41      1.00\n",
      " lambda[63]      2.73      6.13      0.93      0.00      6.47    744.60      1.00\n",
      " lambda[64]      2.52      5.23      0.96      0.00      5.70    879.75      1.00\n",
      " lambda[65]      3.03      9.75      1.00      0.00      5.79    752.42      1.00\n",
      " lambda[66]      2.89      7.23      0.91      0.00      6.00    815.44      1.00\n",
      " lambda[67]      2.52      6.88      0.95      0.00      5.34    766.31      1.00\n",
      " lambda[68]      3.70     11.27      0.98      0.00      7.81    765.27      1.00\n",
      " lambda[69]      3.59     11.24      0.93      0.00      6.52    749.12      1.00\n",
      " lambda[70]      2.89      9.21      0.96      0.00      5.91    752.19      1.00\n",
      " lambda[71]      3.52     18.79      1.00      0.01      5.92    524.62      1.00\n",
      " lambda[72]      2.38      6.20      0.93      0.00      4.90    737.82      1.00\n",
      " lambda[73]      2.88      7.48      0.96      0.00      5.67    679.76      1.01\n",
      " lambda[74]      3.13     16.31      0.98      0.01      5.51    947.80      1.00\n",
      " lambda[75]      4.34     19.31      1.04      0.00      8.23    656.19      1.00\n",
      " lambda[76]      2.49      5.14      0.98      0.00      5.58    710.24      1.00\n",
      " lambda[77]      6.48     36.99      1.02      0.00      7.83    448.54      1.00\n",
      " lambda[78]      2.72      5.88      0.99      0.00      6.02    398.25      1.00\n",
      " lambda[79]      2.60      8.66      0.91      0.00      4.63    781.95      1.00\n",
      " lambda[80]      3.52     10.63      1.06      0.00      6.61    623.22      1.00\n",
      " lambda[81]      2.47      5.40      1.00      0.00      5.42    928.69      1.00\n",
      " lambda[82]      2.39      6.66      0.90      0.00      4.49    732.75      1.00\n",
      " lambda[83]      3.00      8.46      1.04      0.00      5.96    862.12      1.00\n",
      " lambda[84]      4.09     24.34      1.05      0.00      5.85    718.29      1.00\n",
      " lambda[85]      2.67      7.11      0.95      0.00      5.12    511.95      1.00\n",
      " lambda[86]      4.08     21.96      0.97      0.00      6.62    857.23      1.00\n",
      " lambda[87]      2.91      8.16      1.03      0.00      5.52    632.17      1.00\n",
      " lambda[88]      3.04      7.66      1.02      0.00      5.75    602.63      1.00\n",
      " lambda[89]    126.22   2186.69      1.26      0.00     78.42    719.15      1.00\n",
      " lambda[90]      2.10      4.92      0.93      0.00      4.21    978.02      1.00\n",
      " lambda[91]      2.72      8.82      1.01      0.01      5.08    785.53      1.00\n",
      " lambda[92]      2.77      7.39      0.94      0.00      5.25    790.56      1.00\n",
      " lambda[93]      2.64      7.97      0.98      0.00      4.94    556.31      1.00\n",
      " lambda[94]      3.69     11.97      1.00      0.01      6.68    725.96      1.00\n",
      " lambda[95]      4.83     26.16      0.94      0.00      6.30    805.11      1.00\n",
      " lambda[96]      3.03      8.14      0.97      0.00      6.15    472.02      1.00\n",
      " lambda[97]      3.04      7.61      1.00      0.00      6.20    561.89      1.00\n",
      " lambda[98]      4.90     26.04      1.04      0.00      5.78    692.93      1.00\n",
      " lambda[99]      2.54      5.33      0.98      0.01      5.81    800.22      1.00\n",
      "lambda[100]      3.04     11.65      0.95      0.00      5.54    905.51      1.00\n",
      "lambda[101]      3.16      8.53      0.99      0.00      5.73    514.36      1.00\n",
      "lambda[102]      3.41     13.94      0.95      0.00      6.09    469.42      1.00\n",
      "lambda[103]      2.31      4.61      0.91      0.00      5.35    761.61      1.00\n",
      "lambda[104]      3.00     11.50      0.94      0.00      4.96    943.62      1.00\n",
      "lambda[105]      3.07      8.95      1.00      0.00      5.87    596.50      1.00\n",
      "lambda[106]      2.61      8.45      0.92      0.00      5.89    923.68      1.00\n",
      "lambda[107]      5.47     52.18      1.00      0.00      5.99    938.31      1.00\n",
      "lambda[108]      2.48      6.34      0.93      0.00      5.03    899.14      1.00\n",
      "lambda[109]     12.89    281.88      1.02      0.00      6.16   1003.52      1.00\n",
      "lambda[110]      3.70     12.20      1.04      0.00      7.42    770.76      1.00\n",
      "lambda[111]      5.41     42.25      1.03      0.00      5.78    425.28      1.00\n",
      "lambda[112]      2.40      4.71      0.97      0.00      5.64    496.50      1.00\n",
      "lambda[113]      3.84     12.93      1.08      0.00      6.79    517.46      1.00\n",
      "lambda[114]      3.78     25.79      0.98      0.00      5.17   1003.95      1.00\n",
      "lambda[115]      3.56     16.89      0.99      0.00      6.11    946.42      1.00\n",
      "lambda[116]      3.18     14.25      1.00      0.01      5.24    853.94      1.00\n",
      "lambda[117]      3.27     14.54      0.89      0.00      5.09    854.85      1.00\n",
      "lambda[118]      3.32     13.27      0.92      0.00      5.99    703.03      1.00\n",
      "lambda[119]      2.87     10.23      0.91      0.00      5.57    739.65      1.00\n",
      "lambda[120]      4.95     21.81      1.04      0.00      8.55    862.94      1.00\n",
      "lambda[121]      3.51     17.55      1.05      0.00      6.25    855.81      1.00\n",
      "lambda[122]      4.35     19.74      1.02      0.00      5.75    427.36      1.00\n",
      "lambda[123]      2.66      6.30      0.99      0.00      6.41    608.59      1.01\n",
      "lambda[124]      3.35     11.77      1.06      0.01      5.83    692.04      1.00\n",
      "lambda[125]      2.73      9.24      1.00      0.01      5.17    471.38      1.00\n",
      "lambda[126]      2.59      6.97      1.00      0.00      5.40    905.65      1.00\n",
      "lambda[127]      3.35     18.68      0.96      0.00      5.35    916.22      1.00\n",
      "lambda[128]      2.76      6.44      1.02      0.00      5.13    722.66      1.00\n",
      "lambda[129]      3.36     10.54      0.94      0.00      5.65    340.88      1.00\n",
      "lambda[130]      3.21     10.71      1.01      0.00      6.28    768.24      1.01\n",
      "lambda[131]     28.00    373.72      1.04      0.00      7.23    277.99      1.00\n",
      "lambda[132]      2.90      7.00      1.08      0.00      6.24    729.15      1.00\n",
      "lambda[133]      3.14      8.60      0.93      0.00      6.06    789.66      1.00\n",
      "lambda[134]      3.12      7.79      0.97      0.00      6.75    919.58      1.00\n",
      "lambda[135]      2.91     10.26      0.93      0.00      5.17    595.06      1.00\n",
      "lambda[136]      3.25     10.28      0.93      0.00      5.49    702.78      1.00\n",
      "lambda[137]      2.98     11.29      0.98      0.01      5.90   1003.27      1.00\n",
      "lambda[138]      2.98     10.15      0.92      0.00      5.01    780.26      1.00\n",
      "lambda[139]      2.67      7.58      0.94      0.00      5.10    484.20      1.00\n",
      "lambda[140]      3.01      9.50      0.97      0.00      5.40    673.35      1.00\n",
      "lambda[141]      2.91      7.69      0.96      0.00      5.84    491.89      1.00\n",
      "lambda[142]      5.08     37.49      0.93      0.00      5.36    381.01      1.00\n",
      "lambda[143]      2.43      4.66      0.99      0.00      5.92    854.12      1.00\n",
      "        msq    311.38   3070.84      8.45      0.18    176.41    890.50      1.00\n",
      "      sigma      3.17      3.83      1.57      0.00      8.89   1249.81      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    507.21      1.00\n",
      "       xisq     18.74    120.62      1.67      0.08     18.66    510.39      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 30.918081998825073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.36e-04 +- 2.09e-02\n",
      "[dimension 02/145]  inactive:\t-5.18e-04 +- 2.39e-02\n",
      "[dimension 03/145]  inactive:\t3.13e-04 +- 2.63e-02\n",
      "[dimension 04/145]  inactive:\t4.05e-03 +- 3.22e-02\n",
      "[dimension 05/145]  inactive:\t-7.51e-04 +- 2.12e-02\n",
      "[dimension 06/145]  inactive:\t4.11e-03 +- 4.91e-02\n",
      "[dimension 07/145]  inactive:\t6.77e-04 +- 1.83e-02\n",
      "[dimension 08/145]  inactive:\t1.38e-03 +- 2.96e-02\n",
      "[dimension 09/145]  inactive:\t2.88e-04 +- 2.27e-02\n",
      "[dimension 10/145]  inactive:\t3.74e-04 +- 1.98e-02\n",
      "[dimension 11/145]  inactive:\t-5.52e-04 +- 2.75e-02\n",
      "[dimension 12/145]  inactive:\t1.06e-03 +- 2.83e-02\n",
      "[dimension 13/145]  inactive:\t6.59e-03 +- 5.17e-02\n",
      "[dimension 14/145]  inactive:\t-1.15e-03 +- 2.58e-02\n",
      "[dimension 15/145]  inactive:\t1.75e-03 +- 3.63e-02\n",
      "[dimension 16/145]  inactive:\t6.64e-04 +- 1.86e-02\n",
      "[dimension 17/145]  inactive:\t8.57e-04 +- 3.81e-02\n",
      "[dimension 18/145]  inactive:\t1.50e-04 +- 2.65e-02\n",
      "[dimension 19/145]  inactive:\t-1.60e-03 +- 1.93e-02\n",
      "[dimension 20/145]  inactive:\t-1.26e-03 +- 2.87e-02\n",
      "[dimension 21/145]  inactive:\t-2.01e-03 +- 2.71e-02\n",
      "[dimension 22/145]  inactive:\t-1.07e-04 +- 2.11e-02\n",
      "[dimension 23/145]  inactive:\t-7.57e-04 +- 2.64e-02\n",
      "[dimension 24/145]  inactive:\t1.80e-03 +- 3.11e-02\n",
      "[dimension 25/145]  inactive:\t3.20e-03 +- 2.32e-02\n",
      "[dimension 26/145]  inactive:\t-5.04e-04 +- 2.92e-02\n",
      "[dimension 27/145]  inactive:\t1.10e-03 +- 2.49e-02\n",
      "[dimension 28/145]  inactive:\t1.03e-03 +- 2.19e-02\n",
      "[dimension 29/145]  inactive:\t1.29e-04 +- 2.69e-02\n",
      "[dimension 30/145]  inactive:\t2.50e-03 +- 3.64e-02\n",
      "[dimension 31/145]  inactive:\t7.62e-03 +- 5.19e-02\n",
      "[dimension 32/145]  inactive:\t-1.11e-03 +- 2.98e-02\n",
      "[dimension 33/145]  inactive:\t4.63e-03 +- 5.18e-02\n",
      "[dimension 34/145]  inactive:\t1.29e-03 +- 2.23e-02\n",
      "[dimension 35/145]  inactive:\t1.90e-04 +- 2.49e-02\n",
      "[dimension 36/145]  inactive:\t1.07e-03 +- 2.30e-02\n",
      "[dimension 37/145]  inactive:\t5.76e-03 +- 3.49e-02\n",
      "[dimension 38/145]  inactive:\t-1.44e-03 +- 3.51e-02\n",
      "[dimension 39/145]  inactive:\t1.32e-03 +- 3.01e-02\n",
      "[dimension 40/145]  inactive:\t4.09e-03 +- 3.51e-02\n",
      "[dimension 41/145]  inactive:\t-1.97e-03 +- 3.12e-02\n",
      "[dimension 42/145]  inactive:\t3.18e-02 +- 1.51e-01\n",
      "[dimension 43/145]  inactive:\t3.02e-05 +- 1.98e-02\n",
      "[dimension 44/145]  inactive:\t-3.69e-04 +- 3.25e-02\n",
      "[dimension 45/145]  inactive:\t1.14e-04 +- 2.40e-02\n",
      "[dimension 46/145]  inactive:\t7.91e-04 +- 1.56e-02\n",
      "[dimension 47/145]  inactive:\t-1.81e-03 +- 3.56e-02\n",
      "[dimension 48/145]  inactive:\t1.58e-03 +- 2.48e-02\n",
      "[dimension 49/145]  inactive:\t2.72e-03 +- 2.38e-02\n",
      "[dimension 50/145]  inactive:\t-1.58e-03 +- 2.87e-02\n",
      "[dimension 51/145]  inactive:\t2.54e-03 +- 2.81e-02\n",
      "[dimension 52/145]  inactive:\t5.65e-03 +- 2.60e-02\n",
      "[dimension 53/145]  inactive:\t-8.59e-04 +- 2.16e-02\n",
      "[dimension 54/145]  inactive:\t2.89e-04 +- 1.93e-02\n",
      "[dimension 55/145]  inactive:\t5.49e-04 +- 1.60e-02\n",
      "[dimension 56/145]  inactive:\t-1.96e-03 +- 2.27e-02\n",
      "[dimension 57/145]  inactive:\t2.04e-03 +- 3.54e-02\n",
      "[dimension 58/145]  inactive:\t1.97e-02 +- 8.76e-02\n",
      "[dimension 59/145]  inactive:\t-9.78e-04 +- 2.05e-02\n",
      "[dimension 60/145]  inactive:\t3.24e-03 +- 3.92e-02\n",
      "[dimension 61/145]  inactive:\t2.83e-03 +- 2.53e-02\n",
      "[dimension 62/145]  inactive:\t-3.64e-05 +- 2.53e-02\n",
      "[dimension 63/145]  active:\t6.30e-01 +- 4.52e-01\n",
      "[dimension 64/145]  inactive:\t-3.52e-03 +- 2.86e-02\n",
      "[dimension 65/145]  inactive:\t1.99e-05 +- 2.33e-02\n",
      "[dimension 66/145]  inactive:\t7.09e-04 +- 2.31e-02\n",
      "[dimension 67/145]  inactive:\t9.73e-04 +- 2.31e-02\n",
      "[dimension 68/145]  inactive:\t-8.94e-04 +- 3.12e-02\n",
      "[dimension 69/145]  inactive:\t5.04e-03 +- 4.58e-02\n",
      "[dimension 70/145]  inactive:\t4.31e-03 +- 2.69e-02\n",
      "[dimension 71/145]  inactive:\t1.66e-03 +- 3.92e-02\n",
      "[dimension 72/145]  inactive:\t1.29e-03 +- 2.66e-02\n",
      "[dimension 73/145]  inactive:\t3.11e-04 +- 1.67e-02\n",
      "[dimension 74/145]  inactive:\t-1.36e-03 +- 2.56e-02\n",
      "[dimension 75/145]  inactive:\t1.78e-03 +- 3.38e-02\n",
      "[dimension 76/145]  inactive:\t6.33e-03 +- 4.21e-02\n",
      "[dimension 77/145]  inactive:\t-5.63e-04 +- 2.60e-02\n",
      "[dimension 78/145]  inactive:\t9.81e-03 +- 7.48e-02\n",
      "[dimension 79/145]  inactive:\t4.87e-03 +- 2.86e-02\n",
      "[dimension 80/145]  inactive:\t1.68e-04 +- 3.28e-02\n",
      "[dimension 81/145]  inactive:\t1.58e-03 +- 3.31e-02\n",
      "[dimension 82/145]  inactive:\t3.37e-04 +- 1.76e-02\n",
      "[dimension 83/145]  inactive:\t-1.20e-03 +- 1.80e-02\n",
      "[dimension 84/145]  inactive:\t-1.31e-03 +- 2.67e-02\n",
      "[dimension 85/145]  inactive:\t3.63e-03 +- 3.36e-02\n",
      "[dimension 86/145]  inactive:\t-6.13e-04 +- 2.06e-02\n",
      "[dimension 87/145]  inactive:\t2.33e-03 +- 3.94e-02\n",
      "[dimension 88/145]  inactive:\t2.45e-03 +- 2.22e-02\n",
      "[dimension 89/145]  inactive:\t-5.41e-04 +- 2.02e-02\n",
      "[dimension 90/145]  inactive:\t1.09e-01 +- 2.84e-01\n",
      "[dimension 91/145]  inactive:\t4.00e-05 +- 1.69e-02\n",
      "[dimension 92/145]  inactive:\t-9.30e-04 +- 2.25e-02\n",
      "[dimension 93/145]  inactive:\t-6.17e-04 +- 2.79e-02\n",
      "[dimension 94/145]  inactive:\t1.66e-03 +- 2.42e-02\n",
      "[dimension 95/145]  inactive:\t4.70e-05 +- 3.26e-02\n",
      "[dimension 96/145]  inactive:\t9.88e-04 +- 4.22e-02\n",
      "[dimension 97/145]  inactive:\t2.96e-03 +- 2.54e-02\n",
      "[dimension 98/145]  inactive:\t-1.51e-04 +- 2.68e-02\n",
      "[dimension 99/145]  inactive:\t5.82e-03 +- 5.45e-02\n",
      "[dimension 100/145]  inactive:\t-4.54e-04 +- 1.93e-02\n",
      "[dimension 101/145]  inactive:\t-1.84e-03 +- 1.91e-02\n",
      "[dimension 102/145]  inactive:\t2.29e-05 +- 3.04e-02\n",
      "[dimension 103/145]  inactive:\t1.62e-03 +- 2.89e-02\n",
      "[dimension 104/145]  inactive:\t-9.31e-04 +- 1.72e-02\n",
      "[dimension 105/145]  inactive:\t1.19e-03 +- 2.95e-02\n",
      "[dimension 106/145]  inactive:\t5.33e-03 +- 3.67e-02\n",
      "[dimension 107/145]  inactive:\t-7.92e-04 +- 1.77e-02\n",
      "[dimension 108/145]  inactive:\t9.39e-03 +- 7.98e-02\n",
      "[dimension 109/145]  inactive:\t-5.29e-04 +- 1.98e-02\n",
      "[dimension 110/145]  inactive:\t-5.93e-04 +- 3.71e-02\n",
      "[dimension 111/145]  inactive:\t3.70e-03 +- 4.17e-02\n",
      "[dimension 112/145]  inactive:\t6.53e-03 +- 5.97e-02\n",
      "[dimension 113/145]  inactive:\t-1.25e-03 +- 2.06e-02\n",
      "[dimension 114/145]  inactive:\t3.69e-03 +- 4.96e-02\n",
      "[dimension 115/145]  inactive:\t1.83e-03 +- 2.26e-02\n",
      "[dimension 116/145]  inactive:\t5.71e-04 +- 3.22e-02\n",
      "[dimension 117/145]  inactive:\t4.30e-03 +- 4.84e-02\n",
      "[dimension 118/145]  inactive:\t2.31e-03 +- 2.45e-02\n",
      "[dimension 119/145]  inactive:\t-1.71e-03 +- 3.02e-02\n",
      "[dimension 120/145]  inactive:\t-1.06e-04 +- 2.74e-02\n",
      "[dimension 121/145]  inactive:\t6.46e-03 +- 4.72e-02\n",
      "[dimension 122/145]  inactive:\t-2.37e-03 +- 3.40e-02\n",
      "[dimension 123/145]  inactive:\t5.82e-03 +- 6.36e-02\n",
      "[dimension 124/145]  inactive:\t-1.39e-03 +- 1.91e-02\n",
      "[dimension 125/145]  inactive:\t-1.35e-03 +- 2.75e-02\n",
      "[dimension 126/145]  inactive:\t-9.42e-05 +- 2.48e-02\n",
      "[dimension 127/145]  inactive:\t4.81e-05 +- 1.82e-02\n",
      "[dimension 128/145]  inactive:\t-4.69e-04 +- 3.26e-02\n",
      "[dimension 129/145]  inactive:\t4.12e-04 +- 2.44e-02\n",
      "[dimension 130/145]  inactive:\t2.88e-03 +- 2.71e-02\n",
      "[dimension 131/145]  inactive:\t-6.69e-04 +- 3.06e-02\n",
      "[dimension 132/145]  inactive:\t1.07e-02 +- 8.09e-02\n",
      "[dimension 133/145]  inactive:\t3.00e-03 +- 2.23e-02\n",
      "[dimension 134/145]  inactive:\t-3.07e-04 +- 3.27e-02\n",
      "[dimension 135/145]  inactive:\t1.17e-03 +- 2.81e-02\n",
      "[dimension 136/145]  inactive:\t1.08e-03 +- 1.92e-02\n",
      "[dimension 137/145]  inactive:\t5.18e-04 +- 3.87e-02\n",
      "[dimension 138/145]  inactive:\t5.62e-04 +- 2.41e-02\n",
      "[dimension 139/145]  inactive:\t1.89e-04 +- 2.49e-02\n",
      "[dimension 140/145]  inactive:\t-7.43e-04 +- 2.63e-02\n",
      "[dimension 141/145]  inactive:\t1.46e-03 +- 2.82e-02\n",
      "[dimension 142/145]  inactive:\t1.46e-03 +- 1.86e-02\n",
      "[dimension 143/145]  inactive:\t2.12e-03 +- 3.79e-02\n",
      "[dimension 144/145]  inactive:\t4.57e-04 +- 1.92e-02\n",
      "[dimension 145/145]  inactive:\t-5.45e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.92217696]\n",
      "cov_act[[0.033866]]\n",
      "Active_dimensions: [62]\n",
      "1, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:24<00:00, 60.91it/s, 15 steps of size 2.10e-01. acc. prob=0.76] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    184.39      1.00\n",
      "  lambda[0]      3.16      9.92      0.99      0.00      5.97    587.65      1.00\n",
      "  lambda[1]      4.65     41.95      0.88      0.00      5.49    468.10      1.00\n",
      "  lambda[2]      2.80      7.36      0.99      0.00      5.84    646.05      1.00\n",
      "  lambda[3]      3.44     13.14      1.04      0.01      6.67    795.73      1.00\n",
      "  lambda[4]      2.81      6.64      1.02      0.00      6.52    593.24      1.00\n",
      "  lambda[5]      7.06     63.75      1.06      0.00      6.54    565.09      1.00\n",
      "  lambda[6]      3.28      7.40      1.07      0.00      7.03    377.89      1.00\n",
      "  lambda[7]      2.64      7.12      0.94      0.00      5.34    523.56      1.00\n",
      "  lambda[8]      2.77      6.47      0.98      0.00      5.65    579.88      1.00\n",
      "  lambda[9]      2.71      6.45      1.10      0.00      5.44    575.88      1.00\n",
      " lambda[10]      3.24     10.55      0.98      0.00      5.74    415.99      1.00\n",
      " lambda[11]      2.68      8.16      0.95      0.00      5.18    565.52      1.00\n",
      " lambda[12]      8.64     53.94      1.02      0.00      8.16    425.48      1.00\n",
      " lambda[13]      2.30      6.55      0.88      0.00      4.45    502.91      1.00\n",
      " lambda[14]      7.90    115.02      0.97      0.00      5.93    568.04      1.00\n",
      " lambda[15]      3.23      7.96      1.08      0.00      6.37    574.04      1.00\n",
      " lambda[16]      3.99     39.37      0.96      0.00      5.66    588.53      1.00\n",
      " lambda[17]     59.07   1728.61      1.05      0.00      6.10    955.75      1.00\n",
      " lambda[18]      3.20     11.64      0.96      0.00      5.84    660.71      1.00\n",
      " lambda[19]      2.93      7.33      1.07      0.00      6.67    693.49      1.00\n",
      " lambda[20]      3.40     12.78      1.00      0.01      6.31    535.96      1.00\n",
      " lambda[21]      2.92      7.10      1.01      0.00      6.35    420.76      1.00\n",
      " lambda[22]      2.54      6.21      0.99      0.01      5.21    875.79      1.00\n",
      " lambda[23]      5.85     78.32      0.99      0.00      6.15    789.75      1.00\n",
      " lambda[24]      3.23     14.55      0.95      0.00      6.10    745.37      1.00\n",
      " lambda[25]      2.47      5.67      0.99      0.01      5.51    563.33      1.00\n",
      " lambda[26]      2.98      9.91      0.98      0.00      5.13    588.68      1.00\n",
      " lambda[27]      3.26     10.70      0.92      0.00      6.31    390.88      1.00\n",
      " lambda[28]      2.82      8.25      1.03      0.01      5.18    639.76      1.00\n",
      " lambda[29]      5.04     47.41      1.01      0.00      6.41    536.93      1.00\n",
      " lambda[30]      4.07     18.23      0.96      0.00      6.71    439.50      1.00\n",
      " lambda[31]      4.33     18.19      1.07      0.00      5.56    575.36      1.00\n",
      " lambda[32]      7.63     83.90      1.00      0.00      6.31    761.38      1.00\n",
      " lambda[33]      2.59      5.37      1.02      0.00      5.59    490.30      1.01\n",
      " lambda[34]      2.70      5.98      1.02      0.00      6.16    600.50      1.00\n",
      " lambda[35]      3.47     11.00      1.01      0.00      6.85    344.73      1.00\n",
      " lambda[36]      2.70      6.52      1.05      0.00      5.90    546.39      1.00\n",
      " lambda[37]      2.86      7.77      0.96      0.00      5.73    719.80      1.00\n",
      " lambda[38]      5.82     55.88      1.06      0.00      6.06    818.87      1.00\n",
      " lambda[39]      3.88     34.87      0.91      0.00      5.38    780.74      1.00\n",
      " lambda[40]      3.89     31.59      0.97      0.00      5.28    654.79      1.00\n",
      " lambda[41]    222.40   3011.93      1.09      0.00     15.91    583.07      1.00\n",
      " lambda[42]      2.47      5.66      0.96      0.00      5.36    814.20      1.00\n",
      " lambda[43]      6.09     64.05      1.03      0.00      6.50    541.82      1.00\n",
      " lambda[44]      2.75      6.76      0.93      0.00      6.19    743.47      1.00\n",
      " lambda[45]      2.74      9.27      0.98      0.00      5.13    766.16      1.00\n",
      " lambda[46]      3.38     19.66      1.03      0.00      5.05    554.63      1.00\n",
      " lambda[47]      2.43      5.43      0.98      0.00      5.35    793.82      1.00\n",
      " lambda[48]      2.86      9.98      1.05      0.00      5.88    854.35      1.00\n",
      " lambda[49]      2.65      5.33      1.07      0.00      6.09    815.34      1.00\n",
      " lambda[50]      5.29     59.23      0.97      0.00      6.34    784.63      1.00\n",
      " lambda[51]      4.40     20.47      1.00      0.00      7.16    493.33      1.00\n",
      " lambda[52]      3.24      9.40      1.01      0.02      6.15    437.17      1.00\n",
      " lambda[53]      3.60     14.22      0.94      0.00      5.78    415.03      1.01\n",
      " lambda[54]      2.31      5.40      0.98      0.00      5.03    802.24      1.00\n",
      " lambda[55]      2.80     11.89      1.01      0.00      5.24    989.42      1.00\n",
      " lambda[56]      2.74     16.37      0.98      0.00      5.38    818.84      1.00\n",
      " lambda[57]     23.20    277.78      1.12      0.00     12.41    743.72      1.00\n",
      " lambda[58]      2.83      7.36      1.00      0.00      5.67    515.30      1.00\n",
      " lambda[59]      4.29     18.03      1.04      0.00      5.93    402.51      1.00\n",
      " lambda[60]      5.08     21.79      1.10      0.00      6.89    418.43      1.00\n",
      " lambda[61]      2.59      5.29      1.05      0.00      6.06    771.55      1.00\n",
      " lambda[62]   2669.06  18324.44    188.64      0.00   3893.84    615.81      1.00\n",
      " lambda[63]      2.87      8.51      0.87      0.00      5.39    576.05      1.00\n",
      " lambda[64]      3.61     14.47      1.04      0.00      6.39    457.21      1.00\n",
      " lambda[65]      3.27     12.76      1.04      0.00      5.73    582.45      1.00\n",
      " lambda[66]      3.30     13.86      0.93      0.00      6.37    661.43      1.00\n",
      " lambda[67]      3.03      8.50      1.08      0.00      6.27    876.66      1.00\n",
      " lambda[68]      4.40     28.41      1.02      0.00      6.20    411.84      1.00\n",
      " lambda[69]      3.12      8.18      1.04      0.00      6.24    484.69      1.00\n",
      " lambda[70]      4.23     51.89      0.95      0.00      5.70    747.67      1.00\n",
      " lambda[71]      4.47     20.66      1.12      0.00      6.78    590.99      1.00\n",
      " lambda[72]      2.44      6.65      0.94      0.01      4.85    649.76      1.00\n",
      " lambda[73]     13.72    211.87      0.93      0.00      6.69    405.83      1.00\n",
      " lambda[74]      3.81     35.71      0.98      0.01      6.23    947.58      1.00\n",
      " lambda[75]      5.43     24.63      0.96      0.00      6.66    411.47      1.01\n",
      " lambda[76]      2.50      5.30      1.04      0.00      5.06    473.15      1.00\n",
      " lambda[77]     58.83    900.15      1.05      0.00      6.48    531.26      1.00\n",
      " lambda[78]      4.64     21.60      0.98      0.00      7.35    474.85      1.00\n",
      " lambda[79]      3.72     29.58      0.91      0.00      4.47    916.13      1.00\n",
      " lambda[80]      3.83     16.08      0.97      0.00      6.24    489.90      1.00\n",
      " lambda[81]      2.49      5.63      1.01      0.00      5.47    579.29      1.00\n",
      " lambda[82]      2.29      5.21      0.92      0.00      4.87    795.89      1.00\n",
      " lambda[83]      2.74      7.92      0.91      0.00      5.15    677.42      1.00\n",
      " lambda[84]      3.53     26.04      1.00      0.00      6.15    857.40      1.00\n",
      " lambda[85]      2.80      9.64      0.88      0.00      5.57    728.22      1.00\n",
      " lambda[86]      3.22     10.30      0.94      0.00      5.20    487.06      1.00\n",
      " lambda[87]      3.39     14.89      0.92      0.00      5.71    599.70      1.00\n",
      " lambda[88]      2.50      5.03      1.02      0.00      5.29    583.02      1.00\n",
      " lambda[89]    420.40   4458.05      1.19      0.00    172.99    433.54      1.00\n",
      " lambda[90]      2.22      4.43      0.96      0.00      5.01    627.40      1.00\n",
      " lambda[91]      2.62      5.92      1.01      0.00      5.33    446.45      1.00\n",
      " lambda[92]      2.66      6.29      1.06      0.00      5.88    827.92      1.00\n",
      " lambda[93]      3.67     17.03      0.95      0.00      6.63    573.18      1.00\n",
      " lambda[94]      2.89      7.03      1.00      0.00      6.16    428.62      1.00\n",
      " lambda[95]      4.59     45.35      0.93      0.00      6.14    849.73      1.00\n",
      " lambda[96]      3.57     12.00      0.95      0.00      6.82    464.49      1.00\n",
      " lambda[97]      2.59      6.27      1.00      0.00      5.49    563.61      1.00\n",
      " lambda[98]     11.10    144.94      1.00      0.00      6.90    632.14      1.00\n",
      " lambda[99]      1.97      4.72      0.82      0.00      4.09    849.38      1.00\n",
      "lambda[100]      3.10     14.38      0.99      0.00      6.08    828.39      1.00\n",
      "lambda[101]      3.15     11.30      0.99      0.00      5.80    751.56      1.00\n",
      "lambda[102]      2.63      6.31      0.95      0.00      5.46    647.64      1.00\n",
      "lambda[103]      2.42      4.47      0.96      0.00      5.97    637.17      1.00\n",
      "lambda[104]      3.07     10.01      1.06      0.00      5.78    519.81      1.00\n",
      "lambda[105]      3.53     15.75      1.06      0.00      7.17    915.53      1.00\n",
      "lambda[106]      2.51      7.48      0.94      0.00      5.28    575.16      1.00\n",
      "lambda[107]      5.64     38.46      1.02      0.01      5.21    273.70      1.01\n",
      "lambda[108]      2.35      5.36      0.94      0.00      4.78    590.03      1.00\n",
      "lambda[109]     10.77    130.39      1.00      0.00      6.61    315.88      1.00\n",
      "lambda[110]      3.65     13.03      1.00      0.00      6.41    529.38      1.01\n",
      "lambda[111]     15.47    315.50      1.14      0.00      8.50    848.22      1.00\n",
      "lambda[112]      2.07      3.52      0.94      0.00      4.80    484.04      1.00\n",
      "lambda[113]      8.46    106.52      1.08      0.00      8.19    863.41      1.00\n",
      "lambda[114]      2.87      6.82      0.93      0.00      5.91    315.10      1.01\n",
      "lambda[115]      5.27     67.21      0.96      0.00      6.03   1001.19      1.00\n",
      "lambda[116]      3.75     13.51      0.95      0.00      6.74    569.21      1.00\n",
      "lambda[117]      2.79      9.94      0.94      0.00      4.91    721.62      1.00\n",
      "lambda[118]      2.36      8.55      0.91      0.00      5.17    880.87      1.00\n",
      "lambda[119]      4.24     17.27      0.97      0.00      6.81    647.00      1.00\n",
      "lambda[120]      3.90     18.57      0.99      0.00      6.04    947.34      1.00\n",
      "lambda[121]      3.41     13.90      0.99      0.00      5.75    536.45      1.00\n",
      "lambda[122]      3.77     22.10      0.91      0.00      5.94    539.10      1.00\n",
      "lambda[123]      2.93      8.58      1.01      0.00      5.99    488.80      1.00\n",
      "lambda[124]      2.79      9.19      0.95      0.00      5.43    592.56      1.00\n",
      "lambda[125]      3.70     17.31      1.05      0.00      6.04    394.25      1.00\n",
      "lambda[126]      2.58      8.96      0.98      0.00      5.09    728.01      1.00\n",
      "lambda[127]      2.68      7.93      0.95      0.00      5.10    725.18      1.00\n",
      "lambda[128]      2.72      7.88      0.97      0.01      5.17    450.14      1.00\n",
      "lambda[129]      2.93     10.93      0.81      0.00      5.15    858.12      1.00\n",
      "lambda[130]      3.14     10.18      1.01      0.00      5.79    609.77      1.00\n",
      "lambda[131]      4.19     36.12      1.06      0.00      5.31    650.39      1.00\n",
      "lambda[132]      2.96      8.48      0.97      0.01      6.18    616.68      1.00\n",
      "lambda[133]      2.91      9.02      1.02      0.01      5.30    564.29      1.00\n",
      "lambda[134]      3.18      8.23      0.96      0.00      7.96    613.87      1.00\n",
      "lambda[135]      1.95      3.63      0.91      0.01      4.17    825.04      1.00\n",
      "lambda[136]      2.88      8.32      0.98      0.00      5.26    419.31      1.00\n",
      "lambda[137]      3.38     12.17      1.01      0.00      5.56    602.32      1.00\n",
      "lambda[138]      3.41     12.09      0.97      0.00      6.14    583.73      1.00\n",
      "lambda[139]      2.87      6.44      1.00      0.00      5.92    408.42      1.00\n",
      "lambda[140]      3.04     10.73      1.02      0.00      6.60    802.35      1.00\n",
      "lambda[141]      4.11     21.59      0.95      0.00      6.96    358.30      1.00\n",
      "lambda[142]      3.83     15.95      1.05      0.00      6.33    697.45      1.00\n",
      "lambda[143]      2.49      5.10      0.97      0.01      6.03    668.93      1.00\n",
      "        msq      0.25      0.16      0.21      0.07      0.44    408.54      1.00\n",
      "      sigma      2.72      3.84      1.09      0.00      8.12    899.04      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    508.00      1.00\n",
      "       xisq      2.39      9.61      0.64      0.07      3.39    174.81      1.01\n",
      "\n",
      "Number of divergences: 26\n",
      "\n",
      "MCMC elapsed time: 28.269211053848267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t3.50e-04 +- 1.34e-02\n",
      "[dimension 02/145]  inactive:\t2.82e-03 +- 3.31e-02\n",
      "[dimension 03/145]  inactive:\t8.59e-04 +- 1.68e-02\n",
      "[dimension 04/145]  inactive:\t2.79e-03 +- 2.83e-02\n",
      "[dimension 05/145]  inactive:\t6.44e-04 +- 1.57e-02\n",
      "[dimension 06/145]  inactive:\t3.86e-03 +- 4.05e-02\n",
      "[dimension 07/145]  inactive:\t1.27e-03 +- 1.59e-02\n",
      "[dimension 08/145]  inactive:\t1.98e-03 +- 2.47e-02\n",
      "[dimension 09/145]  inactive:\t1.40e-03 +- 2.08e-02\n",
      "[dimension 10/145]  inactive:\t4.57e-04 +- 1.10e-02\n",
      "[dimension 11/145]  inactive:\t1.10e-03 +- 2.20e-02\n",
      "[dimension 12/145]  inactive:\t1.15e-03 +- 1.89e-02\n",
      "[dimension 13/145]  inactive:\t8.09e-03 +- 5.80e-02\n",
      "[dimension 14/145]  inactive:\t1.31e-04 +- 1.25e-02\n",
      "[dimension 15/145]  inactive:\t2.55e-03 +- 3.42e-02\n",
      "[dimension 16/145]  inactive:\t7.24e-04 +- 1.55e-02\n",
      "[dimension 17/145]  inactive:\t1.82e-03 +- 3.06e-02\n",
      "[dimension 18/145]  inactive:\t2.26e-03 +- 3.24e-02\n",
      "[dimension 19/145]  inactive:\t-5.14e-04 +- 1.31e-02\n",
      "[dimension 20/145]  inactive:\t2.23e-04 +- 1.67e-02\n",
      "[dimension 21/145]  inactive:\t1.08e-04 +- 1.54e-02\n",
      "[dimension 22/145]  inactive:\t7.24e-04 +- 1.81e-02\n",
      "[dimension 23/145]  inactive:\t5.60e-04 +- 1.70e-02\n",
      "[dimension 24/145]  inactive:\t1.56e-03 +- 2.20e-02\n",
      "[dimension 25/145]  inactive:\t2.69e-03 +- 2.06e-02\n",
      "[dimension 26/145]  inactive:\t7.82e-04 +- 1.87e-02\n",
      "[dimension 27/145]  inactive:\t1.41e-03 +- 2.05e-02\n",
      "[dimension 28/145]  inactive:\t9.97e-04 +- 1.65e-02\n",
      "[dimension 29/145]  inactive:\t2.46e-03 +- 2.98e-02\n",
      "[dimension 30/145]  inactive:\t3.44e-03 +- 3.87e-02\n",
      "[dimension 31/145]  inactive:\t5.08e-03 +- 4.06e-02\n",
      "[dimension 32/145]  inactive:\t3.08e-03 +- 3.95e-02\n",
      "[dimension 33/145]  inactive:\t5.68e-03 +- 4.78e-02\n",
      "[dimension 34/145]  inactive:\t8.34e-04 +- 1.51e-02\n",
      "[dimension 35/145]  inactive:\t7.67e-04 +- 1.47e-02\n",
      "[dimension 36/145]  inactive:\t1.50e-03 +- 1.89e-02\n",
      "[dimension 37/145]  inactive:\t2.64e-03 +- 1.99e-02\n",
      "[dimension 38/145]  inactive:\t8.66e-04 +- 2.29e-02\n",
      "[dimension 39/145]  inactive:\t4.30e-03 +- 4.58e-02\n",
      "[dimension 40/145]  inactive:\t3.64e-03 +- 3.52e-02\n",
      "[dimension 41/145]  inactive:\t1.02e-03 +- 3.05e-02\n",
      "[dimension 42/145]  inactive:\t4.83e-02 +- 1.83e-01\n",
      "[dimension 43/145]  inactive:\t6.62e-04 +- 1.35e-02\n",
      "[dimension 44/145]  inactive:\t2.84e-03 +- 3.39e-02\n",
      "[dimension 45/145]  inactive:\t1.06e-03 +- 1.89e-02\n",
      "[dimension 46/145]  inactive:\t4.41e-04 +- 1.06e-02\n",
      "[dimension 47/145]  inactive:\t1.18e-04 +- 1.71e-02\n",
      "[dimension 48/145]  inactive:\t1.11e-03 +- 1.80e-02\n",
      "[dimension 49/145]  inactive:\t1.98e-03 +- 2.39e-02\n",
      "[dimension 50/145]  inactive:\t2.21e-05 +- 1.53e-02\n",
      "[dimension 51/145]  inactive:\t3.15e-03 +- 3.30e-02\n",
      "[dimension 52/145]  inactive:\t5.05e-03 +- 2.71e-02\n",
      "[dimension 53/145]  inactive:\t3.12e-04 +- 1.71e-02\n",
      "[dimension 54/145]  inactive:\t2.56e-03 +- 2.62e-02\n",
      "[dimension 55/145]  inactive:\t5.66e-04 +- 1.24e-02\n",
      "[dimension 56/145]  inactive:\t-3.92e-04 +- 1.28e-02\n",
      "[dimension 57/145]  inactive:\t1.62e-03 +- 2.31e-02\n",
      "[dimension 58/145]  inactive:\t2.03e-02 +- 9.50e-02\n",
      "[dimension 59/145]  inactive:\t-1.62e-04 +- 1.53e-02\n",
      "[dimension 60/145]  inactive:\t4.01e-03 +- 4.10e-02\n",
      "[dimension 61/145]  inactive:\t4.38e-03 +- 2.91e-02\n",
      "[dimension 62/145]  inactive:\t5.84e-04 +- 1.59e-02\n",
      "[dimension 63/145]  active:\t5.12e-01 +- 4.49e-01\n",
      "[dimension 64/145]  inactive:\t-5.62e-04 +- 1.33e-02\n",
      "[dimension 65/145]  inactive:\t8.40e-04 +- 1.80e-02\n",
      "[dimension 66/145]  inactive:\t1.61e-03 +- 2.32e-02\n",
      "[dimension 67/145]  inactive:\t1.17e-03 +- 1.84e-02\n",
      "[dimension 68/145]  inactive:\t8.56e-04 +- 2.41e-02\n",
      "[dimension 69/145]  inactive:\t3.62e-03 +- 3.29e-02\n",
      "[dimension 70/145]  inactive:\t2.16e-03 +- 1.72e-02\n",
      "[dimension 71/145]  inactive:\t1.59e-03 +- 2.50e-02\n",
      "[dimension 72/145]  inactive:\t2.48e-03 +- 2.88e-02\n",
      "[dimension 73/145]  inactive:\t6.63e-04 +- 1.33e-02\n",
      "[dimension 74/145]  inactive:\t3.08e-03 +- 4.26e-02\n",
      "[dimension 75/145]  inactive:\t1.69e-03 +- 2.28e-02\n",
      "[dimension 76/145]  inactive:\t7.91e-03 +- 4.85e-02\n",
      "[dimension 77/145]  inactive:\t2.64e-04 +- 1.43e-02\n",
      "[dimension 78/145]  inactive:\t1.52e-02 +- 9.57e-02\n",
      "[dimension 79/145]  inactive:\t7.48e-03 +- 4.36e-02\n",
      "[dimension 80/145]  inactive:\t1.88e-03 +- 2.64e-02\n",
      "[dimension 81/145]  inactive:\t2.40e-03 +- 2.71e-02\n",
      "[dimension 82/145]  inactive:\t4.35e-04 +- 1.24e-02\n",
      "[dimension 83/145]  inactive:\t-1.55e-04 +- 1.20e-02\n",
      "[dimension 84/145]  inactive:\t2.75e-04 +- 1.84e-02\n",
      "[dimension 85/145]  inactive:\t1.97e-03 +- 2.53e-02\n",
      "[dimension 86/145]  inactive:\t1.16e-05 +- 1.32e-02\n",
      "[dimension 87/145]  inactive:\t3.56e-03 +- 3.48e-02\n",
      "[dimension 88/145]  inactive:\t1.81e-03 +- 1.71e-02\n",
      "[dimension 89/145]  inactive:\t3.33e-05 +- 1.42e-02\n",
      "[dimension 90/145]  inactive:\t1.02e-01 +- 2.66e-01\n",
      "[dimension 91/145]  inactive:\t1.26e-04 +- 1.10e-02\n",
      "[dimension 92/145]  inactive:\t-9.12e-06 +- 1.44e-02\n",
      "[dimension 93/145]  inactive:\t9.77e-05 +- 1.58e-02\n",
      "[dimension 94/145]  inactive:\t1.92e-03 +- 2.80e-02\n",
      "[dimension 95/145]  inactive:\t3.72e-04 +- 1.64e-02\n",
      "[dimension 96/145]  inactive:\t2.14e-03 +- 3.38e-02\n",
      "[dimension 97/145]  inactive:\t2.96e-03 +- 2.26e-02\n",
      "[dimension 98/145]  inactive:\t5.96e-04 +- 1.64e-02\n",
      "[dimension 99/145]  inactive:\t1.06e-02 +- 6.85e-02\n",
      "[dimension 100/145]  inactive:\t7.58e-05 +- 1.04e-02\n",
      "[dimension 101/145]  inactive:\t-7.36e-04 +- 1.38e-02\n",
      "[dimension 102/145]  inactive:\t3.40e-04 +- 1.60e-02\n",
      "[dimension 103/145]  inactive:\t1.04e-03 +- 1.73e-02\n",
      "[dimension 104/145]  inactive:\t-2.56e-04 +- 1.15e-02\n",
      "[dimension 105/145]  inactive:\t7.45e-04 +- 1.80e-02\n",
      "[dimension 106/145]  inactive:\t4.29e-03 +- 3.12e-02\n",
      "[dimension 107/145]  inactive:\t-1.47e-04 +- 1.25e-02\n",
      "[dimension 108/145]  inactive:\t7.26e-03 +- 6.47e-02\n",
      "[dimension 109/145]  inactive:\t-3.18e-05 +- 1.08e-02\n",
      "[dimension 110/145]  inactive:\t2.26e-03 +- 3.05e-02\n",
      "[dimension 111/145]  inactive:\t4.14e-03 +- 3.92e-02\n",
      "[dimension 112/145]  inactive:\t8.51e-03 +- 6.13e-02\n",
      "[dimension 113/145]  inactive:\t-7.84e-05 +- 1.18e-02\n",
      "[dimension 114/145]  inactive:\t5.38e-03 +- 5.12e-02\n",
      "[dimension 115/145]  inactive:\t1.21e-03 +- 1.51e-02\n",
      "[dimension 116/145]  inactive:\t2.26e-03 +- 3.61e-02\n",
      "[dimension 117/145]  inactive:\t5.84e-03 +- 4.72e-02\n",
      "[dimension 118/145]  inactive:\t1.49e-03 +- 1.67e-02\n",
      "[dimension 119/145]  inactive:\t2.80e-04 +- 1.77e-02\n",
      "[dimension 120/145]  inactive:\t2.01e-03 +- 3.17e-02\n",
      "[dimension 121/145]  inactive:\t2.85e-03 +- 2.87e-02\n",
      "[dimension 122/145]  inactive:\t-3.71e-05 +- 1.64e-02\n",
      "[dimension 123/145]  inactive:\t2.19e-03 +- 2.92e-02\n",
      "[dimension 124/145]  inactive:\t-4.09e-05 +- 1.31e-02\n",
      "[dimension 125/145]  inactive:\t2.45e-04 +- 2.30e-02\n",
      "[dimension 126/145]  inactive:\t1.60e-03 +- 2.62e-02\n",
      "[dimension 127/145]  inactive:\t4.60e-04 +- 1.13e-02\n",
      "[dimension 128/145]  inactive:\t7.38e-04 +- 1.84e-02\n",
      "[dimension 129/145]  inactive:\t5.68e-04 +- 1.76e-02\n",
      "[dimension 130/145]  inactive:\t2.15e-03 +- 2.19e-02\n",
      "[dimension 131/145]  inactive:\t7.27e-04 +- 2.14e-02\n",
      "[dimension 132/145]  inactive:\t4.26e-03 +- 4.03e-02\n",
      "[dimension 133/145]  inactive:\t1.77e-03 +- 1.56e-02\n",
      "[dimension 134/145]  inactive:\t8.31e-04 +- 2.36e-02\n",
      "[dimension 135/145]  inactive:\t1.26e-03 +- 2.03e-02\n",
      "[dimension 136/145]  inactive:\t7.14e-04 +- 1.24e-02\n",
      "[dimension 137/145]  inactive:\t1.08e-03 +- 2.21e-02\n",
      "[dimension 138/145]  inactive:\t9.72e-04 +- 1.68e-02\n",
      "[dimension 139/145]  inactive:\t1.54e-03 +- 2.15e-02\n",
      "[dimension 140/145]  inactive:\t5.35e-04 +- 1.62e-02\n",
      "[dimension 141/145]  inactive:\t1.16e-03 +- 1.94e-02\n",
      "[dimension 142/145]  inactive:\t2.37e-03 +- 1.88e-02\n",
      "[dimension 143/145]  inactive:\t2.07e-03 +- 2.63e-02\n",
      "[dimension 144/145]  inactive:\t1.15e-03 +- 1.66e-02\n",
      "[dimension 145/145]  inactive:\t1.70e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.93411183]\n",
      "cov_act[[0.01730612]]\n",
      "Active_dimensions: [62]\n",
      "2, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.53it/s, 31 steps of size 1.75e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    794.82      1.00\n",
      "  lambda[0]      2.24      4.75      0.94      0.00      4.63    913.65      1.00\n",
      "  lambda[1]      3.59     11.56      0.99      0.00      6.81    456.83      1.01\n",
      "  lambda[2]      2.73      7.85      0.98      0.00      5.30    738.78      1.00\n",
      "  lambda[3]      4.08     18.66      0.96      0.00      6.72    640.48      1.00\n",
      "  lambda[4]      3.11      9.12      1.06      0.00      6.04    415.40      1.00\n",
      "  lambda[5]      4.36     18.04      0.98      0.00      7.62    683.99      1.00\n",
      "  lambda[6]      2.72      7.61      0.99      0.00      6.18    888.97      1.00\n",
      "  lambda[7]      3.13      8.48      0.99      0.00      6.62    461.27      1.00\n",
      "  lambda[8]      2.49      5.84      1.00      0.00      5.46    717.62      1.00\n",
      "  lambda[9]      2.69      7.56      0.98      0.00      4.89    563.05      1.00\n",
      " lambda[10]      3.08      9.13      1.08      0.00      6.32    880.58      1.00\n",
      " lambda[11]      2.96      7.71      1.04      0.00      6.24    722.66      1.00\n",
      " lambda[12]      4.51     17.73      1.06      0.00      7.23    675.90      1.00\n",
      " lambda[13]      2.84      9.62      0.98      0.00      5.26    792.71      1.00\n",
      " lambda[14]      4.47     31.17      0.96      0.00      5.32    707.11      1.00\n",
      " lambda[15]      2.85      9.84      0.98      0.00      5.05    747.07      1.00\n",
      " lambda[16]      4.26     15.36      0.98      0.00      8.93    638.38      1.00\n",
      " lambda[17]      3.44     26.83      0.96      0.00      5.18    860.51      1.00\n",
      " lambda[18]      2.91      6.84      0.91      0.00      6.17    494.58      1.01\n",
      " lambda[19]      2.76      9.49      0.96      0.00      5.45    927.02      1.00\n",
      " lambda[20]      2.69      9.77      0.93      0.01      5.49    861.17      1.00\n",
      " lambda[21]      2.60      8.79      1.02      0.00      5.76    943.97      1.00\n",
      " lambda[22]      2.50      6.07      0.99      0.00      5.03    838.06      1.01\n",
      " lambda[23]      3.55     14.12      0.96      0.00      5.67    660.42      1.00\n",
      " lambda[24]      3.25     12.91      0.99      0.00      6.24    621.51      1.00\n",
      " lambda[25]      2.96      7.34      1.02      0.01      6.52    584.15      1.00\n",
      " lambda[26]      3.60     14.55      1.02      0.00      5.30    663.54      1.00\n",
      " lambda[27]      2.46      5.80      0.95      0.00      5.18    723.11      1.00\n",
      " lambda[28]      2.84     10.86      0.95      0.00      5.14    633.93      1.00\n",
      " lambda[29]      3.11      9.20      0.96      0.00      5.89    646.53      1.00\n",
      " lambda[30]      3.94     16.27      1.03      0.01      6.43    851.64      1.00\n",
      " lambda[31]      3.26     12.87      0.97      0.01      5.36    518.18      1.00\n",
      " lambda[32]      7.95    110.16      1.03      0.00      6.01    821.75      1.00\n",
      " lambda[33]      2.65      9.09      0.95      0.01      4.63    740.75      1.00\n",
      " lambda[34]      2.75     11.71      0.95      0.00      5.07    721.89      1.00\n",
      " lambda[35]      2.20      3.84      1.08      0.00      4.95    593.14      1.00\n",
      " lambda[36]      3.95     16.77      1.03      0.00      6.29    621.11      1.00\n",
      " lambda[37]      3.84     27.43      1.05      0.00      6.00    960.47      1.00\n",
      " lambda[38]      3.27      9.87      0.89      0.00      6.27    815.92      1.00\n",
      " lambda[39]      3.54     11.27      0.96      0.00      5.77    707.75      1.00\n",
      " lambda[40]      3.75     18.61      0.89      0.01      5.88    770.09      1.00\n",
      " lambda[41]     43.76    461.03      0.93      0.00     11.34    310.39      1.01\n",
      " lambda[42]      2.68      8.40      0.94      0.00      5.59    794.53      1.00\n",
      " lambda[43]      4.18     37.29      1.00      0.00      5.90   1016.83      1.00\n",
      " lambda[44]      2.85      6.06      1.07      0.00      6.17    488.86      1.00\n",
      " lambda[45]      2.86      8.98      0.99      0.00      4.73    670.29      1.00\n",
      " lambda[46]      3.00      9.82      1.01      0.00      5.20    819.02      1.00\n",
      " lambda[47]      2.73      7.09      0.92      0.01      5.37    660.49      1.00\n",
      " lambda[48]      2.89      9.54      0.94      0.01      5.06    763.84      1.00\n",
      " lambda[49]      2.77      8.37      0.96      0.00      5.24    784.76      1.00\n",
      " lambda[50]      2.81      6.30      0.97      0.00      6.33    690.12      1.00\n",
      " lambda[51]      6.18     99.44      1.06      0.00      6.02    989.93      1.00\n",
      " lambda[52]      2.88      8.49      0.99      0.00      5.56    500.23      1.00\n",
      " lambda[53]      2.64      7.14      0.94      0.00      5.55    803.36      1.00\n",
      " lambda[54]      2.20      4.87      0.94      0.00      4.54    738.42      1.00\n",
      " lambda[55]      3.40     14.93      0.98      0.00      5.76    919.12      1.00\n",
      " lambda[56]      2.70      7.40      0.94      0.00      5.18    645.99      1.00\n",
      " lambda[57]     24.34    548.88      1.02      0.00     10.01    862.34      1.00\n",
      " lambda[58]      2.47      5.64      0.92      0.00      5.33    658.93      1.00\n",
      " lambda[59]      4.41     28.39      1.00      0.00      6.80    938.89      1.00\n",
      " lambda[60]      3.31     15.29      0.96      0.00      5.19    915.35      1.00\n",
      " lambda[61]      2.49      5.95      1.00      0.00      5.51    819.16      1.00\n",
      " lambda[62]   5153.04 136066.19    136.82      0.01   1273.02    966.81      1.00\n",
      " lambda[63]      2.66     11.99      1.00      0.00      5.76    948.63      1.00\n",
      " lambda[64]      3.23      9.30      0.95      0.00      5.75    654.62      1.00\n",
      " lambda[65]      2.56      5.87      0.94      0.00      5.24    640.94      1.00\n",
      " lambda[66]      3.26      9.43      0.99      0.00      6.49    870.39      1.00\n",
      " lambda[67]      2.70      7.10      0.92      0.00      5.81    806.97      1.00\n",
      " lambda[68]      4.02     28.59      0.95      0.00      5.33    826.66      1.00\n",
      " lambda[69]      3.97     18.06      0.94      0.00      6.63    926.93      1.00\n",
      " lambda[70]      2.53      6.38      0.99      0.00      5.10    630.83      1.00\n",
      " lambda[71]      2.83     11.36      1.03      0.00      4.94    555.43      1.00\n",
      " lambda[72]      2.88      8.63      0.99      0.01      5.47    617.85      1.00\n",
      " lambda[73]      2.57      5.66      1.06      0.00      5.73    645.28      1.00\n",
      " lambda[74]      2.36      4.64      1.04      0.01      5.80    903.53      1.00\n",
      " lambda[75]      5.53     28.42      0.98      0.00      8.26    447.86      1.00\n",
      " lambda[76]      3.23      9.79      0.96      0.00      6.01    742.34      1.00\n",
      " lambda[77]      3.38     10.87      1.09      0.00      6.94    464.59      1.01\n",
      " lambda[78]      3.70     12.52      1.06      0.00      7.17    887.21      1.00\n",
      " lambda[79]      3.73     17.93      0.97      0.00      5.52    645.43      1.00\n",
      " lambda[80]      3.54     18.56      1.03      0.01      6.29    656.15      1.00\n",
      " lambda[81]      2.68      9.15      0.96      0.00      5.57    823.91      1.00\n",
      " lambda[82]      2.78      8.14      0.93      0.00      4.93    861.81      1.00\n",
      " lambda[83]      3.27     12.52      0.98      0.00      5.48    712.71      1.00\n",
      " lambda[84]      4.33     29.12      0.97      0.00      5.72    719.03      1.00\n",
      " lambda[85]      2.90      9.75      0.95      0.00      6.28    696.76      1.00\n",
      " lambda[86]      3.33      9.26      1.08      0.00      5.96    719.85      1.00\n",
      " lambda[87]      3.29     11.87      0.96      0.01      6.28    538.28      1.00\n",
      " lambda[88]      2.63      7.21      0.93      0.00      5.59    991.84      1.00\n",
      " lambda[89]    108.51    804.70      1.46      0.00    150.85    714.03      1.00\n",
      " lambda[90]      2.88     10.93      1.04      0.00      5.23    565.02      1.00\n",
      " lambda[91]      3.22     10.89      0.99      0.00      6.08    558.31      1.00\n",
      " lambda[92]      2.86      9.32      1.02      0.00      5.17    600.00      1.00\n",
      " lambda[93]      2.83      7.90      1.04      0.00      6.12    589.47      1.00\n",
      " lambda[94]      2.87      7.78      0.95      0.00      6.14    697.94      1.00\n",
      " lambda[95]      3.38     10.10      0.99      0.00      7.35    658.59      1.00\n",
      " lambda[96]      3.11     10.80      0.94      0.00      6.03    568.96      1.00\n",
      " lambda[97]      4.64     27.18      1.03      0.00      7.17    580.92      1.00\n",
      " lambda[98]      4.98     44.46      1.03      0.00      6.39    844.34      1.00\n",
      " lambda[99]      2.60      7.89      0.93      0.00      5.18    860.75      1.00\n",
      "lambda[100]      2.77      7.55      0.90      0.00      5.98    741.95      1.00\n",
      "lambda[101]      3.04      8.33      0.90      0.00      6.15    694.58      1.00\n",
      "lambda[102]      3.18      9.12      0.90      0.00      5.71    545.59      1.00\n",
      "lambda[103]      2.63      6.92      1.03      0.00      5.14    634.57      1.00\n",
      "lambda[104]      3.57     14.51      0.98      0.00      6.05    407.74      1.00\n",
      "lambda[105]      3.23      8.21      1.01      0.01      7.54    613.37      1.00\n",
      "lambda[106]      2.67      6.18      1.01      0.01      6.04    604.57      1.00\n",
      "lambda[107]      4.81     19.00      1.02      0.00      6.64    484.25      1.00\n",
      "lambda[108]      2.11      3.68      0.97      0.01      4.52    522.61      1.01\n",
      "lambda[109]      6.30     88.20      0.98      0.00      6.29    997.33      1.00\n",
      "lambda[110]      3.44     11.72      1.01      0.00      6.11    916.89      1.00\n",
      "lambda[111]      5.33     41.98      0.99      0.00      6.79    767.82      1.00\n",
      "lambda[112]      2.60      7.01      0.95      0.01      5.57    881.01      1.00\n",
      "lambda[113]      3.73     13.75      0.97      0.00      6.03    696.39      1.00\n",
      "lambda[114]      3.36     12.66      1.00      0.00      5.74    748.74      1.00\n",
      "lambda[115]      3.94     16.67      1.00      0.00      5.87    765.38      1.00\n",
      "lambda[116]      4.51     33.31      1.01      0.00      5.93    510.12      1.00\n",
      "lambda[117]      3.53     17.51      1.00      0.00      6.44    919.66      1.00\n",
      "lambda[118]      3.26     12.48      1.01      0.00      5.41    910.87      1.00\n",
      "lambda[119]      3.05     14.66      1.03      0.00      6.06    985.84      1.00\n",
      "lambda[120]      6.25     46.93      0.99      0.00      6.88    731.50      1.00\n",
      "lambda[121]      3.61     13.05      0.91      0.00      6.04    650.61      1.00\n",
      "lambda[122]      3.61     14.25      0.98      0.00      5.88    647.61      1.00\n",
      "lambda[123]      2.79      8.12      0.93      0.00      5.22    602.39      1.00\n",
      "lambda[124]      2.73      6.74      1.03      0.00      5.87    753.83      1.00\n",
      "lambda[125]      2.78      6.69      0.99      0.00      5.85    645.19      1.00\n",
      "lambda[126]      2.36      5.54      0.94      0.00      4.85    794.95      1.00\n",
      "lambda[127]      3.70     13.71      0.98      0.00      6.40    577.50      1.00\n",
      "lambda[128]      2.90     10.11      0.99      0.01      5.01    486.43      1.00\n",
      "lambda[129]      4.64     36.39      1.01      0.00      7.17    993.72      1.00\n",
      "lambda[130]      3.34      9.97      0.96      0.00      6.65    869.84      1.01\n",
      "lambda[131]      4.14     16.77      0.97      0.01      7.08    582.34      1.00\n",
      "lambda[132]      2.59      5.43      0.97      0.00      6.20    645.55      1.00\n",
      "lambda[133]      3.16     12.01      0.99      0.00      5.67    606.77      1.00\n",
      "lambda[134]      3.38      9.17      0.93      0.00      7.24    537.46      1.00\n",
      "lambda[135]      2.88     12.36      0.90      0.00      5.08    747.64      1.00\n",
      "lambda[136]      3.13      8.92      0.99      0.00      5.78    592.95      1.01\n",
      "lambda[137]      3.10     11.09      1.00      0.00      5.02    579.72      1.00\n",
      "lambda[138]      3.99     28.09      0.98      0.00      5.40    715.73      1.00\n",
      "lambda[139]      3.32     12.36      1.00      0.00      5.65    763.52      1.00\n",
      "lambda[140]      3.17      9.51      1.04      0.00      6.19   1006.05      1.00\n",
      "lambda[141]      2.21      4.17      0.87      0.00      5.21    793.67      1.00\n",
      "lambda[142]      4.36     17.90      0.94      0.01      6.63    835.97      1.00\n",
      "lambda[143]      2.44      6.19      0.96      0.01      4.77    520.12      1.00\n",
      "        msq    352.33   3963.02      3.68      0.17     81.11    767.55      1.00\n",
      "      sigma      3.29      4.10      1.66      0.01      8.85   1293.72      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    916.26      1.00\n",
      "       xisq      0.12      0.07      0.11      0.04      0.21   1156.11      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 32.1197292804718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.37e-04 +- 1.82e-02\n",
      "[dimension 02/145]  inactive:\t-2.40e-04 +- 2.93e-02\n",
      "[dimension 03/145]  inactive:\t4.84e-04 +- 2.52e-02\n",
      "[dimension 04/145]  inactive:\t5.07e-03 +- 3.51e-02\n",
      "[dimension 05/145]  inactive:\t-1.10e-03 +- 3.11e-02\n",
      "[dimension 06/145]  inactive:\t4.68e-03 +- 5.06e-02\n",
      "[dimension 07/145]  inactive:\t2.78e-04 +- 2.07e-02\n",
      "[dimension 08/145]  inactive:\t9.95e-04 +- 3.04e-02\n",
      "[dimension 09/145]  inactive:\t3.00e-04 +- 2.00e-02\n",
      "[dimension 10/145]  inactive:\t4.65e-04 +- 2.14e-02\n",
      "[dimension 11/145]  inactive:\t-3.38e-04 +- 2.61e-02\n",
      "[dimension 12/145]  inactive:\t1.49e-04 +- 3.05e-02\n",
      "[dimension 13/145]  inactive:\t7.50e-03 +- 5.50e-02\n",
      "[dimension 14/145]  inactive:\t-1.13e-03 +- 2.53e-02\n",
      "[dimension 15/145]  inactive:\t1.20e-03 +- 3.51e-02\n",
      "[dimension 16/145]  inactive:\t1.11e-03 +- 2.29e-02\n",
      "[dimension 17/145]  inactive:\t9.22e-05 +- 4.12e-02\n",
      "[dimension 18/145]  inactive:\t7.83e-04 +- 2.82e-02\n",
      "[dimension 19/145]  inactive:\t-2.43e-03 +- 2.30e-02\n",
      "[dimension 20/145]  inactive:\t-1.57e-03 +- 2.88e-02\n",
      "[dimension 21/145]  inactive:\t-1.50e-03 +- 2.28e-02\n",
      "[dimension 22/145]  inactive:\t-1.85e-04 +- 2.40e-02\n",
      "[dimension 23/145]  inactive:\t-3.90e-04 +- 2.41e-02\n",
      "[dimension 24/145]  inactive:\t1.54e-03 +- 2.93e-02\n",
      "[dimension 25/145]  inactive:\t3.13e-03 +- 2.36e-02\n",
      "[dimension 26/145]  inactive:\t-7.34e-04 +- 2.99e-02\n",
      "[dimension 27/145]  inactive:\t1.55e-03 +- 2.92e-02\n",
      "[dimension 28/145]  inactive:\t8.25e-04 +- 2.09e-02\n",
      "[dimension 29/145]  inactive:\t-1.35e-05 +- 2.79e-02\n",
      "[dimension 30/145]  inactive:\t1.27e-03 +- 3.14e-02\n",
      "[dimension 31/145]  inactive:\t7.68e-03 +- 5.42e-02\n",
      "[dimension 32/145]  inactive:\t-1.62e-03 +- 2.50e-02\n",
      "[dimension 33/145]  inactive:\t5.60e-03 +- 5.72e-02\n",
      "[dimension 34/145]  inactive:\t6.79e-04 +- 1.86e-02\n",
      "[dimension 35/145]  inactive:\t1.23e-03 +- 3.95e-02\n",
      "[dimension 36/145]  inactive:\t1.23e-03 +- 2.51e-02\n",
      "[dimension 37/145]  inactive:\t5.04e-03 +- 3.11e-02\n",
      "[dimension 38/145]  inactive:\t-1.66e-03 +- 3.33e-02\n",
      "[dimension 39/145]  inactive:\t1.94e-03 +- 3.60e-02\n",
      "[dimension 40/145]  inactive:\t7.28e-03 +- 5.09e-02\n",
      "[dimension 41/145]  inactive:\t-2.05e-03 +- 3.68e-02\n",
      "[dimension 42/145]  inactive:\t3.17e-02 +- 1.53e-01\n",
      "[dimension 43/145]  inactive:\t-7.91e-05 +- 2.05e-02\n",
      "[dimension 44/145]  inactive:\t-4.50e-04 +- 3.26e-02\n",
      "[dimension 45/145]  inactive:\t-2.95e-04 +- 2.54e-02\n",
      "[dimension 46/145]  inactive:\t1.32e-03 +- 1.81e-02\n",
      "[dimension 47/145]  inactive:\t-2.19e-03 +- 3.25e-02\n",
      "[dimension 48/145]  inactive:\t1.77e-03 +- 2.69e-02\n",
      "[dimension 49/145]  inactive:\t2.84e-03 +- 2.41e-02\n",
      "[dimension 50/145]  inactive:\t-1.96e-03 +- 3.12e-02\n",
      "[dimension 51/145]  inactive:\t3.30e-03 +- 3.24e-02\n",
      "[dimension 52/145]  inactive:\t5.01e-03 +- 2.43e-02\n",
      "[dimension 53/145]  inactive:\t-1.37e-03 +- 2.94e-02\n",
      "[dimension 54/145]  inactive:\t7.84e-04 +- 2.29e-02\n",
      "[dimension 55/145]  inactive:\t5.32e-04 +- 1.60e-02\n",
      "[dimension 56/145]  inactive:\t-3.20e-03 +- 3.27e-02\n",
      "[dimension 57/145]  inactive:\t1.70e-03 +- 3.47e-02\n",
      "[dimension 58/145]  inactive:\t1.93e-02 +- 8.84e-02\n",
      "[dimension 59/145]  inactive:\t-3.24e-04 +- 1.91e-02\n",
      "[dimension 60/145]  inactive:\t2.77e-03 +- 4.24e-02\n",
      "[dimension 61/145]  inactive:\t3.40e-03 +- 2.83e-02\n",
      "[dimension 62/145]  inactive:\t-6.98e-05 +- 2.57e-02\n",
      "[dimension 63/145]  active:\t6.18e-01 +- 4.50e-01\n",
      "[dimension 64/145]  inactive:\t-2.70e-03 +- 2.36e-02\n",
      "[dimension 65/145]  inactive:\t-4.12e-04 +- 2.89e-02\n",
      "[dimension 66/145]  inactive:\t2.59e-04 +- 2.30e-02\n",
      "[dimension 67/145]  inactive:\t1.73e-03 +- 3.13e-02\n",
      "[dimension 68/145]  inactive:\t-9.41e-04 +- 2.73e-02\n",
      "[dimension 69/145]  inactive:\t4.82e-03 +- 4.65e-02\n",
      "[dimension 70/145]  inactive:\t4.23e-03 +- 2.76e-02\n",
      "[dimension 71/145]  inactive:\t2.22e-04 +- 2.85e-02\n",
      "[dimension 72/145]  inactive:\t4.11e-04 +- 2.25e-02\n",
      "[dimension 73/145]  inactive:\t5.69e-04 +- 2.01e-02\n",
      "[dimension 74/145]  inactive:\t-1.00e-03 +- 2.97e-02\n",
      "[dimension 75/145]  inactive:\t4.10e-04 +- 2.19e-02\n",
      "[dimension 76/145]  inactive:\t7.29e-03 +- 4.64e-02\n",
      "[dimension 77/145]  inactive:\t-1.61e-03 +- 3.08e-02\n",
      "[dimension 78/145]  inactive:\t5.06e-03 +- 5.14e-02\n",
      "[dimension 79/145]  inactive:\t7.53e-03 +- 3.90e-02\n",
      "[dimension 80/145]  inactive:\t-2.65e-04 +- 3.99e-02\n",
      "[dimension 81/145]  inactive:\t2.59e-03 +- 3.63e-02\n",
      "[dimension 82/145]  inactive:\t3.60e-04 +- 1.76e-02\n",
      "[dimension 83/145]  inactive:\t-1.80e-03 +- 2.37e-02\n",
      "[dimension 84/145]  inactive:\t-1.67e-03 +- 3.29e-02\n",
      "[dimension 85/145]  inactive:\t3.23e-03 +- 3.59e-02\n",
      "[dimension 86/145]  inactive:\t-3.24e-04 +- 2.00e-02\n",
      "[dimension 87/145]  inactive:\t3.53e-03 +- 4.08e-02\n",
      "[dimension 88/145]  inactive:\t3.37e-03 +- 2.64e-02\n",
      "[dimension 89/145]  inactive:\t-3.48e-04 +- 2.35e-02\n",
      "[dimension 90/145]  inactive:\t1.30e-01 +- 3.13e-01\n",
      "[dimension 91/145]  inactive:\t1.27e-04 +- 1.78e-02\n",
      "[dimension 92/145]  inactive:\t-1.58e-03 +- 3.09e-02\n",
      "[dimension 93/145]  inactive:\t-6.05e-04 +- 3.35e-02\n",
      "[dimension 94/145]  inactive:\t2.66e-03 +- 3.24e-02\n",
      "[dimension 95/145]  inactive:\t-3.60e-04 +- 2.36e-02\n",
      "[dimension 96/145]  inactive:\t2.08e-03 +- 5.03e-02\n",
      "[dimension 97/145]  inactive:\t2.60e-03 +- 2.47e-02\n",
      "[dimension 98/145]  inactive:\t-1.20e-03 +- 3.02e-02\n",
      "[dimension 99/145]  inactive:\t5.13e-03 +- 5.05e-02\n",
      "[dimension 100/145]  inactive:\t-3.84e-04 +- 1.71e-02\n",
      "[dimension 101/145]  inactive:\t-2.03e-03 +- 2.24e-02\n",
      "[dimension 102/145]  inactive:\t-2.96e-04 +- 2.66e-02\n",
      "[dimension 103/145]  inactive:\t1.28e-03 +- 2.54e-02\n",
      "[dimension 104/145]  inactive:\t-7.80e-04 +- 2.09e-02\n",
      "[dimension 105/145]  inactive:\t3.06e-04 +- 3.47e-02\n",
      "[dimension 106/145]  inactive:\t5.91e-03 +- 3.69e-02\n",
      "[dimension 107/145]  inactive:\t-1.17e-03 +- 2.28e-02\n",
      "[dimension 108/145]  inactive:\t1.19e-02 +- 8.63e-02\n",
      "[dimension 109/145]  inactive:\t-3.81e-04 +- 1.83e-02\n",
      "[dimension 110/145]  inactive:\t-7.42e-04 +- 3.17e-02\n",
      "[dimension 111/145]  inactive:\t2.44e-03 +- 3.54e-02\n",
      "[dimension 112/145]  inactive:\t9.13e-03 +- 6.50e-02\n",
      "[dimension 113/145]  inactive:\t-1.45e-03 +- 2.09e-02\n",
      "[dimension 114/145]  inactive:\t1.89e-03 +- 4.00e-02\n",
      "[dimension 115/145]  inactive:\t2.22e-03 +- 2.50e-02\n",
      "[dimension 116/145]  inactive:\t2.01e-03 +- 4.87e-02\n",
      "[dimension 117/145]  inactive:\t6.91e-03 +- 5.92e-02\n",
      "[dimension 118/145]  inactive:\t2.84e-03 +- 2.44e-02\n",
      "[dimension 119/145]  inactive:\t-2.40e-03 +- 3.61e-02\n",
      "[dimension 120/145]  inactive:\t7.58e-05 +- 3.07e-02\n",
      "[dimension 121/145]  inactive:\t5.42e-03 +- 4.20e-02\n",
      "[dimension 122/145]  inactive:\t-3.25e-03 +- 4.28e-02\n",
      "[dimension 123/145]  inactive:\t2.62e-03 +- 4.34e-02\n",
      "[dimension 124/145]  inactive:\t-1.31e-03 +- 1.97e-02\n",
      "[dimension 125/145]  inactive:\t-1.67e-03 +- 3.04e-02\n",
      "[dimension 126/145]  inactive:\t-7.79e-04 +- 2.58e-02\n",
      "[dimension 127/145]  inactive:\t3.30e-05 +- 2.02e-02\n",
      "[dimension 128/145]  inactive:\t-9.58e-04 +- 3.33e-02\n",
      "[dimension 129/145]  inactive:\t3.00e-04 +- 2.57e-02\n",
      "[dimension 130/145]  inactive:\t4.37e-03 +- 3.23e-02\n",
      "[dimension 131/145]  inactive:\t-1.23e-03 +- 3.15e-02\n",
      "[dimension 132/145]  inactive:\t6.54e-03 +- 5.36e-02\n",
      "[dimension 133/145]  inactive:\t2.47e-03 +- 2.14e-02\n",
      "[dimension 134/145]  inactive:\t-4.47e-04 +- 3.23e-02\n",
      "[dimension 135/145]  inactive:\t6.40e-04 +- 3.12e-02\n",
      "[dimension 136/145]  inactive:\t9.72e-04 +- 2.06e-02\n",
      "[dimension 137/145]  inactive:\t-3.83e-04 +- 4.08e-02\n",
      "[dimension 138/145]  inactive:\t7.70e-04 +- 2.56e-02\n",
      "[dimension 139/145]  inactive:\t7.71e-04 +- 2.66e-02\n",
      "[dimension 140/145]  inactive:\t-1.67e-03 +- 3.80e-02\n",
      "[dimension 141/145]  inactive:\t1.51e-03 +- 2.96e-02\n",
      "[dimension 142/145]  inactive:\t1.22e-03 +- 1.76e-02\n",
      "[dimension 143/145]  inactive:\t2.26e-03 +- 4.35e-02\n",
      "[dimension 144/145]  inactive:\t3.92e-04 +- 2.06e-02\n",
      "[dimension 145/145]  inactive:\t-1.28e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8995608]\n",
      "cov_act[[0.03884416]]\n",
      "Active_dimensions: [62]\n",
      "3, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.59it/s, 31 steps of size 1.52e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    690.51      1.00\n",
      "  lambda[0]      2.28      8.68      0.94      0.00      4.50    952.98      1.00\n",
      "  lambda[1]      3.24     14.52      0.98      0.00      5.64    646.48      1.00\n",
      "  lambda[2]      3.66     15.82      1.05      0.00      5.86    447.94      1.00\n",
      "  lambda[3]      3.32     12.00      1.02      0.00      6.63    735.26      1.00\n",
      "  lambda[4]      2.95      7.77      1.02      0.00      6.30    698.20      1.00\n",
      "  lambda[5]      7.29     91.97      0.96      0.00      5.83    875.58      1.00\n",
      "  lambda[6]      4.16     23.59      1.00      0.00      7.13    918.59      1.00\n",
      "  lambda[7]      3.40     12.39      1.03      0.00      5.94    469.56      1.01\n",
      "  lambda[8]      2.54      5.73      0.95      0.01      5.71    985.77      1.00\n",
      "  lambda[9]      2.38      5.87      0.97      0.00      4.84    842.18      1.00\n",
      " lambda[10]      4.28     28.86      1.05      0.00      6.00    979.15      1.00\n",
      " lambda[11]      2.96      7.43      1.03      0.00      5.98    672.15      1.00\n",
      " lambda[12]      5.99     38.38      1.08      0.00      7.60    817.18      1.00\n",
      " lambda[13]      2.32      6.13      0.93      0.00      4.67    922.63      1.00\n",
      " lambda[14]      7.78     61.43      0.93      0.00      6.06    715.25      1.00\n",
      " lambda[15]      3.32     13.47      1.01      0.00      5.70    663.77      1.00\n",
      " lambda[16]      3.78     11.69      0.96      0.00      7.83    672.37      1.00\n",
      " lambda[17]      4.82     41.34      0.98      0.00      5.05    562.14      1.00\n",
      " lambda[18]      2.71      6.05      0.96      0.00      6.30    526.10      1.00\n",
      " lambda[19]      4.12     27.64      0.93      0.00      6.04    603.24      1.00\n",
      " lambda[20]      3.00      8.94      0.99      0.00      5.48    516.66      1.00\n",
      " lambda[21]      2.72      6.47      1.00      0.00      5.73    838.81      1.00\n",
      " lambda[22]      2.68      7.08      1.02      0.00      5.46    704.59      1.00\n",
      " lambda[23]      2.80      8.30      0.98      0.00      5.27    893.38      1.00\n",
      " lambda[24]      4.56     24.46      1.00      0.00      6.38    564.84      1.00\n",
      " lambda[25]      4.18     24.22      0.97      0.00      5.91    349.68      1.00\n",
      " lambda[26]      3.40     12.58      0.99      0.00      5.59    708.60      1.00\n",
      " lambda[27]      2.94      7.15      1.01      0.00      6.13    622.15      1.00\n",
      " lambda[28]      3.18     15.67      0.98      0.00      5.36    797.65      1.00\n",
      " lambda[29]      3.13      8.60      0.94      0.00      6.66    795.71      1.00\n",
      " lambda[30]      7.81     72.94      1.08      0.01      7.66    363.81      1.00\n",
      " lambda[31]      4.41     28.05      0.97      0.00      6.00    775.69      1.00\n",
      " lambda[32]      8.55     80.33      0.97      0.00      6.78    451.79      1.00\n",
      " lambda[33]      3.68     26.40      0.96      0.01      7.45   1019.15      1.00\n",
      " lambda[34]      3.00      9.46      0.99      0.00      5.82    539.96      1.00\n",
      " lambda[35]      2.38      6.10      0.99      0.00      4.86    899.58      1.00\n",
      " lambda[36]      3.37     14.89      1.00      0.00      5.80    711.21      1.00\n",
      " lambda[37]      2.75      6.69      0.97      0.00      5.38    655.67      1.00\n",
      " lambda[38]      3.52     12.24      0.97      0.00      6.51    837.66      1.00\n",
      " lambda[39]      4.34     24.43      1.03      0.00      5.86    823.97      1.00\n",
      " lambda[40]      3.66     14.79      0.90      0.00      6.36   1029.05      1.00\n",
      " lambda[41]    120.08   2884.36      0.98      0.00      9.08    986.37      1.00\n",
      " lambda[42]      3.18     19.00      0.99      0.00      5.34   1016.95      1.00\n",
      " lambda[43]      7.09    105.50      0.97      0.00      5.53   1006.76      1.00\n",
      " lambda[44]      2.88     10.55      0.93      0.00      5.51    797.66      1.00\n",
      " lambda[45]      2.27      4.53      0.96      0.00      5.19    689.14      1.00\n",
      " lambda[46]      2.40      5.74      0.99      0.01      4.95    783.10      1.00\n",
      " lambda[47]      2.69      6.02      0.98      0.00      6.10    664.75      1.00\n",
      " lambda[48]      2.70      9.14      1.00      0.00      5.24    739.90      1.00\n",
      " lambda[49]      3.03      9.35      0.98      0.00      6.00    738.60      1.00\n",
      " lambda[50]      3.48     14.51      0.97      0.00      6.31    587.40      1.00\n",
      " lambda[51]      7.40     82.79      1.06      0.00      8.27    946.88      1.00\n",
      " lambda[52]      3.10     12.41      0.88      0.00      5.46    826.83      1.00\n",
      " lambda[53]      4.44     37.09      0.92      0.00      5.93    606.69      1.00\n",
      " lambda[54]      1.91      3.82      0.93      0.00      3.96    694.17      1.00\n",
      " lambda[55]      3.37     17.09      0.95      0.00      5.49    988.64      1.00\n",
      " lambda[56]      2.87      7.13      0.99      0.00      5.27    586.19      1.00\n",
      " lambda[57]     13.29    119.43      1.07      0.00      9.81    711.32      1.00\n",
      " lambda[58]      2.46      7.81      0.94      0.00      4.47    751.76      1.00\n",
      " lambda[59]     10.34    214.05      0.99      0.00      7.29   1003.92      1.00\n",
      " lambda[60]      4.98     27.43      1.00      0.00      6.70    642.12      1.00\n",
      " lambda[61]      2.91     10.69      1.00      0.00      5.27    658.15      1.00\n",
      " lambda[62]   2534.49  36467.93    128.52      0.00   1980.14    577.43      1.00\n",
      " lambda[63]      3.98     40.90      1.00      0.00      5.18    499.95      1.00\n",
      " lambda[64]      2.84      8.20      0.96      0.01      5.26    740.41      1.00\n",
      " lambda[65]      3.91     23.81      0.97      0.00      5.57    887.67      1.00\n",
      " lambda[66]      3.57     12.82      1.00      0.00      6.93    547.58      1.00\n",
      " lambda[67]      7.66     86.85      0.93      0.00      5.07    322.54      1.00\n",
      " lambda[68]     12.01    130.95      0.97      0.00      6.02    501.61      1.00\n",
      " lambda[69]      4.88     18.56      0.99      0.00      7.61    724.74      1.00\n",
      " lambda[70]      2.76      8.73      1.00      0.00      5.01    500.57      1.00\n",
      " lambda[71]      3.01     11.76      0.98      0.00      5.01    502.28      1.00\n",
      " lambda[72]      2.65      7.91      0.99      0.00      4.93    395.74      1.00\n",
      " lambda[73]      2.93     12.23      0.98      0.00      5.65    396.37      1.00\n",
      " lambda[74]      2.31      4.58      1.03      0.01      5.32    868.34      1.00\n",
      " lambda[75]      5.60     23.61      1.01      0.00      8.43    529.91      1.00\n",
      " lambda[76]      2.92      7.95      1.02      0.00      6.04    776.27      1.00\n",
      " lambda[77]      9.48     67.93      1.12      0.00      7.79    502.42      1.00\n",
      " lambda[78]      5.58     45.28      1.12      0.00      6.21   1006.29      1.00\n",
      " lambda[79]      3.39     18.27      1.02      0.00      5.20    860.13      1.00\n",
      " lambda[80]      6.98     68.15      1.05      0.00      6.60    986.12      1.00\n",
      " lambda[81]      2.43      9.49      0.95      0.00      4.48    922.81      1.00\n",
      " lambda[82]      2.05      4.81      0.92      0.00      4.30    934.96      1.00\n",
      " lambda[83]      2.62      7.45      0.90      0.00      5.49    866.59      1.00\n",
      " lambda[84]      4.39     22.90      0.99      0.00      6.23    917.12      1.00\n",
      " lambda[85]      2.81      8.44      0.96      0.00      5.46    448.05      1.00\n",
      " lambda[86]      3.73     30.34      1.00      0.00      5.40    806.31      1.00\n",
      " lambda[87]      4.38     27.76      0.98      0.00      6.34    439.25      1.00\n",
      " lambda[88]      2.50      6.96      0.96      0.00      5.09    791.83      1.00\n",
      " lambda[89]    180.31   1436.96      1.18      0.00    141.21    453.74      1.01\n",
      " lambda[90]      2.51      5.17      0.99      0.00      5.58    812.44      1.00\n",
      " lambda[91]      2.50      7.54      0.92      0.01      4.74    826.99      1.00\n",
      " lambda[92]      3.15     17.93      1.05      0.00      4.62    549.20      1.00\n",
      " lambda[93]      3.08     11.54      1.00      0.00      4.94    524.47      1.00\n",
      " lambda[94]      3.21     13.81      0.98      0.00      5.53    623.19      1.00\n",
      " lambda[95]      4.46     23.22      1.00      0.00      6.74    520.08      1.00\n",
      " lambda[96]      4.00     20.80      0.99      0.00      5.19    528.92      1.00\n",
      " lambda[97]      5.71     64.80      0.98      0.00      6.25    504.21      1.00\n",
      " lambda[98]     18.88    274.10      0.98      0.00      6.48    720.11      1.00\n",
      " lambda[99]      2.00      4.23      0.91      0.00      4.18    781.03      1.00\n",
      "lambda[100]      4.30     27.77      0.91      0.00      6.50    959.44      1.00\n",
      "lambda[101]      2.70      7.91      0.98      0.00      5.18    578.10      1.00\n",
      "lambda[102]      3.29     14.82      0.86      0.00      5.71    535.33      1.00\n",
      "lambda[103]      2.44      5.30      0.99      0.00      5.05    512.73      1.00\n",
      "lambda[104]      3.95     27.89      0.96      0.00      5.97    673.67      1.00\n",
      "lambda[105]      4.43     23.40      1.07      0.00      7.17    814.73      1.00\n",
      "lambda[106]      2.34      4.97      0.95      0.01      5.17    689.48      1.00\n",
      "lambda[107]      8.08     75.86      1.00      0.00      5.43    811.73      1.00\n",
      "lambda[108]      2.39      6.99      0.95      0.00      4.89    592.82      1.00\n",
      "lambda[109]      4.82     36.64      1.01      0.00      7.03    921.43      1.00\n",
      "lambda[110]      4.17     15.94      0.97      0.00      6.98    860.16      1.00\n",
      "lambda[111]      3.59     13.29      0.91      0.00      6.35    700.73      1.00\n",
      "lambda[112]      2.55      5.67      0.97      0.00      5.54    630.17      1.00\n",
      "lambda[113]      8.50     69.97      1.04      0.00      7.22    566.65      1.01\n",
      "lambda[114]      3.90     13.46      0.94      0.00      7.01    778.69      1.00\n",
      "lambda[115]      5.21     25.73      0.95      0.00      6.81    622.82      1.00\n",
      "lambda[116]     10.06    107.36      1.02      0.00      6.78    513.23      1.00\n",
      "lambda[117]      3.39     11.73      1.00      0.00      6.71    846.66      1.00\n",
      "lambda[118]      3.23     13.77      0.98      0.00      5.64    761.24      1.00\n",
      "lambda[119]      2.75      9.91      1.01      0.00      5.06    775.03      1.00\n",
      "lambda[120]      6.39     64.98      0.93      0.00      7.07    932.19      1.00\n",
      "lambda[121]      4.12     23.31      0.89      0.00      5.68    434.58      1.00\n",
      "lambda[122]      4.69     38.70      1.02      0.00      6.50    862.92      1.00\n",
      "lambda[123]      2.27      4.25      0.92      0.00      5.50    890.03      1.00\n",
      "lambda[124]      2.60      8.08      0.97      0.00      5.11    743.28      1.00\n",
      "lambda[125]      2.83      8.10      0.90      0.00      5.36    606.27      1.00\n",
      "lambda[126]      2.33      5.25      0.97      0.00      4.73    834.94      1.00\n",
      "lambda[127]      5.28     27.33      0.98      0.00      7.18    591.66      1.00\n",
      "lambda[128]      3.40     22.16      0.94      0.00      5.37    966.07      1.00\n",
      "lambda[129]      6.77     96.96      0.98      0.00      6.26   1003.02      1.00\n",
      "lambda[130]      3.71     17.72      0.99      0.00      6.65    874.08      1.00\n",
      "lambda[131]      5.39     29.91      1.00      0.00      7.09    950.74      1.00\n",
      "lambda[132]      2.75      6.10      0.95      0.00      5.96    959.01      1.00\n",
      "lambda[133]      2.41      6.19      0.99      0.00      5.04    861.63      1.00\n",
      "lambda[134]      6.51     92.61      0.93      0.00      7.74   1004.94      1.00\n",
      "lambda[135]      6.88    123.41      0.93      0.00      4.80    902.39      1.00\n",
      "lambda[136]      3.32     20.43      0.96      0.01      5.59    847.66      1.00\n",
      "lambda[137]      3.03      9.08      0.99      0.00      5.45    531.43      1.00\n",
      "lambda[138]      3.52     16.02      1.01      0.00      5.45    644.39      1.00\n",
      "lambda[139]      3.62     17.47      1.02      0.00      5.67    825.16      1.00\n",
      "lambda[140]      3.12     11.50      0.95      0.00      5.23    972.47      1.00\n",
      "lambda[141]      2.55      6.00      0.94      0.00      5.22    667.34      1.00\n",
      "lambda[142]      5.54     31.49      0.97      0.01      6.36    450.02      1.00\n",
      "lambda[143]      2.96     16.84      0.96      0.00      4.72    516.68      1.00\n",
      "        msq      0.20      0.12      0.17      0.06      0.35    904.61      1.00\n",
      "      sigma      3.28      4.05      1.68      0.01      9.67   1619.62      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    915.85      1.00\n",
      "       xisq      0.11      0.05      0.10      0.04      0.17   1329.34      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 32.16170883178711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t2.10e-05 +- 1.41e-02\n",
      "[dimension 02/145]  inactive:\t1.26e-03 +- 2.28e-02\n",
      "[dimension 03/145]  inactive:\t1.64e-03 +- 2.72e-02\n",
      "[dimension 04/145]  inactive:\t3.83e-03 +- 3.11e-02\n",
      "[dimension 05/145]  inactive:\t7.68e-04 +- 2.37e-02\n",
      "[dimension 06/145]  inactive:\t3.59e-03 +- 3.90e-02\n",
      "[dimension 07/145]  inactive:\t1.60e-03 +- 2.02e-02\n",
      "[dimension 08/145]  inactive:\t2.95e-03 +- 3.26e-02\n",
      "[dimension 09/145]  inactive:\t1.61e-03 +- 2.47e-02\n",
      "[dimension 10/145]  inactive:\t7.61e-04 +- 1.73e-02\n",
      "[dimension 11/145]  inactive:\t1.45e-03 +- 2.87e-02\n",
      "[dimension 12/145]  inactive:\t1.55e-03 +- 2.71e-02\n",
      "[dimension 13/145]  inactive:\t5.96e-03 +- 4.14e-02\n",
      "[dimension 14/145]  inactive:\t7.62e-05 +- 1.96e-02\n",
      "[dimension 15/145]  inactive:\t5.82e-03 +- 5.25e-02\n",
      "[dimension 16/145]  inactive:\t1.27e-03 +- 2.15e-02\n",
      "[dimension 17/145]  inactive:\t2.25e-03 +- 3.32e-02\n",
      "[dimension 18/145]  inactive:\t3.28e-03 +- 3.73e-02\n",
      "[dimension 19/145]  inactive:\t-1.66e-03 +- 1.94e-02\n",
      "[dimension 20/145]  inactive:\t9.73e-05 +- 2.43e-02\n",
      "[dimension 21/145]  inactive:\t-8.23e-04 +- 2.13e-02\n",
      "[dimension 22/145]  inactive:\t1.68e-04 +- 2.07e-02\n",
      "[dimension 23/145]  inactive:\t6.13e-04 +- 2.44e-02\n",
      "[dimension 24/145]  inactive:\t1.54e-03 +- 2.50e-02\n",
      "[dimension 25/145]  inactive:\t3.98e-03 +- 2.55e-02\n",
      "[dimension 26/145]  inactive:\t2.22e-04 +- 2.65e-02\n",
      "[dimension 27/145]  inactive:\t2.86e-03 +- 3.03e-02\n",
      "[dimension 28/145]  inactive:\t1.43e-03 +- 1.86e-02\n",
      "[dimension 29/145]  inactive:\t1.98e-03 +- 2.93e-02\n",
      "[dimension 30/145]  inactive:\t2.99e-03 +- 2.92e-02\n",
      "[dimension 31/145]  inactive:\t6.67e-03 +- 4.34e-02\n",
      "[dimension 32/145]  inactive:\t1.05e-03 +- 3.00e-02\n",
      "[dimension 33/145]  inactive:\t8.70e-03 +- 5.95e-02\n",
      "[dimension 34/145]  inactive:\t1.29e-03 +- 2.03e-02\n",
      "[dimension 35/145]  inactive:\t1.68e-03 +- 2.49e-02\n",
      "[dimension 36/145]  inactive:\t1.43e-03 +- 2.01e-02\n",
      "[dimension 37/145]  inactive:\t3.96e-03 +- 2.55e-02\n",
      "[dimension 38/145]  inactive:\t7.67e-04 +- 2.72e-02\n",
      "[dimension 39/145]  inactive:\t3.48e-03 +- 3.39e-02\n",
      "[dimension 40/145]  inactive:\t6.00e-03 +- 4.30e-02\n",
      "[dimension 41/145]  inactive:\t9.22e-04 +- 3.15e-02\n",
      "[dimension 42/145]  inactive:\t1.52e-02 +- 8.93e-02\n",
      "[dimension 43/145]  inactive:\t7.49e-04 +- 1.84e-02\n",
      "[dimension 44/145]  inactive:\t1.64e-03 +- 3.58e-02\n",
      "[dimension 45/145]  inactive:\t1.19e-03 +- 2.29e-02\n",
      "[dimension 46/145]  inactive:\t7.86e-04 +- 1.47e-02\n",
      "[dimension 47/145]  inactive:\t-2.52e-04 +- 2.23e-02\n",
      "[dimension 48/145]  inactive:\t1.94e-03 +- 2.36e-02\n",
      "[dimension 49/145]  inactive:\t1.67e-03 +- 2.06e-02\n",
      "[dimension 50/145]  inactive:\t-2.28e-04 +- 2.31e-02\n",
      "[dimension 51/145]  inactive:\t3.95e-03 +- 3.64e-02\n",
      "[dimension 52/145]  inactive:\t7.40e-03 +- 2.99e-02\n",
      "[dimension 53/145]  inactive:\t5.73e-05 +- 2.35e-02\n",
      "[dimension 54/145]  inactive:\t2.00e-03 +- 2.42e-02\n",
      "[dimension 55/145]  inactive:\t4.71e-04 +- 1.34e-02\n",
      "[dimension 56/145]  inactive:\t-1.11e-03 +- 2.07e-02\n",
      "[dimension 57/145]  inactive:\t3.63e-03 +- 3.43e-02\n",
      "[dimension 58/145]  inactive:\t2.20e-02 +- 9.02e-02\n",
      "[dimension 59/145]  inactive:\t1.71e-04 +- 1.56e-02\n",
      "[dimension 60/145]  inactive:\t5.00e-03 +- 4.24e-02\n",
      "[dimension 61/145]  inactive:\t5.08e-03 +- 3.30e-02\n",
      "[dimension 62/145]  inactive:\t4.31e-04 +- 2.11e-02\n",
      "[dimension 63/145]  active:\t4.87e-01 +- 4.21e-01\n",
      "[dimension 64/145]  inactive:\t-2.17e-03 +- 2.28e-02\n",
      "[dimension 65/145]  inactive:\t7.38e-04 +- 2.39e-02\n",
      "[dimension 66/145]  inactive:\t1.46e-03 +- 2.38e-02\n",
      "[dimension 67/145]  inactive:\t1.75e-03 +- 2.44e-02\n",
      "[dimension 68/145]  inactive:\t2.04e-03 +- 3.52e-02\n",
      "[dimension 69/145]  inactive:\t7.14e-03 +- 5.59e-02\n",
      "[dimension 70/145]  inactive:\t6.19e-03 +- 3.24e-02\n",
      "[dimension 71/145]  inactive:\t1.18e-03 +- 2.39e-02\n",
      "[dimension 72/145]  inactive:\t1.55e-03 +- 1.99e-02\n",
      "[dimension 73/145]  inactive:\t9.11e-04 +- 1.66e-02\n",
      "[dimension 74/145]  inactive:\t1.51e-03 +- 3.01e-02\n",
      "[dimension 75/145]  inactive:\t1.42e-03 +- 2.02e-02\n",
      "[dimension 76/145]  inactive:\t9.43e-03 +- 5.21e-02\n",
      "[dimension 77/145]  inactive:\t2.91e-04 +- 2.84e-02\n",
      "[dimension 78/145]  inactive:\t1.37e-02 +- 8.21e-02\n",
      "[dimension 79/145]  inactive:\t7.72e-03 +- 3.95e-02\n",
      "[dimension 80/145]  inactive:\t1.97e-03 +- 3.03e-02\n",
      "[dimension 81/145]  inactive:\t6.01e-03 +- 4.81e-02\n",
      "[dimension 82/145]  inactive:\t5.56e-04 +- 1.46e-02\n",
      "[dimension 83/145]  inactive:\t-5.11e-04 +- 1.37e-02\n",
      "[dimension 84/145]  inactive:\t3.22e-04 +- 2.22e-02\n",
      "[dimension 85/145]  inactive:\t4.60e-03 +- 3.78e-02\n",
      "[dimension 86/145]  inactive:\t-8.41e-05 +- 1.87e-02\n",
      "[dimension 87/145]  inactive:\t2.82e-03 +- 3.06e-02\n",
      "[dimension 88/145]  inactive:\t3.40e-03 +- 2.62e-02\n",
      "[dimension 89/145]  inactive:\t4.33e-04 +- 1.92e-02\n",
      "[dimension 90/145]  inactive:\t9.79e-02 +- 2.46e-01\n",
      "[dimension 91/145]  inactive:\t9.54e-05 +- 1.49e-02\n",
      "[dimension 92/145]  inactive:\t-1.14e-04 +- 1.97e-02\n",
      "[dimension 93/145]  inactive:\t4.41e-04 +- 2.46e-02\n",
      "[dimension 94/145]  inactive:\t2.35e-03 +- 2.83e-02\n",
      "[dimension 95/145]  inactive:\t7.88e-04 +- 2.40e-02\n",
      "[dimension 96/145]  inactive:\t3.51e-03 +- 4.71e-02\n",
      "[dimension 97/145]  inactive:\t3.35e-03 +- 2.58e-02\n",
      "[dimension 98/145]  inactive:\t1.48e-04 +- 2.27e-02\n",
      "[dimension 99/145]  inactive:\t1.06e-02 +- 7.26e-02\n",
      "[dimension 100/145]  inactive:\t-2.75e-05 +- 1.40e-02\n",
      "[dimension 101/145]  inactive:\t-1.38e-03 +- 2.00e-02\n",
      "[dimension 102/145]  inactive:\t5.60e-04 +- 1.89e-02\n",
      "[dimension 103/145]  inactive:\t2.09e-03 +- 2.69e-02\n",
      "[dimension 104/145]  inactive:\t-1.06e-04 +- 1.80e-02\n",
      "[dimension 105/145]  inactive:\t1.25e-03 +- 2.75e-02\n",
      "[dimension 106/145]  inactive:\t7.05e-03 +- 4.03e-02\n",
      "[dimension 107/145]  inactive:\t-5.66e-05 +- 1.89e-02\n",
      "[dimension 108/145]  inactive:\t1.27e-02 +- 8.04e-02\n",
      "[dimension 109/145]  inactive:\t1.09e-04 +- 1.71e-02\n",
      "[dimension 110/145]  inactive:\t2.08e-03 +- 3.56e-02\n",
      "[dimension 111/145]  inactive:\t4.07e-03 +- 3.85e-02\n",
      "[dimension 112/145]  inactive:\t5.30e-03 +- 4.20e-02\n",
      "[dimension 113/145]  inactive:\t-2.78e-04 +- 1.88e-02\n",
      "[dimension 114/145]  inactive:\t4.25e-03 +- 4.78e-02\n",
      "[dimension 115/145]  inactive:\t2.36e-03 +- 2.35e-02\n",
      "[dimension 116/145]  inactive:\t5.72e-03 +- 5.67e-02\n",
      "[dimension 117/145]  inactive:\t9.84e-03 +- 6.47e-02\n",
      "[dimension 118/145]  inactive:\t3.38e-03 +- 2.50e-02\n",
      "[dimension 119/145]  inactive:\t1.32e-04 +- 2.87e-02\n",
      "[dimension 120/145]  inactive:\t8.70e-04 +- 2.20e-02\n",
      "[dimension 121/145]  inactive:\t6.02e-03 +- 4.24e-02\n",
      "[dimension 122/145]  inactive:\t-7.96e-04 +- 2.84e-02\n",
      "[dimension 123/145]  inactive:\t4.04e-03 +- 4.07e-02\n",
      "[dimension 124/145]  inactive:\t-2.68e-04 +- 1.61e-02\n",
      "[dimension 125/145]  inactive:\t1.39e-04 +- 2.09e-02\n",
      "[dimension 126/145]  inactive:\t4.53e-04 +- 1.95e-02\n",
      "[dimension 127/145]  inactive:\t3.70e-04 +- 1.66e-02\n",
      "[dimension 128/145]  inactive:\t2.26e-03 +- 3.55e-02\n",
      "[dimension 129/145]  inactive:\t1.72e-03 +- 2.49e-02\n",
      "[dimension 130/145]  inactive:\t3.67e-03 +- 2.79e-02\n",
      "[dimension 131/145]  inactive:\t1.84e-03 +- 3.33e-02\n",
      "[dimension 132/145]  inactive:\t7.58e-03 +- 5.48e-02\n",
      "[dimension 133/145]  inactive:\t2.94e-03 +- 2.21e-02\n",
      "[dimension 134/145]  inactive:\t5.29e-04 +- 2.01e-02\n",
      "[dimension 135/145]  inactive:\t2.88e-03 +- 3.03e-02\n",
      "[dimension 136/145]  inactive:\t1.49e-03 +- 1.93e-02\n",
      "[dimension 137/145]  inactive:\t1.20e-03 +- 2.80e-02\n",
      "[dimension 138/145]  inactive:\t1.96e-03 +- 2.65e-02\n",
      "[dimension 139/145]  inactive:\t1.47e-03 +- 2.30e-02\n",
      "[dimension 140/145]  inactive:\t4.70e-04 +- 2.48e-02\n",
      "[dimension 141/145]  inactive:\t2.57e-03 +- 3.07e-02\n",
      "[dimension 142/145]  inactive:\t2.51e-03 +- 2.11e-02\n",
      "[dimension 143/145]  inactive:\t4.64e-03 +- 4.44e-02\n",
      "[dimension 144/145]  inactive:\t1.63e-03 +- 2.24e-02\n",
      "[dimension 145/145]  inactive:\t-1.94e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.6823476]\n",
      "cov_act[[0.03397651]]\n",
      "Active_dimensions: [62]\n",
      "4, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:27<00:00, 54.34it/s, 31 steps of size 1.81e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    699.44      1.00\n",
      "  lambda[0]      2.93     13.41      0.92      0.00      4.98    843.64      1.00\n",
      "  lambda[1]      2.95     11.12      0.96      0.00      5.39    693.12      1.00\n",
      "  lambda[2]      2.74      7.54      0.98      0.00      5.31    639.19      1.00\n",
      "  lambda[3]      4.03     13.29      0.98      0.00      6.41    434.55      1.01\n",
      "  lambda[4]      2.82      7.79      1.03      0.00      5.38    710.22      1.00\n",
      "  lambda[5]      5.78     81.65      0.98      0.00      5.42    868.26      1.00\n",
      "  lambda[6]      2.92      9.14      0.93      0.00      5.53    797.01      1.00\n",
      "  lambda[7]      2.70      6.16      0.95      0.00      5.94    789.69      1.00\n",
      "  lambda[8]      2.30      4.32      1.00      0.01      5.03    778.60      1.00\n",
      "  lambda[9]      2.44      7.21      0.95      0.00      4.42    527.08      1.00\n",
      " lambda[10]      2.92     10.42      1.05      0.00      5.04    861.10      1.00\n",
      " lambda[11]      2.82      7.74      1.02      0.00      6.03    751.08      1.00\n",
      " lambda[12]      3.75     13.59      0.99      0.00      6.92    779.61      1.00\n",
      " lambda[13]      2.78      8.05      0.99      0.00      5.27    696.03      1.00\n",
      " lambda[14]      4.72     45.57      0.95      0.00      5.79    512.27      1.00\n",
      " lambda[15]      2.93      9.67      0.92      0.00      5.31   1019.44      1.00\n",
      " lambda[16]      3.77     18.55      0.98      0.00      6.34    522.29      1.00\n",
      " lambda[17]      2.81     12.19      0.98      0.00      5.15    745.45      1.00\n",
      " lambda[18]      2.65      5.72      0.94      0.00      6.04    661.89      1.00\n",
      " lambda[19]      3.13     13.38      0.93      0.00      6.14    655.64      1.00\n",
      " lambda[20]      2.56      7.57      0.98      0.00      5.12    892.14      1.00\n",
      " lambda[21]      2.52      5.30      1.01      0.00      6.06    751.87      1.00\n",
      " lambda[22]      3.01      8.18      1.03      0.00      6.03    534.63      1.00\n",
      " lambda[23]      3.31     12.37      0.94      0.00      5.39    738.48      1.00\n",
      " lambda[24]      3.90     18.64      1.01      0.00      7.07    840.81      1.00\n",
      " lambda[25]      3.25      8.65      0.99      0.00      6.82    436.48      1.00\n",
      " lambda[26]      3.26     12.89      0.95      0.00      5.23    290.89      1.00\n",
      " lambda[27]      2.97      7.40      0.98      0.00      5.90    531.71      1.00\n",
      " lambda[28]      2.79      8.83      1.02      0.00      4.92    759.48      1.00\n",
      " lambda[29]      2.59      6.52      0.95      0.00      5.27    732.46      1.00\n",
      " lambda[30]      3.80     13.34      0.97      0.00      6.91    768.97      1.00\n",
      " lambda[31]      3.79     18.02      0.95      0.00      5.65    506.66      1.00\n",
      " lambda[32]      3.11     12.82      1.02      0.00      5.76    753.57      1.00\n",
      " lambda[33]      2.84      8.72      0.99      0.01      5.97    846.00      1.00\n",
      " lambda[34]      3.27     11.00      1.02      0.00      5.40    475.33      1.00\n",
      " lambda[35]      2.48      6.03      1.03      0.00      5.18    821.61      1.00\n",
      " lambda[36]      4.02     24.40      0.97      0.00      6.21    772.72      1.00\n",
      " lambda[37]      3.89     29.60      0.99      0.00      6.80    969.99      1.00\n",
      " lambda[38]      3.18      8.73      0.97      0.00      6.06    761.25      1.00\n",
      " lambda[39]      2.96      8.07      0.99      0.00      5.89    802.59      1.00\n",
      " lambda[40]      3.61     16.56      0.95      0.00      6.48    963.60      1.00\n",
      " lambda[41]     30.92    309.08      1.00      0.00     11.93    520.69      1.01\n",
      " lambda[42]      2.64      6.58      0.98      0.00      5.14    756.09      1.01\n",
      " lambda[43]      6.59     91.32      0.97      0.00      5.99   1001.65      1.00\n",
      " lambda[44]      3.48     12.79      0.97      0.00      6.18    581.62      1.00\n",
      " lambda[45]      2.73      7.43      0.97      0.00      4.92    574.65      1.00\n",
      " lambda[46]      2.95     11.07      1.01      0.00      4.40    520.55      1.00\n",
      " lambda[47]      2.67      7.47      0.94      0.00      5.04    547.89      1.00\n",
      " lambda[48]      2.81      7.77      0.92      0.00      5.44    718.35      1.00\n",
      " lambda[49]      2.94      7.86      0.93      0.00      5.89    718.23      1.00\n",
      " lambda[50]      3.57     16.87      1.00      0.00      5.88    785.15      1.00\n",
      " lambda[51]      3.98     13.98      1.02      0.00      6.70    501.24      1.01\n",
      " lambda[52]      2.59      7.49      1.02      0.00      4.56    878.12      1.00\n",
      " lambda[53]      3.36     12.25      1.00      0.00      5.90    739.09      1.00\n",
      " lambda[54]      2.17      5.94      0.93      0.01      4.24    951.21      1.00\n",
      " lambda[55]      2.80      7.58      1.01      0.00      5.36    706.25      1.00\n",
      " lambda[56]      2.79      8.10      0.99      0.00      5.48    832.41      1.00\n",
      " lambda[57]     32.87    678.11      1.06      0.00      8.93    952.57      1.00\n",
      " lambda[58]      2.55      5.42      0.99      0.00      5.73    591.23      1.00\n",
      " lambda[59]      3.29     10.51      1.02      0.00      6.00    565.84      1.00\n",
      " lambda[60]      3.06      9.25      0.94      0.00      5.71    805.46      1.00\n",
      " lambda[61]      2.60      8.63      1.00      0.00      5.23    773.13      1.00\n",
      " lambda[62]   4779.62  87881.18    179.66      0.00   1244.03    509.58      1.00\n",
      " lambda[63]      4.10     47.37      1.03      0.00      5.50   1002.37      1.00\n",
      " lambda[64]      3.12      8.85      0.95      0.00      6.07    688.65      1.00\n",
      " lambda[65]      2.54      6.23      0.95      0.00      5.54    647.41      1.00\n",
      " lambda[66]      3.05      8.16      0.98      0.00      6.31    721.36      1.00\n",
      " lambda[67]      2.71      6.83      0.89      0.00      5.34    646.47      1.01\n",
      " lambda[68]      4.25     32.72      0.93      0.00      5.96    715.26      1.00\n",
      " lambda[69]      2.86      7.06      0.94      0.00      6.33    551.88      1.00\n",
      " lambda[70]      2.66      7.07      0.88      0.00      5.20    546.15      1.00\n",
      " lambda[71]      3.37     16.75      1.00      0.00      6.11    784.94      1.00\n",
      " lambda[72]      2.45      6.10      0.94      0.00      4.97    617.06      1.00\n",
      " lambda[73]      2.70      6.58      1.04      0.00      5.93    797.58      1.00\n",
      " lambda[74]      2.62      6.37      1.03      0.01      5.32    722.72      1.00\n",
      " lambda[75]     15.11    277.95      1.05      0.00      7.67    771.60      1.00\n",
      " lambda[76]      2.83      7.09      0.99      0.00      5.60    747.35      1.00\n",
      " lambda[77]      7.18     74.12      1.02      0.00      6.77    729.57      1.00\n",
      " lambda[78]      3.25     10.21      1.00      0.00      6.42    876.31      1.00\n",
      " lambda[79]      3.66     12.54      1.05      0.00      6.91    696.76      1.00\n",
      " lambda[80]      3.13      9.63      1.02      0.00      5.81    579.33      1.00\n",
      " lambda[81]      2.37      5.72      0.93      0.00      4.83   1005.31      1.00\n",
      " lambda[82]      2.27      5.64      0.95      0.00      4.29    661.10      1.00\n",
      " lambda[83]      3.01      9.79      0.92      0.00      6.47    625.82      1.00\n",
      " lambda[84]      3.96     20.04      1.01      0.00      5.96    729.80      1.00\n",
      " lambda[85]      2.59      8.48      0.95      0.00      4.69    497.98      1.00\n",
      " lambda[86]      2.68      7.05      0.98      0.01      5.24    936.40      1.00\n",
      " lambda[87]      3.00     11.65      0.94      0.00      5.94    877.24      1.00\n",
      " lambda[88]      2.47      5.45      0.94      0.00      5.25   1044.88      1.00\n",
      " lambda[89]     48.93    261.39      1.08      0.00     45.69    330.10      1.00\n",
      " lambda[90]      2.68      6.62      1.01      0.00      5.25    558.36      1.00\n",
      " lambda[91]      2.71      7.45      0.99      0.01      5.39    459.08      1.00\n",
      " lambda[92]      4.48     53.75      0.99      0.00      5.11    787.88      1.00\n",
      " lambda[93]      2.88      7.04      1.08      0.00      5.40    783.83      1.00\n",
      " lambda[94]      2.72      7.07      0.99      0.00      5.43    971.64      1.00\n",
      " lambda[95]      4.53     39.64      0.93      0.00      5.73    802.87      1.00\n",
      " lambda[96]      2.38      5.02      0.99      0.00      5.06    615.51      1.00\n",
      " lambda[97]      2.85      6.27      1.06      0.00      5.61    635.19      1.00\n",
      " lambda[98]      5.44     62.54      0.95      0.00      5.83    863.73      1.00\n",
      " lambda[99]      2.92      8.40      0.92      0.00      6.27    722.98      1.00\n",
      "lambda[100]      2.59      7.66      0.88      0.00      5.52    671.80      1.00\n",
      "lambda[101]      2.79      5.81      0.93      0.00      6.43    801.66      1.00\n",
      "lambda[102]      3.27     12.23      0.91      0.00      5.95    616.98      1.00\n",
      "lambda[103]      3.09     12.60      1.03      0.00      5.28    628.52      1.00\n",
      "lambda[104]      3.18     12.95      0.99      0.00      6.43    584.44      1.00\n",
      "lambda[105]      3.69     11.04      1.00      0.00      7.23    448.45      1.00\n",
      "lambda[106]      2.50      5.41      0.98      0.01      5.50    909.01      1.00\n",
      "lambda[107]     36.26    729.78      0.95      0.00      6.88    501.55      1.00\n",
      "lambda[108]      1.87      3.01      0.93      0.01      4.16    688.32      1.00\n",
      "lambda[109]      4.95     64.47      0.94      0.00      6.04   1003.32      1.00\n",
      "lambda[110]      3.57     10.61      0.98      0.00      6.60    651.55      1.00\n",
      "lambda[111]      3.51     13.99      0.96      0.00      5.51    804.94      1.00\n",
      "lambda[112]      2.68      6.14      0.98      0.01      5.95    902.53      1.00\n",
      "lambda[113]      3.66     11.98      0.97      0.00      6.76    630.33      1.00\n",
      "lambda[114]      3.04     11.51      0.99      0.00      5.63    905.27      1.00\n",
      "lambda[115]      3.22     10.30      0.96      0.00      5.95    794.53      1.00\n",
      "lambda[116]      4.07     25.71      0.99      0.00      5.33    567.71      1.00\n",
      "lambda[117]      2.92      9.53      0.97      0.00      6.22    899.87      1.00\n",
      "lambda[118]      3.63     12.26      0.95      0.00      7.54    817.65      1.00\n",
      "lambda[119]      2.94     13.09      1.07      0.00      5.79    877.30      1.00\n",
      "lambda[120]      4.69     20.50      0.98      0.00      6.49    532.23      1.00\n",
      "lambda[121]      3.49     13.48      0.93      0.00      6.29    700.02      1.00\n",
      "lambda[122]      3.65      9.83      1.05      0.00      8.28    455.08      1.00\n",
      "lambda[123]      2.90      8.23      0.93      0.00      5.59    781.37      1.00\n",
      "lambda[124]      2.46      5.40      1.02      0.00      5.75    896.47      1.00\n",
      "lambda[125]      2.58      6.57      0.95      0.00      4.97    764.31      1.00\n",
      "lambda[126]      2.60      7.30      0.99      0.00      5.43    833.90      1.00\n",
      "lambda[127]      2.94      8.26      1.05      0.00      5.52    501.59      1.00\n",
      "lambda[128]      2.51      5.72      0.96      0.01      5.22    890.39      1.00\n",
      "lambda[129]      4.11     22.29      1.04      0.00      6.85    836.95      1.00\n",
      "lambda[130]      3.40      8.78      0.94      0.00      6.24    637.20      1.00\n",
      "lambda[131]      3.24     10.91      0.98      0.00      6.33    831.66      1.00\n",
      "lambda[132]      2.71      6.40      0.94      0.00      5.90    798.04      1.00\n",
      "lambda[133]      3.05      8.21      0.97      0.00      6.03    800.95      1.00\n",
      "lambda[134]      3.27      8.86      0.90      0.00      7.01    739.22      1.00\n",
      "lambda[135]      2.74      8.72      0.90      0.00      5.58    775.54      1.00\n",
      "lambda[136]      3.03     11.76      0.98      0.00      5.56    903.84      1.00\n",
      "lambda[137]      2.72      8.01      0.95      0.01      5.15   1040.19      1.00\n",
      "lambda[138]      2.97     10.60      1.02      0.00      5.24    856.12      1.00\n",
      "lambda[139]      3.15      8.45      1.03      0.01      5.85    700.61      1.01\n",
      "lambda[140]      3.00      8.97      1.03      0.00      5.70    812.92      1.00\n",
      "lambda[141]      2.71      6.59      0.95      0.00      5.88    864.19      1.01\n",
      "lambda[142]      5.25     30.00      0.97      0.00      6.79    259.40      1.00\n",
      "lambda[143]      2.28      4.43      1.00      0.00      5.03    956.53      1.00\n",
      "        msq  15978.23 344229.28      7.97      0.16    189.14    994.12      1.00\n",
      "      sigma      4.35      5.83      1.96      0.01     12.09   1359.85      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1054.05      1.00\n",
      "       xisq     15.92    155.31      1.36      0.09     11.44    956.72      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.189662218093872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.40e-04 +- 1.87e-02\n",
      "[dimension 02/145]  inactive:\t-4.61e-04 +- 2.55e-02\n",
      "[dimension 03/145]  inactive:\t4.63e-04 +- 2.42e-02\n",
      "[dimension 04/145]  inactive:\t6.78e-03 +- 4.62e-02\n",
      "[dimension 05/145]  inactive:\t-7.02e-04 +- 2.22e-02\n",
      "[dimension 06/145]  inactive:\t2.94e-03 +- 4.11e-02\n",
      "[dimension 07/145]  inactive:\t6.73e-04 +- 1.92e-02\n",
      "[dimension 08/145]  inactive:\t5.43e-04 +- 2.73e-02\n",
      "[dimension 09/145]  inactive:\t4.08e-04 +- 1.88e-02\n",
      "[dimension 10/145]  inactive:\t4.84e-04 +- 1.84e-02\n",
      "[dimension 11/145]  inactive:\t-4.89e-04 +- 2.21e-02\n",
      "[dimension 12/145]  inactive:\t-4.84e-04 +- 2.83e-02\n",
      "[dimension 13/145]  inactive:\t4.00e-03 +- 3.70e-02\n",
      "[dimension 14/145]  inactive:\t-1.07e-03 +- 2.71e-02\n",
      "[dimension 15/145]  inactive:\t8.71e-04 +- 3.23e-02\n",
      "[dimension 16/145]  inactive:\t9.40e-04 +- 2.08e-02\n",
      "[dimension 17/145]  inactive:\t3.63e-04 +- 2.89e-02\n",
      "[dimension 18/145]  inactive:\t4.29e-04 +- 2.21e-02\n",
      "[dimension 19/145]  inactive:\t-1.87e-03 +- 1.93e-02\n",
      "[dimension 20/145]  inactive:\t-1.07e-03 +- 2.29e-02\n",
      "[dimension 21/145]  inactive:\t-1.18e-03 +- 2.29e-02\n",
      "[dimension 22/145]  inactive:\t-2.12e-04 +- 2.09e-02\n",
      "[dimension 23/145]  inactive:\t-6.96e-04 +- 2.67e-02\n",
      "[dimension 24/145]  inactive:\t2.17e-03 +- 2.82e-02\n",
      "[dimension 25/145]  inactive:\t4.03e-03 +- 2.68e-02\n",
      "[dimension 26/145]  inactive:\t-6.28e-04 +- 2.46e-02\n",
      "[dimension 27/145]  inactive:\t9.28e-04 +- 2.42e-02\n",
      "[dimension 28/145]  inactive:\t1.35e-03 +- 2.39e-02\n",
      "[dimension 29/145]  inactive:\t-1.89e-04 +- 2.71e-02\n",
      "[dimension 30/145]  inactive:\t3.13e-04 +- 2.34e-02\n",
      "[dimension 31/145]  inactive:\t7.21e-03 +- 5.06e-02\n",
      "[dimension 32/145]  inactive:\t-1.99e-03 +- 2.90e-02\n",
      "[dimension 33/145]  inactive:\t2.02e-03 +- 3.50e-02\n",
      "[dimension 34/145]  inactive:\t1.07e-03 +- 1.94e-02\n",
      "[dimension 35/145]  inactive:\t5.85e-04 +- 2.72e-02\n",
      "[dimension 36/145]  inactive:\t1.01e-03 +- 2.18e-02\n",
      "[dimension 37/145]  inactive:\t4.28e-03 +- 2.72e-02\n",
      "[dimension 38/145]  inactive:\t-1.57e-03 +- 3.18e-02\n",
      "[dimension 39/145]  inactive:\t1.41e-03 +- 3.11e-02\n",
      "[dimension 40/145]  inactive:\t4.31e-03 +- 3.74e-02\n",
      "[dimension 41/145]  inactive:\t-1.82e-03 +- 2.93e-02\n",
      "[dimension 42/145]  inactive:\t2.74e-02 +- 1.38e-01\n",
      "[dimension 43/145]  inactive:\t6.23e-05 +- 1.73e-02\n",
      "[dimension 44/145]  inactive:\t4.61e-04 +- 3.31e-02\n",
      "[dimension 45/145]  inactive:\t-2.55e-04 +- 2.79e-02\n",
      "[dimension 46/145]  inactive:\t1.10e-03 +- 1.66e-02\n",
      "[dimension 47/145]  inactive:\t-1.56e-03 +- 2.69e-02\n",
      "[dimension 48/145]  inactive:\t1.11e-03 +- 2.33e-02\n",
      "[dimension 49/145]  inactive:\t2.83e-03 +- 2.58e-02\n",
      "[dimension 50/145]  inactive:\t-1.50e-03 +- 2.64e-02\n",
      "[dimension 51/145]  inactive:\t3.36e-03 +- 3.80e-02\n",
      "[dimension 52/145]  inactive:\t5.31e-03 +- 2.48e-02\n",
      "[dimension 53/145]  inactive:\t-8.65e-04 +- 2.07e-02\n",
      "[dimension 54/145]  inactive:\t3.06e-04 +- 2.23e-02\n",
      "[dimension 55/145]  inactive:\t2.54e-04 +- 1.52e-02\n",
      "[dimension 56/145]  inactive:\t-2.32e-03 +- 2.26e-02\n",
      "[dimension 57/145]  inactive:\t1.50e-03 +- 3.27e-02\n",
      "[dimension 58/145]  inactive:\t1.74e-02 +- 8.65e-02\n",
      "[dimension 59/145]  inactive:\t-7.30e-04 +- 1.79e-02\n",
      "[dimension 60/145]  inactive:\t1.60e-03 +- 3.44e-02\n",
      "[dimension 61/145]  inactive:\t2.74e-03 +- 2.47e-02\n",
      "[dimension 62/145]  inactive:\t-6.86e-04 +- 1.96e-02\n",
      "[dimension 63/145]  active:\t6.99e-01 +- 4.19e-01\n",
      "[dimension 64/145]  inactive:\t-2.50e-03 +- 2.51e-02\n",
      "[dimension 65/145]  inactive:\t-8.81e-04 +- 2.97e-02\n",
      "[dimension 66/145]  inactive:\t3.32e-04 +- 2.13e-02\n",
      "[dimension 67/145]  inactive:\t1.21e-03 +- 2.70e-02\n",
      "[dimension 68/145]  inactive:\t-6.49e-04 +- 2.75e-02\n",
      "[dimension 69/145]  inactive:\t5.06e-03 +- 5.02e-02\n",
      "[dimension 70/145]  inactive:\t2.92e-03 +- 2.19e-02\n",
      "[dimension 71/145]  inactive:\t4.29e-04 +- 2.76e-02\n",
      "[dimension 72/145]  inactive:\t4.33e-04 +- 2.14e-02\n",
      "[dimension 73/145]  inactive:\t1.59e-04 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-7.45e-04 +- 2.64e-02\n",
      "[dimension 75/145]  inactive:\t1.00e-03 +- 2.47e-02\n",
      "[dimension 76/145]  inactive:\t7.66e-03 +- 4.93e-02\n",
      "[dimension 77/145]  inactive:\t-1.25e-03 +- 2.74e-02\n",
      "[dimension 78/145]  inactive:\t9.30e-03 +- 7.85e-02\n",
      "[dimension 79/145]  inactive:\t4.97e-03 +- 3.05e-02\n",
      "[dimension 80/145]  inactive:\t-8.70e-04 +- 3.44e-02\n",
      "[dimension 81/145]  inactive:\t9.82e-04 +- 2.93e-02\n",
      "[dimension 82/145]  inactive:\t3.03e-04 +- 1.60e-02\n",
      "[dimension 83/145]  inactive:\t-1.26e-03 +- 1.66e-02\n",
      "[dimension 84/145]  inactive:\t-1.02e-03 +- 2.74e-02\n",
      "[dimension 85/145]  inactive:\t3.45e-03 +- 3.27e-02\n",
      "[dimension 86/145]  inactive:\t-4.73e-04 +- 1.68e-02\n",
      "[dimension 87/145]  inactive:\t1.54e-03 +- 3.29e-02\n",
      "[dimension 88/145]  inactive:\t2.93e-03 +- 2.57e-02\n",
      "[dimension 89/145]  inactive:\t-1.06e-04 +- 2.02e-02\n",
      "[dimension 90/145]  inactive:\t8.76e-02 +- 2.64e-01\n",
      "[dimension 91/145]  inactive:\t1.16e-04 +- 1.96e-02\n",
      "[dimension 92/145]  inactive:\t-1.27e-03 +- 2.28e-02\n",
      "[dimension 93/145]  inactive:\t-5.09e-05 +- 2.74e-02\n",
      "[dimension 94/145]  inactive:\t1.97e-03 +- 2.96e-02\n",
      "[dimension 95/145]  inactive:\t-4.28e-04 +- 2.02e-02\n",
      "[dimension 96/145]  inactive:\t2.49e-03 +- 5.07e-02\n",
      "[dimension 97/145]  inactive:\t1.76e-03 +- 1.95e-02\n",
      "[dimension 98/145]  inactive:\t-2.92e-04 +- 2.40e-02\n",
      "[dimension 99/145]  inactive:\t4.79e-03 +- 5.04e-02\n",
      "[dimension 100/145]  inactive:\t-7.27e-04 +- 1.87e-02\n",
      "[dimension 101/145]  inactive:\t-1.64e-03 +- 1.80e-02\n",
      "[dimension 102/145]  inactive:\t-5.54e-04 +- 2.56e-02\n",
      "[dimension 103/145]  inactive:\t8.13e-04 +- 2.26e-02\n",
      "[dimension 104/145]  inactive:\t-7.27e-04 +- 1.88e-02\n",
      "[dimension 105/145]  inactive:\t1.28e-04 +- 2.45e-02\n",
      "[dimension 106/145]  inactive:\t6.46e-03 +- 3.83e-02\n",
      "[dimension 107/145]  inactive:\t-1.11e-03 +- 1.94e-02\n",
      "[dimension 108/145]  inactive:\t7.09e-03 +- 6.35e-02\n",
      "[dimension 109/145]  inactive:\t-2.92e-04 +- 1.45e-02\n",
      "[dimension 110/145]  inactive:\t-1.07e-03 +- 2.74e-02\n",
      "[dimension 111/145]  inactive:\t3.24e-03 +- 4.45e-02\n",
      "[dimension 112/145]  inactive:\t4.85e-03 +- 4.17e-02\n",
      "[dimension 113/145]  inactive:\t-1.36e-03 +- 2.24e-02\n",
      "[dimension 114/145]  inactive:\t1.38e-03 +- 3.44e-02\n",
      "[dimension 115/145]  inactive:\t1.91e-03 +- 2.17e-02\n",
      "[dimension 116/145]  inactive:\t9.45e-04 +- 4.26e-02\n",
      "[dimension 117/145]  inactive:\t3.93e-03 +- 4.92e-02\n",
      "[dimension 118/145]  inactive:\t3.03e-03 +- 2.53e-02\n",
      "[dimension 119/145]  inactive:\t-2.29e-03 +- 2.99e-02\n",
      "[dimension 120/145]  inactive:\t5.83e-04 +- 2.79e-02\n",
      "[dimension 121/145]  inactive:\t5.15e-03 +- 4.22e-02\n",
      "[dimension 122/145]  inactive:\t-2.79e-03 +- 4.02e-02\n",
      "[dimension 123/145]  inactive:\t3.85e-03 +- 4.99e-02\n",
      "[dimension 124/145]  inactive:\t-1.51e-03 +- 2.06e-02\n",
      "[dimension 125/145]  inactive:\t-9.04e-04 +- 2.17e-02\n",
      "[dimension 126/145]  inactive:\t-6.48e-04 +- 1.99e-02\n",
      "[dimension 127/145]  inactive:\t1.48e-04 +- 1.88e-02\n",
      "[dimension 128/145]  inactive:\t-6.06e-04 +- 2.66e-02\n",
      "[dimension 129/145]  inactive:\t-7.02e-05 +- 2.02e-02\n",
      "[dimension 130/145]  inactive:\t3.24e-03 +- 2.70e-02\n",
      "[dimension 131/145]  inactive:\t-1.18e-03 +- 3.73e-02\n",
      "[dimension 132/145]  inactive:\t3.05e-03 +- 3.50e-02\n",
      "[dimension 133/145]  inactive:\t2.11e-03 +- 1.99e-02\n",
      "[dimension 134/145]  inactive:\t-8.81e-04 +- 2.61e-02\n",
      "[dimension 135/145]  inactive:\t6.53e-04 +- 2.72e-02\n",
      "[dimension 136/145]  inactive:\t9.70e-04 +- 1.98e-02\n",
      "[dimension 137/145]  inactive:\t-1.28e-04 +- 2.61e-02\n",
      "[dimension 138/145]  inactive:\t7.83e-04 +- 2.55e-02\n",
      "[dimension 139/145]  inactive:\t2.58e-04 +- 2.32e-02\n",
      "[dimension 140/145]  inactive:\t-8.18e-04 +- 2.86e-02\n",
      "[dimension 141/145]  inactive:\t9.95e-04 +- 2.63e-02\n",
      "[dimension 142/145]  inactive:\t1.36e-03 +- 1.79e-02\n",
      "[dimension 143/145]  inactive:\t1.23e-03 +- 3.50e-02\n",
      "[dimension 144/145]  inactive:\t6.64e-05 +- 1.75e-02\n",
      "[dimension 145/145]  inactive:\t1.01e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.98904634]\n",
      "cov_act[[0.02102524]]\n",
      "Active_dimensions: [62]\n",
      "5, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:25<00:00, 59.72it/s, 15 steps of size 2.10e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    285.43      1.00\n",
      "  lambda[0]      2.53      8.81      0.93      0.00      5.42    947.78      1.00\n",
      "  lambda[1]     13.07    268.74      0.97      0.00      6.16    658.31      1.00\n",
      "  lambda[2]      3.34     11.28      1.05      0.00      5.84    348.28      1.00\n",
      "  lambda[3]      3.17      9.36      0.97      0.00      6.19    729.50      1.00\n",
      "  lambda[4]      2.65      6.25      0.98      0.00      5.81    561.95      1.00\n",
      "  lambda[5]      4.76     40.07      1.00      0.00      5.83    671.43      1.00\n",
      "  lambda[6]      4.42     21.48      0.97      0.00      8.19    721.67      1.00\n",
      "  lambda[7]      2.87      7.05      0.92      0.00      6.26    787.36      1.00\n",
      "  lambda[8]      2.76      6.84      0.94      0.01      5.84    785.91      1.00\n",
      "  lambda[9]      2.96      9.32      1.17      0.00      5.09    859.07      1.00\n",
      " lambda[10]      2.95      7.69      0.99      0.00      5.97    610.15      1.00\n",
      " lambda[11]      3.94     23.94      0.96      0.00      5.36    417.98      1.00\n",
      " lambda[12]      6.64     50.05      0.99      0.01      7.51    590.13      1.00\n",
      " lambda[13]      2.44      5.70      0.94      0.00      4.99    514.23      1.00\n",
      " lambda[14]      5.45     28.81      1.06      0.00      7.95    543.98      1.00\n",
      " lambda[15]      3.02      8.76      1.03      0.00      5.56    893.56      1.00\n",
      " lambda[16]      2.85     10.85      1.02      0.00      5.69    984.18      1.00\n",
      " lambda[17]      7.90    113.36      1.00      0.00      6.07    881.12      1.00\n",
      " lambda[18]      2.86      7.47      0.94      0.00      5.37    664.24      1.00\n",
      " lambda[19]      3.76     20.03      1.00      0.00      6.00    382.02      1.00\n",
      " lambda[20]      3.27      9.56      0.94      0.00      6.32    528.04      1.00\n",
      " lambda[21]      2.75      6.79      1.01      0.01      5.80    347.85      1.00\n",
      " lambda[22]      2.74      9.80      1.05      0.00      5.20    921.19      1.00\n",
      " lambda[23]      3.11     12.69      1.02      0.00      4.93    896.88      1.00\n",
      " lambda[24]      3.81     15.15      1.01      0.00      6.65    878.93      1.00\n",
      " lambda[25]      2.26      5.89      0.93      0.00      4.91    612.58      1.00\n",
      " lambda[26]      3.16     11.25      0.98      0.00      5.60    525.81      1.00\n",
      " lambda[27]      3.02      9.75      0.92      0.00      5.50    410.75      1.00\n",
      " lambda[28]      2.62      6.23      1.01      0.00      5.71    618.14      1.00\n",
      " lambda[29]      2.80      7.84      0.97      0.01      5.39    753.73      1.00\n",
      " lambda[30]      3.98     19.51      0.94      0.00      6.84    736.57      1.00\n",
      " lambda[31]      5.23     40.22      0.99      0.00      5.54    421.48      1.00\n",
      " lambda[32]      4.14     20.31      1.01      0.00      6.67    612.82      1.00\n",
      " lambda[33]      3.06      7.07      0.98      0.00      6.99    335.51      1.01\n",
      " lambda[34]      2.56      6.39      1.02      0.00      4.83    420.53      1.00\n",
      " lambda[35]      3.02      9.88      1.00      0.00      5.27    526.35      1.00\n",
      " lambda[36]      3.00      7.36      1.04      0.00      6.12    653.99      1.00\n",
      " lambda[37]      3.29     10.20      1.06      0.01      6.34    720.31      1.00\n",
      " lambda[38]      9.08    120.80      1.03      0.00      6.04    898.25      1.00\n",
      " lambda[39]      2.94     10.32      0.99      0.01      6.05    839.82      1.00\n",
      " lambda[40]      2.97      9.48      0.93      0.00      5.35    896.01      1.00\n",
      " lambda[41]    168.75   1090.71      1.13      0.00     35.56    229.31      1.01\n",
      " lambda[42]      2.46      5.91      0.98      0.00      5.20    799.18      1.00\n",
      " lambda[43]      3.59     20.20      1.03      0.00      5.83    735.22      1.00\n",
      " lambda[44]      2.78      7.95      0.93      0.01      6.05    902.31      1.00\n",
      " lambda[45]      2.36      5.36      0.93      0.00      5.18    695.95      1.01\n",
      " lambda[46]      2.68      9.63      0.96      0.00      4.69    552.31      1.00\n",
      " lambda[47]      2.85      9.16      1.03      0.01      6.19    907.16      1.00\n",
      " lambda[48]      2.94      6.74      1.02      0.00      6.56    711.60      1.00\n",
      " lambda[49]      3.12     10.84      1.07      0.00      5.81    817.80      1.00\n",
      " lambda[50]      5.40     59.68      0.93      0.00      6.73    984.55      1.00\n",
      " lambda[51]      5.83     33.45      1.02      0.00      8.54    482.39      1.00\n",
      " lambda[52]      2.73      7.20      0.99      0.00      5.19    751.09      1.00\n",
      " lambda[53]      2.86      6.54      1.00      0.00      5.98    598.78      1.00\n",
      " lambda[54]      2.39      6.69      0.90      0.00      4.82    785.68      1.00\n",
      " lambda[55]      2.90     13.77      0.91      0.00      4.87    950.90      1.00\n",
      " lambda[56]      2.56      7.07      0.95      0.00      5.01    917.63      1.00\n",
      " lambda[57]      5.08     19.57      1.01      0.00      7.97    402.91      1.00\n",
      " lambda[58]      2.32      5.07      0.92      0.00      5.24    708.78      1.00\n",
      " lambda[59]      3.17     13.26      1.01      0.00      5.45    599.76      1.00\n",
      " lambda[60]      4.03     21.09      1.07      0.00      7.69    783.07      1.00\n",
      " lambda[61]      2.41      5.30      0.95      0.01      5.47    672.51      1.00\n",
      " lambda[62]   2132.22  11548.46    218.99      0.01   3363.62    547.63      1.00\n",
      " lambda[63]      2.46      5.88      0.94      0.00      5.02    617.21      1.00\n",
      " lambda[64]      2.89      8.41      1.01      0.00      5.24    817.47      1.00\n",
      " lambda[65]      2.78      9.86      1.00      0.00      5.35    947.93      1.00\n",
      " lambda[66]      2.50      5.58      0.95      0.00      5.71    690.73      1.00\n",
      " lambda[67]      2.94      9.33      1.00      0.00      5.74    809.95      1.00\n",
      " lambda[68]      3.87     12.50      0.97      0.01      7.05    689.92      1.00\n",
      " lambda[69]      4.68     18.01      1.03      0.00      8.62    597.79      1.00\n",
      " lambda[70]      3.10     10.51      0.97      0.00      5.15    549.78      1.00\n",
      " lambda[71]      2.98      7.77      1.03      0.00      5.37    461.39      1.00\n",
      " lambda[72]      2.64      8.24      1.00      0.00      5.20    462.90      1.00\n",
      " lambda[73]      3.78     38.10      0.96      0.00      5.39    986.40      1.00\n",
      " lambda[74]      3.46     16.79      0.95      0.01      5.57    524.87      1.00\n",
      " lambda[75]      8.97    138.90      1.00      0.00      6.26    788.44      1.00\n",
      " lambda[76]      4.33     40.66      1.04      0.00      5.32    579.45      1.00\n",
      " lambda[77]    162.27   1574.51      1.13      0.00     22.21    463.92      1.00\n",
      " lambda[78]      6.89     73.87      1.04      0.00      5.47    309.80      1.00\n",
      " lambda[79]      2.70      8.24      0.96      0.01      5.28    535.06      1.00\n",
      " lambda[80]      4.92     35.77      0.99      0.00      6.05    672.65      1.00\n",
      " lambda[81]      2.58      4.95      0.99      0.00      6.29    799.46      1.00\n",
      " lambda[82]      2.75      9.48      0.91      0.00      4.98    813.03      1.00\n",
      " lambda[83]      3.33     10.29      0.99      0.00      6.11    673.27      1.00\n",
      " lambda[84]      6.11     69.29      1.02      0.00      6.04    826.60      1.00\n",
      " lambda[85]      2.83      7.21      0.92      0.00      5.79    539.69      1.00\n",
      " lambda[86]      4.53     26.79      0.97      0.00      5.84    574.41      1.00\n",
      " lambda[87]      3.57     23.82      0.93      0.00      6.26    779.51      1.00\n",
      " lambda[88]      2.36      5.76      0.96      0.00      4.61    777.71      1.00\n",
      " lambda[89]    199.84   3932.69      1.10      0.00     14.96    817.11      1.00\n",
      " lambda[90]      2.48      6.61      0.92      0.00      5.04    712.69      1.00\n",
      " lambda[91]      2.99      8.63      1.02      0.00      5.44    408.11      1.00\n",
      " lambda[92]      3.32     10.14      1.03      0.00      6.72    615.23      1.00\n",
      " lambda[93]      2.49      7.40      1.00      0.00      4.99    646.99      1.00\n",
      " lambda[94]      4.12     19.68      0.99      0.01      6.71    440.07      1.00\n",
      " lambda[95]      3.84     22.54      0.97      0.00      6.53    944.04      1.00\n",
      " lambda[96]      2.98      7.54      0.98      0.00      6.09    519.29      1.00\n",
      " lambda[97]      2.30      4.80      0.97      0.00      5.10    704.98      1.00\n",
      " lambda[98]      5.97     51.44      0.92      0.00      6.19    471.99      1.00\n",
      " lambda[99]      2.15      5.42      0.89      0.00      4.48    688.51      1.00\n",
      "lambda[100]      2.53      6.21      0.96      0.00      5.30    952.99      1.00\n",
      "lambda[101]      3.59     15.87      1.03      0.00      5.74    695.26      1.00\n",
      "lambda[102]      2.43      6.18      0.93      0.00      5.27    954.25      1.00\n",
      "lambda[103]      2.13      4.85      0.91      0.00      5.00    729.13      1.00\n",
      "lambda[104]      4.19     32.53      0.91      0.00      4.34    327.21      1.00\n",
      "lambda[105]      5.18     29.82      1.02      0.00      7.38    749.80      1.00\n",
      "lambda[106]      2.52      9.30      0.90      0.00      5.29    941.54      1.00\n",
      "lambda[107]      3.47     14.55      1.04      0.00      5.07    237.63      1.00\n",
      "lambda[108]      2.66      6.73      0.96      0.00      5.41    710.00      1.00\n",
      "lambda[109]     22.43    422.01      1.00      0.00      6.79    571.25      1.00\n",
      "lambda[110]      3.91     16.65      1.00      0.00      6.44    473.25      1.01\n",
      "lambda[111]      7.89     44.22      1.12      0.00      9.46    340.86      1.00\n",
      "lambda[112]      1.88      2.95      0.94      0.01      4.21    617.92      1.00\n",
      "lambda[113]      4.15     18.58      0.98      0.00      6.68    490.67      1.00\n",
      "lambda[114]      3.33     14.79      0.96      0.00      6.43    791.29      1.00\n",
      "lambda[115]      4.24     27.54      1.00      0.00      6.72    582.91      1.00\n",
      "lambda[116]      3.57     32.08      1.01      0.01      5.29    971.50      1.00\n",
      "lambda[117]      3.05     10.21      0.90      0.00      5.43    875.11      1.00\n",
      "lambda[118]      3.02     13.46      0.91      0.00      5.56    707.64      1.00\n",
      "lambda[119]      3.65     10.92      1.03      0.00      6.85    679.29      1.00\n",
      "lambda[120]      4.36     23.25      0.96      0.00      7.29    759.75      1.00\n",
      "lambda[121]      2.61      6.98      0.99      0.00      5.65    674.38      1.00\n",
      "lambda[122]      6.28     48.71      0.99      0.00      6.06    521.46      1.00\n",
      "lambda[123]      2.61      6.10      0.91      0.00      5.84    805.93      1.00\n",
      "lambda[124]      2.88      8.48      0.98      0.00      5.59    694.63      1.00\n",
      "lambda[125]      2.91      7.97      0.97      0.00      5.82    432.50      1.00\n",
      "lambda[126]      2.41      6.62      0.97      0.00      5.25    817.72      1.00\n",
      "lambda[127]      3.23     13.37      0.96      0.00      5.30    650.15      1.00\n",
      "lambda[128]     28.12    525.42      0.96      0.00      6.09    436.06      1.00\n",
      "lambda[129]      3.19     18.35      0.90      0.00      5.20    894.88      1.00\n",
      "lambda[130]      4.10     23.29      1.01      0.00      6.08    811.39      1.00\n",
      "lambda[131]      5.89     52.67      0.98      0.00      5.43    453.08      1.00\n",
      "lambda[132]      3.47     12.76      1.03      0.00      6.11    625.11      1.00\n",
      "lambda[133]      2.73      6.78      0.92      0.00      5.35    695.10      1.00\n",
      "lambda[134]      3.63     10.52      0.96      0.00      7.23    618.85      1.00\n",
      "lambda[135]      2.61     10.93      0.97      0.00      4.92    976.00      1.00\n",
      "lambda[136]      2.66      7.17      0.93      0.00      5.31    801.99      1.00\n",
      "lambda[137]      3.04      9.01      1.05      0.00      6.11    721.96      1.00\n",
      "lambda[138]      3.25      9.99      0.98      0.00      6.42    574.10      1.00\n",
      "lambda[139]      3.23     13.02      0.97      0.00      6.32    806.78      1.00\n",
      "lambda[140]      3.43     18.99      0.97      0.00      6.00    502.17      1.00\n",
      "lambda[141]      3.46     12.40      0.99      0.00      6.84    700.94      1.00\n",
      "lambda[142]      3.39     13.31      0.97      0.00      5.01    758.87      1.00\n",
      "lambda[143]      2.54      7.27      0.95      0.00      4.83    778.78      1.00\n",
      "        msq      0.24      0.15      0.20      0.06      0.40    607.83      1.00\n",
      "      sigma      4.16      6.04      1.47      0.00     12.25    914.98      1.00\n",
      "    var_obs      0.11      0.02      0.10      0.07      0.14    360.78      1.00\n",
      "       xisq      1.96      7.47      0.57      0.08      2.78    309.97      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 28.654279947280884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t2.45e-04 +- 1.16e-02\n",
      "[dimension 02/145]  inactive:\t1.05e-03 +- 2.33e-02\n",
      "[dimension 03/145]  inactive:\t1.08e-03 +- 2.04e-02\n",
      "[dimension 04/145]  inactive:\t3.01e-03 +- 2.66e-02\n",
      "[dimension 05/145]  inactive:\t1.09e-03 +- 2.10e-02\n",
      "[dimension 06/145]  inactive:\t4.19e-03 +- 4.19e-02\n",
      "[dimension 07/145]  inactive:\t1.40e-03 +- 1.76e-02\n",
      "[dimension 08/145]  inactive:\t1.79e-03 +- 2.44e-02\n",
      "[dimension 09/145]  inactive:\t1.18e-03 +- 1.94e-02\n",
      "[dimension 10/145]  inactive:\t6.68e-04 +- 1.38e-02\n",
      "[dimension 11/145]  inactive:\t8.05e-04 +- 2.00e-02\n",
      "[dimension 12/145]  inactive:\t2.27e-03 +- 3.03e-02\n",
      "[dimension 13/145]  inactive:\t3.94e-03 +- 3.45e-02\n",
      "[dimension 14/145]  inactive:\t1.54e-04 +- 1.31e-02\n",
      "[dimension 15/145]  inactive:\t3.31e-03 +- 3.76e-02\n",
      "[dimension 16/145]  inactive:\t6.83e-04 +- 1.42e-02\n",
      "[dimension 17/145]  inactive:\t1.16e-03 +- 2.29e-02\n",
      "[dimension 18/145]  inactive:\t3.36e-03 +- 3.64e-02\n",
      "[dimension 19/145]  inactive:\t-2.13e-04 +- 1.25e-02\n",
      "[dimension 20/145]  inactive:\t4.78e-04 +- 2.34e-02\n",
      "[dimension 21/145]  inactive:\t9.28e-05 +- 1.48e-02\n",
      "[dimension 22/145]  inactive:\t3.68e-04 +- 1.23e-02\n",
      "[dimension 23/145]  inactive:\t6.75e-04 +- 1.81e-02\n",
      "[dimension 24/145]  inactive:\t1.71e-03 +- 2.55e-02\n",
      "[dimension 25/145]  inactive:\t3.03e-03 +- 2.22e-02\n",
      "[dimension 26/145]  inactive:\t4.76e-04 +- 1.66e-02\n",
      "[dimension 27/145]  inactive:\t2.20e-03 +- 2.69e-02\n",
      "[dimension 28/145]  inactive:\t6.57e-04 +- 1.29e-02\n",
      "[dimension 29/145]  inactive:\t1.33e-03 +- 2.12e-02\n",
      "[dimension 30/145]  inactive:\t1.52e-03 +- 2.03e-02\n",
      "[dimension 31/145]  inactive:\t4.07e-03 +- 3.89e-02\n",
      "[dimension 32/145]  inactive:\t2.05e-03 +- 3.23e-02\n",
      "[dimension 33/145]  inactive:\t4.16e-03 +- 3.80e-02\n",
      "[dimension 34/145]  inactive:\t9.16e-04 +- 1.58e-02\n",
      "[dimension 35/145]  inactive:\t1.16e-03 +- 2.05e-02\n",
      "[dimension 36/145]  inactive:\t2.18e-03 +- 2.66e-02\n",
      "[dimension 37/145]  inactive:\t2.27e-03 +- 1.83e-02\n",
      "[dimension 38/145]  inactive:\t8.38e-04 +- 2.52e-02\n",
      "[dimension 39/145]  inactive:\t5.18e-03 +- 4.93e-02\n",
      "[dimension 40/145]  inactive:\t1.93e-03 +- 1.93e-02\n",
      "[dimension 41/145]  inactive:\t3.46e-04 +- 1.64e-02\n",
      "[dimension 42/145]  inactive:\t6.69e-02 +- 2.19e-01\n",
      "[dimension 43/145]  inactive:\t7.03e-04 +- 1.34e-02\n",
      "[dimension 44/145]  inactive:\t1.36e-03 +- 2.41e-02\n",
      "[dimension 45/145]  inactive:\t7.90e-04 +- 1.76e-02\n",
      "[dimension 46/145]  inactive:\t4.35e-04 +- 1.02e-02\n",
      "[dimension 47/145]  inactive:\t3.48e-04 +- 2.20e-02\n",
      "[dimension 48/145]  inactive:\t1.27e-03 +- 1.93e-02\n",
      "[dimension 49/145]  inactive:\t1.50e-03 +- 1.72e-02\n",
      "[dimension 50/145]  inactive:\t8.81e-05 +- 2.07e-02\n",
      "[dimension 51/145]  inactive:\t3.38e-03 +- 3.45e-02\n",
      "[dimension 52/145]  inactive:\t5.50e-03 +- 2.78e-02\n",
      "[dimension 53/145]  inactive:\t1.90e-04 +- 1.52e-02\n",
      "[dimension 54/145]  inactive:\t9.97e-04 +- 1.49e-02\n",
      "[dimension 55/145]  inactive:\t5.66e-04 +- 1.29e-02\n",
      "[dimension 56/145]  inactive:\t-4.81e-04 +- 1.31e-02\n",
      "[dimension 57/145]  inactive:\t1.90e-03 +- 2.58e-02\n",
      "[dimension 58/145]  inactive:\t8.89e-03 +- 5.46e-02\n",
      "[dimension 59/145]  inactive:\t8.18e-05 +- 1.19e-02\n",
      "[dimension 60/145]  inactive:\t2.14e-03 +- 2.60e-02\n",
      "[dimension 61/145]  inactive:\t3.46e-03 +- 2.58e-02\n",
      "[dimension 62/145]  inactive:\t4.29e-04 +- 1.33e-02\n",
      "[dimension 63/145]  active:\t5.36e-01 +- 4.37e-01\n",
      "[dimension 64/145]  inactive:\t-8.18e-04 +- 1.40e-02\n",
      "[dimension 65/145]  inactive:\t7.18e-04 +- 1.84e-02\n",
      "[dimension 66/145]  inactive:\t5.32e-04 +- 1.54e-02\n",
      "[dimension 67/145]  inactive:\t6.78e-04 +- 1.46e-02\n",
      "[dimension 68/145]  inactive:\t4.34e-04 +- 1.88e-02\n",
      "[dimension 69/145]  inactive:\t4.49e-03 +- 4.12e-02\n",
      "[dimension 70/145]  inactive:\t4.02e-03 +- 2.49e-02\n",
      "[dimension 71/145]  inactive:\t1.54e-03 +- 2.70e-02\n",
      "[dimension 72/145]  inactive:\t1.52e-03 +- 1.93e-02\n",
      "[dimension 73/145]  inactive:\t6.23e-04 +- 1.25e-02\n",
      "[dimension 74/145]  inactive:\t4.17e-04 +- 2.02e-02\n",
      "[dimension 75/145]  inactive:\t2.52e-03 +- 3.08e-02\n",
      "[dimension 76/145]  inactive:\t5.80e-03 +- 4.36e-02\n",
      "[dimension 77/145]  inactive:\t6.11e-04 +- 2.29e-02\n",
      "[dimension 78/145]  inactive:\t4.78e-02 +- 1.74e-01\n",
      "[dimension 79/145]  inactive:\t6.04e-03 +- 4.02e-02\n",
      "[dimension 80/145]  inactive:\t1.89e-03 +- 2.73e-02\n",
      "[dimension 81/145]  inactive:\t3.56e-03 +- 3.83e-02\n",
      "[dimension 82/145]  inactive:\t5.10e-04 +- 1.24e-02\n",
      "[dimension 83/145]  inactive:\t-3.96e-04 +- 1.21e-02\n",
      "[dimension 84/145]  inactive:\t4.62e-04 +- 1.64e-02\n",
      "[dimension 85/145]  inactive:\t3.30e-03 +- 3.28e-02\n",
      "[dimension 86/145]  inactive:\t8.84e-05 +- 1.29e-02\n",
      "[dimension 87/145]  inactive:\t2.74e-03 +- 3.00e-02\n",
      "[dimension 88/145]  inactive:\t2.15e-03 +- 2.19e-02\n",
      "[dimension 89/145]  inactive:\t1.60e-05 +- 1.21e-02\n",
      "[dimension 90/145]  inactive:\t5.03e-02 +- 1.91e-01\n",
      "[dimension 91/145]  inactive:\t1.39e-04 +- 1.25e-02\n",
      "[dimension 92/145]  inactive:\t8.09e-05 +- 1.51e-02\n",
      "[dimension 93/145]  inactive:\t1.03e-04 +- 1.81e-02\n",
      "[dimension 94/145]  inactive:\t9.47e-04 +- 1.53e-02\n",
      "[dimension 95/145]  inactive:\t1.18e-03 +- 2.42e-02\n",
      "[dimension 96/145]  inactive:\t1.50e-03 +- 2.58e-02\n",
      "[dimension 97/145]  inactive:\t2.66e-03 +- 2.16e-02\n",
      "[dimension 98/145]  inactive:\t4.60e-04 +- 1.46e-02\n",
      "[dimension 99/145]  inactive:\t5.68e-03 +- 5.11e-02\n",
      "[dimension 100/145]  inactive:\t1.28e-04 +- 1.03e-02\n",
      "[dimension 101/145]  inactive:\t-4.33e-04 +- 1.13e-02\n",
      "[dimension 102/145]  inactive:\t1.50e-03 +- 2.39e-02\n",
      "[dimension 103/145]  inactive:\t9.63e-04 +- 1.62e-02\n",
      "[dimension 104/145]  inactive:\t-4.18e-06 +- 1.09e-02\n",
      "[dimension 105/145]  inactive:\t1.12e-03 +- 2.00e-02\n",
      "[dimension 106/145]  inactive:\t6.18e-03 +- 3.96e-02\n",
      "[dimension 107/145]  inactive:\t-2.08e-04 +- 1.15e-02\n",
      "[dimension 108/145]  inactive:\t4.49e-03 +- 4.23e-02\n",
      "[dimension 109/145]  inactive:\t6.00e-05 +- 1.14e-02\n",
      "[dimension 110/145]  inactive:\t2.36e-03 +- 3.23e-02\n",
      "[dimension 111/145]  inactive:\t3.51e-03 +- 3.62e-02\n",
      "[dimension 112/145]  inactive:\t9.29e-03 +- 5.97e-02\n",
      "[dimension 113/145]  inactive:\t-1.71e-05 +- 1.08e-02\n",
      "[dimension 114/145]  inactive:\t3.01e-03 +- 3.72e-02\n",
      "[dimension 115/145]  inactive:\t1.57e-03 +- 1.74e-02\n",
      "[dimension 116/145]  inactive:\t1.50e-03 +- 2.59e-02\n",
      "[dimension 117/145]  inactive:\t2.43e-03 +- 3.36e-02\n",
      "[dimension 118/145]  inactive:\t1.55e-03 +- 1.66e-02\n",
      "[dimension 119/145]  inactive:\t4.95e-04 +- 1.83e-02\n",
      "[dimension 120/145]  inactive:\t1.97e-03 +- 2.73e-02\n",
      "[dimension 121/145]  inactive:\t3.94e-03 +- 3.43e-02\n",
      "[dimension 122/145]  inactive:\t4.69e-05 +- 1.69e-02\n",
      "[dimension 123/145]  inactive:\t5.71e-03 +- 5.48e-02\n",
      "[dimension 124/145]  inactive:\t-6.24e-05 +- 1.21e-02\n",
      "[dimension 125/145]  inactive:\t9.27e-05 +- 1.63e-02\n",
      "[dimension 126/145]  inactive:\t1.38e-03 +- 2.46e-02\n",
      "[dimension 127/145]  inactive:\t4.14e-04 +- 1.20e-02\n",
      "[dimension 128/145]  inactive:\t1.65e-03 +- 2.74e-02\n",
      "[dimension 129/145]  inactive:\t2.23e-03 +- 3.27e-02\n",
      "[dimension 130/145]  inactive:\t2.00e-03 +- 2.02e-02\n",
      "[dimension 131/145]  inactive:\t1.09e-03 +- 2.83e-02\n",
      "[dimension 132/145]  inactive:\t3.66e-03 +- 3.73e-02\n",
      "[dimension 133/145]  inactive:\t2.04e-03 +- 1.81e-02\n",
      "[dimension 134/145]  inactive:\t6.18e-04 +- 1.68e-02\n",
      "[dimension 135/145]  inactive:\t2.56e-03 +- 3.07e-02\n",
      "[dimension 136/145]  inactive:\t1.05e-03 +- 1.42e-02\n",
      "[dimension 137/145]  inactive:\t5.67e-04 +- 1.61e-02\n",
      "[dimension 138/145]  inactive:\t8.54e-04 +- 1.45e-02\n",
      "[dimension 139/145]  inactive:\t1.52e-03 +- 2.41e-02\n",
      "[dimension 140/145]  inactive:\t7.35e-04 +- 2.15e-02\n",
      "[dimension 141/145]  inactive:\t1.57e-03 +- 2.43e-02\n",
      "[dimension 142/145]  inactive:\t2.04e-03 +- 1.73e-02\n",
      "[dimension 143/145]  inactive:\t2.37e-03 +- 3.32e-02\n",
      "[dimension 144/145]  inactive:\t1.51e-03 +- 1.97e-02\n",
      "[dimension 145/145]  inactive:\t3.38e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[6.824732e-06]\n",
      "cov_act[[9.49949e-07]]\n",
      "Active_dimensions: [62]\n",
      "6, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:27<00:00, 54.13it/s, 31 steps of size 1.57e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    747.43      1.00\n",
      "  lambda[0]      2.18      5.09      0.93      0.00      4.44    727.97      1.00\n",
      "  lambda[1]      3.29     12.51      1.01      0.00      5.62    658.32      1.01\n",
      "  lambda[2]      2.99     10.52      1.01      0.00      5.79    667.06      1.00\n",
      "  lambda[3]      4.83     26.83      0.95      0.00      7.13    586.17      1.00\n",
      "  lambda[4]      3.31     14.96      1.03      0.00      5.89    781.95      1.00\n",
      "  lambda[5]      3.13     10.28      0.99      0.00      5.68    872.93      1.00\n",
      "  lambda[6]      3.15     13.23      1.01      0.00      6.01    892.26      1.00\n",
      "  lambda[7]      3.18     11.48      0.97      0.00      5.62    657.63      1.00\n",
      "  lambda[8]      2.29      4.72      0.99      0.00      5.00    708.00      1.00\n",
      "  lambda[9]      2.43      7.32      0.90      0.00      4.57    959.42      1.00\n",
      " lambda[10]      3.75     14.95      1.00      0.00      6.34    884.60      1.00\n",
      " lambda[11]      3.04      7.06      1.02      0.01      6.76    657.21      1.00\n",
      " lambda[12]      4.66     16.33      1.01      0.00      8.27    896.44      1.00\n",
      " lambda[13]      2.66      8.63      0.92      0.00      5.29    736.06      1.00\n",
      " lambda[14]      4.54     30.25      0.94      0.00      5.40    847.86      1.00\n",
      " lambda[15]      2.81      8.34      0.99      0.00      4.75    592.54      1.00\n",
      " lambda[16]      3.82     11.63      0.99      0.00      8.66    727.26      1.00\n",
      " lambda[17]      3.36     25.65      0.98      0.00      5.17    776.68      1.00\n",
      " lambda[18]      2.93      7.29      0.92      0.00      6.53    687.98      1.00\n",
      " lambda[19]      5.02     46.98      0.92      0.00      6.21    524.58      1.00\n",
      " lambda[20]      3.18      9.65      0.99      0.00      6.72    855.19      1.00\n",
      " lambda[21]      3.39     11.70      1.01      0.00      6.35    856.87      1.00\n",
      " lambda[22]      2.41      5.30      0.97      0.00      5.28    720.34      1.00\n",
      " lambda[23]      2.91      7.84      0.98      0.00      6.13    802.02      1.00\n",
      " lambda[24]      3.17      8.74      1.00      0.00      6.27    743.30      1.00\n",
      " lambda[25]      2.99      6.68      0.95      0.01      6.56    601.37      1.00\n",
      " lambda[26]      2.94     10.01      1.01      0.00      5.64    838.75      1.00\n",
      " lambda[27]      3.01      7.65      0.97      0.00      5.78    520.48      1.00\n",
      " lambda[28]      2.68      7.98      1.00      0.00      5.25    715.96      1.00\n",
      " lambda[29]      3.36     11.30      0.95      0.00      6.94    706.47      1.00\n",
      " lambda[30]      4.18     21.48      1.01      0.00      6.44    578.47      1.00\n",
      " lambda[31]      3.63     14.29      0.99      0.00      6.79    725.62      1.00\n",
      " lambda[32]      3.81     14.88      0.90      0.00      6.64    671.69      1.00\n",
      " lambda[33]      2.85      7.93      0.99      0.01      5.34    474.11      1.00\n",
      " lambda[34]      2.83     10.66      1.01      0.00      5.79    651.49      1.00\n",
      " lambda[35]      2.37      6.02      0.99      0.00      4.48    951.02      1.00\n",
      " lambda[36]      3.49     13.79      1.03      0.00      6.23    907.65      1.00\n",
      " lambda[37]      2.79      6.52      0.98      0.00      6.16    742.56      1.00\n",
      " lambda[38]      2.88      6.58      0.96      0.00      5.78    838.42      1.00\n",
      " lambda[39]      3.68     13.42      0.97      0.00      5.55    494.86      1.00\n",
      " lambda[40]      4.50     26.11      0.92      0.00      6.09    841.68      1.00\n",
      " lambda[41]     36.22    446.25      0.95      0.00     11.78    434.56      1.00\n",
      " lambda[42]      2.50      5.61      0.95      0.00      5.41    777.54      1.01\n",
      " lambda[43]      3.59     20.70      0.99      0.00      5.90    997.60      1.00\n",
      " lambda[44]      2.58      7.16      0.92      0.00      5.28    870.72      1.00\n",
      " lambda[45]      2.60      5.76      0.98      0.00      5.50    734.13      1.00\n",
      " lambda[46]      3.12      9.73      1.02      0.00      5.46    657.75      1.00\n",
      " lambda[47]      2.57      5.21      0.96      0.01      6.14    712.26      1.00\n",
      " lambda[48]      2.83      9.24      1.04      0.00      5.76    747.73      1.00\n",
      " lambda[49]      2.94      8.60      0.92      0.00      5.94    768.15      1.00\n",
      " lambda[50]      3.06     10.14      0.95      0.00      5.66    718.09      1.00\n",
      " lambda[51]      4.91     27.73      1.02      0.00      7.53    961.89      1.00\n",
      " lambda[52]      3.64     15.82      0.95      0.00      5.85    599.19      1.00\n",
      " lambda[53]      7.59    111.10      0.94      0.01      5.06    528.61      1.00\n",
      " lambda[54]      2.35      5.62      0.91      0.00      5.11    426.78      1.00\n",
      " lambda[55]      3.59     23.65      0.99      0.00      5.83    969.12      1.00\n",
      " lambda[56]      2.77      6.60      1.02      0.00      5.29    758.54      1.00\n",
      " lambda[57]      6.19     28.84      0.99      0.00      8.92    499.06      1.01\n",
      " lambda[58]      2.48      5.54      1.01      0.00      5.43    612.83      1.00\n",
      " lambda[59]      3.36     10.61      1.01      0.00      7.31    458.83      1.00\n",
      " lambda[60]      2.63      6.36      0.96      0.00      5.85    667.24      1.00\n",
      " lambda[61]      2.58      5.40      1.01      0.00      5.99    807.41      1.00\n",
      " lambda[62]   2600.60  34818.41    119.16      0.00   1187.47    577.50      1.00\n",
      " lambda[63]      2.49     10.13      1.04      0.00      5.02    931.80      1.00\n",
      " lambda[64]      3.89     18.50      0.97      0.00      5.86    346.99      1.00\n",
      " lambda[65]      3.27     11.57      0.94      0.00      6.10    553.99      1.00\n",
      " lambda[66]      3.49     11.92      1.01      0.00      6.67    673.77      1.00\n",
      " lambda[67]      2.82      8.20      0.92      0.00      5.88    616.39      1.00\n",
      " lambda[68]      6.79     73.18      0.94      0.00      5.67    473.25      1.00\n",
      " lambda[69]      3.48     12.09      0.95      0.00      6.11    919.34      1.00\n",
      " lambda[70]      2.51      5.09      1.01      0.01      5.23    587.27      1.00\n",
      " lambda[71]      2.44      5.91      0.97      0.00      4.48    526.45      1.00\n",
      " lambda[72]      2.72      9.27      0.97      0.00      4.94    434.14      1.00\n",
      " lambda[73]      2.56      5.89      1.01      0.00      5.34    704.78      1.00\n",
      " lambda[74]      2.35      3.92      1.06      0.00      5.60    856.02      1.00\n",
      " lambda[75]      4.18     13.53      1.00      0.00      7.17    661.75      1.00\n",
      " lambda[76]      3.04      8.52      0.96      0.00      5.65    754.59      1.00\n",
      " lambda[77]      6.38     45.20      1.09      0.00      7.95    613.52      1.00\n",
      " lambda[78]      4.05     19.60      1.09      0.00      6.41    810.61      1.00\n",
      " lambda[79]      3.30     13.85      1.02      0.00      6.11    759.59      1.00\n",
      " lambda[80]      4.35     24.76      1.05      0.00      5.90    640.23      1.00\n",
      " lambda[81]      2.52     10.07      0.99      0.00      4.88    689.46      1.00\n",
      " lambda[82]      2.33      5.65      0.96      0.00      4.63    795.44      1.00\n",
      " lambda[83]      3.28      9.80      0.93      0.00      7.05    800.43      1.00\n",
      " lambda[84]      4.79     40.12      1.00      0.00      6.05    912.31      1.00\n",
      " lambda[85]      3.15     12.34      0.94      0.00      5.58    380.80      1.00\n",
      " lambda[86]      4.69     27.47      0.99      0.01      5.75    714.24      1.00\n",
      " lambda[87]      4.21     22.60      0.93      0.00      6.15    681.70      1.00\n",
      " lambda[88]      2.85     10.31      0.93      0.00      5.75    932.46      1.00\n",
      " lambda[89]    112.40    830.60      1.42      0.00    145.57    717.25      1.00\n",
      " lambda[90]      2.73     13.64      0.95      0.00      5.20   1023.09      1.00\n",
      " lambda[91]      2.58      6.83      0.97      0.02      5.02    763.23      1.00\n",
      " lambda[92]      2.52      5.57      1.07      0.00      5.17    784.45      1.00\n",
      " lambda[93]      2.77      6.74      1.04      0.00      5.80    771.63      1.00\n",
      " lambda[94]      2.57      7.33      0.98      0.01      5.31    831.00      1.00\n",
      " lambda[95]      3.41     13.50      1.02      0.00      6.22    591.15      1.00\n",
      " lambda[96]      3.67     19.34      1.03      0.00      5.25    534.73      1.00\n",
      " lambda[97]      5.04     53.34      0.98      0.00      5.87    522.91      1.00\n",
      " lambda[98]      6.56     52.06      0.96      0.00      6.50    443.81      1.00\n",
      " lambda[99]      2.72      8.52      0.99      0.00      5.00    513.93      1.00\n",
      "lambda[100]      3.46     13.13      0.95      0.01      6.54    838.58      1.00\n",
      "lambda[101]      2.89      6.92      0.91      0.00      6.18    607.23      1.00\n",
      "lambda[102]      2.89      8.46      0.94      0.00      5.56    817.81      1.00\n",
      "lambda[103]      2.38      4.60      0.98      0.00      5.28    814.69      1.00\n",
      "lambda[104]      4.20     31.97      0.98      0.00      6.44    757.45      1.00\n",
      "lambda[105]      3.93     14.67      1.07      0.00      6.19    563.07      1.00\n",
      "lambda[106]      2.61      6.22      0.98      0.00      5.42    674.91      1.00\n",
      "lambda[107]      6.25     36.21      1.03      0.00      7.01    737.70      1.00\n",
      "lambda[108]      2.24      5.49      0.98      0.00      4.47    580.74      1.01\n",
      "lambda[109]      3.36     10.46      0.97      0.00      6.62    802.65      1.00\n",
      "lambda[110]      3.89     15.56      0.97      0.00      6.63    810.65      1.00\n",
      "lambda[111]      3.25     12.66      0.91      0.00      5.49    705.12      1.00\n",
      "lambda[112]      3.73     24.86      0.92      0.00      6.00    638.73      1.00\n",
      "lambda[113]      3.95     19.09      1.01      0.00      6.46    776.66      1.00\n",
      "lambda[114]      3.79     15.08      1.01      0.00      6.16    891.43      1.00\n",
      "lambda[115]      4.12     23.31      0.96      0.00      6.01    583.12      1.00\n",
      "lambda[116]      5.05     29.94      0.99      0.00      5.92    332.82      1.00\n",
      "lambda[117]      3.41     13.08      0.99      0.00      6.55    818.73      1.00\n",
      "lambda[118]      3.06     10.21      0.97      0.00      6.37    936.11      1.00\n",
      "lambda[119]      2.99     15.29      1.02      0.00      5.55   1002.29      1.00\n",
      "lambda[120]      3.89     16.81      0.96      0.00      6.31    821.43      1.00\n",
      "lambda[121]      3.24     12.61      0.90      0.00      5.63    788.01      1.00\n",
      "lambda[122]      4.62     40.36      1.00      0.00      6.24    833.81      1.00\n",
      "lambda[123]      2.78      6.96      0.88      0.00      6.03    661.03      1.00\n",
      "lambda[124]      2.60      6.32      0.96      0.01      5.50    758.58      1.00\n",
      "lambda[125]      3.12     10.35      0.99      0.00      5.68    563.93      1.00\n",
      "lambda[126]      2.49      6.97      0.95      0.00      5.12    925.49      1.00\n",
      "lambda[127]      4.10     18.67      1.00      0.00      6.28    549.66      1.00\n",
      "lambda[128]      3.48     16.36      0.99      0.00      5.54    437.81      1.00\n",
      "lambda[129]      4.91     35.31      1.02      0.00      7.95   1013.77      1.00\n",
      "lambda[130]      3.25      7.96      0.95      0.00      6.51    646.94      1.00\n",
      "lambda[131]      3.35      9.98      0.99      0.00      6.19    692.92      1.00\n",
      "lambda[132]      2.75      6.64      0.94      0.00      5.48    849.50      1.00\n",
      "lambda[133]      2.79     11.08      0.99      0.00      5.20    593.40      1.00\n",
      "lambda[134]      3.64      9.88      0.91      0.00      7.76    592.14      1.01\n",
      "lambda[135]      3.37     17.31      0.96      0.00      5.50    691.51      1.00\n",
      "lambda[136]      3.63     18.06      1.01      0.01      6.31    843.34      1.00\n",
      "lambda[137]      2.59      6.83      0.97      0.00      5.39    816.50      1.00\n",
      "lambda[138]      3.25     12.46      1.01      0.00      5.27    719.67      1.00\n",
      "lambda[139]      3.34     10.10      0.98      0.00      6.34    955.92      1.00\n",
      "lambda[140]      3.08      9.47      0.95      0.00      5.54    910.74      1.00\n",
      "lambda[141]      2.37      5.99      0.87      0.00      5.07    566.46      1.00\n",
      "lambda[142]      4.63     23.43      1.01      0.01      6.18    828.88      1.00\n",
      "lambda[143]      2.37      5.37      0.93      0.00      5.34    589.88      1.00\n",
      "        msq    445.49   6956.62      3.31      0.13     77.08    929.65      1.00\n",
      "      sigma      4.73      6.22      2.29      0.01     12.73    991.74      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    678.35      1.00\n",
      "       xisq      0.12      0.07      0.10      0.04      0.20   1304.83      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.361026763916016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.50e-04 +- 1.80e-02\n",
      "[dimension 02/145]  inactive:\t1.92e-04 +- 2.73e-02\n",
      "[dimension 03/145]  inactive:\t3.58e-04 +- 2.75e-02\n",
      "[dimension 04/145]  inactive:\t7.68e-03 +- 4.79e-02\n",
      "[dimension 05/145]  inactive:\t-1.46e-03 +- 4.14e-02\n",
      "[dimension 06/145]  inactive:\t3.24e-03 +- 3.96e-02\n",
      "[dimension 07/145]  inactive:\t5.91e-04 +- 2.06e-02\n",
      "[dimension 08/145]  inactive:\t1.00e-03 +- 2.90e-02\n",
      "[dimension 09/145]  inactive:\t4.67e-04 +- 2.21e-02\n",
      "[dimension 10/145]  inactive:\t3.89e-04 +- 1.84e-02\n",
      "[dimension 11/145]  inactive:\t-5.51e-04 +- 2.59e-02\n",
      "[dimension 12/145]  inactive:\t2.23e-04 +- 3.27e-02\n",
      "[dimension 13/145]  inactive:\t6.74e-03 +- 5.06e-02\n",
      "[dimension 14/145]  inactive:\t-1.15e-03 +- 2.53e-02\n",
      "[dimension 15/145]  inactive:\t2.33e-04 +- 3.94e-02\n",
      "[dimension 16/145]  inactive:\t1.28e-03 +- 2.21e-02\n",
      "[dimension 17/145]  inactive:\t-2.31e-04 +- 3.17e-02\n",
      "[dimension 18/145]  inactive:\t1.37e-03 +- 3.46e-02\n",
      "[dimension 19/145]  inactive:\t-2.58e-03 +- 2.27e-02\n",
      "[dimension 20/145]  inactive:\t-1.38e-03 +- 3.09e-02\n",
      "[dimension 21/145]  inactive:\t-2.61e-03 +- 3.12e-02\n",
      "[dimension 22/145]  inactive:\t2.41e-04 +- 2.46e-02\n",
      "[dimension 23/145]  inactive:\t-4.94e-04 +- 2.36e-02\n",
      "[dimension 24/145]  inactive:\t1.58e-03 +- 2.80e-02\n",
      "[dimension 25/145]  inactive:\t3.75e-03 +- 2.56e-02\n",
      "[dimension 26/145]  inactive:\t-1.13e-03 +- 3.23e-02\n",
      "[dimension 27/145]  inactive:\t9.65e-04 +- 2.47e-02\n",
      "[dimension 28/145]  inactive:\t7.49e-04 +- 2.28e-02\n",
      "[dimension 29/145]  inactive:\t-3.39e-05 +- 2.88e-02\n",
      "[dimension 30/145]  inactive:\t1.19e-03 +- 3.33e-02\n",
      "[dimension 31/145]  inactive:\t7.41e-03 +- 5.46e-02\n",
      "[dimension 32/145]  inactive:\t-1.98e-03 +- 3.27e-02\n",
      "[dimension 33/145]  inactive:\t6.20e-03 +- 6.10e-02\n",
      "[dimension 34/145]  inactive:\t6.34e-04 +- 2.33e-02\n",
      "[dimension 35/145]  inactive:\t6.79e-04 +- 3.13e-02\n",
      "[dimension 36/145]  inactive:\t1.00e-03 +- 2.59e-02\n",
      "[dimension 37/145]  inactive:\t3.99e-03 +- 2.68e-02\n",
      "[dimension 38/145]  inactive:\t-1.22e-03 +- 3.11e-02\n",
      "[dimension 39/145]  inactive:\t1.70e-03 +- 3.37e-02\n",
      "[dimension 40/145]  inactive:\t6.43e-03 +- 4.61e-02\n",
      "[dimension 41/145]  inactive:\t-2.05e-03 +- 3.51e-02\n",
      "[dimension 42/145]  inactive:\t3.23e-02 +- 1.63e-01\n",
      "[dimension 43/145]  inactive:\t-1.82e-04 +- 1.98e-02\n",
      "[dimension 44/145]  inactive:\t-1.50e-04 +- 3.47e-02\n",
      "[dimension 45/145]  inactive:\t6.06e-05 +- 2.81e-02\n",
      "[dimension 46/145]  inactive:\t1.27e-03 +- 1.88e-02\n",
      "[dimension 47/145]  inactive:\t-3.13e-03 +- 3.80e-02\n",
      "[dimension 48/145]  inactive:\t2.54e-03 +- 3.03e-02\n",
      "[dimension 49/145]  inactive:\t3.08e-03 +- 2.83e-02\n",
      "[dimension 50/145]  inactive:\t-1.97e-03 +- 3.21e-02\n",
      "[dimension 51/145]  inactive:\t5.12e-03 +- 4.43e-02\n",
      "[dimension 52/145]  inactive:\t6.82e-03 +- 2.92e-02\n",
      "[dimension 53/145]  inactive:\t-1.19e-03 +- 3.08e-02\n",
      "[dimension 54/145]  inactive:\t3.95e-04 +- 2.38e-02\n",
      "[dimension 55/145]  inactive:\t9.77e-04 +- 2.04e-02\n",
      "[dimension 56/145]  inactive:\t-3.05e-03 +- 2.58e-02\n",
      "[dimension 57/145]  inactive:\t1.41e-03 +- 3.18e-02\n",
      "[dimension 58/145]  inactive:\t1.69e-02 +- 8.02e-02\n",
      "[dimension 59/145]  inactive:\t-6.86e-04 +- 1.88e-02\n",
      "[dimension 60/145]  inactive:\t2.19e-03 +- 3.72e-02\n",
      "[dimension 61/145]  inactive:\t3.40e-03 +- 2.83e-02\n",
      "[dimension 62/145]  inactive:\t-4.80e-04 +- 2.51e-02\n",
      "[dimension 63/145]  active:\t5.95e-01 +- 4.62e-01\n",
      "[dimension 64/145]  inactive:\t-2.38e-03 +- 2.31e-02\n",
      "[dimension 65/145]  inactive:\t-1.86e-04 +- 3.58e-02\n",
      "[dimension 66/145]  inactive:\t9.81e-04 +- 2.73e-02\n",
      "[dimension 67/145]  inactive:\t1.64e-03 +- 2.81e-02\n",
      "[dimension 68/145]  inactive:\t-1.13e-03 +- 3.17e-02\n",
      "[dimension 69/145]  inactive:\t5.94e-03 +- 5.47e-02\n",
      "[dimension 70/145]  inactive:\t3.58e-03 +- 2.47e-02\n",
      "[dimension 71/145]  inactive:\t4.65e-04 +- 2.52e-02\n",
      "[dimension 72/145]  inactive:\t4.90e-04 +- 2.15e-02\n",
      "[dimension 73/145]  inactive:\t3.02e-04 +- 1.90e-02\n",
      "[dimension 74/145]  inactive:\t-5.51e-04 +- 3.56e-02\n",
      "[dimension 75/145]  inactive:\t5.03e-04 +- 2.29e-02\n",
      "[dimension 76/145]  inactive:\t7.82e-03 +- 4.77e-02\n",
      "[dimension 77/145]  inactive:\t-1.67e-03 +- 3.35e-02\n",
      "[dimension 78/145]  inactive:\t1.32e-02 +- 8.85e-02\n",
      "[dimension 79/145]  inactive:\t7.65e-03 +- 4.18e-02\n",
      "[dimension 80/145]  inactive:\t-5.22e-05 +- 3.24e-02\n",
      "[dimension 81/145]  inactive:\t1.78e-03 +- 3.24e-02\n",
      "[dimension 82/145]  inactive:\t2.57e-04 +- 1.62e-02\n",
      "[dimension 83/145]  inactive:\t-1.10e-03 +- 1.83e-02\n",
      "[dimension 84/145]  inactive:\t-1.11e-03 +- 3.12e-02\n",
      "[dimension 85/145]  inactive:\t3.57e-03 +- 3.64e-02\n",
      "[dimension 86/145]  inactive:\t-1.24e-04 +- 2.30e-02\n",
      "[dimension 87/145]  inactive:\t5.67e-03 +- 5.79e-02\n",
      "[dimension 88/145]  inactive:\t3.92e-03 +- 2.90e-02\n",
      "[dimension 89/145]  inactive:\t-7.61e-04 +- 2.43e-02\n",
      "[dimension 90/145]  inactive:\t1.37e-01 +- 3.17e-01\n",
      "[dimension 91/145]  inactive:\t-9.78e-05 +- 1.82e-02\n",
      "[dimension 92/145]  inactive:\t-1.24e-03 +- 2.69e-02\n",
      "[dimension 93/145]  inactive:\t-7.31e-04 +- 3.10e-02\n",
      "[dimension 94/145]  inactive:\t2.52e-03 +- 3.19e-02\n",
      "[dimension 95/145]  inactive:\t-2.15e-04 +- 2.10e-02\n",
      "[dimension 96/145]  inactive:\t1.70e-03 +- 4.41e-02\n",
      "[dimension 97/145]  inactive:\t3.37e-03 +- 2.81e-02\n",
      "[dimension 98/145]  inactive:\t-5.91e-04 +- 2.82e-02\n",
      "[dimension 99/145]  inactive:\t6.66e-03 +- 6.21e-02\n",
      "[dimension 100/145]  inactive:\t-4.77e-04 +- 1.75e-02\n",
      "[dimension 101/145]  inactive:\t-3.05e-03 +- 2.41e-02\n",
      "[dimension 102/145]  inactive:\t-7.91e-04 +- 3.18e-02\n",
      "[dimension 103/145]  inactive:\t1.14e-03 +- 2.77e-02\n",
      "[dimension 104/145]  inactive:\t-7.68e-04 +- 1.85e-02\n",
      "[dimension 105/145]  inactive:\t4.98e-04 +- 3.21e-02\n",
      "[dimension 106/145]  inactive:\t7.06e-03 +- 4.28e-02\n",
      "[dimension 107/145]  inactive:\t-1.10e-03 +- 2.13e-02\n",
      "[dimension 108/145]  inactive:\t1.67e-02 +- 1.07e-01\n",
      "[dimension 109/145]  inactive:\t-5.22e-04 +- 1.96e-02\n",
      "[dimension 110/145]  inactive:\t-1.12e-03 +- 3.21e-02\n",
      "[dimension 111/145]  inactive:\t3.43e-03 +- 4.19e-02\n",
      "[dimension 112/145]  inactive:\t4.97e-03 +- 4.15e-02\n",
      "[dimension 113/145]  inactive:\t-1.62e-03 +- 2.82e-02\n",
      "[dimension 114/145]  inactive:\t4.53e-05 +- 2.94e-02\n",
      "[dimension 115/145]  inactive:\t2.62e-03 +- 2.71e-02\n",
      "[dimension 116/145]  inactive:\t3.54e-03 +- 6.07e-02\n",
      "[dimension 117/145]  inactive:\t5.62e-03 +- 5.35e-02\n",
      "[dimension 118/145]  inactive:\t2.99e-03 +- 2.45e-02\n",
      "[dimension 119/145]  inactive:\t-2.37e-03 +- 3.61e-02\n",
      "[dimension 120/145]  inactive:\t1.99e-04 +- 2.73e-02\n",
      "[dimension 121/145]  inactive:\t4.36e-03 +- 3.75e-02\n",
      "[dimension 122/145]  inactive:\t-2.72e-03 +- 2.94e-02\n",
      "[dimension 123/145]  inactive:\t3.27e-03 +- 5.17e-02\n",
      "[dimension 124/145]  inactive:\t-1.50e-03 +- 2.18e-02\n",
      "[dimension 125/145]  inactive:\t-1.69e-03 +- 2.84e-02\n",
      "[dimension 126/145]  inactive:\t-7.64e-04 +- 2.60e-02\n",
      "[dimension 127/145]  inactive:\t-1.06e-05 +- 1.88e-02\n",
      "[dimension 128/145]  inactive:\t-7.49e-04 +- 3.74e-02\n",
      "[dimension 129/145]  inactive:\t8.22e-04 +- 3.00e-02\n",
      "[dimension 130/145]  inactive:\t4.78e-03 +- 3.47e-02\n",
      "[dimension 131/145]  inactive:\t-6.68e-04 +- 3.54e-02\n",
      "[dimension 132/145]  inactive:\t4.93e-03 +- 4.57e-02\n",
      "[dimension 133/145]  inactive:\t2.67e-03 +- 2.28e-02\n",
      "[dimension 134/145]  inactive:\t-4.98e-04 +- 2.86e-02\n",
      "[dimension 135/145]  inactive:\t9.11e-04 +- 3.57e-02\n",
      "[dimension 136/145]  inactive:\t1.24e-03 +- 2.52e-02\n",
      "[dimension 137/145]  inactive:\t2.91e-04 +- 3.90e-02\n",
      "[dimension 138/145]  inactive:\t6.28e-04 +- 2.41e-02\n",
      "[dimension 139/145]  inactive:\t6.10e-04 +- 2.22e-02\n",
      "[dimension 140/145]  inactive:\t-1.23e-03 +- 3.24e-02\n",
      "[dimension 141/145]  inactive:\t1.46e-03 +- 3.13e-02\n",
      "[dimension 142/145]  inactive:\t1.41e-03 +- 1.87e-02\n",
      "[dimension 143/145]  inactive:\t2.30e-03 +- 4.02e-02\n",
      "[dimension 144/145]  inactive:\t4.90e-04 +- 2.21e-02\n",
      "[dimension 145/145]  inactive:\t-3.28e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9499717]\n",
      "cov_act[[0.0451012]]\n",
      "Active_dimensions: [62]\n",
      "7, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [03:11<00:00,  7.82it/s, 15 steps of size 2.06e-01. acc. prob=0.86]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    358.26      1.00\n",
      "  lambda[0]      2.48      6.75      0.93      0.00      5.11    801.75      1.00\n",
      "  lambda[1]      2.72      7.39      0.91      0.01      6.16    752.87      1.00\n",
      "  lambda[2]      2.95      9.58      1.01      0.01      5.54    631.65      1.00\n",
      "  lambda[3]      3.48     11.19      0.96      0.01      6.54    629.54      1.00\n",
      "  lambda[4]      2.82     10.64      0.97      0.00      5.69    854.18      1.00\n",
      "  lambda[5]      4.16     27.47      0.98      0.00      5.30    547.07      1.00\n",
      "  lambda[6]     10.06    211.07      1.03      0.00      7.16    935.70      1.00\n",
      "  lambda[7]      2.81      6.42      0.91      0.00      6.29    819.37      1.00\n",
      "  lambda[8]      2.84      7.12      1.00      0.00      5.80    676.79      1.00\n",
      "  lambda[9]      2.51      5.17      1.04      0.00      5.13    792.54      1.00\n",
      " lambda[10]      2.82      6.36      1.05      0.00      5.66    544.17      1.00\n",
      " lambda[11]      3.52     15.57      1.03      0.00      5.79    705.17      1.00\n",
      " lambda[12]      7.40     35.26      0.99      0.00      9.83    533.49      1.00\n",
      " lambda[13]      2.96     12.98      0.97      0.00      5.51    712.90      1.00\n",
      " lambda[14]      4.59     25.55      1.01      0.00      6.54    565.53      1.00\n",
      " lambda[15]      2.49      5.47      0.99      0.00      5.33    890.09      1.00\n",
      " lambda[16]      3.30     11.30      0.99      0.00      6.56    813.31      1.00\n",
      " lambda[17]      8.26    154.85      1.04      0.00      5.56    831.90      1.00\n",
      " lambda[18]      3.80     12.90      1.02      0.00      6.33    517.45      1.00\n",
      " lambda[19]      2.94      8.42      1.00      0.00      5.81    610.49      1.00\n",
      " lambda[20]      3.21     11.14      1.07      0.00      5.67    781.23      1.00\n",
      " lambda[21]      2.90      7.56      1.00      0.00      6.28    341.13      1.00\n",
      " lambda[22]      2.43      5.22      1.02      0.00      5.73    948.28      1.00\n",
      " lambda[23]      4.90     27.84      1.01      0.00      6.12    470.62      1.00\n",
      " lambda[24]      4.42     24.21      1.01      0.00      7.12    741.65      1.00\n",
      " lambda[25]      2.55      7.92      0.99      0.00      5.53    564.87      1.00\n",
      " lambda[26]      4.13     37.58      0.99      0.00      5.33    750.78      1.00\n",
      " lambda[27]      2.37      5.40      0.93      0.00      5.12    641.94      1.00\n",
      " lambda[28]      2.91      8.60      1.01      0.01      5.80    695.15      1.00\n",
      " lambda[29]      3.51     13.72      0.94      0.00      5.82    746.17      1.00\n",
      " lambda[30]      4.07     18.22      1.03      0.00      5.97    698.01      1.00\n",
      " lambda[31]      3.60     22.71      1.01      0.00      5.37   1017.36      1.00\n",
      " lambda[32]      5.98     37.79      1.06      0.00      6.89    870.43      1.00\n",
      " lambda[33]      2.95      8.90      1.00      0.00      5.46    610.13      1.01\n",
      " lambda[34]      3.27     10.33      1.00      0.00      6.55    562.79      1.00\n",
      " lambda[35]      3.53     12.85      1.08      0.00      5.98    605.83      1.00\n",
      " lambda[36]      3.18     10.10      0.96      0.00      5.46    325.62      1.00\n",
      " lambda[37]      4.67     26.85      1.00      0.01      6.45    285.19      1.00\n",
      " lambda[38]      8.01    144.48      1.00      0.01      6.77    978.01      1.00\n",
      " lambda[39]      3.61     19.36      1.00      0.00      6.29    856.11      1.00\n",
      " lambda[40]      3.28      9.53      1.02      0.00      6.46    660.44      1.00\n",
      " lambda[41]     43.91    483.55      1.04      0.00     11.14    636.33      1.00\n",
      " lambda[42]      2.42      6.10      0.96      0.00      5.34    991.44      1.00\n",
      " lambda[43]      9.02    144.17      1.01      0.00      6.47    638.24      1.00\n",
      " lambda[44]      3.19      9.76      0.94      0.00      6.68    639.69      1.00\n",
      " lambda[45]      2.91     13.78      0.95      0.00      5.59    916.71      1.00\n",
      " lambda[46]      2.63      9.17      1.03      0.00      4.73    709.23      1.00\n",
      " lambda[47]      2.71      6.11      1.02      0.01      5.99    695.83      1.00\n",
      " lambda[48]      2.76      8.32      0.97      0.00      5.17    637.27      1.00\n",
      " lambda[49]      2.91      9.27      0.99      0.00      5.49    913.27      1.00\n",
      " lambda[50]      4.16     21.24      1.01      0.00      6.65    748.03      1.00\n",
      " lambda[51]      3.94     13.42      1.03      0.00      7.19    604.24      1.00\n",
      " lambda[52]      3.41     15.89      1.01      0.00      5.11    819.72      1.00\n",
      " lambda[53]      3.17      8.53      0.96      0.00      6.29    367.62      1.00\n",
      " lambda[54]      2.35      6.90      0.94      0.00      4.51    889.51      1.00\n",
      " lambda[55]      2.90     16.68      0.93      0.00      5.01    518.91      1.00\n",
      " lambda[56]      6.12     56.70      0.98      0.01      6.25    632.96      1.00\n",
      " lambda[57]     23.70    334.68      1.09      0.00     11.75    823.76      1.00\n",
      " lambda[58]      2.07      3.84      0.92      0.00      4.62    621.06      1.00\n",
      " lambda[59]      3.48     11.70      1.04      0.00      6.16    594.48      1.00\n",
      " lambda[60]      4.01     12.38      1.08      0.01      7.52    371.02      1.01\n",
      " lambda[61]      2.43      5.56      0.93      0.00      5.71    969.37      1.00\n",
      " lambda[62]   1226.05   6188.15    111.17      0.00   1896.65    658.56      1.00\n",
      " lambda[63]      2.48      5.20      0.98      0.00      5.43    676.80      1.00\n",
      " lambda[64]      2.69      7.65      0.97      0.00      5.24    871.72      1.00\n",
      " lambda[65]      3.15     14.19      0.97      0.00      4.97    697.10      1.00\n",
      " lambda[66]      2.88      8.32      1.02      0.00      5.99    826.25      1.00\n",
      " lambda[67]      3.27     14.42      0.99      0.00      6.02    622.62      1.00\n",
      " lambda[68]      3.55     12.34      1.05      0.00      7.06    788.49      1.00\n",
      " lambda[69]      5.05     23.86      1.03      0.00      7.20    426.75      1.00\n",
      " lambda[70]      3.12      9.59      0.94      0.00      5.54    589.60      1.00\n",
      " lambda[71]      3.77     20.11      1.06      0.00      6.14    847.33      1.00\n",
      " lambda[72]      2.44      6.32      0.97      0.00      4.81    584.54      1.00\n",
      " lambda[73]      8.63    107.34      0.98      0.00      5.70    328.69      1.00\n",
      " lambda[74]      3.04      9.09      0.97      0.01      5.98    466.48      1.00\n",
      " lambda[75]      5.64     26.59      1.06      0.00      7.79    552.82      1.00\n",
      " lambda[76]      3.13      8.45      1.02      0.00      6.10    536.36      1.00\n",
      " lambda[77]      9.58     71.96      1.05      0.00      6.54    576.14      1.00\n",
      " lambda[78]      3.07      8.64      1.00      0.01      5.39    644.35      1.00\n",
      " lambda[79]      3.40     22.34      0.96      0.01      4.49    871.74      1.00\n",
      " lambda[80]      5.14     37.19      0.92      0.00      5.72    661.23      1.00\n",
      " lambda[81]      2.45      5.20      0.95      0.01      5.75    704.56      1.00\n",
      " lambda[82]      2.55      7.78      0.96      0.01      5.55    565.29      1.00\n",
      " lambda[83]      3.39     10.99      0.98      0.00      5.93    643.37      1.00\n",
      " lambda[84]     11.28    135.50      0.96      0.00      5.90    657.39      1.00\n",
      " lambda[85]      2.83     11.18      0.96      0.00      5.21    668.27      1.00\n",
      " lambda[86]     10.83    136.51      0.99      0.00      5.94    424.35      1.00\n",
      " lambda[87]      4.40     56.21      1.00      0.00      5.98    999.81      1.00\n",
      " lambda[88]      2.63      7.21      1.01      0.00      5.13    636.05      1.00\n",
      " lambda[89]    153.22   1667.88      1.28      0.00     67.89    575.77      1.00\n",
      " lambda[90]      2.48      5.59      0.92      0.00      5.41    724.84      1.00\n",
      " lambda[91]      2.37      5.60      1.00      0.00      4.96    584.46      1.00\n",
      " lambda[92]      2.72      6.81      0.98      0.00      5.73    874.38      1.00\n",
      " lambda[93]      2.94     19.58      0.99      0.00      5.12    961.88      1.00\n",
      " lambda[94]      3.44     12.63      0.99      0.00      6.44    782.54      1.00\n",
      " lambda[95]      3.92     21.07      0.95      0.00      6.07    963.90      1.00\n",
      " lambda[96]      3.95     30.73      0.95      0.00      5.99    797.55      1.00\n",
      " lambda[97]      3.15     15.03      0.98      0.00      5.00    438.15      1.00\n",
      " lambda[98]      5.82     53.04      0.99      0.00      5.84    826.61      1.00\n",
      " lambda[99]      2.03      3.60      0.87      0.00      5.03    604.94      1.00\n",
      "lambda[100]      2.66      6.73      0.93      0.00      5.97    661.97      1.00\n",
      "lambda[101]      2.79      8.58      1.04      0.00      5.52    796.94      1.00\n",
      "lambda[102]      2.37      5.14      0.96      0.00      5.21    724.04      1.00\n",
      "lambda[103]      2.03      3.65      0.94      0.00      4.60    637.63      1.00\n",
      "lambda[104]     12.14    159.33      0.95      0.00      5.22    500.78      1.00\n",
      "lambda[105]      5.44     27.92      0.96      0.00      7.17    409.19      1.01\n",
      "lambda[106]      2.76      9.86      1.01      0.00      5.20    553.11      1.00\n",
      "lambda[107]     10.28     79.36      1.04      0.00      6.94    473.53      1.00\n",
      "lambda[108]      2.48      5.58      0.96      0.00      5.61    686.41      1.00\n",
      "lambda[109]      7.40     81.49      0.96      0.00      7.27    700.27      1.00\n",
      "lambda[110]      3.73     16.73      0.96      0.00      5.80    758.23      1.00\n",
      "lambda[111]      6.07     38.83      1.06      0.00      9.10    696.25      1.00\n",
      "lambda[112]      2.18      4.31      0.98      0.00      4.64    649.49      1.00\n",
      "lambda[113]      7.01     46.92      1.00      0.01      6.68    272.33      1.00\n",
      "lambda[114]      3.81     22.98      0.93      0.00      5.57    602.29      1.00\n",
      "lambda[115]      3.97     29.15      1.00      0.00      6.37    950.47      1.00\n",
      "lambda[116]      6.23    108.60      1.07      0.01      5.90    999.82      1.00\n",
      "lambda[117]      3.38     11.01      0.94      0.00      6.22    628.25      1.00\n",
      "lambda[118]      2.33      6.90      0.98      0.00      4.60    508.81      1.00\n",
      "lambda[119]      3.78     12.92      0.90      0.01      6.48    440.27      1.00\n",
      "lambda[120]      4.81     26.36      1.08      0.00      6.95    534.19      1.00\n",
      "lambda[121]      3.63     14.06      1.00      0.00      6.40    836.44      1.00\n",
      "lambda[122]      4.19     20.59      1.06      0.01      5.77    483.44      1.00\n",
      "lambda[123]      2.58      6.48      0.92      0.00      5.54    812.89      1.00\n",
      "lambda[124]      2.48      6.49      0.95      0.00      4.90    633.13      1.00\n",
      "lambda[125]      2.57      7.08      0.97      0.00      5.50    629.72      1.00\n",
      "lambda[126]      2.31      6.24      0.89      0.00      4.90    760.16      1.00\n",
      "lambda[127]      4.03     20.02      0.94      0.00      6.39    581.63      1.00\n",
      "lambda[128]      2.59      6.33      0.96      0.01      5.04    391.07      1.00\n",
      "lambda[129]      3.57     14.51      0.83      0.00      5.56    481.19      1.00\n",
      "lambda[130]      3.68     18.50      0.99      0.00      6.12    699.29      1.00\n",
      "lambda[131]      3.80     21.03      0.97      0.00      5.77    828.55      1.00\n",
      "lambda[132]      2.65      7.30      1.00      0.00      5.32    722.59      1.00\n",
      "lambda[133]      3.18     12.81      0.95      0.00      5.52    775.20      1.00\n",
      "lambda[134]      2.91      6.98      0.92      0.00      6.10    889.20      1.00\n",
      "lambda[135]      2.73     10.26      0.97      0.00      4.90    841.92      1.00\n",
      "lambda[136]      3.00      8.75      0.96      0.00      5.83    766.68      1.01\n",
      "lambda[137]      2.52      8.32      1.02      0.00      5.23    912.86      1.00\n",
      "lambda[138]      4.18     16.94      0.95      0.00      6.62    368.72      1.00\n",
      "lambda[139]      2.98     11.33      0.96      0.00      6.05    787.76      1.00\n",
      "lambda[140]      3.74     20.74      0.98      0.00      6.04    523.13      1.00\n",
      "lambda[141]      2.98      8.98      0.89      0.00      6.10    624.01      1.00\n",
      "lambda[142]      9.18    121.26      1.00      0.00      6.03    566.05      1.00\n",
      "lambda[143]      2.31      5.54      0.95      0.00      4.67    714.79      1.00\n",
      "        msq      0.21      0.13      0.18      0.06      0.36    657.05      1.00\n",
      "      sigma      4.47      5.98      1.87      0.01     12.55    841.82      1.00\n",
      "    var_obs      0.11      0.02      0.10      0.07      0.14    551.20      1.00\n",
      "       xisq      0.12      0.06      0.10      0.03      0.19    393.97      1.00\n",
      "\n",
      "Number of divergences: 4\n",
      "\n",
      "MCMC elapsed time: 195.44246292114258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t3.90e-05 +- 1.80e-02\n",
      "[dimension 02/145]  inactive:\t1.35e-03 +- 2.63e-02\n",
      "[dimension 03/145]  inactive:\t1.93e-03 +- 2.73e-02\n",
      "[dimension 04/145]  inactive:\t5.00e-03 +- 3.71e-02\n",
      "[dimension 05/145]  inactive:\t1.21e-03 +- 2.58e-02\n",
      "[dimension 06/145]  inactive:\t3.50e-03 +- 3.85e-02\n",
      "[dimension 07/145]  inactive:\t1.47e-03 +- 2.04e-02\n",
      "[dimension 08/145]  inactive:\t1.84e-03 +- 2.62e-02\n",
      "[dimension 09/145]  inactive:\t1.94e-03 +- 2.39e-02\n",
      "[dimension 10/145]  inactive:\t8.74e-04 +- 1.84e-02\n",
      "[dimension 11/145]  inactive:\t1.65e-03 +- 2.79e-02\n",
      "[dimension 12/145]  inactive:\t2.32e-03 +- 3.25e-02\n",
      "[dimension 13/145]  inactive:\t9.12e-03 +- 5.69e-02\n",
      "[dimension 14/145]  inactive:\t4.76e-04 +- 2.50e-02\n",
      "[dimension 15/145]  inactive:\t4.13e-03 +- 4.10e-02\n",
      "[dimension 16/145]  inactive:\t1.12e-03 +- 2.06e-02\n",
      "[dimension 17/145]  inactive:\t2.41e-03 +- 3.38e-02\n",
      "[dimension 18/145]  inactive:\t2.32e-03 +- 3.13e-02\n",
      "[dimension 19/145]  inactive:\t-1.24e-03 +- 2.01e-02\n",
      "[dimension 20/145]  inactive:\t2.10e-05 +- 2.69e-02\n",
      "[dimension 21/145]  inactive:\t-6.34e-04 +- 2.41e-02\n",
      "[dimension 22/145]  inactive:\t3.55e-04 +- 2.21e-02\n",
      "[dimension 23/145]  inactive:\t4.90e-04 +- 2.21e-02\n",
      "[dimension 24/145]  inactive:\t4.24e-03 +- 3.93e-02\n",
      "[dimension 25/145]  inactive:\t4.72e-03 +- 2.71e-02\n",
      "[dimension 26/145]  inactive:\t6.17e-04 +- 2.29e-02\n",
      "[dimension 27/145]  inactive:\t2.47e-03 +- 2.91e-02\n",
      "[dimension 28/145]  inactive:\t1.07e-03 +- 1.75e-02\n",
      "[dimension 29/145]  inactive:\t2.51e-03 +- 3.25e-02\n",
      "[dimension 30/145]  inactive:\t3.54e-03 +- 3.47e-02\n",
      "[dimension 31/145]  inactive:\t6.69e-03 +- 4.67e-02\n",
      "[dimension 32/145]  inactive:\t1.11e-03 +- 2.70e-02\n",
      "[dimension 33/145]  inactive:\t7.68e-03 +- 5.51e-02\n",
      "[dimension 34/145]  inactive:\t1.31e-03 +- 2.13e-02\n",
      "[dimension 35/145]  inactive:\t2.64e-03 +- 3.21e-02\n",
      "[dimension 36/145]  inactive:\t3.15e-03 +- 3.15e-02\n",
      "[dimension 37/145]  inactive:\t3.91e-03 +- 2.57e-02\n",
      "[dimension 38/145]  inactive:\t9.37e-04 +- 3.14e-02\n",
      "[dimension 39/145]  inactive:\t5.59e-03 +- 4.33e-02\n",
      "[dimension 40/145]  inactive:\t5.09e-03 +- 3.93e-02\n",
      "[dimension 41/145]  inactive:\t1.52e-04 +- 2.83e-02\n",
      "[dimension 42/145]  inactive:\t2.87e-02 +- 1.33e-01\n",
      "[dimension 43/145]  inactive:\t8.05e-04 +- 1.91e-02\n",
      "[dimension 44/145]  inactive:\t1.96e-03 +- 3.45e-02\n",
      "[dimension 45/145]  inactive:\t1.40e-03 +- 2.74e-02\n",
      "[dimension 46/145]  inactive:\t8.10e-04 +- 1.60e-02\n",
      "[dimension 47/145]  inactive:\t4.82e-05 +- 2.61e-02\n",
      "[dimension 48/145]  inactive:\t2.61e-03 +- 2.86e-02\n",
      "[dimension 49/145]  inactive:\t2.10e-03 +- 2.17e-02\n",
      "[dimension 50/145]  inactive:\t-2.82e-04 +- 2.65e-02\n",
      "[dimension 51/145]  inactive:\t3.52e-03 +- 3.29e-02\n",
      "[dimension 52/145]  inactive:\t5.96e-03 +- 2.71e-02\n",
      "[dimension 53/145]  inactive:\t5.13e-04 +- 2.47e-02\n",
      "[dimension 54/145]  inactive:\t1.64e-03 +- 2.31e-02\n",
      "[dimension 55/145]  inactive:\t8.91e-04 +- 1.61e-02\n",
      "[dimension 56/145]  inactive:\t-9.74e-04 +- 1.83e-02\n",
      "[dimension 57/145]  inactive:\t6.03e-03 +- 4.81e-02\n",
      "[dimension 58/145]  inactive:\t2.34e-02 +- 9.66e-02\n",
      "[dimension 59/145]  inactive:\t1.27e-04 +- 1.73e-02\n",
      "[dimension 60/145]  inactive:\t5.60e-03 +- 4.35e-02\n",
      "[dimension 61/145]  inactive:\t4.69e-03 +- 3.04e-02\n",
      "[dimension 62/145]  inactive:\t7.83e-04 +- 2.02e-02\n",
      "[dimension 63/145]  active:\t4.88e-01 +- 4.19e-01\n",
      "[dimension 64/145]  inactive:\t-2.03e-03 +- 2.38e-02\n",
      "[dimension 65/145]  inactive:\t7.45e-04 +- 2.45e-02\n",
      "[dimension 66/145]  inactive:\t1.19e-03 +- 2.44e-02\n",
      "[dimension 67/145]  inactive:\t1.22e-03 +- 2.30e-02\n",
      "[dimension 68/145]  inactive:\t4.21e-04 +- 2.72e-02\n",
      "[dimension 69/145]  inactive:\t4.71e-03 +- 3.97e-02\n",
      "[dimension 70/145]  inactive:\t5.51e-03 +- 2.90e-02\n",
      "[dimension 71/145]  inactive:\t2.25e-03 +- 3.40e-02\n",
      "[dimension 72/145]  inactive:\t2.16e-03 +- 2.40e-02\n",
      "[dimension 73/145]  inactive:\t8.11e-04 +- 1.69e-02\n",
      "[dimension 74/145]  inactive:\t2.08e-04 +- 2.56e-02\n",
      "[dimension 75/145]  inactive:\t1.58e-03 +- 2.22e-02\n",
      "[dimension 76/145]  inactive:\t9.26e-03 +- 5.39e-02\n",
      "[dimension 77/145]  inactive:\t3.03e-04 +- 2.90e-02\n",
      "[dimension 78/145]  inactive:\t1.36e-02 +- 8.33e-02\n",
      "[dimension 79/145]  inactive:\t6.40e-03 +- 3.48e-02\n",
      "[dimension 80/145]  inactive:\t1.61e-03 +- 2.66e-02\n",
      "[dimension 81/145]  inactive:\t6.62e-03 +- 4.95e-02\n",
      "[dimension 82/145]  inactive:\t7.41e-04 +- 1.74e-02\n",
      "[dimension 83/145]  inactive:\t-9.37e-04 +- 1.85e-02\n",
      "[dimension 84/145]  inactive:\t-8.57e-05 +- 2.49e-02\n",
      "[dimension 85/145]  inactive:\t5.91e-03 +- 4.52e-02\n",
      "[dimension 86/145]  inactive:\t-4.21e-04 +- 1.85e-02\n",
      "[dimension 87/145]  inactive:\t6.96e-03 +- 5.20e-02\n",
      "[dimension 88/145]  inactive:\t2.59e-03 +- 2.23e-02\n",
      "[dimension 89/145]  inactive:\t6.96e-05 +- 1.97e-02\n",
      "[dimension 90/145]  inactive:\t8.03e-02 +- 2.26e-01\n",
      "[dimension 91/145]  inactive:\t9.61e-05 +- 1.64e-02\n",
      "[dimension 92/145]  inactive:\t-1.14e-04 +- 1.97e-02\n",
      "[dimension 93/145]  inactive:\t5.77e-05 +- 2.14e-02\n",
      "[dimension 94/145]  inactive:\t1.80e-03 +- 2.43e-02\n",
      "[dimension 95/145]  inactive:\t9.72e-04 +- 2.65e-02\n",
      "[dimension 96/145]  inactive:\t1.66e-03 +- 2.98e-02\n",
      "[dimension 97/145]  inactive:\t3.57e-03 +- 2.67e-02\n",
      "[dimension 98/145]  inactive:\t8.07e-04 +- 2.50e-02\n",
      "[dimension 99/145]  inactive:\t6.66e-03 +- 5.21e-02\n",
      "[dimension 100/145]  inactive:\t-1.44e-04 +- 1.56e-02\n",
      "[dimension 101/145]  inactive:\t-9.88e-04 +- 1.75e-02\n",
      "[dimension 102/145]  inactive:\t8.35e-04 +- 2.47e-02\n",
      "[dimension 103/145]  inactive:\t1.58e-03 +- 2.34e-02\n",
      "[dimension 104/145]  inactive:\t-3.68e-04 +- 1.55e-02\n",
      "[dimension 105/145]  inactive:\t1.48e-03 +- 2.71e-02\n",
      "[dimension 106/145]  inactive:\t8.60e-03 +- 4.70e-02\n",
      "[dimension 107/145]  inactive:\t1.09e-04 +- 1.87e-02\n",
      "[dimension 108/145]  inactive:\t1.42e-02 +- 8.36e-02\n",
      "[dimension 109/145]  inactive:\t-1.96e-04 +- 1.76e-02\n",
      "[dimension 110/145]  inactive:\t2.78e-03 +- 3.94e-02\n",
      "[dimension 111/145]  inactive:\t4.26e-03 +- 4.03e-02\n",
      "[dimension 112/145]  inactive:\t1.00e-02 +- 6.50e-02\n",
      "[dimension 113/145]  inactive:\t-2.93e-04 +- 1.80e-02\n",
      "[dimension 114/145]  inactive:\t7.55e-03 +- 6.32e-02\n",
      "[dimension 115/145]  inactive:\t1.82e-03 +- 2.14e-02\n",
      "[dimension 116/145]  inactive:\t2.28e-03 +- 3.17e-02\n",
      "[dimension 117/145]  inactive:\t4.56e-03 +- 4.53e-02\n",
      "[dimension 118/145]  inactive:\t3.03e-03 +- 2.36e-02\n",
      "[dimension 119/145]  inactive:\t2.15e-04 +- 2.60e-02\n",
      "[dimension 120/145]  inactive:\t1.98e-03 +- 3.20e-02\n",
      "[dimension 121/145]  inactive:\t4.34e-03 +- 3.52e-02\n",
      "[dimension 122/145]  inactive:\t-5.94e-04 +- 3.29e-02\n",
      "[dimension 123/145]  inactive:\t4.41e-03 +- 4.18e-02\n",
      "[dimension 124/145]  inactive:\t-3.17e-04 +- 1.77e-02\n",
      "[dimension 125/145]  inactive:\t3.63e-05 +- 2.33e-02\n",
      "[dimension 126/145]  inactive:\t8.27e-04 +- 2.35e-02\n",
      "[dimension 127/145]  inactive:\t5.80e-04 +- 1.53e-02\n",
      "[dimension 128/145]  inactive:\t2.17e-03 +- 3.67e-02\n",
      "[dimension 129/145]  inactive:\t1.36e-03 +- 2.10e-02\n",
      "[dimension 130/145]  inactive:\t4.30e-03 +- 3.37e-02\n",
      "[dimension 131/145]  inactive:\t1.55e-03 +- 3.39e-02\n",
      "[dimension 132/145]  inactive:\t5.03e-03 +- 4.16e-02\n",
      "[dimension 133/145]  inactive:\t2.55e-03 +- 1.97e-02\n",
      "[dimension 134/145]  inactive:\t1.09e-03 +- 2.84e-02\n",
      "[dimension 135/145]  inactive:\t2.17e-03 +- 2.82e-02\n",
      "[dimension 136/145]  inactive:\t1.60e-03 +- 2.20e-02\n",
      "[dimension 137/145]  inactive:\t1.56e-03 +- 3.14e-02\n",
      "[dimension 138/145]  inactive:\t1.16e-03 +- 2.21e-02\n",
      "[dimension 139/145]  inactive:\t1.80e-03 +- 2.65e-02\n",
      "[dimension 140/145]  inactive:\t3.37e-04 +- 2.24e-02\n",
      "[dimension 141/145]  inactive:\t2.00e-03 +- 2.65e-02\n",
      "[dimension 142/145]  inactive:\t2.59e-03 +- 2.04e-02\n",
      "[dimension 143/145]  inactive:\t3.75e-03 +- 4.10e-02\n",
      "[dimension 144/145]  inactive:\t1.41e-03 +- 1.95e-02\n",
      "[dimension 145/145]  inactive:\t-2.29e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00149108]\n",
      "cov_act[[0.00011422]]\n",
      "Active_dimensions: [62]\n",
      "8, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:38<00:00, 39.11it/s, 31 steps of size 1.89e-01. acc. prob=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    534.29      1.00\n",
      "  lambda[0]      2.44     12.31      0.92      0.00      4.93   1001.88      1.00\n",
      "  lambda[1]      3.41     11.53      1.02      0.00      6.81    702.97      1.01\n",
      "  lambda[2]      2.83      7.51      0.94      0.00      5.96    665.87      1.00\n",
      "  lambda[3]      4.66     34.71      0.98      0.00      7.16    837.91      1.00\n",
      "  lambda[4]      2.73      5.98      1.00      0.00      5.77    536.56      1.00\n",
      "  lambda[5]      3.65     18.67      0.96      0.00      6.79    935.52      1.00\n",
      "  lambda[6]      3.04     11.74      0.99      0.00      5.65    869.95      1.00\n",
      "  lambda[7]      2.97      7.59      0.97      0.00      6.14    769.20      1.00\n",
      "  lambda[8]      2.52      6.28      0.99      0.01      5.47    775.90      1.00\n",
      "  lambda[9]      3.00      6.93      1.01      0.00      6.17    461.98      1.00\n",
      " lambda[10]      3.43     11.92      1.05      0.00      6.12    886.96      1.00\n",
      " lambda[11]      2.92      7.71      1.06      0.00      5.79    754.32      1.00\n",
      " lambda[12]      4.20     16.56      1.05      0.00      7.31    662.53      1.00\n",
      " lambda[13]      3.15      9.35      1.03      0.00      6.14    695.96      1.00\n",
      " lambda[14]      3.63     15.00      0.94      0.00      6.48    951.46      1.00\n",
      " lambda[15]      3.23     14.93      1.02      0.00      5.44    918.67      1.00\n",
      " lambda[16]      2.89      7.24      0.93      0.00      5.62    760.54      1.00\n",
      " lambda[17]      3.85     24.18      0.94      0.00      5.06    637.59      1.00\n",
      " lambda[18]      2.74      7.19      0.97      0.00      5.65    678.27      1.00\n",
      " lambda[19]      2.86      8.61      1.00      0.00      5.50    672.27      1.00\n",
      " lambda[20]      2.76      7.56      0.94      0.00      5.66    776.09      1.00\n",
      " lambda[21]      2.99      8.42      1.00      0.00      6.27    767.70      1.00\n",
      " lambda[22]      2.56      6.39      1.03      0.00      4.88    674.51      1.00\n",
      " lambda[23]      3.07     10.13      0.94      0.00      5.59    668.01      1.00\n",
      " lambda[24]      3.11      8.63      0.99      0.00      6.47    668.77      1.00\n",
      " lambda[25]      2.66      6.25      1.00      0.01      5.67    435.86      1.00\n",
      " lambda[26]      3.54     14.69      0.97      0.00      5.30    397.86      1.00\n",
      " lambda[27]      2.80      6.50      0.95      0.00      6.41    479.60      1.00\n",
      " lambda[28]      2.69     10.43      0.93      0.01      4.71    573.71      1.00\n",
      " lambda[29]      3.44     13.79      0.95      0.00      5.77    610.92      1.00\n",
      " lambda[30]      3.75     12.95      1.08      0.00      6.66    851.06      1.00\n",
      " lambda[31]      3.85     19.39      0.93      0.00      5.81    520.57      1.00\n",
      " lambda[32]      3.64     13.57      1.03      0.00      6.68    961.51      1.00\n",
      " lambda[33]      2.79      7.42      0.97      0.01      5.14    537.71      1.00\n",
      " lambda[34]      2.73      6.91      1.03      0.00      5.57    541.33      1.00\n",
      " lambda[35]      3.61     19.19      0.98      0.00      5.66    720.34      1.00\n",
      " lambda[36]      3.28     13.15      0.97      0.00      5.66    894.90      1.00\n",
      " lambda[37]      3.93     20.14      0.99      0.00      6.77    856.40      1.00\n",
      " lambda[38]      3.83     12.43      1.05      0.00      7.22    772.31      1.00\n",
      " lambda[39]      3.11      7.99      0.97      0.00      6.22    650.28      1.00\n",
      " lambda[40]      4.23     20.09      0.99      0.00      6.09    455.15      1.00\n",
      " lambda[41]     10.42     84.34      0.99      0.00      7.69    506.11      1.00\n",
      " lambda[42]      2.95      7.70      1.02      0.00      5.95    505.58      1.00\n",
      " lambda[43]      2.97      9.63      1.01      0.00      5.66    787.68      1.00\n",
      " lambda[44]      2.79      7.08      1.04      0.00      5.74    845.67      1.00\n",
      " lambda[45]      2.66      8.63      1.02      0.00      4.81    782.35      1.00\n",
      " lambda[46]      2.91     10.59      0.99      0.00      4.85    720.34      1.00\n",
      " lambda[47]      2.52      5.01      0.96      0.00      5.83    800.12      1.00\n",
      " lambda[48]      2.67      8.38      0.93      0.00      4.66    742.88      1.00\n",
      " lambda[49]      3.30     10.76      1.01      0.00      5.51    738.27      1.00\n",
      " lambda[50]      2.69      6.35      0.91      0.00      5.71    610.89      1.00\n",
      " lambda[51]      3.26      9.98      1.08      0.00      5.93    691.49      1.00\n",
      " lambda[52]      2.84      9.19      1.04      0.00      5.03    891.85      1.00\n",
      " lambda[53]      3.02      8.59      1.00      0.00      5.96    683.65      1.00\n",
      " lambda[54]      2.18      5.17      0.96      0.00      4.18    867.09      1.00\n",
      " lambda[55]      3.18     10.48      0.97      0.00      6.12    564.74      1.00\n",
      " lambda[56]      2.71      7.34      0.93      0.00      5.04    608.34      1.00\n",
      " lambda[57]      6.79     27.62      0.99      0.00      7.89    308.97      1.00\n",
      " lambda[58]      2.29      4.81      0.94      0.01      5.14    719.55      1.00\n",
      " lambda[59]      4.18     18.52      1.04      0.00      6.04    850.04      1.00\n",
      " lambda[60]      2.46      5.38      1.03      0.00      5.21    785.21      1.00\n",
      " lambda[61]      3.19     15.38      1.05      0.00      5.82    899.28      1.00\n",
      " lambda[62]    713.69   2743.35    154.68      0.00   1392.74    511.84      1.00\n",
      " lambda[63]      2.76      6.75      1.04      0.00      5.61    748.82      1.00\n",
      " lambda[64]      2.73      6.08      0.96      0.01      5.75    636.97      1.00\n",
      " lambda[65]      2.60      8.54      0.97      0.00      4.06    614.26      1.00\n",
      " lambda[66]      2.77      6.09      0.97      0.01      6.02    742.83      1.00\n",
      " lambda[67]      2.84      7.62      0.97      0.00      6.07    772.31      1.00\n",
      " lambda[68]      2.98      7.74      0.97      0.00      6.57    728.72      1.00\n",
      " lambda[69]      3.10      8.94      1.02      0.00      5.73    623.04      1.00\n",
      " lambda[70]      2.72      7.02      0.90      0.00      5.90    573.17      1.00\n",
      " lambda[71]      4.30     36.11      0.97      0.00      6.23    840.75      1.00\n",
      " lambda[72]      2.27      6.09      0.94      0.00      5.19    638.20      1.00\n",
      " lambda[73]      2.82      9.10      1.05      0.00      5.68    572.60      1.00\n",
      " lambda[74]      2.70      5.93      1.01      0.00      5.97    800.62      1.00\n",
      " lambda[75]      4.42     16.37      1.09      0.00      7.96    618.29      1.00\n",
      " lambda[76]      3.47     12.56      0.98      0.00      5.55    561.01      1.00\n",
      " lambda[77]      4.32     22.65      1.01      0.00      5.72    859.89      1.00\n",
      " lambda[78]      3.43     13.32      1.00      0.00      5.72    665.38      1.01\n",
      " lambda[79]      3.04     14.11      0.91      0.00      4.64    650.97      1.00\n",
      " lambda[80]      3.69     14.44      1.03      0.00      6.31    649.50      1.00\n",
      " lambda[81]      2.45      6.62      0.91      0.01      4.93    793.22      1.00\n",
      " lambda[82]      2.64      8.85      0.95      0.00      4.42    753.09      1.00\n",
      " lambda[83]      3.55     12.79      1.01      0.00      7.00    966.88      1.00\n",
      " lambda[84]      4.07     19.84      1.02      0.00      6.98    641.87      1.00\n",
      " lambda[85]      2.80      7.45      0.97      0.00      6.06    928.06      1.00\n",
      " lambda[86]      3.95     29.73      1.01      0.00      5.75    944.18      1.00\n",
      " lambda[87]      3.96     24.43      0.99      0.00      5.75    435.06      1.00\n",
      " lambda[88]      2.76      6.91      0.95      0.00      6.32    751.96      1.00\n",
      " lambda[89]     65.37    418.75      1.27      0.00    106.96    473.98      1.00\n",
      " lambda[90]      2.85      8.31      0.96      0.00      5.08    440.44      1.00\n",
      " lambda[91]      2.56      6.34      0.94      0.00      5.66    836.40      1.00\n",
      " lambda[92]      3.06     15.50      0.99      0.00      5.83    906.04      1.00\n",
      " lambda[93]      2.79      7.26      1.00      0.00      5.56    516.60      1.00\n",
      " lambda[94]      3.68     12.87      0.98      0.00      6.19    498.75      1.00\n",
      " lambda[95]      3.52     18.38      1.03      0.00      6.31    713.81      1.00\n",
      " lambda[96]      3.79     24.00      0.96      0.00      6.55    421.45      1.00\n",
      " lambda[97]      2.60      5.69      1.00      0.00      6.05    594.12      1.00\n",
      " lambda[98]      4.94     38.69      1.04      0.00      6.98    886.48      1.00\n",
      " lambda[99]      2.71      7.85      0.92      0.00      5.24    627.31      1.00\n",
      "lambda[100]      2.72      9.87      0.87      0.00      5.32    770.12      1.00\n",
      "lambda[101]      2.91      8.08      0.98      0.00      5.71    554.21      1.00\n",
      "lambda[102]      2.75      8.53      0.99      0.00      5.78    926.13      1.00\n",
      "lambda[103]      2.22      4.30      0.98      0.00      5.03    904.14      1.00\n",
      "lambda[104]      2.69      6.52      0.97      0.00      5.27    796.58      1.00\n",
      "lambda[105]      3.55     13.03      1.08      0.00      6.11    520.55      1.00\n",
      "lambda[106]      3.22     10.84      0.93      0.00      6.54    483.39      1.00\n",
      "lambda[107]      4.63     19.65      1.03      0.00      5.95    359.19      1.00\n",
      "lambda[108]      2.30      6.03      0.95      0.00      5.04    831.78      1.00\n",
      "lambda[109]      5.66     51.30      0.95      0.00      5.57    827.94      1.00\n",
      "lambda[110]      2.81      7.71      0.97      0.00      5.36    621.45      1.00\n",
      "lambda[111]      4.89     20.84      0.99      0.00      7.10    577.61      1.00\n",
      "lambda[112]      2.27      4.37      1.00      0.01      5.17    736.30      1.00\n",
      "lambda[113]      3.50     13.01      1.05      0.00      6.30    644.17      1.00\n",
      "lambda[114]      2.89     16.43      0.97      0.00      4.90    916.35      1.00\n",
      "lambda[115]      3.02      9.80      1.00      0.00      5.49    789.04      1.00\n",
      "lambda[116]      4.82     36.89      0.92      0.00      5.45    325.86      1.00\n",
      "lambda[117]     10.63    219.60      0.92      0.00      5.93    817.94      1.00\n",
      "lambda[118]      3.80     13.15      1.02      0.00      7.53    729.83      1.00\n",
      "lambda[119]      2.51      5.64      1.03      0.00      5.53    768.26      1.00\n",
      "lambda[120]      3.82     17.02      1.08      0.00      6.45    913.22      1.00\n",
      "lambda[121]      3.93     15.01      0.98      0.00      7.07    545.47      1.00\n",
      "lambda[122]      4.25     22.03      1.03      0.00      6.00    685.17      1.00\n",
      "lambda[123]      2.72      8.05      0.96      0.01      5.06    424.12      1.00\n",
      "lambda[124]      2.64      6.68      0.95      0.00      6.15    794.04      1.00\n",
      "lambda[125]      2.67      5.68      0.99      0.00      6.35    696.84      1.00\n",
      "lambda[126]      2.17      4.02      0.97      0.00      4.73    856.96      1.00\n",
      "lambda[127]      2.93      8.54      0.92      0.00      5.58    773.09      1.00\n",
      "lambda[128]      2.80      7.53      1.02      0.00      5.70    642.62      1.00\n",
      "lambda[129]      3.91     17.61      1.00      0.01      6.38    798.79      1.00\n",
      "lambda[130]      2.94      8.17      0.98      0.00      5.58    711.29      1.00\n",
      "lambda[131]      5.32     44.98      0.99      0.00      5.94    870.22      1.00\n",
      "lambda[132]      2.82      6.50      0.99      0.00      6.43    871.80      1.00\n",
      "lambda[133]      2.85      9.56      1.05      0.00      5.25    992.94      1.00\n",
      "lambda[134]      3.30      8.80      0.91      0.00      6.78    546.35      1.00\n",
      "lambda[135]      2.74      7.43      0.93      0.00      5.03    732.26      1.00\n",
      "lambda[136]      2.66      6.95      0.97      0.00      5.02    907.35      1.00\n",
      "lambda[137]      2.47      4.99      0.99      0.00      5.35    670.20      1.00\n",
      "lambda[138]      2.72      7.50      0.89      0.00      5.64    898.72      1.00\n",
      "lambda[139]      2.95     10.74      0.96      0.00      5.40    494.97      1.00\n",
      "lambda[140]      3.90     14.36      0.91      0.00      7.74    491.42      1.00\n",
      "lambda[141]      2.78      7.49      0.94      0.00      5.78    699.88      1.00\n",
      "lambda[142]      5.37     60.49      0.99      0.00      6.25    726.83      1.00\n",
      "lambda[143]      2.50      5.24      1.02      0.00      5.51    710.91      1.00\n",
      "        msq  11449.09 190949.62      9.73      0.18    300.72    663.85      1.00\n",
      "      sigma      5.59      7.69      2.51      0.00     15.62   1025.22      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    657.75      1.00\n",
      "       xisq     37.84    381.99      1.31      0.08     15.68    276.27      1.00\n",
      "\n",
      "Number of divergences: 4\n",
      "\n",
      "MCMC elapsed time: 42.12932014465332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.65e-04 +- 1.62e-02\n",
      "[dimension 02/145]  inactive:\t-2.89e-04 +- 2.87e-02\n",
      "[dimension 03/145]  inactive:\t7.26e-04 +- 2.59e-02\n",
      "[dimension 04/145]  inactive:\t4.92e-03 +- 3.63e-02\n",
      "[dimension 05/145]  inactive:\t-6.29e-04 +- 3.01e-02\n",
      "[dimension 06/145]  inactive:\t3.53e-03 +- 4.23e-02\n",
      "[dimension 07/145]  inactive:\t6.98e-04 +- 2.02e-02\n",
      "[dimension 08/145]  inactive:\t1.57e-03 +- 3.15e-02\n",
      "[dimension 09/145]  inactive:\t7.21e-04 +- 2.52e-02\n",
      "[dimension 10/145]  inactive:\t4.68e-04 +- 2.04e-02\n",
      "[dimension 11/145]  inactive:\t-7.55e-04 +- 2.29e-02\n",
      "[dimension 12/145]  inactive:\t2.28e-04 +- 2.92e-02\n",
      "[dimension 13/145]  inactive:\t5.92e-03 +- 4.83e-02\n",
      "[dimension 14/145]  inactive:\t-1.55e-03 +- 3.18e-02\n",
      "[dimension 15/145]  inactive:\t2.73e-03 +- 4.09e-02\n",
      "[dimension 16/145]  inactive:\t1.11e-03 +- 2.13e-02\n",
      "[dimension 17/145]  inactive:\t-1.24e-04 +- 2.58e-02\n",
      "[dimension 18/145]  inactive:\t5.63e-04 +- 3.07e-02\n",
      "[dimension 19/145]  inactive:\t-2.35e-03 +- 2.35e-02\n",
      "[dimension 20/145]  inactive:\t-1.28e-03 +- 2.99e-02\n",
      "[dimension 21/145]  inactive:\t-1.52e-03 +- 2.40e-02\n",
      "[dimension 22/145]  inactive:\t-2.27e-05 +- 2.23e-02\n",
      "[dimension 23/145]  inactive:\t-5.40e-04 +- 2.26e-02\n",
      "[dimension 24/145]  inactive:\t2.17e-03 +- 3.17e-02\n",
      "[dimension 25/145]  inactive:\t3.81e-03 +- 2.65e-02\n",
      "[dimension 26/145]  inactive:\t-6.20e-04 +- 2.67e-02\n",
      "[dimension 27/145]  inactive:\t1.01e-03 +- 2.40e-02\n",
      "[dimension 28/145]  inactive:\t8.73e-04 +- 2.07e-02\n",
      "[dimension 29/145]  inactive:\t4.58e-04 +- 2.77e-02\n",
      "[dimension 30/145]  inactive:\t1.17e-03 +- 2.73e-02\n",
      "[dimension 31/145]  inactive:\t6.55e-03 +- 4.70e-02\n",
      "[dimension 32/145]  inactive:\t-7.34e-04 +- 3.31e-02\n",
      "[dimension 33/145]  inactive:\t3.07e-03 +- 4.50e-02\n",
      "[dimension 34/145]  inactive:\t6.82e-04 +- 1.99e-02\n",
      "[dimension 35/145]  inactive:\t7.96e-04 +- 2.93e-02\n",
      "[dimension 36/145]  inactive:\t1.57e-03 +- 2.98e-02\n",
      "[dimension 37/145]  inactive:\t4.21e-03 +- 2.83e-02\n",
      "[dimension 38/145]  inactive:\t-9.04e-04 +- 3.82e-02\n",
      "[dimension 39/145]  inactive:\t2.38e-03 +- 3.64e-02\n",
      "[dimension 40/145]  inactive:\t5.22e-03 +- 4.02e-02\n",
      "[dimension 41/145]  inactive:\t-1.98e-03 +- 3.65e-02\n",
      "[dimension 42/145]  inactive:\t1.67e-02 +- 1.06e-01\n",
      "[dimension 43/145]  inactive:\t-2.16e-05 +- 2.09e-02\n",
      "[dimension 44/145]  inactive:\t-5.10e-04 +- 3.41e-02\n",
      "[dimension 45/145]  inactive:\t5.54e-05 +- 2.35e-02\n",
      "[dimension 46/145]  inactive:\t1.06e-03 +- 1.63e-02\n",
      "[dimension 47/145]  inactive:\t-1.76e-03 +- 3.38e-02\n",
      "[dimension 48/145]  inactive:\t1.88e-03 +- 2.60e-02\n",
      "[dimension 49/145]  inactive:\t2.66e-03 +- 2.34e-02\n",
      "[dimension 50/145]  inactive:\t-1.67e-03 +- 3.06e-02\n",
      "[dimension 51/145]  inactive:\t4.02e-03 +- 3.66e-02\n",
      "[dimension 52/145]  inactive:\t5.31e-03 +- 2.52e-02\n",
      "[dimension 53/145]  inactive:\t-1.43e-03 +- 2.48e-02\n",
      "[dimension 54/145]  inactive:\t1.52e-04 +- 2.34e-02\n",
      "[dimension 55/145]  inactive:\t7.40e-04 +- 1.68e-02\n",
      "[dimension 56/145]  inactive:\t-1.99e-03 +- 2.28e-02\n",
      "[dimension 57/145]  inactive:\t1.82e-03 +- 3.47e-02\n",
      "[dimension 58/145]  inactive:\t1.93e-02 +- 9.59e-02\n",
      "[dimension 59/145]  inactive:\t-6.66e-04 +- 1.76e-02\n",
      "[dimension 60/145]  inactive:\t5.17e-03 +- 5.31e-02\n",
      "[dimension 61/145]  inactive:\t2.45e-03 +- 2.35e-02\n",
      "[dimension 62/145]  inactive:\t-4.26e-04 +- 2.30e-02\n",
      "[dimension 63/145]  active:\t6.43e-01 +- 4.53e-01\n",
      "[dimension 64/145]  inactive:\t-2.42e-03 +- 2.29e-02\n",
      "[dimension 65/145]  inactive:\t3.69e-04 +- 2.79e-02\n",
      "[dimension 66/145]  inactive:\t8.36e-04 +- 2.27e-02\n",
      "[dimension 67/145]  inactive:\t1.87e-03 +- 2.78e-02\n",
      "[dimension 68/145]  inactive:\t-6.82e-04 +- 3.12e-02\n",
      "[dimension 69/145]  inactive:\t3.08e-03 +- 3.47e-02\n",
      "[dimension 70/145]  inactive:\t3.61e-03 +- 2.34e-02\n",
      "[dimension 71/145]  inactive:\t1.25e-03 +- 3.42e-02\n",
      "[dimension 72/145]  inactive:\t1.26e-03 +- 2.63e-02\n",
      "[dimension 73/145]  inactive:\t1.42e-04 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-8.46e-04 +- 2.59e-02\n",
      "[dimension 75/145]  inactive:\t8.37e-04 +- 2.62e-02\n",
      "[dimension 76/145]  inactive:\t8.04e-03 +- 4.81e-02\n",
      "[dimension 77/145]  inactive:\t-2.33e-03 +- 3.87e-02\n",
      "[dimension 78/145]  inactive:\t7.21e-03 +- 6.50e-02\n",
      "[dimension 79/145]  inactive:\t6.00e-03 +- 3.41e-02\n",
      "[dimension 80/145]  inactive:\t7.22e-04 +- 3.38e-02\n",
      "[dimension 81/145]  inactive:\t3.46e-03 +- 4.35e-02\n",
      "[dimension 82/145]  inactive:\t2.32e-04 +- 1.73e-02\n",
      "[dimension 83/145]  inactive:\t-1.16e-03 +- 1.66e-02\n",
      "[dimension 84/145]  inactive:\t-1.95e-03 +- 3.19e-02\n",
      "[dimension 85/145]  inactive:\t3.47e-03 +- 3.70e-02\n",
      "[dimension 86/145]  inactive:\t-8.27e-04 +- 2.16e-02\n",
      "[dimension 87/145]  inactive:\t3.85e-03 +- 4.39e-02\n",
      "[dimension 88/145]  inactive:\t2.61e-03 +- 2.39e-02\n",
      "[dimension 89/145]  inactive:\t-9.48e-04 +- 2.34e-02\n",
      "[dimension 90/145]  inactive:\t1.22e-01 +- 2.99e-01\n",
      "[dimension 91/145]  inactive:\t1.97e-05 +- 1.97e-02\n",
      "[dimension 92/145]  inactive:\t-1.00e-03 +- 2.13e-02\n",
      "[dimension 93/145]  inactive:\t-7.35e-04 +- 2.82e-02\n",
      "[dimension 94/145]  inactive:\t2.25e-03 +- 3.54e-02\n",
      "[dimension 95/145]  inactive:\t-6.16e-04 +- 2.59e-02\n",
      "[dimension 96/145]  inactive:\t2.61e-03 +- 4.77e-02\n",
      "[dimension 97/145]  inactive:\t3.04e-03 +- 2.83e-02\n",
      "[dimension 98/145]  inactive:\t-4.42e-04 +- 2.32e-02\n",
      "[dimension 99/145]  inactive:\t4.77e-03 +- 5.26e-02\n",
      "[dimension 100/145]  inactive:\t-7.08e-04 +- 1.83e-02\n",
      "[dimension 101/145]  inactive:\t-1.90e-03 +- 1.93e-02\n",
      "[dimension 102/145]  inactive:\t-7.97e-04 +- 2.72e-02\n",
      "[dimension 103/145]  inactive:\t8.49e-04 +- 2.40e-02\n",
      "[dimension 104/145]  inactive:\t-9.34e-04 +- 1.67e-02\n",
      "[dimension 105/145]  inactive:\t1.04e-04 +- 2.36e-02\n",
      "[dimension 106/145]  inactive:\t5.24e-03 +- 3.36e-02\n",
      "[dimension 107/145]  inactive:\t-1.34e-03 +- 2.27e-02\n",
      "[dimension 108/145]  inactive:\t1.17e-02 +- 8.39e-02\n",
      "[dimension 109/145]  inactive:\t-5.31e-04 +- 1.83e-02\n",
      "[dimension 110/145]  inactive:\t-6.43e-04 +- 3.71e-02\n",
      "[dimension 111/145]  inactive:\t1.16e-03 +- 2.63e-02\n",
      "[dimension 112/145]  inactive:\t8.90e-03 +- 5.99e-02\n",
      "[dimension 113/145]  inactive:\t-1.19e-03 +- 2.18e-02\n",
      "[dimension 114/145]  inactive:\t1.46e-03 +- 3.59e-02\n",
      "[dimension 115/145]  inactive:\t1.50e-03 +- 1.97e-02\n",
      "[dimension 116/145]  inactive:\t9.26e-04 +- 3.55e-02\n",
      "[dimension 117/145]  inactive:\t6.28e-03 +- 5.87e-02\n",
      "[dimension 118/145]  inactive:\t2.96e-03 +- 2.59e-02\n",
      "[dimension 119/145]  inactive:\t-2.63e-03 +- 3.86e-02\n",
      "[dimension 120/145]  inactive:\t1.21e-04 +- 2.38e-02\n",
      "[dimension 121/145]  inactive:\t4.38e-03 +- 4.08e-02\n",
      "[dimension 122/145]  inactive:\t-2.42e-03 +- 3.58e-02\n",
      "[dimension 123/145]  inactive:\t5.34e-03 +- 5.77e-02\n",
      "[dimension 124/145]  inactive:\t-1.63e-03 +- 2.05e-02\n",
      "[dimension 125/145]  inactive:\t-1.18e-03 +- 2.49e-02\n",
      "[dimension 126/145]  inactive:\t-1.11e-03 +- 2.74e-02\n",
      "[dimension 127/145]  inactive:\t5.54e-05 +- 1.61e-02\n",
      "[dimension 128/145]  inactive:\t-9.13e-04 +- 2.90e-02\n",
      "[dimension 129/145]  inactive:\t1.70e-04 +- 2.70e-02\n",
      "[dimension 130/145]  inactive:\t3.74e-03 +- 2.97e-02\n",
      "[dimension 131/145]  inactive:\t-5.52e-04 +- 3.16e-02\n",
      "[dimension 132/145]  inactive:\t4.72e-03 +- 4.53e-02\n",
      "[dimension 133/145]  inactive:\t2.85e-03 +- 2.37e-02\n",
      "[dimension 134/145]  inactive:\t-7.34e-05 +- 2.80e-02\n",
      "[dimension 135/145]  inactive:\t3.97e-04 +- 2.86e-02\n",
      "[dimension 136/145]  inactive:\t1.13e-03 +- 1.94e-02\n",
      "[dimension 137/145]  inactive:\t3.79e-04 +- 3.07e-02\n",
      "[dimension 138/145]  inactive:\t4.63e-04 +- 2.62e-02\n",
      "[dimension 139/145]  inactive:\t2.62e-04 +- 2.48e-02\n",
      "[dimension 140/145]  inactive:\t-9.09e-04 +- 3.64e-02\n",
      "[dimension 141/145]  inactive:\t1.84e-03 +- 3.30e-02\n",
      "[dimension 142/145]  inactive:\t1.56e-03 +- 1.92e-02\n",
      "[dimension 143/145]  inactive:\t2.27e-03 +- 3.99e-02\n",
      "[dimension 144/145]  inactive:\t2.92e-04 +- 2.19e-02\n",
      "[dimension 145/145]  inactive:\t5.36e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.0189095]\n",
      "cov_act[[0.0490818]]\n",
      "Active_dimensions: [62]\n",
      "9, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:26<00:00, 55.65it/s, 15 steps of size 2.31e-01. acc. prob=0.87] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    231.57      1.04\n",
      "  lambda[0]      2.37      4.93      0.97      0.00      5.47    761.43      1.00\n",
      "  lambda[1]      4.86     24.59      0.92      0.00      6.49    294.99      1.00\n",
      "  lambda[2]      3.04      8.80      0.95      0.01      5.78    331.74      1.00\n",
      "  lambda[3]      4.71     29.05      1.06      0.00      7.21    440.98      1.00\n",
      "  lambda[4]      2.53      7.29      0.99      0.00      5.22   1000.34      1.00\n",
      "  lambda[5]      3.64     19.39      1.00      0.00      5.74    833.48      1.00\n",
      "  lambda[6]     11.65    255.89      0.99      0.00      6.22    932.42      1.00\n",
      "  lambda[7]      3.03      9.11      0.99      0.00      5.83    787.67      1.00\n",
      "  lambda[8]      3.12      8.66      0.98      0.00      5.87    642.33      1.00\n",
      "  lambda[9]      2.79      6.72      1.03      0.00      5.50    774.90      1.00\n",
      " lambda[10]      2.93      8.32      0.98      0.00      6.05    748.77      1.00\n",
      " lambda[11]      4.12     31.40      0.94      0.00      6.13    500.60      1.00\n",
      " lambda[12]      5.31     33.70      1.02      0.01      7.29    484.16      1.00\n",
      " lambda[13]      2.61      9.50      0.96      0.00      5.23    799.30      1.00\n",
      " lambda[14]      3.41     10.36      1.04      0.00      6.51    803.45      1.00\n",
      " lambda[15]      3.46     11.15      1.04      0.00      7.12    897.26      1.00\n",
      " lambda[16]      2.70      6.37      0.97      0.00      6.17    853.91      1.00\n",
      " lambda[17]      9.20    187.72      1.09      0.00      5.32    938.88      1.00\n",
      " lambda[18]      2.78      8.30      0.95      0.00      5.43    760.67      1.00\n",
      " lambda[19]      2.56      5.60      1.00      0.00      6.08    963.87      1.00\n",
      " lambda[20]      2.80      6.96      1.01      0.00      5.60    640.88      1.00\n",
      " lambda[21]      2.80      6.90      1.04      0.00      5.75    352.61      1.00\n",
      " lambda[22]      2.80     11.26      1.02      0.00      4.92    713.10      1.00\n",
      " lambda[23]      3.96     32.31      1.02      0.00      5.45    861.64      1.00\n",
      " lambda[24]      4.24     20.12      1.01      0.00      6.77    728.60      1.00\n",
      " lambda[25]      2.32      5.93      0.92      0.00      4.77    648.77      1.00\n",
      " lambda[26]      3.44     15.28      1.00      0.00      5.20    427.40      1.00\n",
      " lambda[27]      2.95      7.50      0.91      0.00      6.59    557.95      1.00\n",
      " lambda[28]      2.62      5.62      1.01      0.01      6.57    707.17      1.00\n",
      " lambda[29]      3.85     25.29      0.95      0.01      5.59    589.72      1.00\n",
      " lambda[30]      3.46     14.68      0.96      0.00      6.33    624.81      1.00\n",
      " lambda[31]      7.91    101.75      0.97      0.00      5.79    459.01      1.00\n",
      " lambda[32]      3.95     22.38      1.05      0.00      6.96    927.10      1.00\n",
      " lambda[33]      2.51      5.38      0.96      0.00      5.02    551.38      1.00\n",
      " lambda[34]      3.14     10.18      1.00      0.00      6.04    493.97      1.00\n",
      " lambda[35]      2.73      7.42      0.97      0.00      5.10    777.79      1.00\n",
      " lambda[36]      3.07      9.61      1.03      0.01      6.16    614.99      1.00\n",
      " lambda[37]      3.28     15.51      0.99      0.01      5.68    956.19      1.00\n",
      " lambda[38]     10.04    179.10      0.96      0.00      6.37    973.86      1.00\n",
      " lambda[39]      3.36     14.36      0.96      0.00      6.62    840.77      1.00\n",
      " lambda[40]      2.93      7.57      0.97      0.00      6.08    684.59      1.00\n",
      " lambda[41]    139.43   1438.85      1.02      0.00     12.23    146.46      1.01\n",
      " lambda[42]      2.21      4.81      0.96      0.00      4.84    941.87      1.00\n",
      " lambda[43]     10.67    202.19      1.07      0.00      5.94    682.02      1.00\n",
      " lambda[44]     33.99    630.55      0.89      0.00      6.89    420.48      1.00\n",
      " lambda[45]      2.43      6.01      0.99      0.00      5.29    776.46      1.00\n",
      " lambda[46]      3.04     13.97      0.90      0.00      4.16    924.39      1.00\n",
      " lambda[47]      2.42      4.34      1.05      0.00      5.37    799.47      1.00\n",
      " lambda[48]      3.39     14.94      0.97      0.00      5.87    907.85      1.00\n",
      " lambda[49]      2.90      8.09      1.01      0.00      5.61    616.76      1.00\n",
      " lambda[50]      3.49     16.02      0.98      0.00      6.07    817.52      1.00\n",
      " lambda[51]      7.56     73.96      1.03      0.00      8.60    677.05      1.00\n",
      " lambda[52]      3.32     16.62      0.96      0.00      4.61    654.45      1.00\n",
      " lambda[53]      3.38     10.20      0.94      0.01      5.77    511.16      1.00\n",
      " lambda[54]      2.22      5.24      0.92      0.00      4.75    909.73      1.00\n",
      " lambda[55]      2.96     14.06      0.89      0.00      5.40   1027.93      1.00\n",
      " lambda[56]      2.45      7.12      0.97      0.01      5.16    973.61      1.00\n",
      " lambda[57]     46.62    498.97      1.07      0.00     11.16    349.45      1.00\n",
      " lambda[58]      2.42      5.10      0.97      0.00      4.82    832.81      1.00\n",
      " lambda[59]      3.13      9.79      1.02      0.00      5.89    686.76      1.00\n",
      " lambda[60]      3.66     12.99      1.01      0.00      6.22    748.09      1.00\n",
      " lambda[61]      2.51      6.22      0.98      0.00      5.32    607.44      1.00\n",
      " lambda[62]   6812.39  98576.41    237.94      0.01   3811.02    642.57      1.00\n",
      " lambda[63]      2.63      8.65      0.93      0.00      4.84    556.98      1.00\n",
      " lambda[64]      3.10     17.10      0.95      0.00      4.87    957.03      1.00\n",
      " lambda[65]      2.84      9.16      0.98      0.00      5.59    695.36      1.00\n",
      " lambda[66]      3.03      8.48      0.97      0.00      6.20    792.56      1.00\n",
      " lambda[67]      2.97      8.36      1.07      0.00      5.77    926.82      1.00\n",
      " lambda[68]      5.44     47.64      0.98      0.00      6.85    512.68      1.00\n",
      " lambda[69]      4.75     17.64      1.00      0.00      7.46    580.40      1.00\n",
      " lambda[70]      2.81     11.29      0.94      0.00      4.90    780.77      1.00\n",
      " lambda[71]      5.20     44.40      1.04      0.00      5.82    822.99      1.00\n",
      " lambda[72]      2.31      5.77      0.98      0.00      4.67    658.22      1.00\n",
      " lambda[73]      4.21     29.74      0.99      0.00      6.05    479.60      1.00\n",
      " lambda[74]      4.14     50.98      0.94      0.01      5.80    978.30      1.00\n",
      " lambda[75]     10.22     98.05      1.11      0.00      7.86    557.38      1.00\n",
      " lambda[76]      2.71      6.89      1.00      0.00      5.70    455.45      1.00\n",
      " lambda[77]      5.82     33.62      0.97      0.00      6.78    430.65      1.01\n",
      " lambda[78]      3.09      9.34      0.99      0.00      5.82    374.85      1.00\n",
      " lambda[79]      2.54     12.51      0.91      0.00      4.30    881.56      1.00\n",
      " lambda[80]      3.56     10.49      0.96      0.00      7.22    524.81      1.00\n",
      " lambda[81]      2.85      7.63      0.93      0.00      5.96    315.34      1.00\n",
      " lambda[82]      2.19      4.37      0.95      0.00      4.94    811.34      1.00\n",
      " lambda[83]      3.28      9.55      1.02      0.00      6.05    697.77      1.00\n",
      " lambda[84]      7.16     80.82      1.00      0.00      5.59    852.26      1.00\n",
      " lambda[85]      2.72      8.06      0.95      0.00      5.56    606.89      1.00\n",
      " lambda[86]      4.59     30.67      0.96      0.00      6.02    464.50      1.00\n",
      " lambda[87]      2.66      6.02      0.92      0.00      5.61    913.97      1.00\n",
      " lambda[88]      3.74     17.74      1.02      0.01      7.09    585.51      1.00\n",
      " lambda[89]    169.75   1935.39      1.21      0.00     90.83    650.88      1.01\n",
      " lambda[90]      2.15      4.29      0.89      0.00      4.79    636.58      1.00\n",
      " lambda[91]      2.87      9.05      0.99      0.00      5.41    463.59      1.00\n",
      " lambda[92]      2.65      7.21      0.94      0.00      5.15    998.68      1.00\n",
      " lambda[93]      2.74      9.14      0.98      0.00      5.07    649.06      1.00\n",
      " lambda[94]      3.24      8.69      1.03      0.00      6.56    573.89      1.00\n",
      " lambda[95]      3.25     11.40      1.01      0.00      6.18    766.47      1.00\n",
      " lambda[96]      3.14      9.44      1.00      0.00      6.45    559.42      1.00\n",
      " lambda[97]      2.62      6.35      0.99      0.00      5.61    706.66      1.00\n",
      " lambda[98]     14.64    141.82      1.04      0.00      5.97    270.88      1.00\n",
      " lambda[99]      2.31      5.81      0.90      0.00      4.95    839.56      1.00\n",
      "lambda[100]      2.91      9.25      0.93      0.00      6.84    948.55      1.00\n",
      "lambda[101]      3.52     14.53      1.04      0.00      5.40    602.72      1.00\n",
      "lambda[102]      2.81      8.17      0.86      0.00      5.72    950.64      1.00\n",
      "lambda[103]      5.73     55.72      0.93      0.00      5.75    302.84      1.00\n",
      "lambda[104]      3.06     11.75      0.96      0.00      4.90    479.19      1.00\n",
      "lambda[105]      3.53     12.15      1.01      0.00      6.39    680.43      1.00\n",
      "lambda[106]      2.53      9.04      0.94      0.00      5.06    998.27      1.00\n",
      "lambda[107]      4.15     21.29      0.98      0.01      5.39    375.64      1.00\n",
      "lambda[108]      2.37      7.07      0.96      0.00      4.88    916.00      1.00\n",
      "lambda[109]      6.57     70.91      1.03      0.00      7.13    544.58      1.00\n",
      "lambda[110]      4.13     21.26      1.00      0.00      6.44    506.55      1.00\n",
      "lambda[111]      8.67    110.76      1.04      0.00      7.43    639.08      1.00\n",
      "lambda[112]      2.33      4.96      1.02      0.01      4.85    569.55      1.00\n",
      "lambda[113]      6.15     44.99      0.97      0.00      6.24    472.37      1.00\n",
      "lambda[114]      2.82      9.13      0.98      0.00      5.44    803.81      1.00\n",
      "lambda[115]      3.20     15.69      0.97      0.00      5.24    960.17      1.00\n",
      "lambda[116]      4.42     36.53      0.99      0.00      5.35    788.97      1.00\n",
      "lambda[117]      3.96     16.80      0.95      0.00      5.50    436.77      1.00\n",
      "lambda[118]      3.52     28.93      0.95      0.00      4.53    812.22      1.00\n",
      "lambda[119]      4.48     25.56      0.98      0.01      7.21    936.75      1.00\n",
      "lambda[120]      3.88     15.54      0.93      0.00      6.88    653.60      1.00\n",
      "lambda[121]      2.72      7.76      0.97      0.00      5.49    741.11      1.00\n",
      "lambda[122]      3.71     20.80      0.95      0.00      5.26    534.46      1.00\n",
      "lambda[123]      2.71      8.10      0.91      0.00      5.53    731.50      1.01\n",
      "lambda[124]      2.81      7.78      0.97      0.00      6.11    837.62      1.00\n",
      "lambda[125]      2.89      8.82      0.98      0.00      5.97    630.85      1.00\n",
      "lambda[126]      2.58     10.01      0.96      0.00      4.93    858.00      1.00\n",
      "lambda[127]      3.28     17.76      0.96      0.00      5.31    970.35      1.00\n",
      "lambda[128]      3.30     11.16      1.02      0.00      6.18    463.93      1.00\n",
      "lambda[129]      3.13     17.93      0.87      0.00      5.62    837.72      1.00\n",
      "lambda[130]      2.98      8.27      0.97      0.00      6.19    825.26      1.00\n",
      "lambda[131]      5.41     35.35      1.04      0.00      5.44    529.78      1.00\n",
      "lambda[132]      3.04      8.19      1.01      0.00      6.16    673.81      1.00\n",
      "lambda[133]      2.77      7.98      0.91      0.01      5.20    918.92      1.00\n",
      "lambda[134]      3.10      7.96      1.01      0.00      6.28    822.57      1.00\n",
      "lambda[135]      2.53      6.83      0.96      0.00      5.17    708.08      1.00\n",
      "lambda[136]      2.80      7.65      0.96      0.00      5.34    744.22      1.00\n",
      "lambda[137]      2.85      9.28      1.02      0.00      5.59    720.42      1.00\n",
      "lambda[138]      3.30     10.61      0.95      0.00      6.98    481.01      1.00\n",
      "lambda[139]      2.49      5.44      0.94      0.00      5.67    725.94      1.00\n",
      "lambda[140]      2.95      9.06      1.02      0.00      5.87    884.13      1.00\n",
      "lambda[141]      3.21      9.62      1.00      0.00      6.48    638.54      1.00\n",
      "lambda[142]      3.73     12.93      0.97      0.00      6.37    706.52      1.00\n",
      "lambda[143]      2.59      8.33      0.90      0.00      5.56    809.22      1.00\n",
      "        msq      0.24      0.17      0.20      0.07      0.40    515.30      1.00\n",
      "      sigma      5.28      7.84      1.83      0.00     15.09   1040.19      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    447.74      1.00\n",
      "       xisq      1.49      4.03      0.59      0.06      2.53    289.17      1.02\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.780436992645264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.25e-04 +- 1.27e-02\n",
      "[dimension 02/145]  inactive:\t3.03e-03 +- 3.66e-02\n",
      "[dimension 03/145]  inactive:\t1.34e-03 +- 2.25e-02\n",
      "[dimension 04/145]  inactive:\t3.31e-03 +- 2.96e-02\n",
      "[dimension 05/145]  inactive:\t3.69e-04 +- 1.42e-02\n",
      "[dimension 06/145]  inactive:\t3.95e-03 +- 4.08e-02\n",
      "[dimension 07/145]  inactive:\t1.47e-03 +- 1.75e-02\n",
      "[dimension 08/145]  inactive:\t2.50e-03 +- 2.93e-02\n",
      "[dimension 09/145]  inactive:\t1.35e-03 +- 2.02e-02\n",
      "[dimension 10/145]  inactive:\t8.16e-04 +- 1.52e-02\n",
      "[dimension 11/145]  inactive:\t1.19e-03 +- 2.16e-02\n",
      "[dimension 12/145]  inactive:\t2.28e-03 +- 2.96e-02\n",
      "[dimension 13/145]  inactive:\t4.33e-03 +- 3.66e-02\n",
      "[dimension 14/145]  inactive:\t4.97e-04 +- 1.69e-02\n",
      "[dimension 15/145]  inactive:\t2.39e-03 +- 3.12e-02\n",
      "[dimension 16/145]  inactive:\t8.81e-04 +- 1.81e-02\n",
      "[dimension 17/145]  inactive:\t1.56e-03 +- 2.58e-02\n",
      "[dimension 18/145]  inactive:\t2.27e-03 +- 2.88e-02\n",
      "[dimension 19/145]  inactive:\t-4.79e-04 +- 1.27e-02\n",
      "[dimension 20/145]  inactive:\t2.09e-04 +- 1.45e-02\n",
      "[dimension 21/145]  inactive:\t-1.71e-04 +- 1.46e-02\n",
      "[dimension 22/145]  inactive:\t6.52e-04 +- 1.71e-02\n",
      "[dimension 23/145]  inactive:\t6.08e-04 +- 1.76e-02\n",
      "[dimension 24/145]  inactive:\t1.40e-03 +- 1.91e-02\n",
      "[dimension 25/145]  inactive:\t3.44e-03 +- 2.52e-02\n",
      "[dimension 26/145]  inactive:\t3.43e-04 +- 1.65e-02\n",
      "[dimension 27/145]  inactive:\t1.81e-03 +- 2.46e-02\n",
      "[dimension 28/145]  inactive:\t1.01e-03 +- 1.56e-02\n",
      "[dimension 29/145]  inactive:\t1.52e-03 +- 2.14e-02\n",
      "[dimension 30/145]  inactive:\t2.70e-03 +- 2.84e-02\n",
      "[dimension 31/145]  inactive:\t4.51e-03 +- 3.80e-02\n",
      "[dimension 32/145]  inactive:\t2.46e-03 +- 3.65e-02\n",
      "[dimension 33/145]  inactive:\t4.34e-03 +- 4.14e-02\n",
      "[dimension 34/145]  inactive:\t7.58e-04 +- 1.34e-02\n",
      "[dimension 35/145]  inactive:\t1.68e-03 +- 2.52e-02\n",
      "[dimension 36/145]  inactive:\t1.67e-03 +- 2.39e-02\n",
      "[dimension 37/145]  inactive:\t2.89e-03 +- 2.09e-02\n",
      "[dimension 38/145]  inactive:\t9.62e-04 +- 2.33e-02\n",
      "[dimension 39/145]  inactive:\t4.07e-03 +- 3.77e-02\n",
      "[dimension 40/145]  inactive:\t2.87e-03 +- 2.90e-02\n",
      "[dimension 41/145]  inactive:\t8.41e-05 +- 1.74e-02\n",
      "[dimension 42/145]  inactive:\t3.28e-02 +- 1.54e-01\n",
      "[dimension 43/145]  inactive:\t4.70e-04 +- 1.27e-02\n",
      "[dimension 44/145]  inactive:\t1.19e-03 +- 2.33e-02\n",
      "[dimension 45/145]  inactive:\t4.75e-03 +- 5.23e-02\n",
      "[dimension 46/145]  inactive:\t4.57e-04 +- 9.87e-03\n",
      "[dimension 47/145]  inactive:\t2.86e-04 +- 2.28e-02\n",
      "[dimension 48/145]  inactive:\t9.67e-04 +- 1.66e-02\n",
      "[dimension 49/145]  inactive:\t2.30e-03 +- 2.60e-02\n",
      "[dimension 50/145]  inactive:\t1.67e-04 +- 1.92e-02\n",
      "[dimension 51/145]  inactive:\t2.53e-03 +- 2.80e-02\n",
      "[dimension 52/145]  inactive:\t5.12e-03 +- 2.67e-02\n",
      "[dimension 53/145]  inactive:\t2.11e-04 +- 1.67e-02\n",
      "[dimension 54/145]  inactive:\t2.20e-03 +- 2.35e-02\n",
      "[dimension 55/145]  inactive:\t4.63e-04 +- 1.10e-02\n",
      "[dimension 56/145]  inactive:\t-5.23e-04 +- 1.48e-02\n",
      "[dimension 57/145]  inactive:\t2.07e-03 +- 2.73e-02\n",
      "[dimension 58/145]  inactive:\t2.02e-02 +- 9.61e-02\n",
      "[dimension 59/145]  inactive:\t-7.45e-05 +- 1.37e-02\n",
      "[dimension 60/145]  inactive:\t2.70e-03 +- 3.20e-02\n",
      "[dimension 61/145]  inactive:\t3.37e-03 +- 2.49e-02\n",
      "[dimension 62/145]  inactive:\t3.10e-04 +- 1.43e-02\n",
      "[dimension 63/145]  active:\t5.66e-01 +- 4.34e-01\n",
      "[dimension 64/145]  inactive:\t-5.78e-04 +- 1.22e-02\n",
      "[dimension 65/145]  inactive:\t6.46e-04 +- 1.84e-02\n",
      "[dimension 66/145]  inactive:\t9.70e-04 +- 1.86e-02\n",
      "[dimension 67/145]  inactive:\t1.11e-03 +- 1.71e-02\n",
      "[dimension 68/145]  inactive:\t8.48e-04 +- 2.70e-02\n",
      "[dimension 69/145]  inactive:\t4.61e-03 +- 4.08e-02\n",
      "[dimension 70/145]  inactive:\t4.14e-03 +- 2.49e-02\n",
      "[dimension 71/145]  inactive:\t7.34e-04 +- 1.82e-02\n",
      "[dimension 72/145]  inactive:\t2.51e-03 +- 2.88e-02\n",
      "[dimension 73/145]  inactive:\t5.26e-04 +- 1.17e-02\n",
      "[dimension 74/145]  inactive:\t7.04e-04 +- 2.64e-02\n",
      "[dimension 75/145]  inactive:\t1.29e-03 +- 2.18e-02\n",
      "[dimension 76/145]  inactive:\t7.73e-03 +- 5.00e-02\n",
      "[dimension 77/145]  inactive:\t4.87e-04 +- 2.11e-02\n",
      "[dimension 78/145]  inactive:\t9.36e-03 +- 7.14e-02\n",
      "[dimension 79/145]  inactive:\t4.44e-03 +- 2.82e-02\n",
      "[dimension 80/145]  inactive:\t8.76e-04 +- 1.80e-02\n",
      "[dimension 81/145]  inactive:\t2.87e-03 +- 3.15e-02\n",
      "[dimension 82/145]  inactive:\t4.25e-04 +- 1.18e-02\n",
      "[dimension 83/145]  inactive:\t-3.29e-04 +- 1.08e-02\n",
      "[dimension 84/145]  inactive:\t1.58e-04 +- 1.73e-02\n",
      "[dimension 85/145]  inactive:\t3.90e-03 +- 3.54e-02\n",
      "[dimension 86/145]  inactive:\t-2.29e-04 +- 1.33e-02\n",
      "[dimension 87/145]  inactive:\t3.76e-03 +- 3.82e-02\n",
      "[dimension 88/145]  inactive:\t1.88e-03 +- 1.81e-02\n",
      "[dimension 89/145]  inactive:\t4.29e-05 +- 1.56e-02\n",
      "[dimension 90/145]  inactive:\t7.90e-02 +- 2.31e-01\n",
      "[dimension 91/145]  inactive:\t3.16e-05 +- 1.18e-02\n",
      "[dimension 92/145]  inactive:\t-4.23e-05 +- 1.44e-02\n",
      "[dimension 93/145]  inactive:\t8.93e-05 +- 1.67e-02\n",
      "[dimension 94/145]  inactive:\t1.06e-03 +- 1.59e-02\n",
      "[dimension 95/145]  inactive:\t6.64e-04 +- 1.89e-02\n",
      "[dimension 96/145]  inactive:\t1.97e-03 +- 3.07e-02\n",
      "[dimension 97/145]  inactive:\t2.33e-03 +- 1.97e-02\n",
      "[dimension 98/145]  inactive:\t2.99e-04 +- 1.40e-02\n",
      "[dimension 99/145]  inactive:\t1.40e-02 +- 8.93e-02\n",
      "[dimension 100/145]  inactive:\t-4.35e-06 +- 1.25e-02\n",
      "[dimension 101/145]  inactive:\t-6.48e-04 +- 1.37e-02\n",
      "[dimension 102/145]  inactive:\t8.96e-04 +- 2.10e-02\n",
      "[dimension 103/145]  inactive:\t1.12e-03 +- 1.92e-02\n",
      "[dimension 104/145]  inactive:\t-2.88e-04 +- 1.09e-02\n",
      "[dimension 105/145]  inactive:\t4.24e-04 +- 1.52e-02\n",
      "[dimension 106/145]  inactive:\t4.25e-03 +- 3.05e-02\n",
      "[dimension 107/145]  inactive:\t1.02e-04 +- 1.43e-02\n",
      "[dimension 108/145]  inactive:\t5.26e-03 +- 5.03e-02\n",
      "[dimension 109/145]  inactive:\t1.75e-04 +- 1.09e-02\n",
      "[dimension 110/145]  inactive:\t3.98e-03 +- 4.65e-02\n",
      "[dimension 111/145]  inactive:\t3.07e-03 +- 3.19e-02\n",
      "[dimension 112/145]  inactive:\t7.07e-03 +- 6.03e-02\n",
      "[dimension 113/145]  inactive:\t7.02e-05 +- 1.27e-02\n",
      "[dimension 114/145]  inactive:\t4.54e-03 +- 4.85e-02\n",
      "[dimension 115/145]  inactive:\t1.37e-03 +- 1.62e-02\n",
      "[dimension 116/145]  inactive:\t1.69e-03 +- 2.47e-02\n",
      "[dimension 117/145]  inactive:\t4.52e-03 +- 4.46e-02\n",
      "[dimension 118/145]  inactive:\t2.12e-03 +- 1.95e-02\n",
      "[dimension 119/145]  inactive:\t9.54e-04 +- 2.42e-02\n",
      "[dimension 120/145]  inactive:\t1.54e-03 +- 2.63e-02\n",
      "[dimension 121/145]  inactive:\t3.36e-03 +- 3.08e-02\n",
      "[dimension 122/145]  inactive:\t-1.06e-04 +- 1.83e-02\n",
      "[dimension 123/145]  inactive:\t2.67e-03 +- 3.61e-02\n",
      "[dimension 124/145]  inactive:\t-3.66e-05 +- 1.18e-02\n",
      "[dimension 125/145]  inactive:\t2.80e-04 +- 1.87e-02\n",
      "[dimension 126/145]  inactive:\t5.41e-04 +- 1.51e-02\n",
      "[dimension 127/145]  inactive:\t3.85e-04 +- 1.16e-02\n",
      "[dimension 128/145]  inactive:\t9.05e-04 +- 2.11e-02\n",
      "[dimension 129/145]  inactive:\t5.67e-04 +- 1.91e-02\n",
      "[dimension 130/145]  inactive:\t2.11e-03 +- 2.15e-02\n",
      "[dimension 131/145]  inactive:\t8.74e-04 +- 2.39e-02\n",
      "[dimension 132/145]  inactive:\t4.37e-03 +- 4.24e-02\n",
      "[dimension 133/145]  inactive:\t2.07e-03 +- 1.77e-02\n",
      "[dimension 134/145]  inactive:\t6.50e-04 +- 1.70e-02\n",
      "[dimension 135/145]  inactive:\t2.47e-03 +- 2.88e-02\n",
      "[dimension 136/145]  inactive:\t8.49e-04 +- 1.31e-02\n",
      "[dimension 137/145]  inactive:\t1.50e-03 +- 2.68e-02\n",
      "[dimension 138/145]  inactive:\t6.51e-04 +- 1.38e-02\n",
      "[dimension 139/145]  inactive:\t1.44e-03 +- 2.31e-02\n",
      "[dimension 140/145]  inactive:\t2.75e-04 +- 1.51e-02\n",
      "[dimension 141/145]  inactive:\t1.53e-03 +- 2.02e-02\n",
      "[dimension 142/145]  inactive:\t1.51e-03 +- 1.56e-02\n",
      "[dimension 143/145]  inactive:\t3.60e-03 +- 3.94e-02\n",
      "[dimension 144/145]  inactive:\t1.06e-03 +- 1.67e-02\n",
      "[dimension 145/145]  inactive:\t-3.02e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00072129]\n",
      "cov_act[[5.4437667e-05]]\n",
      "Active_dimensions: [62]\n",
      "10, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.88it/s, 31 steps of size 1.73e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    590.31      1.00\n",
      "  lambda[0]      2.23      4.94      0.92      0.00      4.69    687.76      1.00\n",
      "  lambda[1]      2.81      7.83      0.97      0.00      5.48    504.10      1.00\n",
      "  lambda[2]      3.04      8.74      0.99      0.00      5.96    681.32      1.00\n",
      "  lambda[3]      4.53     25.92      0.98      0.00      6.03    658.50      1.00\n",
      "  lambda[4]      2.92      8.75      1.08      0.00      5.51    638.55      1.00\n",
      "  lambda[5]      3.60     12.53      0.96      0.00      6.18    676.80      1.00\n",
      "  lambda[6]      2.84     10.50      1.04      0.00      5.53    937.74      1.00\n",
      "  lambda[7]      2.75      6.85      0.99      0.00      5.85    591.23      1.00\n",
      "  lambda[8]      2.36      4.47      0.99      0.00      5.31   1164.98      1.00\n",
      "  lambda[9]      2.39      6.01      0.97      0.00      4.68    754.67      1.00\n",
      " lambda[10]      3.02     11.04      1.02      0.00      4.94    875.89      1.00\n",
      " lambda[11]      2.75      7.05      1.00      0.01      5.57    851.07      1.00\n",
      " lambda[12]      3.72     11.65      0.98      0.00      6.94    582.83      1.00\n",
      " lambda[13]      2.91      9.30      0.97      0.00      5.91    650.93      1.00\n",
      " lambda[14]      5.14     37.38      0.96      0.00      6.46    885.13      1.00\n",
      " lambda[15]      3.02     13.65      0.99      0.00      5.06    623.42      1.00\n",
      " lambda[16]      3.34      8.81      0.98      0.00      7.93    598.32      1.00\n",
      " lambda[17]      3.11     25.23      0.97      0.00      5.28    720.83      1.00\n",
      " lambda[18]      2.94      7.18      0.95      0.00      6.58    409.17      1.00\n",
      " lambda[19]      3.91     21.54      0.99      0.00      5.85    659.62      1.00\n",
      " lambda[20]      2.73      7.81      0.93      0.00      5.71    791.11      1.00\n",
      " lambda[21]      2.70      7.00      0.98      0.00      5.84    983.36      1.00\n",
      " lambda[22]      2.51      5.15      1.04      0.00      5.20    644.77      1.00\n",
      " lambda[23]      4.17     27.81      0.96      0.00      5.99    529.73      1.00\n",
      " lambda[24]      3.76     16.87      0.99      0.00      6.77    724.36      1.00\n",
      " lambda[25]      3.45     11.90      1.04      0.01      5.84    375.70      1.00\n",
      " lambda[26]      3.25     15.42      1.02      0.00      4.84    396.09      1.00\n",
      " lambda[27]      2.81      9.55      0.95      0.00      5.57    523.29      1.00\n",
      " lambda[28]      3.03      9.53      1.02      0.00      6.43    516.08      1.00\n",
      " lambda[29]      3.29     11.06      0.96      0.00      5.76    597.63      1.00\n",
      " lambda[30]      3.57     13.95      1.04      0.01      6.25    996.47      1.00\n",
      " lambda[31]      4.06     20.64      0.97      0.00      6.59    772.86      1.00\n",
      " lambda[32]      3.33      9.40      1.01      0.00      6.09    455.49      1.00\n",
      " lambda[33]      2.62      8.35      0.93      0.01      4.78    782.37      1.00\n",
      " lambda[34]      2.69      7.55      1.02      0.00      5.19    660.43      1.00\n",
      " lambda[35]      2.51      6.30      1.02      0.00      5.09    501.42      1.00\n",
      " lambda[36]      3.82     15.15      1.03      0.00      6.91    904.48      1.00\n",
      " lambda[37]      3.23     14.07      1.01      0.00      5.62    612.03      1.00\n",
      " lambda[38]      2.92      8.29      0.93      0.00      5.77    934.89      1.00\n",
      " lambda[39]      3.50     11.41      0.99      0.01      6.85    793.92      1.00\n",
      " lambda[40]      3.91     18.00      0.96      0.00      6.41    966.34      1.00\n",
      " lambda[41]     26.83    282.33      0.98      0.00     11.21    285.84      1.00\n",
      " lambda[42]      2.38      5.03      0.99      0.00      5.13    920.18      1.00\n",
      " lambda[43]      6.96    116.19      0.92      0.00      6.99   1005.68      1.00\n",
      " lambda[44]      2.66      6.02      0.90      0.01      5.42    631.13      1.00\n",
      " lambda[45]      2.71      7.47      0.99      0.00      4.97    824.42      1.00\n",
      " lambda[46]      2.77      7.58      1.08      0.01      5.22    631.39      1.00\n",
      " lambda[47]      2.73      7.62      0.95      0.00      5.22    545.81      1.00\n",
      " lambda[48]      2.88     10.52      1.05      0.01      5.49    830.57      1.00\n",
      " lambda[49]      3.67     19.50      0.96      0.00      5.80    926.95      1.00\n",
      " lambda[50]      3.30     10.71      1.02      0.00      5.69    686.84      1.00\n",
      " lambda[51]      5.44     70.17      1.05      0.00      7.03    991.27      1.00\n",
      " lambda[52]      3.42     22.99      0.96      0.00      5.71    883.07      1.00\n",
      " lambda[53]      2.78      7.48      0.97      0.00      5.35    754.53      1.00\n",
      " lambda[54]      1.98      4.18      0.92      0.00      4.16    938.45      1.00\n",
      " lambda[55]      3.46     16.71      1.02      0.00      5.59    849.44      1.00\n",
      " lambda[56]      2.76      6.23      1.02      0.00      5.57    692.20      1.00\n",
      " lambda[57]     37.89    932.36      1.08      0.00     11.32    921.12      1.00\n",
      " lambda[58]      2.20      4.85      0.91      0.00      4.59    747.84      1.00\n",
      " lambda[59]      4.17     20.09      0.99      0.00      6.62    654.31      1.00\n",
      " lambda[60]      3.04     10.59      0.96      0.00      5.28    886.99      1.00\n",
      " lambda[61]      2.76      6.66      0.98      0.01      5.58    635.13      1.00\n",
      " lambda[62]   1239.10  18677.93    110.00      0.01    847.67    520.00      1.00\n",
      " lambda[63]      2.69      9.23      1.00      0.00      5.87    751.07      1.00\n",
      " lambda[64]      2.94      7.67      0.98      0.00      5.96    774.78      1.00\n",
      " lambda[65]      2.90      9.09      0.95      0.00      5.90    864.24      1.00\n",
      " lambda[66]      2.90      7.56      1.03      0.00      6.55    718.13      1.00\n",
      " lambda[67]      2.63      6.25      0.89      0.00      5.76    557.05      1.00\n",
      " lambda[68]      4.31     40.11      0.91      0.00      5.69    771.24      1.00\n",
      " lambda[69]      3.74     16.10      0.99      0.00      5.51    634.25      1.00\n",
      " lambda[70]      2.74      9.45      0.97      0.00      4.90    636.41      1.00\n",
      " lambda[71]      3.29     13.83      0.94      0.00      5.72    496.96      1.00\n",
      " lambda[72]      2.62      6.41      0.96      0.01      5.25    460.53      1.00\n",
      " lambda[73]      2.71      6.75      1.05      0.00      5.12    748.36      1.00\n",
      " lambda[74]      2.33      4.15      1.05      0.01      5.21    857.50      1.01\n",
      " lambda[75]      4.33     17.73      1.00      0.00      6.85    732.95      1.00\n",
      " lambda[76]      3.12      8.70      0.99      0.00      5.73    771.71      1.00\n",
      " lambda[77]      6.60     71.05      1.05      0.00      6.76    861.13      1.00\n",
      " lambda[78]      3.36      9.43      1.03      0.00      6.90    737.85      1.00\n",
      " lambda[79]      3.00     13.75      1.00      0.00      5.26    910.17      1.00\n",
      " lambda[80]      3.55     18.87      1.08      0.00      6.14    787.01      1.00\n",
      " lambda[81]      2.43      5.31      0.89      0.00      5.65    814.92      1.00\n",
      " lambda[82]      2.25      4.78      0.94      0.01      4.43    849.35      1.00\n",
      " lambda[83]      2.92      9.09      0.99      0.00      5.61    700.13      1.00\n",
      " lambda[84]      4.30     37.21      1.00      0.00      5.82    892.40      1.00\n",
      " lambda[85]      2.72      6.87      0.97      0.00      6.35    710.65      1.00\n",
      " lambda[86]      2.81      7.07      1.00      0.00      5.45    317.47      1.00\n",
      " lambda[87]      3.71     18.07      0.98      0.00      5.84    495.61      1.00\n",
      " lambda[88]      2.91      9.81      0.92      0.00      5.94    918.41      1.00\n",
      " lambda[89]    123.11    834.04      1.48      0.00    192.48    716.37      1.00\n",
      " lambda[90]      3.02      8.44      1.00      0.00      5.52    511.05      1.00\n",
      " lambda[91]      3.25      9.77      1.01      0.01      5.93    487.95      1.00\n",
      " lambda[92]      2.76      7.30      1.04      0.00      5.27    775.43      1.00\n",
      " lambda[93]      2.40      4.67      1.04      0.00      5.14    756.67      1.00\n",
      " lambda[94]      2.47      7.40      0.89      0.00      4.81    852.26      1.00\n",
      " lambda[95]      3.11      9.76      0.94      0.00      5.68    637.75      1.00\n",
      " lambda[96]      3.74     22.39      0.96      0.00      5.17    473.08      1.00\n",
      " lambda[97]      3.24     15.53      0.98      0.00      5.54    706.90      1.00\n",
      " lambda[98]      5.74     40.98      1.00      0.00      5.75    584.16      1.00\n",
      " lambda[99]      2.58      6.57      0.95      0.00      5.12    691.21      1.00\n",
      "lambda[100]      3.90     29.94      0.92      0.00      5.95    914.72      1.00\n",
      "lambda[101]      2.62      5.44      0.91      0.01      5.96    774.87      1.00\n",
      "lambda[102]      2.83      8.24      0.93      0.00      5.53    863.33      1.00\n",
      "lambda[103]      2.19      4.16      0.99      0.00      5.05    749.60      1.00\n",
      "lambda[104]      3.27     16.22      0.95      0.00      6.40    490.98      1.00\n",
      "lambda[105]      3.54      9.59      0.96      0.00      7.50    690.00      1.00\n",
      "lambda[106]      2.48      5.46      0.96      0.01      5.55    813.65      1.00\n",
      "lambda[107]      4.60     17.78      0.99      0.00      6.44    808.23      1.00\n",
      "lambda[108]      2.02      3.23      0.94      0.01      4.74    754.96      1.00\n",
      "lambda[109]      3.73     11.43      0.97      0.00      5.99    472.17      1.00\n",
      "lambda[110]      3.65     11.68      0.99      0.00      7.46    699.94      1.00\n",
      "lambda[111]      4.20     18.42      0.97      0.00      5.92    708.99      1.00\n",
      "lambda[112]      2.63      5.92      0.95      0.01      6.25    924.52      1.00\n",
      "lambda[113]      4.47     20.98      1.00      0.00      6.64    612.37      1.00\n",
      "lambda[114]      3.52     11.52      0.96      0.00      6.09    726.71      1.00\n",
      "lambda[115]      4.06     19.76      0.94      0.00      5.57    661.88      1.00\n",
      "lambda[116]      5.44     47.12      1.00      0.00      5.91    419.30      1.00\n",
      "lambda[117]      3.76     18.22      0.96      0.00      6.42    995.83      1.00\n",
      "lambda[118]      2.90      9.55      0.95      0.00      5.56    968.54      1.00\n",
      "lambda[119]      3.54     15.66      1.06      0.00      6.86    839.27      1.00\n",
      "lambda[120]      4.86     34.36      1.00      0.00      6.99    858.62      1.00\n",
      "lambda[121]      2.75      7.83      0.95      0.00      5.66    821.08      1.00\n",
      "lambda[122]      3.42      9.76      1.07      0.00      6.59    465.42      1.00\n",
      "lambda[123]      2.71      8.19      0.91      0.00      5.22    727.78      1.00\n",
      "lambda[124]      2.74      7.13      0.98      0.00      5.81    587.36      1.00\n",
      "lambda[125]      2.74      6.87      0.93      0.01      5.60    425.88      1.00\n",
      "lambda[126]      2.49      7.83      0.92      0.00      4.58    876.22      1.00\n",
      "lambda[127]      4.27     18.47      0.99      0.00      6.76    589.12      1.00\n",
      "lambda[128]      2.33      5.35      0.95      0.01      4.33    638.18      1.00\n",
      "lambda[129]      4.56     41.47      1.00      0.00      5.88   1009.59      1.00\n",
      "lambda[130]      3.03      7.88      0.94      0.00      6.70    848.44      1.00\n",
      "lambda[131]      3.37      9.24      0.96      0.00      6.86    680.30      1.00\n",
      "lambda[132]      2.72      6.52      0.98      0.00      6.53    823.87      1.00\n",
      "lambda[133]      2.98      9.83      0.95      0.00      5.38    594.31      1.00\n",
      "lambda[134]      3.38      7.94      0.88      0.00      8.09    655.54      1.00\n",
      "lambda[135]      2.59      8.34      0.90      0.00      4.62    678.93      1.00\n",
      "lambda[136]      2.53      6.11      0.92      0.00      5.27    926.51      1.00\n",
      "lambda[137]      2.61      7.80      0.93      0.00      4.63    740.90      1.00\n",
      "lambda[138]      3.20     12.72      1.06      0.00      5.96    690.71      1.00\n",
      "lambda[139]      3.11      9.33      1.04      0.01      6.14    649.18      1.00\n",
      "lambda[140]      3.12     10.35      0.97      0.00      5.61    611.23      1.00\n",
      "lambda[141]      2.88     12.15      0.91      0.00      5.49    828.96      1.00\n",
      "lambda[142]      4.97     32.55      0.94      0.00      5.84    386.43      1.00\n",
      "lambda[143]      2.42      5.29      0.94      0.00      5.71    524.23      1.00\n",
      "        msq    450.72   5072.38      3.55      0.13    103.19    837.54      1.00\n",
      "      sigma      5.89      7.92      2.69      0.01     15.89   1213.84      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    861.15      1.00\n",
      "       xisq      0.12      0.06      0.11      0.04      0.21   1174.01      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 32.03691101074219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.16e-04 +- 2.02e-02\n",
      "[dimension 02/145]  inactive:\t-4.33e-04 +- 2.64e-02\n",
      "[dimension 03/145]  inactive:\t1.51e-03 +- 3.32e-02\n",
      "[dimension 04/145]  inactive:\t6.64e-03 +- 4.90e-02\n",
      "[dimension 05/145]  inactive:\t-1.06e-03 +- 3.24e-02\n",
      "[dimension 06/145]  inactive:\t3.28e-03 +- 4.01e-02\n",
      "[dimension 07/145]  inactive:\t7.00e-04 +- 2.03e-02\n",
      "[dimension 08/145]  inactive:\t1.72e-03 +- 3.65e-02\n",
      "[dimension 09/145]  inactive:\t6.75e-04 +- 2.62e-02\n",
      "[dimension 10/145]  inactive:\t5.75e-04 +- 1.97e-02\n",
      "[dimension 11/145]  inactive:\t-9.25e-04 +- 2.62e-02\n",
      "[dimension 12/145]  inactive:\t-5.38e-05 +- 2.75e-02\n",
      "[dimension 13/145]  inactive:\t5.73e-03 +- 4.70e-02\n",
      "[dimension 14/145]  inactive:\t-1.49e-03 +- 2.71e-02\n",
      "[dimension 15/145]  inactive:\t2.55e-03 +- 4.91e-02\n",
      "[dimension 16/145]  inactive:\t9.12e-04 +- 2.17e-02\n",
      "[dimension 17/145]  inactive:\t9.26e-04 +- 3.55e-02\n",
      "[dimension 18/145]  inactive:\t2.00e-04 +- 2.96e-02\n",
      "[dimension 19/145]  inactive:\t-2.93e-03 +- 2.56e-02\n",
      "[dimension 20/145]  inactive:\t-1.65e-03 +- 3.36e-02\n",
      "[dimension 21/145]  inactive:\t-2.09e-03 +- 2.76e-02\n",
      "[dimension 22/145]  inactive:\t-4.38e-04 +- 2.76e-02\n",
      "[dimension 23/145]  inactive:\t-7.74e-05 +- 2.61e-02\n",
      "[dimension 24/145]  inactive:\t2.15e-03 +- 3.31e-02\n",
      "[dimension 25/145]  inactive:\t4.04e-03 +- 2.67e-02\n",
      "[dimension 26/145]  inactive:\t1.88e-05 +- 3.44e-02\n",
      "[dimension 27/145]  inactive:\t1.02e-03 +- 2.70e-02\n",
      "[dimension 28/145]  inactive:\t8.11e-04 +- 2.12e-02\n",
      "[dimension 29/145]  inactive:\t4.22e-04 +- 3.23e-02\n",
      "[dimension 30/145]  inactive:\t1.49e-03 +- 3.41e-02\n",
      "[dimension 31/145]  inactive:\t7.11e-03 +- 4.99e-02\n",
      "[dimension 32/145]  inactive:\t-1.99e-03 +- 3.28e-02\n",
      "[dimension 33/145]  inactive:\t2.72e-03 +- 3.92e-02\n",
      "[dimension 34/145]  inactive:\t8.81e-04 +- 2.09e-02\n",
      "[dimension 35/145]  inactive:\t1.05e-03 +- 2.96e-02\n",
      "[dimension 36/145]  inactive:\t1.52e-03 +- 2.86e-02\n",
      "[dimension 37/145]  inactive:\t5.41e-03 +- 3.26e-02\n",
      "[dimension 38/145]  inactive:\t-1.73e-03 +- 3.92e-02\n",
      "[dimension 39/145]  inactive:\t1.58e-03 +- 3.30e-02\n",
      "[dimension 40/145]  inactive:\t6.35e-03 +- 4.38e-02\n",
      "[dimension 41/145]  inactive:\t-2.46e-03 +- 3.71e-02\n",
      "[dimension 42/145]  inactive:\t2.77e-02 +- 1.36e-01\n",
      "[dimension 43/145]  inactive:\t-3.16e-04 +- 2.18e-02\n",
      "[dimension 44/145]  inactive:\t4.42e-05 +- 4.11e-02\n",
      "[dimension 45/145]  inactive:\t-3.81e-04 +- 2.81e-02\n",
      "[dimension 46/145]  inactive:\t1.14e-03 +- 1.88e-02\n",
      "[dimension 47/145]  inactive:\t-2.02e-03 +- 2.95e-02\n",
      "[dimension 48/145]  inactive:\t2.06e-03 +- 2.77e-02\n",
      "[dimension 49/145]  inactive:\t3.01e-03 +- 2.45e-02\n",
      "[dimension 50/145]  inactive:\t-1.98e-03 +- 3.42e-02\n",
      "[dimension 51/145]  inactive:\t5.13e-03 +- 4.41e-02\n",
      "[dimension 52/145]  inactive:\t5.93e-03 +- 2.61e-02\n",
      "[dimension 53/145]  inactive:\t-1.48e-03 +- 2.87e-02\n",
      "[dimension 54/145]  inactive:\t-2.25e-04 +- 2.13e-02\n",
      "[dimension 55/145]  inactive:\t6.81e-04 +- 1.57e-02\n",
      "[dimension 56/145]  inactive:\t-2.61e-03 +- 2.43e-02\n",
      "[dimension 57/145]  inactive:\t8.83e-04 +- 2.87e-02\n",
      "[dimension 58/145]  inactive:\t2.34e-02 +- 1.01e-01\n",
      "[dimension 59/145]  inactive:\t-8.92e-04 +- 2.03e-02\n",
      "[dimension 60/145]  inactive:\t3.87e-03 +- 4.90e-02\n",
      "[dimension 61/145]  inactive:\t3.45e-03 +- 2.97e-02\n",
      "[dimension 62/145]  inactive:\t-8.04e-04 +- 2.88e-02\n",
      "[dimension 63/145]  active:\t5.74e-01 +- 4.61e-01\n",
      "[dimension 64/145]  inactive:\t-3.88e-03 +- 3.56e-02\n",
      "[dimension 65/145]  inactive:\t-4.53e-04 +- 3.12e-02\n",
      "[dimension 66/145]  inactive:\t8.64e-04 +- 2.76e-02\n",
      "[dimension 67/145]  inactive:\t1.53e-03 +- 2.95e-02\n",
      "[dimension 68/145]  inactive:\t-1.01e-03 +- 3.11e-02\n",
      "[dimension 69/145]  inactive:\t4.26e-03 +- 4.63e-02\n",
      "[dimension 70/145]  inactive:\t4.39e-03 +- 2.77e-02\n",
      "[dimension 71/145]  inactive:\t4.06e-04 +- 2.77e-02\n",
      "[dimension 72/145]  inactive:\t6.90e-04 +- 2.63e-02\n",
      "[dimension 73/145]  inactive:\t6.80e-04 +- 2.25e-02\n",
      "[dimension 74/145]  inactive:\t-1.05e-03 +- 2.96e-02\n",
      "[dimension 75/145]  inactive:\t5.06e-04 +- 2.32e-02\n",
      "[dimension 76/145]  inactive:\t8.06e-03 +- 4.75e-02\n",
      "[dimension 77/145]  inactive:\t-2.06e-03 +- 3.48e-02\n",
      "[dimension 78/145]  inactive:\t8.52e-03 +- 7.32e-02\n",
      "[dimension 79/145]  inactive:\t7.35e-03 +- 3.79e-02\n",
      "[dimension 80/145]  inactive:\t4.79e-04 +- 3.53e-02\n",
      "[dimension 81/145]  inactive:\t2.36e-03 +- 3.67e-02\n",
      "[dimension 82/145]  inactive:\t4.39e-04 +- 1.85e-02\n",
      "[dimension 83/145]  inactive:\t-1.80e-03 +- 2.09e-02\n",
      "[dimension 84/145]  inactive:\t-1.13e-03 +- 2.89e-02\n",
      "[dimension 85/145]  inactive:\t2.87e-03 +- 3.17e-02\n",
      "[dimension 86/145]  inactive:\t-8.74e-04 +- 2.44e-02\n",
      "[dimension 87/145]  inactive:\t4.25e-03 +- 4.99e-02\n",
      "[dimension 88/145]  inactive:\t3.46e-03 +- 2.84e-02\n",
      "[dimension 89/145]  inactive:\t-6.04e-04 +- 2.63e-02\n",
      "[dimension 90/145]  inactive:\t1.70e-01 +- 3.47e-01\n",
      "[dimension 91/145]  inactive:\t-2.75e-05 +- 2.20e-02\n",
      "[dimension 92/145]  inactive:\t-1.87e-03 +- 3.10e-02\n",
      "[dimension 93/145]  inactive:\t-4.20e-04 +- 3.11e-02\n",
      "[dimension 94/145]  inactive:\t1.89e-03 +- 2.72e-02\n",
      "[dimension 95/145]  inactive:\t-6.01e-04 +- 2.26e-02\n",
      "[dimension 96/145]  inactive:\t4.88e-04 +- 4.30e-02\n",
      "[dimension 97/145]  inactive:\t2.93e-03 +- 2.67e-02\n",
      "[dimension 98/145]  inactive:\t-8.34e-04 +- 2.86e-02\n",
      "[dimension 99/145]  inactive:\t7.17e-03 +- 6.40e-02\n",
      "[dimension 100/145]  inactive:\t-6.59e-04 +- 1.91e-02\n",
      "[dimension 101/145]  inactive:\t-2.79e-03 +- 2.38e-02\n",
      "[dimension 102/145]  inactive:\t-9.12e-04 +- 3.01e-02\n",
      "[dimension 103/145]  inactive:\t1.08e-03 +- 2.76e-02\n",
      "[dimension 104/145]  inactive:\t-4.92e-04 +- 2.00e-02\n",
      "[dimension 105/145]  inactive:\t4.27e-04 +- 3.18e-02\n",
      "[dimension 106/145]  inactive:\t6.53e-03 +- 3.74e-02\n",
      "[dimension 107/145]  inactive:\t-1.33e-03 +- 2.21e-02\n",
      "[dimension 108/145]  inactive:\t1.09e-02 +- 8.29e-02\n",
      "[dimension 109/145]  inactive:\t-5.89e-04 +- 2.00e-02\n",
      "[dimension 110/145]  inactive:\t-3.46e-04 +- 3.93e-02\n",
      "[dimension 111/145]  inactive:\t2.97e-03 +- 3.89e-02\n",
      "[dimension 112/145]  inactive:\t6.68e-03 +- 5.11e-02\n",
      "[dimension 113/145]  inactive:\t-1.95e-03 +- 2.70e-02\n",
      "[dimension 114/145]  inactive:\t2.73e-03 +- 4.77e-02\n",
      "[dimension 115/145]  inactive:\t2.23e-03 +- 2.43e-02\n",
      "[dimension 116/145]  inactive:\t2.44e-03 +- 5.20e-02\n",
      "[dimension 117/145]  inactive:\t8.00e-03 +- 6.68e-02\n",
      "[dimension 118/145]  inactive:\t3.77e-03 +- 2.89e-02\n",
      "[dimension 119/145]  inactive:\t-1.85e-03 +- 3.41e-02\n",
      "[dimension 120/145]  inactive:\t4.72e-04 +- 3.14e-02\n",
      "[dimension 121/145]  inactive:\t4.74e-03 +- 3.76e-02\n",
      "[dimension 122/145]  inactive:\t-2.54e-03 +- 3.32e-02\n",
      "[dimension 123/145]  inactive:\t3.55e-03 +- 4.61e-02\n",
      "[dimension 124/145]  inactive:\t-1.37e-03 +- 2.02e-02\n",
      "[dimension 125/145]  inactive:\t-1.40e-03 +- 2.85e-02\n",
      "[dimension 126/145]  inactive:\t-6.96e-04 +- 2.35e-02\n",
      "[dimension 127/145]  inactive:\t8.56e-05 +- 2.13e-02\n",
      "[dimension 128/145]  inactive:\t-1.24e-03 +- 3.86e-02\n",
      "[dimension 129/145]  inactive:\t3.26e-04 +- 2.69e-02\n",
      "[dimension 130/145]  inactive:\t3.86e-03 +- 2.98e-02\n",
      "[dimension 131/145]  inactive:\t-8.76e-04 +- 3.23e-02\n",
      "[dimension 132/145]  inactive:\t5.08e-03 +- 4.61e-02\n",
      "[dimension 133/145]  inactive:\t2.89e-03 +- 2.33e-02\n",
      "[dimension 134/145]  inactive:\t-1.35e-03 +- 3.77e-02\n",
      "[dimension 135/145]  inactive:\t5.86e-04 +- 3.50e-02\n",
      "[dimension 136/145]  inactive:\t1.12e-03 +- 2.07e-02\n",
      "[dimension 137/145]  inactive:\t9.72e-06 +- 2.80e-02\n",
      "[dimension 138/145]  inactive:\t3.76e-04 +- 2.25e-02\n",
      "[dimension 139/145]  inactive:\t7.14e-04 +- 2.78e-02\n",
      "[dimension 140/145]  inactive:\t-9.05e-04 +- 3.07e-02\n",
      "[dimension 141/145]  inactive:\t1.21e-03 +- 2.66e-02\n",
      "[dimension 142/145]  inactive:\t1.76e-03 +- 2.11e-02\n",
      "[dimension 143/145]  inactive:\t1.25e-03 +- 3.81e-02\n",
      "[dimension 144/145]  inactive:\t4.77e-04 +- 2.37e-02\n",
      "[dimension 145/145]  inactive:\t2.98e-11 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8746177]\n",
      "cov_act[[0.0270252]]\n",
      "Active_dimensions: [62]\n",
      "11, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.11it/s, 31 steps of size 1.50e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    565.69      1.00\n",
      "  lambda[0]      2.35      7.03      0.96      0.00      5.14    919.40      1.00\n",
      "  lambda[1]      4.15     22.13      1.00      0.00      5.77    362.84      1.01\n",
      "  lambda[2]     38.51    836.86      1.02      0.00      5.17    559.98      1.00\n",
      "  lambda[3]      4.00     14.58      0.97      0.00      7.36    508.93      1.00\n",
      "  lambda[4]      2.94      9.03      0.99      0.00      5.57    663.07      1.00\n",
      "  lambda[5]     28.56    716.48      0.98      0.00      6.16    845.21      1.00\n",
      "  lambda[6]      3.85     19.56      1.08      0.00      6.87    833.20      1.00\n",
      "  lambda[7]      3.11      8.65      0.97      0.00      5.64    603.84      1.01\n",
      "  lambda[8]      2.47      6.01      0.95      0.00      5.62   1007.63      1.00\n",
      "  lambda[9]      2.48      6.89      0.94      0.00      4.95    608.48      1.00\n",
      " lambda[10]      3.83     15.37      1.04      0.00      6.42    885.69      1.00\n",
      " lambda[11]      3.30     11.54      0.98      0.00      5.69    652.09      1.00\n",
      " lambda[12]     10.24    143.00      1.01      0.00      9.28    924.46      1.00\n",
      " lambda[13]      2.77      8.31      0.91      0.00      5.14    561.54      1.00\n",
      " lambda[14]      8.01    144.86      0.96      0.00      4.85    825.49      1.00\n",
      " lambda[15]      2.59      7.12      0.97      0.00      4.82    718.75      1.00\n",
      " lambda[16]      3.65      9.90      1.00      0.00      8.03    672.69      1.00\n",
      " lambda[17]      6.99     73.97      0.97      0.00      5.86    519.34      1.00\n",
      " lambda[18]      2.81     12.55      0.94      0.00      5.52   1044.09      1.00\n",
      " lambda[19]      3.99     24.92      1.00      0.00      5.61    565.10      1.00\n",
      " lambda[20]      2.87      7.75      0.97      0.01      5.82    630.92      1.00\n",
      " lambda[21]      3.22      9.42      1.02      0.00      6.23    608.49      1.00\n",
      " lambda[22]      2.62      6.30      1.06      0.00      5.80    721.83      1.00\n",
      " lambda[23]      2.79      7.70      1.00      0.00      5.62    747.44      1.00\n",
      " lambda[24]      4.11     19.72      1.02      0.00      6.53    593.41      1.00\n",
      " lambda[25]      2.97      7.07      0.95      0.00      6.48    635.48      1.00\n",
      " lambda[26]     11.15    258.70      0.98      0.00      5.62    942.77      1.00\n",
      " lambda[27]      2.93      8.88      1.00      0.00      5.37    756.41      1.00\n",
      " lambda[28]      3.30     11.10      1.02      0.00      5.75    555.69      1.00\n",
      " lambda[29]      2.96      8.97      0.98      0.00      5.75    729.70      1.00\n",
      " lambda[30]      7.82     80.49      1.02      0.01      6.53    759.69      1.00\n",
      " lambda[31]      3.55     12.69      0.95      0.00      6.73    803.40      1.00\n",
      " lambda[32]      5.66     40.38      0.97      0.00      6.51    592.72      1.00\n",
      " lambda[33]      3.43     14.37      0.94      0.01      6.20    802.31      1.00\n",
      " lambda[34]      2.78      7.67      0.90      0.00      5.58    665.37      1.00\n",
      " lambda[35]      2.85      7.93      0.99      0.00      5.16    868.38      1.00\n",
      " lambda[36]      3.94     16.78      1.03      0.00      6.10    951.68      1.00\n",
      " lambda[37]      3.10      7.91      1.00      0.00      6.05    611.79      1.00\n",
      " lambda[38]      2.97      9.18      0.97      0.00      5.61    912.79      1.00\n",
      " lambda[39]      4.12     19.04      1.00      0.00      6.25    546.99      1.00\n",
      " lambda[40]      3.99     16.04      0.94      0.00      6.44    736.51      1.00\n",
      " lambda[41]     56.64    556.31      1.02      0.00     12.27    365.45      1.00\n",
      " lambda[42]      2.26      4.28      0.98      0.01      4.96    940.08      1.00\n",
      " lambda[43]      2.99     18.30      1.00      0.00      5.15   1006.78      1.00\n",
      " lambda[44]      2.85     14.04      0.93      0.00      4.75    843.73      1.00\n",
      " lambda[45]      2.42      5.33      0.98      0.00      5.26    779.14      1.00\n",
      " lambda[46]      2.29      5.22      1.04      0.01      4.85    827.34      1.00\n",
      " lambda[47]      2.47      5.21      0.96      0.00      5.27    677.82      1.00\n",
      " lambda[48]      2.44      6.09      1.01      0.01      5.32    908.37      1.00\n",
      " lambda[49]      3.28     10.46      0.96      0.00      6.18    817.04      1.00\n",
      " lambda[50]      4.47     22.41      1.09      0.00      5.81    705.74      1.00\n",
      " lambda[51]      8.57    156.55      1.04      0.00      7.48    996.47      1.00\n",
      " lambda[52]      2.65      8.14      0.89      0.00      5.02    632.33      1.00\n",
      " lambda[53]      5.93     60.69      0.95      0.00      6.31    527.99      1.00\n",
      " lambda[54]      1.92      3.66      0.92      0.00      4.43   1027.71      1.00\n",
      " lambda[55]      3.36     18.62      1.00      0.00      5.88    883.52      1.00\n",
      " lambda[56]      2.86      6.31      0.97      0.00      5.88    560.06      1.00\n",
      " lambda[57]     12.35    107.12      1.07      0.00      9.87    723.44      1.00\n",
      " lambda[58]      2.31      5.16      0.96      0.00      5.19    684.39      1.00\n",
      " lambda[59]      4.16     25.21      0.98      0.00      7.39    959.98      1.00\n",
      " lambda[60]      5.40     21.36      0.97      0.00      7.02    464.71      1.00\n",
      " lambda[61]      2.51      5.98      1.02      0.01      5.48    827.63      1.00\n",
      " lambda[62]   2158.76  33457.45    127.46      0.01   1720.09    650.97      1.00\n",
      " lambda[63]      2.65     17.61      0.94      0.00      5.07    898.99      1.00\n",
      " lambda[64]      3.63     12.10      1.01      0.00      5.81    499.55      1.00\n",
      " lambda[65]      3.96     20.68      1.00      0.00      5.74    885.22      1.00\n",
      " lambda[66]      3.11      7.96      1.04      0.00      6.45    745.53      1.00\n",
      " lambda[67]      2.69      7.84      0.95      0.00      5.03    518.93      1.00\n",
      " lambda[68]     10.41    129.69      0.92      0.00      5.42    459.06      1.00\n",
      " lambda[69]      5.75     22.99      0.97      0.00      9.21    539.98      1.00\n",
      " lambda[70]      2.72      7.43      1.02      0.00      5.42    649.25      1.00\n",
      " lambda[71]      2.90     12.08      0.97      0.00      4.83    850.91      1.00\n",
      " lambda[72]      2.71      7.65      0.98      0.00      5.26    702.35      1.00\n",
      " lambda[73]      2.43      5.11      1.02      0.00      5.08    719.36      1.00\n",
      " lambda[74]      2.28      4.12      1.02      0.01      5.17    758.32      1.00\n",
      " lambda[75]      5.29     40.24      0.95      0.00      7.35   1012.94      1.00\n",
      " lambda[76]      3.00      9.86      0.99      0.00      5.58    821.14      1.00\n",
      " lambda[77]     53.25    899.94      1.13      0.00      8.08    736.22      1.00\n",
      " lambda[78]      5.91     44.42      1.12      0.00      7.52    977.05      1.00\n",
      " lambda[79]      3.51     17.33      1.05      0.00      5.13    725.70      1.00\n",
      " lambda[80]      5.96     54.55      1.11      0.01      6.41    978.75      1.00\n",
      " lambda[81]      2.57     13.37      0.94      0.00      4.49   1005.08      1.00\n",
      " lambda[82]      2.08      3.81      0.95      0.01      4.72    749.51      1.00\n",
      " lambda[83]      2.91     11.65      0.93      0.00      5.59    572.97      1.00\n",
      " lambda[84]      3.77     30.71      0.99      0.01      5.73    993.40      1.00\n",
      " lambda[85]      2.36      5.29      0.95      0.00      5.19    639.66      1.00\n",
      " lambda[86]      7.05     76.41      0.99      0.00      5.79    785.84      1.00\n",
      " lambda[87]      3.89     19.10      1.00      0.00      6.60    736.93      1.00\n",
      " lambda[88]      2.74      7.54      0.91      0.00      5.32    750.31      1.00\n",
      " lambda[89]     68.71    866.30      1.09      0.00     45.50    810.69      1.00\n",
      " lambda[90]      2.72      7.00      1.04      0.00      5.22    498.06      1.00\n",
      " lambda[91]      2.58     10.34      0.94      0.00      4.98    867.27      1.00\n",
      " lambda[92]      2.57      5.99      1.01      0.00      5.42    704.66      1.00\n",
      " lambda[93]      2.66      7.19      1.02      0.00      5.05    470.38      1.00\n",
      " lambda[94]      2.54      6.85      0.93      0.00      5.00    670.86      1.00\n",
      " lambda[95]      3.82     18.46      0.98      0.00      5.79    655.74      1.00\n",
      " lambda[96]      3.23     14.71      0.98      0.00      4.96    571.82      1.00\n",
      " lambda[97]      5.69     64.54      0.96      0.00      5.74    485.41      1.00\n",
      " lambda[98]     11.10     81.87      0.99      0.00      6.54    583.09      1.00\n",
      " lambda[99]      2.29      5.38      0.97      0.00      4.49    981.60      1.00\n",
      "lambda[100]      4.07     53.12      0.92      0.00      5.49   1003.27      1.00\n",
      "lambda[101]      2.94     11.36      0.99      0.00      5.53    543.56      1.00\n",
      "lambda[102]      3.27     10.61      0.97      0.00      5.07    616.77      1.00\n",
      "lambda[103]      2.31      4.43      0.96      0.00      5.18    796.71      1.00\n",
      "lambda[104]      3.34     16.64      0.99      0.00      5.81    538.44      1.00\n",
      "lambda[105]      6.27     38.03      1.05      0.00      8.73    827.13      1.00\n",
      "lambda[106]      2.48      5.31      1.04      0.01      5.49    575.19      1.00\n",
      "lambda[107]      7.01     41.96      0.98      0.00      6.98    696.26      1.00\n",
      "lambda[108]      2.49     11.84      1.01      0.01      4.70    908.21      1.00\n",
      "lambda[109]      4.44     30.48      0.96      0.00      6.35    925.91      1.00\n",
      "lambda[110]      3.74     14.43      1.02      0.00      7.00    817.42      1.00\n",
      "lambda[111]      4.49     24.11      0.95      0.00      6.93    867.21      1.00\n",
      "lambda[112]      2.44      5.15      0.95      0.01      5.48    924.66      1.00\n",
      "lambda[113]      6.74     43.08      1.05      0.00      8.06    521.04      1.00\n",
      "lambda[114]      3.97     16.81      0.96      0.00      6.26    630.66      1.00\n",
      "lambda[115]      4.32     19.34      0.96      0.00      6.35    707.81      1.00\n",
      "lambda[116]     16.59    223.63      0.98      0.00      6.88    787.55      1.00\n",
      "lambda[117]      3.13     10.51      0.95      0.00      6.47    808.45      1.00\n",
      "lambda[118]      3.21     10.72      1.01      0.00      6.59    715.60      1.00\n",
      "lambda[119]      2.63      7.85      1.02      0.00      5.38   1005.59      1.00\n",
      "lambda[120]      5.05     26.92      1.03      0.00      6.77    596.40      1.00\n",
      "lambda[121]      3.03     10.50      0.92      0.00      5.74    793.25      1.00\n",
      "lambda[122]      3.46     11.23      1.05      0.00      6.76    610.70      1.00\n",
      "lambda[123]      2.78      8.21      0.97      0.01      5.53    550.32      1.01\n",
      "lambda[124]      2.78      8.15      1.00      0.00      5.84    587.56      1.00\n",
      "lambda[125]      2.85      8.71      1.00      0.01      5.19    619.33      1.00\n",
      "lambda[126]      2.26      4.68      0.92      0.00      4.85    899.29      1.00\n",
      "lambda[127]      6.04     38.12      1.03      0.00      6.40    462.71      1.00\n",
      "lambda[128]      2.87     14.90      0.96      0.00      4.75    881.87      1.00\n",
      "lambda[129]      5.90     75.31      0.98      0.00      6.30   1001.58      1.00\n",
      "lambda[130]      3.30      9.91      0.97      0.00      6.25    851.24      1.00\n",
      "lambda[131]      5.15     40.24      1.01      0.00      5.92    578.58      1.00\n",
      "lambda[132]      2.77      7.30      0.91      0.00      5.69    731.33      1.00\n",
      "lambda[133]      2.36      6.24      0.97      0.00      4.68   1074.00      1.00\n",
      "lambda[134]      3.65     15.93      0.93      0.00      7.36    921.37      1.00\n",
      "lambda[135]      3.24     19.11      1.00      0.00      4.84    566.60      1.00\n",
      "lambda[136]      3.48     16.86      0.96      0.00      6.06    763.62      1.00\n",
      "lambda[137]      2.64      7.80      1.02      0.00      5.29    789.44      1.00\n",
      "lambda[138]      3.86     22.23      1.02      0.00      5.20    743.02      1.00\n",
      "lambda[139]      3.38     13.53      0.98      0.00      6.50    824.32      1.00\n",
      "lambda[140]      3.14     11.42      0.94      0.00      5.91   1001.46      1.00\n",
      "lambda[141]      2.20      4.37      0.90      0.00      4.86    957.59      1.00\n",
      "lambda[142]      5.06     28.88      1.00      0.01      6.64    761.57      1.00\n",
      "lambda[143]      4.62     39.92      1.01      0.00      5.88    498.32      1.00\n",
      "        msq      0.20      0.14      0.17      0.06      0.33    731.22      1.00\n",
      "      sigma      5.61      7.92      2.37      0.01     15.47   1041.12      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    710.53      1.00\n",
      "       xisq      0.11      0.05      0.09      0.04      0.17   1443.34      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 33.66427683830261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.82e-05 +- 1.42e-02\n",
      "[dimension 02/145]  inactive:\t2.31e-03 +- 3.43e-02\n",
      "[dimension 03/145]  inactive:\t2.46e-03 +- 3.12e-02\n",
      "[dimension 04/145]  inactive:\t4.84e-03 +- 3.36e-02\n",
      "[dimension 05/145]  inactive:\t9.78e-04 +- 2.64e-02\n",
      "[dimension 06/145]  inactive:\t4.37e-03 +- 4.34e-02\n",
      "[dimension 07/145]  inactive:\t1.44e-03 +- 1.99e-02\n",
      "[dimension 08/145]  inactive:\t2.79e-03 +- 3.00e-02\n",
      "[dimension 09/145]  inactive:\t1.75e-03 +- 2.50e-02\n",
      "[dimension 10/145]  inactive:\t8.31e-04 +- 1.74e-02\n",
      "[dimension 11/145]  inactive:\t1.45e-03 +- 2.95e-02\n",
      "[dimension 12/145]  inactive:\t2.74e-03 +- 3.31e-02\n",
      "[dimension 13/145]  inactive:\t7.25e-03 +- 4.90e-02\n",
      "[dimension 14/145]  inactive:\t2.34e-04 +- 2.32e-02\n",
      "[dimension 15/145]  inactive:\t3.57e-03 +- 3.94e-02\n",
      "[dimension 16/145]  inactive:\t1.22e-03 +- 2.02e-02\n",
      "[dimension 17/145]  inactive:\t2.74e-03 +- 3.52e-02\n",
      "[dimension 18/145]  inactive:\t3.27e-03 +- 3.73e-02\n",
      "[dimension 19/145]  inactive:\t-1.23e-03 +- 1.75e-02\n",
      "[dimension 20/145]  inactive:\t1.44e-04 +- 2.45e-02\n",
      "[dimension 21/145]  inactive:\t-1.30e-03 +- 2.42e-02\n",
      "[dimension 22/145]  inactive:\t4.93e-04 +- 2.23e-02\n",
      "[dimension 23/145]  inactive:\t6.29e-04 +- 2.42e-02\n",
      "[dimension 24/145]  inactive:\t1.37e-03 +- 2.62e-02\n",
      "[dimension 25/145]  inactive:\t4.16e-03 +- 2.65e-02\n",
      "[dimension 26/145]  inactive:\t4.38e-04 +- 2.61e-02\n",
      "[dimension 27/145]  inactive:\t2.77e-03 +- 3.17e-02\n",
      "[dimension 28/145]  inactive:\t1.31e-03 +- 1.94e-02\n",
      "[dimension 29/145]  inactive:\t2.96e-03 +- 3.68e-02\n",
      "[dimension 30/145]  inactive:\t3.57e-03 +- 3.52e-02\n",
      "[dimension 31/145]  inactive:\t6.75e-03 +- 4.70e-02\n",
      "[dimension 32/145]  inactive:\t7.48e-04 +- 2.79e-02\n",
      "[dimension 33/145]  inactive:\t7.83e-03 +- 5.57e-02\n",
      "[dimension 34/145]  inactive:\t1.44e-03 +- 2.12e-02\n",
      "[dimension 35/145]  inactive:\t1.56e-03 +- 2.33e-02\n",
      "[dimension 36/145]  inactive:\t2.48e-03 +- 2.76e-02\n",
      "[dimension 37/145]  inactive:\t4.63e-03 +- 2.88e-02\n",
      "[dimension 38/145]  inactive:\t1.50e-03 +- 3.19e-02\n",
      "[dimension 39/145]  inactive:\t2.84e-03 +- 3.00e-02\n",
      "[dimension 40/145]  inactive:\t7.55e-03 +- 4.84e-02\n",
      "[dimension 41/145]  inactive:\t9.13e-04 +- 3.27e-02\n",
      "[dimension 42/145]  inactive:\t3.20e-02 +- 1.39e-01\n",
      "[dimension 43/145]  inactive:\t7.25e-04 +- 1.74e-02\n",
      "[dimension 44/145]  inactive:\t1.38e-03 +- 2.76e-02\n",
      "[dimension 45/145]  inactive:\t9.22e-04 +- 2.13e-02\n",
      "[dimension 46/145]  inactive:\t8.41e-04 +- 1.58e-02\n",
      "[dimension 47/145]  inactive:\t-4.79e-05 +- 2.12e-02\n",
      "[dimension 48/145]  inactive:\t2.11e-03 +- 2.50e-02\n",
      "[dimension 49/145]  inactive:\t1.79e-03 +- 2.12e-02\n",
      "[dimension 50/145]  inactive:\t-2.40e-04 +- 2.95e-02\n",
      "[dimension 51/145]  inactive:\t5.73e-03 +- 4.44e-02\n",
      "[dimension 52/145]  inactive:\t6.00e-03 +- 2.61e-02\n",
      "[dimension 53/145]  inactive:\t1.68e-04 +- 2.30e-02\n",
      "[dimension 54/145]  inactive:\t2.48e-03 +- 2.53e-02\n",
      "[dimension 55/145]  inactive:\t6.49e-04 +- 1.46e-02\n",
      "[dimension 56/145]  inactive:\t-1.05e-03 +- 2.21e-02\n",
      "[dimension 57/145]  inactive:\t3.21e-03 +- 3.13e-02\n",
      "[dimension 58/145]  inactive:\t1.86e-02 +- 8.55e-02\n",
      "[dimension 59/145]  inactive:\t8.47e-05 +- 1.60e-02\n",
      "[dimension 60/145]  inactive:\t4.62e-03 +- 3.87e-02\n",
      "[dimension 61/145]  inactive:\t5.95e-03 +- 3.62e-02\n",
      "[dimension 62/145]  inactive:\t6.06e-04 +- 2.16e-02\n",
      "[dimension 63/145]  active:\t4.80e-01 +- 4.19e-01\n",
      "[dimension 64/145]  inactive:\t-1.57e-03 +- 1.96e-02\n",
      "[dimension 65/145]  inactive:\t1.27e-03 +- 2.74e-02\n",
      "[dimension 66/145]  inactive:\t1.68e-03 +- 2.84e-02\n",
      "[dimension 67/145]  inactive:\t1.84e-03 +- 2.51e-02\n",
      "[dimension 68/145]  inactive:\t6.15e-04 +- 2.28e-02\n",
      "[dimension 69/145]  inactive:\t6.33e-03 +- 5.02e-02\n",
      "[dimension 70/145]  inactive:\t6.82e-03 +- 3.35e-02\n",
      "[dimension 71/145]  inactive:\t1.12e-03 +- 2.51e-02\n",
      "[dimension 72/145]  inactive:\t2.12e-03 +- 2.57e-02\n",
      "[dimension 73/145]  inactive:\t6.89e-04 +- 1.65e-02\n",
      "[dimension 74/145]  inactive:\t1.42e-03 +- 2.78e-02\n",
      "[dimension 75/145]  inactive:\t1.61e-03 +- 2.15e-02\n",
      "[dimension 76/145]  inactive:\t7.30e-03 +- 4.51e-02\n",
      "[dimension 77/145]  inactive:\t3.88e-04 +- 2.63e-02\n",
      "[dimension 78/145]  inactive:\t2.24e-02 +- 1.12e-01\n",
      "[dimension 79/145]  inactive:\t8.28e-03 +- 3.86e-02\n",
      "[dimension 80/145]  inactive:\t2.50e-03 +- 3.53e-02\n",
      "[dimension 81/145]  inactive:\t4.44e-03 +- 4.00e-02\n",
      "[dimension 82/145]  inactive:\t4.00e-04 +- 1.43e-02\n",
      "[dimension 83/145]  inactive:\t-3.18e-04 +- 1.37e-02\n",
      "[dimension 84/145]  inactive:\t3.81e-04 +- 2.05e-02\n",
      "[dimension 85/145]  inactive:\t3.14e-03 +- 3.01e-02\n",
      "[dimension 86/145]  inactive:\t-1.37e-04 +- 1.67e-02\n",
      "[dimension 87/145]  inactive:\t5.85e-03 +- 4.71e-02\n",
      "[dimension 88/145]  inactive:\t3.76e-03 +- 2.69e-02\n",
      "[dimension 89/145]  inactive:\t4.93e-04 +- 2.08e-02\n",
      "[dimension 90/145]  inactive:\t6.58e-02 +- 2.06e-01\n",
      "[dimension 91/145]  inactive:\t-7.27e-05 +- 1.93e-02\n",
      "[dimension 92/145]  inactive:\t-1.25e-05 +- 1.85e-02\n",
      "[dimension 93/145]  inactive:\t1.84e-04 +- 2.19e-02\n",
      "[dimension 94/145]  inactive:\t2.14e-03 +- 2.64e-02\n",
      "[dimension 95/145]  inactive:\t8.36e-04 +- 2.14e-02\n",
      "[dimension 96/145]  inactive:\t2.50e-03 +- 3.68e-02\n",
      "[dimension 97/145]  inactive:\t3.34e-03 +- 2.81e-02\n",
      "[dimension 98/145]  inactive:\t9.01e-04 +- 2.47e-02\n",
      "[dimension 99/145]  inactive:\t1.24e-02 +- 7.61e-02\n",
      "[dimension 100/145]  inactive:\t7.24e-05 +- 1.52e-02\n",
      "[dimension 101/145]  inactive:\t-1.15e-03 +- 2.02e-02\n",
      "[dimension 102/145]  inactive:\t1.49e-03 +- 2.50e-02\n",
      "[dimension 103/145]  inactive:\t2.35e-03 +- 2.88e-02\n",
      "[dimension 104/145]  inactive:\t-2.95e-04 +- 1.71e-02\n",
      "[dimension 105/145]  inactive:\t1.75e-03 +- 2.97e-02\n",
      "[dimension 106/145]  inactive:\t9.98e-03 +- 5.00e-02\n",
      "[dimension 107/145]  inactive:\t6.41e-05 +- 1.89e-02\n",
      "[dimension 108/145]  inactive:\t1.31e-02 +- 7.84e-02\n",
      "[dimension 109/145]  inactive:\t-5.40e-05 +- 1.73e-02\n",
      "[dimension 110/145]  inactive:\t2.56e-03 +- 3.76e-02\n",
      "[dimension 111/145]  inactive:\t4.45e-03 +- 4.03e-02\n",
      "[dimension 112/145]  inactive:\t5.63e-03 +- 4.27e-02\n",
      "[dimension 113/145]  inactive:\t-3.10e-04 +- 1.86e-02\n",
      "[dimension 114/145]  inactive:\t5.24e-03 +- 5.22e-02\n",
      "[dimension 115/145]  inactive:\t2.48e-03 +- 2.63e-02\n",
      "[dimension 116/145]  inactive:\t4.17e-03 +- 4.85e-02\n",
      "[dimension 117/145]  inactive:\t1.07e-02 +- 7.03e-02\n",
      "[dimension 118/145]  inactive:\t2.90e-03 +- 2.21e-02\n",
      "[dimension 119/145]  inactive:\t-3.99e-05 +- 2.60e-02\n",
      "[dimension 120/145]  inactive:\t9.47e-04 +- 2.10e-02\n",
      "[dimension 121/145]  inactive:\t6.44e-03 +- 4.40e-02\n",
      "[dimension 122/145]  inactive:\t-6.59e-04 +- 2.55e-02\n",
      "[dimension 123/145]  inactive:\t4.05e-03 +- 4.03e-02\n",
      "[dimension 124/145]  inactive:\t-1.13e-04 +- 1.74e-02\n",
      "[dimension 125/145]  inactive:\t2.75e-04 +- 2.45e-02\n",
      "[dimension 126/145]  inactive:\t6.18e-04 +- 2.13e-02\n",
      "[dimension 127/145]  inactive:\t3.72e-04 +- 1.62e-02\n",
      "[dimension 128/145]  inactive:\t2.29e-03 +- 3.63e-02\n",
      "[dimension 129/145]  inactive:\t1.16e-03 +- 2.24e-02\n",
      "[dimension 130/145]  inactive:\t3.34e-03 +- 2.72e-02\n",
      "[dimension 131/145]  inactive:\t1.29e-03 +- 3.17e-02\n",
      "[dimension 132/145]  inactive:\t6.05e-03 +- 4.73e-02\n",
      "[dimension 133/145]  inactive:\t2.92e-03 +- 2.21e-02\n",
      "[dimension 134/145]  inactive:\t4.61e-04 +- 1.95e-02\n",
      "[dimension 135/145]  inactive:\t3.04e-03 +- 3.12e-02\n",
      "[dimension 136/145]  inactive:\t1.38e-03 +- 1.80e-02\n",
      "[dimension 137/145]  inactive:\t2.36e-03 +- 3.64e-02\n",
      "[dimension 138/145]  inactive:\t1.21e-03 +- 2.19e-02\n",
      "[dimension 139/145]  inactive:\t1.96e-03 +- 2.72e-02\n",
      "[dimension 140/145]  inactive:\t6.26e-04 +- 2.82e-02\n",
      "[dimension 141/145]  inactive:\t2.06e-03 +- 2.67e-02\n",
      "[dimension 142/145]  inactive:\t1.74e-03 +- 1.68e-02\n",
      "[dimension 143/145]  inactive:\t4.63e-03 +- 4.14e-02\n",
      "[dimension 144/145]  inactive:\t2.77e-03 +- 2.96e-02\n",
      "[dimension 145/145]  inactive:\t2.95e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.7459698]\n",
      "cov_act[[0.02900151]]\n",
      "Active_dimensions: [62]\n",
      "12, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 51.69it/s, 31 steps of size 1.58e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    883.39      1.00\n",
      "  lambda[0]      2.22      4.56      0.95      0.00      4.97    787.85      1.00\n",
      "  lambda[1]      2.96      8.32      1.01      0.00      6.12    612.12      1.00\n",
      "  lambda[2]      2.96      9.10      1.01      0.00      5.58    697.82      1.00\n",
      "  lambda[3]      3.45     12.25      0.99      0.00      6.13    716.00      1.00\n",
      "  lambda[4]      2.90      9.85      1.01      0.00      5.37    521.02      1.00\n",
      "  lambda[5]      3.10     10.48      0.98      0.01      5.56    826.00      1.00\n",
      "  lambda[6]      3.34     12.95      0.99      0.00      5.45    642.98      1.00\n",
      "  lambda[7]      3.33      9.64      1.00      0.00      6.31    419.45      1.01\n",
      "  lambda[8]      2.41      5.39      1.02      0.00      5.49    956.24      1.00\n",
      "  lambda[9]      2.33      4.85      0.95      0.00      5.15    899.05      1.00\n",
      " lambda[10]      4.09     15.55      1.09      0.00      6.47    445.78      1.00\n",
      " lambda[11]      2.87      7.30      0.96      0.00      5.37    723.24      1.00\n",
      " lambda[12]      4.62     14.13      1.06      0.00      8.39    498.97      1.00\n",
      " lambda[13]      2.67      8.15      0.97      0.00      5.49    767.06      1.00\n",
      " lambda[14]      4.08     26.24      0.94      0.00      4.98    550.02      1.00\n",
      " lambda[15]      2.97      9.05      0.95      0.00      5.62    786.46      1.00\n",
      " lambda[16]      3.94     11.95      0.99      0.00      8.20    641.58      1.00\n",
      " lambda[17]      3.21     15.83      0.99      0.00      5.84    627.80      1.00\n",
      " lambda[18]      2.58      5.65      0.96      0.00      5.41    918.09      1.00\n",
      " lambda[19]      3.39     16.04      0.99      0.01      5.92    925.74      1.00\n",
      " lambda[20]      2.94      9.64      0.94      0.00      6.30    636.75      1.00\n",
      " lambda[21]      3.74     14.01      1.04      0.00      6.69    687.15      1.00\n",
      " lambda[22]      2.78      7.08      1.06      0.00      5.86    722.76      1.00\n",
      " lambda[23]      2.90      7.60      1.01      0.00      5.63    699.38      1.00\n",
      " lambda[24]      3.83     24.75      1.03      0.00      5.98    886.04      1.00\n",
      " lambda[25]      3.16      9.24      1.04      0.01      5.73    417.70      1.00\n",
      " lambda[26]      2.74      8.44      0.99      0.00      5.15    822.00      1.00\n",
      " lambda[27]      2.90      8.48      1.01      0.00      5.89    473.05      1.00\n",
      " lambda[28]      2.79     10.19      0.99      0.00      5.08    545.29      1.00\n",
      " lambda[29]      2.98     10.32      0.97      0.00      5.87    724.20      1.00\n",
      " lambda[30]      4.70     20.35      1.04      0.01      7.24    499.34      1.00\n",
      " lambda[31]      4.16     17.85      0.98      0.00      6.26    723.60      1.00\n",
      " lambda[32]      3.85     20.24      0.95      0.00      6.77    720.73      1.00\n",
      " lambda[33]      2.91      8.90      0.95      0.01      5.43    731.73      1.00\n",
      " lambda[34]      2.80      9.92      0.96      0.00      4.91    698.87      1.00\n",
      " lambda[35]      2.58      6.85      0.99      0.00      4.86    901.92      1.00\n",
      " lambda[36]      3.51     14.10      1.04      0.00      6.06    846.78      1.00\n",
      " lambda[37]      3.24     16.04      1.02      0.00      5.37    951.41      1.00\n",
      " lambda[38]      3.11     10.00      0.97      0.00      6.91    837.58      1.00\n",
      " lambda[39]      3.38     12.30      0.94      0.00      5.64    504.73      1.00\n",
      " lambda[40]      3.69     15.08      0.96      0.00      6.09    988.86      1.00\n",
      " lambda[41]     11.37     86.39      0.94      0.00      8.86    313.39      1.00\n",
      " lambda[42]      3.25     19.27      0.97      0.00      5.71    998.09      1.00\n",
      " lambda[43]      4.02     33.36      0.97      0.00      5.93   1019.40      1.00\n",
      " lambda[44]      2.67      8.92      0.91      0.00      5.61    898.13      1.00\n",
      " lambda[45]      2.48      5.77      0.94      0.00      4.71    672.03      1.00\n",
      " lambda[46]      2.56      6.38      1.03      0.00      5.11    716.86      1.00\n",
      " lambda[47]      2.90      8.13      0.95      0.00      5.55    577.50      1.00\n",
      " lambda[48]      2.64      8.73      0.97      0.01      4.91    986.54      1.00\n",
      " lambda[49]      3.19      8.97      0.92      0.00      6.53    734.07      1.00\n",
      " lambda[50]      2.64      8.25      0.96      0.00      5.34    883.28      1.00\n",
      " lambda[51]      4.41     16.02      1.05      0.00      7.56    729.28      1.00\n",
      " lambda[52]      3.57     17.86      0.96      0.00      5.88    466.85      1.00\n",
      " lambda[53]      2.90      7.85      0.94      0.00      5.52    477.81      1.00\n",
      " lambda[54]      2.51      9.06      0.98      0.00      4.53    589.77      1.00\n",
      " lambda[55]      3.19     18.02      0.96      0.00      4.99    933.30      1.00\n",
      " lambda[56]      2.73      6.48      0.97      0.00      5.78    686.89      1.00\n",
      " lambda[57]     10.28     94.01      0.98      0.00      9.59    904.64      1.00\n",
      " lambda[58]      2.30      5.16      0.95      0.00      4.97    624.73      1.00\n",
      " lambda[59]      2.78      6.11      0.97      0.00      6.26    495.00      1.00\n",
      " lambda[60]      3.10     13.43      0.94      0.00      5.55    877.61      1.00\n",
      " lambda[61]      2.62      5.58      1.01      0.00      5.51    554.23      1.00\n",
      " lambda[62]   6554.37 166700.14    244.67      0.00   1489.68    882.78      1.00\n",
      " lambda[63]      2.34      4.48      0.99      0.00      5.22    735.58      1.00\n",
      " lambda[64]      3.51     11.17      1.02      0.00      6.80    587.62      1.00\n",
      " lambda[65]      2.93     11.31      0.99      0.00      5.02    360.36      1.00\n",
      " lambda[66]      3.12      7.56      0.98      0.00      7.05    773.64      1.00\n",
      " lambda[67]      2.59      6.91      0.93      0.00      5.62    752.28      1.00\n",
      " lambda[68]      4.34     44.52      0.95      0.00      5.29    727.88      1.00\n",
      " lambda[69]      3.61     13.40      0.95      0.00      6.39    859.20      1.00\n",
      " lambda[70]      2.68      7.56      1.01      0.00      4.95    566.95      1.00\n",
      " lambda[71]      3.03      9.15      0.95      0.00      5.75    687.07      1.00\n",
      " lambda[72]      2.73      6.82      1.00      0.01      5.44    656.60      1.00\n",
      " lambda[73]      3.27     15.61      1.08      0.00      5.69    845.21      1.00\n",
      " lambda[74]      2.44      4.87      1.04      0.01      5.18    765.19      1.00\n",
      " lambda[75]      3.48     11.53      0.99      0.00      6.28    840.07      1.00\n",
      " lambda[76]      3.02      7.88      1.00      0.00      5.69    775.49      1.00\n",
      " lambda[77]      2.93      8.39      1.08      0.00      6.09    739.72      1.00\n",
      " lambda[78]      3.23      8.27      1.06      0.00      6.75    409.59      1.01\n",
      " lambda[79]      3.01      8.87      0.99      0.00      6.01    582.96      1.01\n",
      " lambda[80]      3.68     15.14      1.04      0.00      6.33    653.73      1.00\n",
      " lambda[81]      2.27      6.17      0.99      0.00      4.68   1022.78      1.00\n",
      " lambda[82]      2.51      7.29      0.97      0.00      4.87    788.92      1.00\n",
      " lambda[83]      3.19     10.06      0.98      0.00      6.25    860.45      1.00\n",
      " lambda[84]      4.73     54.15      1.02      0.00      5.88    991.09      1.00\n",
      " lambda[85]      2.53      6.34      0.94      0.00      5.61    824.47      1.00\n",
      " lambda[86]      3.67     15.14      1.06      0.00      5.75    596.49      1.00\n",
      " lambda[87]      3.04      9.45      0.96      0.01      6.61    589.61      1.00\n",
      " lambda[88]      2.77      8.68      0.95      0.00      5.91    890.05      1.00\n",
      " lambda[89]     17.97    117.30      1.04      0.00      9.76    292.46      1.00\n",
      " lambda[90]      2.39      4.84      1.02      0.00      5.33    881.47      1.00\n",
      " lambda[91]      2.39      5.93      0.93      0.01      4.46    671.10      1.00\n",
      " lambda[92]      2.46      5.48      1.04      0.01      4.77    761.67      1.00\n",
      " lambda[93]      2.66      6.48      1.02      0.00      5.19    740.63      1.00\n",
      " lambda[94]      2.47      6.08      0.99      0.00      5.17    941.11      1.00\n",
      " lambda[95]      2.88      8.48      1.02      0.00      7.03    883.36      1.00\n",
      " lambda[96]      3.54     19.50      0.99      0.00      5.41    582.96      1.00\n",
      " lambda[97]      3.16     11.08      0.99      0.00      5.42    589.31      1.00\n",
      " lambda[98]      4.06     21.92      0.98      0.00      5.94    483.44      1.00\n",
      " lambda[99]      2.46      7.31      0.92      0.00      5.23    897.12      1.00\n",
      "lambda[100]      2.68      8.26      0.95      0.00      5.57    646.83      1.00\n",
      "lambda[101]      3.02      9.71      0.97      0.00      5.56    464.54      1.00\n",
      "lambda[102]      2.88      8.67      0.88      0.00      5.48    862.86      1.00\n",
      "lambda[103]      2.33      5.18      0.97      0.00      5.23    736.85      1.00\n",
      "lambda[104]      3.46     21.61      0.97      0.00      6.24    768.05      1.00\n",
      "lambda[105]      3.01      8.26      1.00      0.00      6.05    662.77      1.00\n",
      "lambda[106]      2.49      5.01      1.00      0.00      5.75    878.52      1.00\n",
      "lambda[107]      3.78     14.14      1.06      0.00      5.61    657.45      1.00\n",
      "lambda[108]      2.32      5.35      0.96      0.00      4.88    482.62      1.00\n",
      "lambda[109]      3.75     18.82      0.95      0.00      6.31    904.86      1.00\n",
      "lambda[110]      3.21      9.06      0.98      0.00      6.19    748.17      1.00\n",
      "lambda[111]      3.32     15.36      0.94      0.00      5.65    602.04      1.00\n",
      "lambda[112]      2.73      7.03      0.93      0.01      6.13    784.51      1.00\n",
      "lambda[113]      3.62     15.97      1.00      0.00      6.40    675.40      1.00\n",
      "lambda[114]      3.32     10.27      0.96      0.00      6.48    884.54      1.00\n",
      "lambda[115]      4.00     15.73      0.97      0.00      6.35    797.89      1.00\n",
      "lambda[116]      3.24     14.76      0.98      0.00      5.13    394.35      1.00\n",
      "lambda[117]      3.54     12.24      0.97      0.00      6.17    875.75      1.00\n",
      "lambda[118]      3.36     12.84      0.97      0.00      6.16    882.08      1.00\n",
      "lambda[119]      2.64      9.23      0.99      0.00      5.02    825.06      1.00\n",
      "lambda[120]      3.11      7.99      0.99      0.00      6.62    886.66      1.00\n",
      "lambda[121]      3.20      9.40      0.93      0.00      6.03    674.92      1.00\n",
      "lambda[122]      3.35     11.70      0.98      0.00      6.20    652.41      1.00\n",
      "lambda[123]      2.86      8.34      0.95      0.00      6.27    604.50      1.00\n",
      "lambda[124]      2.56      4.97      0.97      0.00      6.00    706.27      1.00\n",
      "lambda[125]      2.98      8.85      0.99      0.01      5.90    615.62      1.00\n",
      "lambda[126]      2.39      5.61      0.92      0.00      4.73    732.19      1.00\n",
      "lambda[127]      4.26     19.65      0.95      0.00      7.06    897.47      1.00\n",
      "lambda[128]      2.70      8.17      0.95      0.00      4.95    494.93      1.00\n",
      "lambda[129]      3.78     19.39      0.98      0.00      5.94    983.83      1.00\n",
      "lambda[130]      3.22      7.92      0.91      0.00      6.90    649.58      1.00\n",
      "lambda[131]      3.29     10.33      0.94      0.00      6.28    814.13      1.00\n",
      "lambda[132]      2.75      6.58      0.96      0.00      5.69    695.20      1.00\n",
      "lambda[133]      2.62      6.59      1.01      0.00      4.99    749.32      1.00\n",
      "lambda[134]      3.49      8.61      0.91      0.00      7.47    637.57      1.00\n",
      "lambda[135]      2.62      6.73      0.94      0.00      5.09    604.26      1.00\n",
      "lambda[136]      3.27      8.47      1.02      0.00      5.85    383.44      1.00\n",
      "lambda[137]      3.12     11.80      0.97      0.00      4.97    715.82      1.00\n",
      "lambda[138]      3.06     10.54      1.05      0.00      5.29    676.30      1.00\n",
      "lambda[139]      3.52     13.62      1.00      0.00      6.33    772.83      1.01\n",
      "lambda[140]      3.90     27.72      0.96      0.00      5.85    784.77      1.00\n",
      "lambda[141]      2.22      5.11      0.90      0.00      4.82   1007.62      1.00\n",
      "lambda[142]      4.96     41.32      1.00      0.01      5.69    668.32      1.00\n",
      "lambda[143]      2.21      5.00      0.97      0.00      4.44    669.09      1.00\n",
      "        msq    670.55   6514.27      7.07      0.18    236.93    932.72      1.00\n",
      "      sigma      3.30      4.28      1.57      0.01      8.83   1494.30      1.00\n",
      "    var_obs      0.09      0.01      0.08      0.06      0.11   1287.93      1.00\n",
      "       xisq     18.77    161.38      1.37      0.08     15.82    971.69      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 32.92209601402283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.10e-04 +- 1.71e-02\n",
      "[dimension 02/145]  inactive:\t-5.82e-04 +- 2.16e-02\n",
      "[dimension 03/145]  inactive:\t1.30e-04 +- 2.22e-02\n",
      "[dimension 04/145]  inactive:\t4.62e-03 +- 3.36e-02\n",
      "[dimension 05/145]  inactive:\t-1.39e-03 +- 2.69e-02\n",
      "[dimension 06/145]  inactive:\t1.80e-03 +- 3.24e-02\n",
      "[dimension 07/145]  inactive:\t7.26e-04 +- 1.64e-02\n",
      "[dimension 08/145]  inactive:\t1.13e-03 +- 3.58e-02\n",
      "[dimension 09/145]  inactive:\t2.27e-04 +- 2.21e-02\n",
      "[dimension 10/145]  inactive:\t3.17e-04 +- 1.63e-02\n",
      "[dimension 11/145]  inactive:\t-1.95e-03 +- 2.27e-02\n",
      "[dimension 12/145]  inactive:\t-5.43e-04 +- 2.58e-02\n",
      "[dimension 13/145]  inactive:\t6.01e-03 +- 4.36e-02\n",
      "[dimension 14/145]  inactive:\t-1.40e-03 +- 2.52e-02\n",
      "[dimension 15/145]  inactive:\t4.04e-04 +- 3.10e-02\n",
      "[dimension 16/145]  inactive:\t8.63e-04 +- 1.92e-02\n",
      "[dimension 17/145]  inactive:\t-6.13e-04 +- 3.21e-02\n",
      "[dimension 18/145]  inactive:\t-6.72e-04 +- 2.88e-02\n",
      "[dimension 19/145]  inactive:\t-1.87e-03 +- 1.90e-02\n",
      "[dimension 20/145]  inactive:\t-1.52e-03 +- 3.03e-02\n",
      "[dimension 21/145]  inactive:\t-1.03e-03 +- 2.08e-02\n",
      "[dimension 22/145]  inactive:\t2.28e-04 +- 2.20e-02\n",
      "[dimension 23/145]  inactive:\t-6.82e-04 +- 2.77e-02\n",
      "[dimension 24/145]  inactive:\t1.25e-03 +- 2.25e-02\n",
      "[dimension 25/145]  inactive:\t3.02e-03 +- 2.28e-02\n",
      "[dimension 26/145]  inactive:\t-1.12e-03 +- 2.68e-02\n",
      "[dimension 27/145]  inactive:\t2.95e-04 +- 1.90e-02\n",
      "[dimension 28/145]  inactive:\t7.27e-04 +- 1.76e-02\n",
      "[dimension 29/145]  inactive:\t-6.35e-04 +- 2.60e-02\n",
      "[dimension 30/145]  inactive:\t5.85e-04 +- 2.53e-02\n",
      "[dimension 31/145]  inactive:\t7.18e-03 +- 5.05e-02\n",
      "[dimension 32/145]  inactive:\t-1.94e-03 +- 3.08e-02\n",
      "[dimension 33/145]  inactive:\t2.97e-03 +- 4.16e-02\n",
      "[dimension 34/145]  inactive:\t8.41e-04 +- 1.89e-02\n",
      "[dimension 35/145]  inactive:\t-1.03e-05 +- 2.45e-02\n",
      "[dimension 36/145]  inactive:\t6.23e-04 +- 2.14e-02\n",
      "[dimension 37/145]  inactive:\t3.64e-03 +- 2.43e-02\n",
      "[dimension 38/145]  inactive:\t-1.71e-03 +- 2.79e-02\n",
      "[dimension 39/145]  inactive:\t1.05e-03 +- 2.90e-02\n",
      "[dimension 40/145]  inactive:\t4.44e-03 +- 3.61e-02\n",
      "[dimension 41/145]  inactive:\t-2.62e-03 +- 3.63e-02\n",
      "[dimension 42/145]  inactive:\t1.42e-02 +- 9.42e-02\n",
      "[dimension 43/145]  inactive:\t-6.52e-04 +- 1.88e-02\n",
      "[dimension 44/145]  inactive:\t-8.18e-04 +- 2.62e-02\n",
      "[dimension 45/145]  inactive:\t-4.18e-04 +- 2.00e-02\n",
      "[dimension 46/145]  inactive:\t1.32e-03 +- 1.65e-02\n",
      "[dimension 47/145]  inactive:\t-1.38e-03 +- 2.21e-02\n",
      "[dimension 48/145]  inactive:\t9.34e-04 +- 2.22e-02\n",
      "[dimension 49/145]  inactive:\t2.44e-03 +- 2.09e-02\n",
      "[dimension 50/145]  inactive:\t-2.08e-03 +- 3.26e-02\n",
      "[dimension 51/145]  inactive:\t1.96e-03 +- 2.41e-02\n",
      "[dimension 52/145]  inactive:\t6.25e-03 +- 2.67e-02\n",
      "[dimension 53/145]  inactive:\t-9.40e-04 +- 2.49e-02\n",
      "[dimension 54/145]  inactive:\t-9.23e-05 +- 1.89e-02\n",
      "[dimension 55/145]  inactive:\t2.86e-04 +- 1.44e-02\n",
      "[dimension 56/145]  inactive:\t-1.72e-03 +- 2.01e-02\n",
      "[dimension 57/145]  inactive:\t3.52e-04 +- 2.48e-02\n",
      "[dimension 58/145]  inactive:\t1.88e-02 +- 9.02e-02\n",
      "[dimension 59/145]  inactive:\t-6.51e-04 +- 1.53e-02\n",
      "[dimension 60/145]  inactive:\t-1.11e-04 +- 2.67e-02\n",
      "[dimension 61/145]  inactive:\t1.75e-03 +- 2.09e-02\n",
      "[dimension 62/145]  inactive:\t-8.15e-04 +- 1.96e-02\n",
      "[dimension 63/145]  active:\t8.25e-01 +- 3.35e-01\n",
      "[dimension 64/145]  inactive:\t-2.67e-03 +- 2.55e-02\n",
      "[dimension 65/145]  inactive:\t-5.72e-04 +- 2.78e-02\n",
      "[dimension 66/145]  inactive:\t6.26e-04 +- 2.07e-02\n",
      "[dimension 67/145]  inactive:\t1.55e-03 +- 2.44e-02\n",
      "[dimension 68/145]  inactive:\t-6.92e-04 +- 2.18e-02\n",
      "[dimension 69/145]  inactive:\t2.52e-03 +- 3.21e-02\n",
      "[dimension 70/145]  inactive:\t3.36e-03 +- 2.28e-02\n",
      "[dimension 71/145]  inactive:\t-3.58e-04 +- 2.34e-02\n",
      "[dimension 72/145]  inactive:\t2.34e-04 +- 2.25e-02\n",
      "[dimension 73/145]  inactive:\t1.14e-04 +- 1.70e-02\n",
      "[dimension 74/145]  inactive:\t-1.98e-03 +- 2.90e-02\n",
      "[dimension 75/145]  inactive:\t-1.31e-04 +- 2.14e-02\n",
      "[dimension 76/145]  inactive:\t3.25e-03 +- 2.67e-02\n",
      "[dimension 77/145]  inactive:\t-1.90e-03 +- 2.88e-02\n",
      "[dimension 78/145]  inactive:\t1.70e-03 +- 2.72e-02\n",
      "[dimension 79/145]  inactive:\t4.67e-03 +- 2.80e-02\n",
      "[dimension 80/145]  inactive:\t-7.09e-04 +- 3.06e-02\n",
      "[dimension 81/145]  inactive:\t6.95e-04 +- 3.07e-02\n",
      "[dimension 82/145]  inactive:\t1.99e-04 +- 1.31e-02\n",
      "[dimension 83/145]  inactive:\t-1.15e-03 +- 1.42e-02\n",
      "[dimension 84/145]  inactive:\t-1.71e-03 +- 2.56e-02\n",
      "[dimension 85/145]  inactive:\t2.45e-03 +- 2.96e-02\n",
      "[dimension 86/145]  inactive:\t-1.30e-04 +- 1.75e-02\n",
      "[dimension 87/145]  inactive:\t1.97e-03 +- 3.86e-02\n",
      "[dimension 88/145]  inactive:\t2.40e-03 +- 2.18e-02\n",
      "[dimension 89/145]  inactive:\t-1.10e-03 +- 2.11e-02\n",
      "[dimension 90/145]  inactive:\t3.80e-02 +- 1.77e-01\n",
      "[dimension 91/145]  inactive:\t1.24e-04 +- 1.49e-02\n",
      "[dimension 92/145]  inactive:\t-1.00e-03 +- 1.96e-02\n",
      "[dimension 93/145]  inactive:\t-4.39e-04 +- 2.33e-02\n",
      "[dimension 94/145]  inactive:\t1.59e-03 +- 2.65e-02\n",
      "[dimension 95/145]  inactive:\t-3.03e-04 +- 1.96e-02\n",
      "[dimension 96/145]  inactive:\t2.31e-04 +- 2.47e-02\n",
      "[dimension 97/145]  inactive:\t2.35e-03 +- 2.22e-02\n",
      "[dimension 98/145]  inactive:\t-5.51e-04 +- 2.12e-02\n",
      "[dimension 99/145]  inactive:\t1.90e-03 +- 3.06e-02\n",
      "[dimension 100/145]  inactive:\t-5.51e-04 +- 1.48e-02\n",
      "[dimension 101/145]  inactive:\t-1.72e-03 +- 1.79e-02\n",
      "[dimension 102/145]  inactive:\t-1.11e-03 +- 2.50e-02\n",
      "[dimension 103/145]  inactive:\t3.35e-04 +- 2.05e-02\n",
      "[dimension 104/145]  inactive:\t-5.81e-04 +- 1.70e-02\n",
      "[dimension 105/145]  inactive:\t-3.95e-04 +- 2.66e-02\n",
      "[dimension 106/145]  inactive:\t3.51e-03 +- 2.55e-02\n",
      "[dimension 107/145]  inactive:\t-9.67e-04 +- 1.73e-02\n",
      "[dimension 108/145]  inactive:\t4.27e-03 +- 5.83e-02\n",
      "[dimension 109/145]  inactive:\t-3.44e-04 +- 1.67e-02\n",
      "[dimension 110/145]  inactive:\t-1.48e-03 +- 2.97e-02\n",
      "[dimension 111/145]  inactive:\t8.00e-04 +- 2.75e-02\n",
      "[dimension 112/145]  inactive:\t3.43e-03 +- 3.28e-02\n",
      "[dimension 113/145]  inactive:\t-1.63e-03 +- 2.08e-02\n",
      "[dimension 114/145]  inactive:\t9.85e-04 +- 3.59e-02\n",
      "[dimension 115/145]  inactive:\t1.64e-03 +- 2.16e-02\n",
      "[dimension 116/145]  inactive:\t1.39e-03 +- 4.45e-02\n",
      "[dimension 117/145]  inactive:\t3.96e-03 +- 4.77e-02\n",
      "[dimension 118/145]  inactive:\t3.13e-03 +- 2.50e-02\n",
      "[dimension 119/145]  inactive:\t-2.25e-03 +- 3.25e-02\n",
      "[dimension 120/145]  inactive:\t2.06e-04 +- 2.44e-02\n",
      "[dimension 121/145]  inactive:\t3.87e-03 +- 3.44e-02\n",
      "[dimension 122/145]  inactive:\t-2.24e-03 +- 2.98e-02\n",
      "[dimension 123/145]  inactive:\t1.67e-03 +- 3.39e-02\n",
      "[dimension 124/145]  inactive:\t-1.27e-03 +- 1.65e-02\n",
      "[dimension 125/145]  inactive:\t-1.48e-03 +- 2.63e-02\n",
      "[dimension 126/145]  inactive:\t-7.44e-04 +- 1.99e-02\n",
      "[dimension 127/145]  inactive:\t2.13e-05 +- 1.62e-02\n",
      "[dimension 128/145]  inactive:\t-2.30e-03 +- 3.55e-02\n",
      "[dimension 129/145]  inactive:\t-1.04e-04 +- 2.21e-02\n",
      "[dimension 130/145]  inactive:\t3.14e-03 +- 2.61e-02\n",
      "[dimension 131/145]  inactive:\t-1.12e-03 +- 2.92e-02\n",
      "[dimension 132/145]  inactive:\t3.18e-03 +- 3.44e-02\n",
      "[dimension 133/145]  inactive:\t2.39e-03 +- 2.08e-02\n",
      "[dimension 134/145]  inactive:\t-6.08e-04 +- 2.39e-02\n",
      "[dimension 135/145]  inactive:\t3.43e-04 +- 2.90e-02\n",
      "[dimension 136/145]  inactive:\t1.01e-03 +- 1.92e-02\n",
      "[dimension 137/145]  inactive:\t-1.20e-03 +- 4.10e-02\n",
      "[dimension 138/145]  inactive:\t7.85e-04 +- 2.21e-02\n",
      "[dimension 139/145]  inactive:\t9.00e-04 +- 2.33e-02\n",
      "[dimension 140/145]  inactive:\t-1.45e-03 +- 2.80e-02\n",
      "[dimension 141/145]  inactive:\t1.40e-03 +- 2.45e-02\n",
      "[dimension 142/145]  inactive:\t1.01e-03 +- 1.55e-02\n",
      "[dimension 143/145]  inactive:\t1.65e-03 +- 3.62e-02\n",
      "[dimension 144/145]  inactive:\t1.95e-04 +- 1.66e-02\n",
      "[dimension 145/145]  inactive:\t7.30e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8750688]\n",
      "cov_act[[0.02655633]]\n",
      "Active_dimensions: [62]\n",
      "13, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.98it/s, 31 steps of size 1.74e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    452.33      1.00\n",
      "  lambda[0]      2.29      5.63      0.97      0.00      4.76    918.29      1.00\n",
      "  lambda[1]      2.89      7.61      0.98      0.00      5.74    591.77      1.01\n",
      "  lambda[2]      2.93      7.76      1.01      0.00      6.47    671.85      1.00\n",
      "  lambda[3]      4.59     24.88      1.02      0.00      7.36    667.83      1.00\n",
      "  lambda[4]      2.70      6.65      1.07      0.00      5.83    557.04      1.00\n",
      "  lambda[5]      4.42     26.05      1.00      0.00      6.40    861.84      1.00\n",
      "  lambda[6]      4.85     22.18      1.11      0.00      8.33    786.00      1.00\n",
      "  lambda[7]      2.87      8.27      0.95      0.00      5.88    369.18      1.00\n",
      "  lambda[8]      2.44      4.88      1.02      0.00      5.34    647.81      1.00\n",
      "  lambda[9]      2.32      5.85      0.94      0.00      4.58    717.39      1.00\n",
      " lambda[10]      2.98      9.66      0.99      0.00      5.55    715.75      1.00\n",
      " lambda[11]      2.62      5.64      1.00      0.01      6.25    833.77      1.00\n",
      " lambda[12]      6.90     58.67      1.01      0.00      8.44    940.57      1.00\n",
      " lambda[13]      2.45      6.04      0.94      0.00      5.02    700.26      1.00\n",
      " lambda[14]      5.15     38.73      0.92      0.00      5.66    711.48      1.00\n",
      " lambda[15]      3.78     15.10      1.03      0.00      6.49    728.13      1.00\n",
      " lambda[16]      3.37      9.30      0.98      0.00      7.47    654.35      1.00\n",
      " lambda[17]      4.03     43.84      1.03      0.00      5.31   1012.18      1.00\n",
      " lambda[18]      2.85      7.84      0.97      0.00      5.96    491.85      1.00\n",
      " lambda[19]      3.15     15.16      1.01      0.01      5.24    789.27      1.00\n",
      " lambda[20]      2.86      9.51      0.93      0.00      5.51    712.47      1.00\n",
      " lambda[21]      3.24     11.98      0.99      0.01      5.86    798.12      1.00\n",
      " lambda[22]      2.93     14.18      0.95      0.00      5.02    449.10      1.00\n",
      " lambda[23]      3.75     19.23      0.94      0.00      5.81    502.79      1.00\n",
      " lambda[24]      4.77     32.30      1.00      0.00      6.41    575.41      1.00\n",
      " lambda[25]      3.14      9.46      0.99      0.00      4.78    360.22      1.00\n",
      " lambda[26]      2.53      5.73      1.02      0.00      5.08    740.55      1.00\n",
      " lambda[27]      3.02      8.12      0.96      0.00      6.19    529.90      1.00\n",
      " lambda[28]      3.38     11.76      1.02      0.00      6.04    455.00      1.00\n",
      " lambda[29]      3.05      9.54      0.96      0.00      5.64    475.61      1.00\n",
      " lambda[30]      4.63     27.07      1.00      0.01      6.72    901.39      1.00\n",
      " lambda[31]      3.69     15.66      0.97      0.00      6.14    757.21      1.00\n",
      " lambda[32]      5.46     71.00      0.97      0.00      6.76   1001.78      1.00\n",
      " lambda[33]      3.42      9.96      1.03      0.01      7.53    798.88      1.00\n",
      " lambda[34]      2.91     11.50      0.98      0.00      4.98    749.26      1.00\n",
      " lambda[35]      2.64      6.79      1.00      0.00      5.32    814.13      1.00\n",
      " lambda[36]      3.57     17.13      0.98      0.00      5.51    730.99      1.00\n",
      " lambda[37]      3.24     10.80      0.97      0.00      5.73    904.42      1.00\n",
      " lambda[38]      2.92      8.07      0.96      0.00      5.73    863.63      1.00\n",
      " lambda[39]      3.47     11.20      0.95      0.01      6.01    752.99      1.00\n",
      " lambda[40]      3.79     19.25      0.93      0.00      6.71   1027.46      1.00\n",
      " lambda[41]     32.26    376.86      0.94      0.00     10.91    439.50      1.00\n",
      " lambda[42]      2.48      5.30      0.93      0.00      5.18    624.59      1.00\n",
      " lambda[43]      4.59     46.71      0.99      0.00      6.12   1015.02      1.00\n",
      " lambda[44]      4.27     43.01      0.96      0.00      5.98   1008.34      1.00\n",
      " lambda[45]      2.24      4.89      0.96      0.01      4.40    697.68      1.00\n",
      " lambda[46]      2.43      6.04      1.03      0.01      5.13    830.18      1.00\n",
      " lambda[47]      2.34      5.08      0.95      0.01      4.91    607.57      1.00\n",
      " lambda[48]      2.61      7.29      0.99      0.00      5.82    785.81      1.00\n",
      " lambda[49]      3.02      7.84      0.95      0.01      6.00    706.92      1.00\n",
      " lambda[50]      2.89      7.20      0.97      0.00      6.31    603.82      1.00\n",
      " lambda[51]      9.18    171.83      1.05      0.00      7.39    991.73      1.00\n",
      " lambda[52]      2.70      7.29      1.05      0.00      5.22    906.13      1.00\n",
      " lambda[53]      3.29     10.63      0.92      0.00      5.59    628.95      1.00\n",
      " lambda[54]      2.00      3.93      0.97      0.00      4.19    787.11      1.00\n",
      " lambda[55]      3.16     18.99      0.99      0.01      5.82    905.27      1.00\n",
      " lambda[56]      3.03     12.50      1.07      0.00      5.39    506.32      1.00\n",
      " lambda[57]      8.20    148.68      0.92      0.00      6.21    984.07      1.00\n",
      " lambda[58]      2.41      5.28      1.00      0.00      5.25    609.62      1.00\n",
      " lambda[59]      3.03      8.93      0.97      0.00      6.82    499.63      1.01\n",
      " lambda[60]      7.30     40.44      0.98      0.00      7.67    359.22      1.00\n",
      " lambda[61]      2.63      6.81      0.98      0.00      5.20    652.03      1.00\n",
      " lambda[62]   2877.62  14879.87    494.03      0.02   4635.00    679.14      1.00\n",
      " lambda[63]      2.06      3.68      0.99      0.00      4.98    654.25      1.00\n",
      " lambda[64]      3.13      9.91      0.94      0.00      5.16    826.98      1.00\n",
      " lambda[65]      3.23     13.14      0.95      0.00      5.95    877.14      1.00\n",
      " lambda[66]      3.33      9.78      1.07      0.00      6.41    715.27      1.00\n",
      " lambda[67]      2.43      6.87      0.95      0.00      5.16    781.04      1.00\n",
      " lambda[68]      6.23     65.85      1.01      0.00      6.93    439.52      1.00\n",
      " lambda[69]      5.14     30.08      0.97      0.00      7.16    727.21      1.00\n",
      " lambda[70]      3.07     10.93      0.95      0.01      5.20    354.75      1.00\n",
      " lambda[71]      4.03     34.17      0.93      0.00      5.32    496.58      1.00\n",
      " lambda[72]      2.61      8.20      0.99      0.01      5.30    595.13      1.00\n",
      " lambda[73]      2.69      6.15      1.00      0.00      5.92    777.50      1.00\n",
      " lambda[74]      2.35      4.44      1.06      0.01      5.38    909.39      1.00\n",
      " lambda[75]      4.37     16.90      0.99      0.00      7.12    923.44      1.00\n",
      " lambda[76]      2.95      8.73      0.94      0.00      5.79    728.60      1.00\n",
      " lambda[77]     11.88    100.02      1.01      0.00      7.17    283.99      1.01\n",
      " lambda[78]      4.13     29.51      1.12      0.00      6.74    971.04      1.00\n",
      " lambda[79]      3.43     19.58      1.00      0.00      5.62    960.88      1.00\n",
      " lambda[80]      3.80     26.86      1.03      0.00      6.46    899.75      1.00\n",
      " lambda[81]      2.14      3.86      0.94      0.00      4.80   1087.54      1.00\n",
      " lambda[82]      2.23      5.70      0.95      0.00      4.25    646.51      1.00\n",
      " lambda[83]      2.79      7.90      0.90      0.00      6.03    813.19      1.00\n",
      " lambda[84]      3.42     10.56      0.98      0.00      6.33    509.56      1.00\n",
      " lambda[85]      2.61      8.19      0.92      0.00      5.33    804.86      1.00\n",
      " lambda[86]      3.55     26.27      1.02      0.00      5.63   1023.15      1.00\n",
      " lambda[87]      3.98     16.54      1.00      0.00      6.85    546.47      1.00\n",
      " lambda[88]      2.41      5.21      0.95      0.00      5.28    865.63      1.00\n",
      " lambda[89]    109.61   1845.22      0.99      0.00      9.86    500.88      1.00\n",
      " lambda[90]      2.61      5.80      1.04      0.00      5.22    528.08      1.00\n",
      " lambda[91]      2.44      6.14      0.95      0.01      4.72    636.82      1.00\n",
      " lambda[92]      2.83     11.18      0.98      0.01      5.51    987.64      1.00\n",
      " lambda[93]      2.84      8.19      1.03      0.00      5.46    560.28      1.00\n",
      " lambda[94]      2.59      8.81      0.99      0.00      5.67    876.66      1.00\n",
      " lambda[95]      2.86      7.19      0.99      0.00      6.91   1004.67      1.00\n",
      " lambda[96]      3.39     15.32      0.95      0.00      5.48    416.95      1.00\n",
      " lambda[97]      3.93     18.25      1.01      0.00      6.27    522.24      1.00\n",
      " lambda[98]     19.40    318.29      0.97      0.00      6.05    830.33      1.00\n",
      " lambda[99]      2.43      6.89      0.99      0.00      4.62    908.25      1.00\n",
      "lambda[100]      2.17      4.78      0.95      0.00      4.86    702.97      1.00\n",
      "lambda[101]      2.87      9.32      1.00      0.00      5.74    525.31      1.00\n",
      "lambda[102]      2.57      6.17      1.02      0.00      5.30    856.91      1.00\n",
      "lambda[103]      2.55      5.62      0.98      0.00      5.61    706.10      1.00\n",
      "lambda[104]      2.61      5.55      0.99      0.00      5.55    772.22      1.00\n",
      "lambda[105]      3.60     11.38      1.10      0.00      7.49    502.07      1.00\n",
      "lambda[106]      2.55      5.98      0.98      0.01      5.38    552.25      1.00\n",
      "lambda[107]      4.12     24.94      0.99      0.00      5.51    644.54      1.00\n",
      "lambda[108]      2.61     12.77      0.94      0.00      5.01    915.97      1.00\n",
      "lambda[109]      4.56     47.02      0.99      0.00      6.28   1000.28      1.00\n",
      "lambda[110]      3.40     14.17      1.03      0.00      6.10    955.91      1.00\n",
      "lambda[111]      5.01     19.01      0.99      0.00      8.07    502.53      1.01\n",
      "lambda[112]      2.64      7.60      0.95      0.00      5.38    954.67      1.00\n",
      "lambda[113]      4.15     19.24      0.97      0.00      6.02    537.52      1.00\n",
      "lambda[114]      4.31     19.77      1.02      0.00      6.76    814.51      1.00\n",
      "lambda[115]      4.09     20.87      0.94      0.00      5.56    617.85      1.00\n",
      "lambda[116]     15.31    172.03      0.98      0.00      6.08    301.20      1.00\n",
      "lambda[117]      3.48     13.40      0.95      0.00      7.04    804.18      1.00\n",
      "lambda[118]      2.92      7.58      0.98      0.00      5.91    784.00      1.00\n",
      "lambda[119]      3.28     15.84      1.03      0.00      6.08    838.09      1.00\n",
      "lambda[120]      3.98     19.94      0.99      0.00      6.15    859.77      1.00\n",
      "lambda[121]      3.16     10.94      0.86      0.00      5.90    901.42      1.00\n",
      "lambda[122]      3.50     14.84      0.95      0.00      6.44    908.86      1.00\n",
      "lambda[123]      2.57      5.93      0.89      0.00      5.92    726.49      1.00\n",
      "lambda[124]      2.54      5.80      1.02      0.00      5.82    629.08      1.00\n",
      "lambda[125]      2.76      6.74      0.94      0.00      6.03    702.90      1.00\n",
      "lambda[126]      2.78      6.87      1.04      0.00      5.98    519.15      1.00\n",
      "lambda[127]      3.94     14.10      0.98      0.00      6.97    591.00      1.00\n",
      "lambda[128]      2.95     10.65      0.98      0.00      5.58    439.37      1.00\n",
      "lambda[129]      4.25     26.07      1.01      0.00      5.83    978.65      1.00\n",
      "lambda[130]      3.48     16.73      0.96      0.01      5.42    790.07      1.00\n",
      "lambda[131]      3.04      8.79      0.98      0.01      5.86    698.94      1.00\n",
      "lambda[132]      2.68      5.80      1.03      0.00      5.99    666.05      1.00\n",
      "lambda[133]      3.55     26.78      0.96      0.00      5.05    670.47      1.00\n",
      "lambda[134]      2.80      6.91      0.94      0.00      6.19    559.65      1.00\n",
      "lambda[135]      2.57      7.71      0.92      0.00      5.24    667.25      1.00\n",
      "lambda[136]      3.36     15.28      0.99      0.00      6.17    828.63      1.00\n",
      "lambda[137]      2.73      7.85      0.96      0.00      5.42    641.54      1.00\n",
      "lambda[138]      3.39     14.73      1.01      0.00      5.39    432.55      1.00\n",
      "lambda[139]      3.29     10.82      1.08      0.00      5.29    688.75      1.00\n",
      "lambda[140]      2.76      8.21      0.95      0.00      5.64    800.80      1.00\n",
      "lambda[141]      2.88      8.83      0.90      0.00      5.63    609.35      1.00\n",
      "lambda[142]      3.69     13.46      1.02      0.00      6.16    832.28      1.00\n",
      "lambda[143]      2.24      4.77      0.93      0.00      4.94    507.50      1.00\n",
      "        msq      0.24      0.14      0.20      0.07      0.40   1089.50      1.00\n",
      "      sigma      2.92      4.18      1.22      0.00      8.35   1203.22      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    769.10      1.00\n",
      "       xisq      1.22      2.60      0.57      0.09      2.56    889.93      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 32.54544401168823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.77e-05 +- 9.71e-03\n",
      "[dimension 02/145]  inactive:\t2.43e-04 +- 1.54e-02\n",
      "[dimension 03/145]  inactive:\t4.39e-04 +- 1.39e-02\n",
      "[dimension 04/145]  inactive:\t2.50e-03 +- 2.28e-02\n",
      "[dimension 05/145]  inactive:\t5.13e-04 +- 1.79e-02\n",
      "[dimension 06/145]  inactive:\t2.66e-03 +- 3.46e-02\n",
      "[dimension 07/145]  inactive:\t1.18e-03 +- 1.66e-02\n",
      "[dimension 08/145]  inactive:\t8.92e-04 +- 1.73e-02\n",
      "[dimension 09/145]  inactive:\t6.64e-04 +- 1.49e-02\n",
      "[dimension 10/145]  inactive:\t6.07e-04 +- 1.16e-02\n",
      "[dimension 11/145]  inactive:\t2.19e-04 +- 1.39e-02\n",
      "[dimension 12/145]  inactive:\t3.88e-04 +- 1.51e-02\n",
      "[dimension 13/145]  inactive:\t3.86e-03 +- 3.31e-02\n",
      "[dimension 14/145]  inactive:\t1.05e-04 +- 1.49e-02\n",
      "[dimension 15/145]  inactive:\t1.68e-03 +- 2.54e-02\n",
      "[dimension 16/145]  inactive:\t7.83e-04 +- 1.66e-02\n",
      "[dimension 17/145]  inactive:\t1.20e-03 +- 2.09e-02\n",
      "[dimension 18/145]  inactive:\t1.63e-03 +- 2.89e-02\n",
      "[dimension 19/145]  inactive:\t-4.68e-04 +- 1.17e-02\n",
      "[dimension 20/145]  inactive:\t6.95e-05 +- 1.53e-02\n",
      "[dimension 21/145]  inactive:\t-4.70e-04 +- 1.39e-02\n",
      "[dimension 22/145]  inactive:\t5.77e-04 +- 1.42e-02\n",
      "[dimension 23/145]  inactive:\t3.06e-04 +- 1.79e-02\n",
      "[dimension 24/145]  inactive:\t1.38e-03 +- 1.99e-02\n",
      "[dimension 25/145]  inactive:\t2.66e-03 +- 2.07e-02\n",
      "[dimension 26/145]  inactive:\t3.06e-04 +- 1.90e-02\n",
      "[dimension 27/145]  inactive:\t7.80e-04 +- 1.45e-02\n",
      "[dimension 28/145]  inactive:\t9.11e-04 +- 1.34e-02\n",
      "[dimension 29/145]  inactive:\t1.76e-03 +- 2.87e-02\n",
      "[dimension 30/145]  inactive:\t1.33e-03 +- 1.97e-02\n",
      "[dimension 31/145]  inactive:\t3.92e-03 +- 3.46e-02\n",
      "[dimension 32/145]  inactive:\t8.43e-04 +- 2.28e-02\n",
      "[dimension 33/145]  inactive:\t2.98e-03 +- 3.18e-02\n",
      "[dimension 34/145]  inactive:\t8.90e-04 +- 1.45e-02\n",
      "[dimension 35/145]  inactive:\t1.13e-03 +- 2.13e-02\n",
      "[dimension 36/145]  inactive:\t1.25e-03 +- 2.00e-02\n",
      "[dimension 37/145]  inactive:\t2.48e-03 +- 2.01e-02\n",
      "[dimension 38/145]  inactive:\t1.55e-04 +- 1.72e-02\n",
      "[dimension 39/145]  inactive:\t1.54e-03 +- 2.22e-02\n",
      "[dimension 40/145]  inactive:\t4.57e-03 +- 3.83e-02\n",
      "[dimension 41/145]  inactive:\t3.59e-04 +- 2.00e-02\n",
      "[dimension 42/145]  inactive:\t1.85e-02 +- 1.09e-01\n",
      "[dimension 43/145]  inactive:\t3.37e-04 +- 1.38e-02\n",
      "[dimension 44/145]  inactive:\t2.95e-04 +- 1.57e-02\n",
      "[dimension 45/145]  inactive:\t9.62e-04 +- 2.02e-02\n",
      "[dimension 46/145]  inactive:\t4.32e-04 +- 9.79e-03\n",
      "[dimension 47/145]  inactive:\t-1.73e-04 +- 1.46e-02\n",
      "[dimension 48/145]  inactive:\t6.18e-04 +- 1.34e-02\n",
      "[dimension 49/145]  inactive:\t9.95e-04 +- 1.36e-02\n",
      "[dimension 50/145]  inactive:\t-1.06e-04 +- 1.78e-02\n",
      "[dimension 51/145]  inactive:\t1.25e-03 +- 1.88e-02\n",
      "[dimension 52/145]  inactive:\t3.81e-03 +- 1.93e-02\n",
      "[dimension 53/145]  inactive:\t6.25e-05 +- 1.30e-02\n",
      "[dimension 54/145]  inactive:\t1.42e-03 +- 1.98e-02\n",
      "[dimension 55/145]  inactive:\t2.91e-04 +- 9.08e-03\n",
      "[dimension 56/145]  inactive:\t-8.93e-04 +- 1.45e-02\n",
      "[dimension 57/145]  inactive:\t2.52e-03 +- 3.26e-02\n",
      "[dimension 58/145]  inactive:\t4.97e-03 +- 4.21e-02\n",
      "[dimension 59/145]  inactive:\t-1.88e-04 +- 1.16e-02\n",
      "[dimension 60/145]  inactive:\t1.04e-03 +- 1.81e-02\n",
      "[dimension 61/145]  inactive:\t4.64e-03 +- 3.29e-02\n",
      "[dimension 62/145]  inactive:\t-4.93e-05 +- 1.22e-02\n",
      "[dimension 63/145]  active:\t7.25e-01 +- 3.54e-01\n",
      "[dimension 64/145]  inactive:\t-6.87e-04 +- 1.17e-02\n",
      "[dimension 65/145]  inactive:\t4.46e-04 +- 1.57e-02\n",
      "[dimension 66/145]  inactive:\t4.57e-04 +- 1.35e-02\n",
      "[dimension 67/145]  inactive:\t7.64e-04 +- 1.73e-02\n",
      "[dimension 68/145]  inactive:\t1.18e-04 +- 1.39e-02\n",
      "[dimension 69/145]  inactive:\t2.53e-03 +- 2.88e-02\n",
      "[dimension 70/145]  inactive:\t3.33e-03 +- 2.16e-02\n",
      "[dimension 71/145]  inactive:\t6.41e-04 +- 1.70e-02\n",
      "[dimension 72/145]  inactive:\t1.64e-03 +- 2.13e-02\n",
      "[dimension 73/145]  inactive:\t4.59e-04 +- 1.02e-02\n",
      "[dimension 74/145]  inactive:\t2.81e-04 +- 1.70e-02\n",
      "[dimension 75/145]  inactive:\t3.66e-04 +- 1.18e-02\n",
      "[dimension 76/145]  inactive:\t4.63e-03 +- 3.38e-02\n",
      "[dimension 77/145]  inactive:\t5.49e-05 +- 1.47e-02\n",
      "[dimension 78/145]  inactive:\t1.31e-02 +- 8.76e-02\n",
      "[dimension 79/145]  inactive:\t3.85e-03 +- 2.64e-02\n",
      "[dimension 80/145]  inactive:\t1.12e-03 +- 2.34e-02\n",
      "[dimension 81/145]  inactive:\t1.87e-03 +- 2.39e-02\n",
      "[dimension 82/145]  inactive:\t2.30e-04 +- 9.00e-03\n",
      "[dimension 83/145]  inactive:\t-4.83e-04 +- 1.05e-02\n",
      "[dimension 84/145]  inactive:\t4.27e-05 +- 1.33e-02\n",
      "[dimension 85/145]  inactive:\t1.97e-03 +- 2.29e-02\n",
      "[dimension 86/145]  inactive:\t-1.07e-04 +- 1.07e-02\n",
      "[dimension 87/145]  inactive:\t1.83e-03 +- 2.51e-02\n",
      "[dimension 88/145]  inactive:\t2.10e-03 +- 1.99e-02\n",
      "[dimension 89/145]  inactive:\t-6.42e-05 +- 1.17e-02\n",
      "[dimension 90/145]  inactive:\t3.40e-02 +- 1.56e-01\n",
      "[dimension 91/145]  inactive:\t2.17e-04 +- 1.06e-02\n",
      "[dimension 92/145]  inactive:\t8.74e-05 +- 1.36e-02\n",
      "[dimension 93/145]  inactive:\t2.24e-04 +- 1.54e-02\n",
      "[dimension 94/145]  inactive:\t1.11e-03 +- 1.91e-02\n",
      "[dimension 95/145]  inactive:\t1.31e-04 +- 1.43e-02\n",
      "[dimension 96/145]  inactive:\t8.42e-04 +- 1.90e-02\n",
      "[dimension 97/145]  inactive:\t1.72e-03 +- 1.57e-02\n",
      "[dimension 98/145]  inactive:\t9.75e-05 +- 1.68e-02\n",
      "[dimension 99/145]  inactive:\t8.60e-03 +- 6.62e-02\n",
      "[dimension 100/145]  inactive:\t4.91e-06 +- 1.02e-02\n",
      "[dimension 101/145]  inactive:\t-5.05e-04 +- 1.01e-02\n",
      "[dimension 102/145]  inactive:\t5.87e-04 +- 1.81e-02\n",
      "[dimension 103/145]  inactive:\t5.70e-04 +- 1.32e-02\n",
      "[dimension 104/145]  inactive:\t-2.61e-04 +- 1.23e-02\n",
      "[dimension 105/145]  inactive:\t2.43e-04 +- 1.46e-02\n",
      "[dimension 106/145]  inactive:\t4.45e-03 +- 3.13e-02\n",
      "[dimension 107/145]  inactive:\t-1.34e-04 +- 1.27e-02\n",
      "[dimension 108/145]  inactive:\t4.73e-03 +- 5.33e-02\n",
      "[dimension 109/145]  inactive:\t1.95e-04 +- 1.25e-02\n",
      "[dimension 110/145]  inactive:\t5.19e-04 +- 1.69e-02\n",
      "[dimension 111/145]  inactive:\t1.81e-03 +- 2.60e-02\n",
      "[dimension 112/145]  inactive:\t5.00e-03 +- 4.02e-02\n",
      "[dimension 113/145]  inactive:\t-6.96e-05 +- 1.93e-02\n",
      "[dimension 114/145]  inactive:\t2.04e-03 +- 3.29e-02\n",
      "[dimension 115/145]  inactive:\t1.98e-03 +- 1.87e-02\n",
      "[dimension 116/145]  inactive:\t2.23e-03 +- 3.68e-02\n",
      "[dimension 117/145]  inactive:\t5.79e-03 +- 5.48e-02\n",
      "[dimension 118/145]  inactive:\t2.10e-03 +- 1.77e-02\n",
      "[dimension 119/145]  inactive:\t-3.76e-05 +- 1.47e-02\n",
      "[dimension 120/145]  inactive:\t6.92e-04 +- 1.87e-02\n",
      "[dimension 121/145]  inactive:\t2.79e-03 +- 2.59e-02\n",
      "[dimension 122/145]  inactive:\t-5.70e-05 +- 2.07e-02\n",
      "[dimension 123/145]  inactive:\t2.08e-03 +- 3.26e-02\n",
      "[dimension 124/145]  inactive:\t-2.01e-04 +- 1.07e-02\n",
      "[dimension 125/145]  inactive:\t4.56e-06 +- 1.52e-02\n",
      "[dimension 126/145]  inactive:\t2.97e-04 +- 1.40e-02\n",
      "[dimension 127/145]  inactive:\t3.96e-04 +- 1.22e-02\n",
      "[dimension 128/145]  inactive:\t4.61e-04 +- 1.80e-02\n",
      "[dimension 129/145]  inactive:\t7.93e-04 +- 1.78e-02\n",
      "[dimension 130/145]  inactive:\t2.23e-03 +- 2.08e-02\n",
      "[dimension 131/145]  inactive:\t1.78e-03 +- 3.52e-02\n",
      "[dimension 132/145]  inactive:\t1.78e-03 +- 2.05e-02\n",
      "[dimension 133/145]  inactive:\t1.32e-03 +- 1.35e-02\n",
      "[dimension 134/145]  inactive:\t6.82e-04 +- 2.17e-02\n",
      "[dimension 135/145]  inactive:\t7.38e-04 +- 1.41e-02\n",
      "[dimension 136/145]  inactive:\t7.34e-04 +- 1.28e-02\n",
      "[dimension 137/145]  inactive:\t1.19e-03 +- 2.35e-02\n",
      "[dimension 138/145]  inactive:\t2.76e-04 +- 1.36e-02\n",
      "[dimension 139/145]  inactive:\t7.66e-04 +- 1.64e-02\n",
      "[dimension 140/145]  inactive:\t3.97e-04 +- 2.21e-02\n",
      "[dimension 141/145]  inactive:\t1.35e-03 +- 2.38e-02\n",
      "[dimension 142/145]  inactive:\t1.36e-03 +- 1.31e-02\n",
      "[dimension 143/145]  inactive:\t2.05e-03 +- 2.84e-02\n",
      "[dimension 144/145]  inactive:\t7.10e-04 +- 1.33e-02\n",
      "[dimension 145/145]  inactive:\t1.46e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.86915386]\n",
      "cov_act[[0.01498539]]\n",
      "Active_dimensions: [62]\n",
      "14, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:23<00:00, 64.32it/s, 15 steps of size 2.63e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    325.69      1.00\n",
      "  lambda[0]      2.27      5.50      0.95      0.00      5.05   1055.02      1.00\n",
      "  lambda[1]      3.05     17.14      0.93      0.01      4.78    604.75      1.00\n",
      "  lambda[2]      2.62      5.75      0.97      0.00      6.23    738.54      1.00\n",
      "  lambda[3]      3.95     14.00      1.08      0.00      8.06    685.25      1.00\n",
      "  lambda[4]      2.90      8.63      0.95      0.00      5.16    700.17      1.00\n",
      "  lambda[5]      3.65     12.61      1.02      0.00      6.72    574.69      1.00\n",
      "  lambda[6]      2.75      7.75      0.98      0.00      5.28    647.73      1.00\n",
      "  lambda[7]      3.15      9.09      0.98      0.00      5.81    694.18      1.00\n",
      "  lambda[8]      2.71      5.88      0.93      0.00      6.05    868.54      1.00\n",
      "  lambda[9]      3.12      9.07      1.01      0.00      5.81    705.98      1.00\n",
      " lambda[10]      3.58     15.63      1.05      0.00      5.81    389.46      1.00\n",
      " lambda[11]      3.05      8.86      1.00      0.01      6.49    826.92      1.00\n",
      " lambda[12]      4.06     21.24      0.99      0.00      6.24    521.29      1.00\n",
      " lambda[13]      2.58      6.97      0.95      0.00      4.97    802.78      1.00\n",
      " lambda[14]      5.79     44.15      1.02      0.00      6.14    535.65      1.00\n",
      " lambda[15]      3.22     15.68      0.94      0.00      5.59    897.07      1.00\n",
      " lambda[16]      2.42      5.18      0.92      0.01      5.62    960.12      1.00\n",
      " lambda[17]      2.91      7.08      1.01      0.00      6.16    756.37      1.00\n",
      " lambda[18]      3.24     10.84      0.95      0.00      5.84    686.44      1.00\n",
      " lambda[19]      2.85      7.26      1.00      0.00      6.17    764.13      1.00\n",
      " lambda[20]      2.98      7.36      1.00      0.00      6.31    717.38      1.00\n",
      " lambda[21]      2.61      5.58      1.01      0.00      6.03    719.44      1.00\n",
      " lambda[22]      2.43      5.45      1.01      0.00      5.60    600.00      1.00\n",
      " lambda[23]      3.54     17.43      1.05      0.00      5.35    870.08      1.00\n",
      " lambda[24]      3.55     11.60      1.02      0.00      7.10    835.90      1.00\n",
      " lambda[25]      2.49      6.51      0.99      0.00      5.34    585.66      1.00\n",
      " lambda[26]      2.55      7.10      0.98      0.00      4.95    890.34      1.00\n",
      " lambda[27]      2.79      7.13      0.92      0.01      6.04    844.55      1.00\n",
      " lambda[28]      2.57      5.48      0.98      0.01      5.29    620.73      1.00\n",
      " lambda[29]      3.07     13.57      0.93      0.00      5.75    892.44      1.00\n",
      " lambda[30]      3.52     14.23      1.01      0.00      6.23    617.48      1.00\n",
      " lambda[31]      3.33      9.92      1.01      0.00      6.48    772.34      1.00\n",
      " lambda[32]      3.22     10.27      0.98      0.00      6.96    478.34      1.00\n",
      " lambda[33]      2.54      7.50      0.98      0.00      5.05    807.82      1.01\n",
      " lambda[34]      2.68      7.36      1.03      0.00      5.40    727.45      1.00\n",
      " lambda[35]      3.14     12.69      1.00      0.00      5.35    677.43      1.00\n",
      " lambda[36]      3.09      9.42      1.01      0.00      5.71    995.64      1.00\n",
      " lambda[37]      3.17     12.46      1.01      0.00      5.92    948.23      1.00\n",
      " lambda[38]      6.12     97.02      0.95      0.00      5.98    979.90      1.00\n",
      " lambda[39]      3.49     17.89      0.98      0.00      6.32    932.33      1.00\n",
      " lambda[40]      2.62      6.71      0.95      0.00      5.89    963.73      1.00\n",
      " lambda[41]      7.52     39.90      1.04      0.00      7.95    555.83      1.00\n",
      " lambda[42]      2.36      5.95      0.94      0.00      4.74    934.69      1.00\n",
      " lambda[43]     11.18    236.80      0.96      0.01      5.69    804.70      1.00\n",
      " lambda[44]      2.95      7.68      0.99      0.01      5.87    766.65      1.00\n",
      " lambda[45]      2.65      8.35      0.94      0.00      5.37    848.50      1.00\n",
      " lambda[46]      2.57      7.42      0.96      0.00      4.72    679.20      1.00\n",
      " lambda[47]      2.68      6.85      1.03      0.00      5.43    507.33      1.00\n",
      " lambda[48]      3.33     10.00      0.97      0.00      6.69    612.96      1.00\n",
      " lambda[49]      4.23     20.76      1.03      0.00      6.83    968.88      1.00\n",
      " lambda[50]      5.09     50.92      0.99      0.00      5.70    900.72      1.00\n",
      " lambda[51]      3.78     12.76      1.03      0.00      7.16    730.92      1.00\n",
      " lambda[52]      3.09     16.70      0.96      0.01      5.50    735.92      1.00\n",
      " lambda[53]      3.24      9.97      1.00      0.00      6.27    785.14      1.00\n",
      " lambda[54]      2.46      6.13      0.95      0.00      4.69    838.38      1.00\n",
      " lambda[55]      3.23     12.83      0.86      0.00      5.76   1074.12      1.00\n",
      " lambda[56]      2.78      8.31      0.94      0.01      5.10    962.11      1.00\n",
      " lambda[57]      8.59     40.14      1.08      0.00     12.18    517.17      1.00\n",
      " lambda[58]      2.30      4.97      0.93      0.00      4.68    869.60      1.00\n",
      " lambda[59]      2.98      8.43      0.98      0.00      5.67    755.94      1.00\n",
      " lambda[60]      3.40     14.30      0.99      0.00      5.36    616.49      1.00\n",
      " lambda[61]      2.49      6.23      1.01      0.00      5.15    926.71      1.00\n",
      " lambda[62]   1042.02   6477.35    160.55      0.02   1363.35    597.00      1.00\n",
      " lambda[63]      2.54      5.97      1.01      0.00      4.95    877.72      1.00\n",
      " lambda[64]      2.78      8.28      0.96      0.00      5.35    932.12      1.00\n",
      " lambda[65]      3.24     12.64      0.97      0.00      4.93    798.07      1.00\n",
      " lambda[66]      3.40     10.95      0.94      0.00      6.35    868.37      1.00\n",
      " lambda[67]      3.24     13.35      0.99      0.00      5.99    985.56      1.00\n",
      " lambda[68]      3.40     11.61      1.02      0.00      6.28    966.51      1.00\n",
      " lambda[69]      4.25     18.56      0.96      0.00      6.79    726.51      1.00\n",
      " lambda[70]      2.74      9.57      0.99      0.00      5.58    863.43      1.00\n",
      " lambda[71]      3.01      9.76      0.99      0.00      5.35    548.11      1.00\n",
      " lambda[72]      2.41      6.47      0.99      0.00      5.05    842.73      1.00\n",
      " lambda[73]      2.54      6.22      0.97      0.00      5.13    909.92      1.00\n",
      " lambda[74]      2.63      6.33      0.94      0.00      5.77    782.76      1.00\n",
      " lambda[75]      5.64     38.96      1.02      0.00      6.90    857.85      1.00\n",
      " lambda[76]      2.77      6.67      1.05      0.00      6.04    552.97      1.00\n",
      " lambda[77]     16.22    311.03      0.98      0.00      6.88    606.20      1.00\n",
      " lambda[78]      2.96      7.19      1.00      0.00      6.25    597.95      1.00\n",
      " lambda[79]      2.73     11.49      0.94      0.00      5.06    704.82      1.00\n",
      " lambda[80]      3.15      7.69      0.99      0.00      7.25    592.53      1.00\n",
      " lambda[81]      2.62      6.10      1.01      0.00      5.52    772.75      1.00\n",
      " lambda[82]      2.78      8.19      0.96      0.00      5.16    887.31      1.00\n",
      " lambda[83]      3.75     13.85      1.02      0.00      7.00    711.14      1.00\n",
      " lambda[84]      3.72     23.94      0.97      0.00      5.11    956.89      1.00\n",
      " lambda[85]      2.68      7.83      0.93      0.00      5.46    476.14      1.00\n",
      " lambda[86]      4.82     29.99      0.97      0.00      6.48    859.52      1.00\n",
      " lambda[87]      3.33     20.73      0.93      0.00      5.76    520.82      1.00\n",
      " lambda[88]      3.97     22.47      0.97      0.00      6.88    532.91      1.00\n",
      " lambda[89]    120.43    904.16      1.39      0.00    121.34    378.64      1.00\n",
      " lambda[90]      2.41      5.60      0.93      0.00      5.01    938.98      1.00\n",
      " lambda[91]      2.62      9.57      0.97      0.00      5.07    837.86      1.00\n",
      " lambda[92]      3.02      7.75      0.96      0.00      6.65    867.12      1.00\n",
      " lambda[93]      2.86     13.58      1.00      0.00      5.21    607.30      1.00\n",
      " lambda[94]      3.58     12.42      0.97      0.00      6.30    713.09      1.00\n",
      " lambda[95]      3.30     12.12      1.00      0.00      5.85    665.31      1.00\n",
      " lambda[96]      3.03      9.25      0.96      0.00      6.05    654.84      1.00\n",
      " lambda[97]      2.48      5.71      1.05      0.00      5.29    985.29      1.00\n",
      " lambda[98]      4.31     31.29      0.99      0.00      5.26    758.55      1.00\n",
      " lambda[99]      2.54      7.88      0.94      0.00      5.00   1026.04      1.00\n",
      "lambda[100]      2.62      5.37      0.93      0.00      5.68    622.49      1.00\n",
      "lambda[101]      3.34     13.44      0.99      0.00      5.54    553.69      1.00\n",
      "lambda[102]      3.16     12.73      0.93      0.00      5.94    993.15      1.00\n",
      "lambda[103]      3.21     12.76      0.91      0.00      5.69    452.57      1.00\n",
      "lambda[104]      4.21     28.64      1.04      0.00      4.93    400.12      1.00\n",
      "lambda[105]      3.81     11.52      1.00      0.00      7.52    766.88      1.00\n",
      "lambda[106]      3.21     17.20      1.01      0.00      5.29    613.72      1.00\n",
      "lambda[107]      3.25     12.02      0.96      0.00      5.18    478.50      1.00\n",
      "lambda[108]      2.41      5.66      0.92      0.01      5.56    946.97      1.00\n",
      "lambda[109]      3.80     16.58      0.98      0.00      6.34    979.13      1.00\n",
      "lambda[110]      3.55     14.32      1.03      0.00      6.26    803.69      1.00\n",
      "lambda[111]      5.23     32.69      1.03      0.00      6.38    728.59      1.00\n",
      "lambda[112]      2.22      5.75      0.96      0.01      4.44    603.55      1.00\n",
      "lambda[113]      3.21     10.32      1.00      0.00      5.42    958.97      1.00\n",
      "lambda[114]      2.65      6.78      0.98      0.00      5.36    771.66      1.00\n",
      "lambda[115]      4.48     48.24      1.01      0.00      6.08    993.14      1.00\n",
      "lambda[116]      3.83     33.30      1.04      0.00      5.51    983.32      1.00\n",
      "lambda[117]      3.86     18.29      0.95      0.00      7.28    971.37      1.00\n",
      "lambda[118]      3.59     26.13      0.97      0.00      4.82    872.89      1.00\n",
      "lambda[119]      4.25     17.58      0.98      0.00      6.46    705.82      1.00\n",
      "lambda[120]      3.78     13.74      0.98      0.00      6.49    752.03      1.00\n",
      "lambda[121]      3.31      9.94      1.02      0.00      6.24    672.27      1.00\n",
      "lambda[122]      5.62     64.59      0.98      0.00      5.35    668.26      1.00\n",
      "lambda[123]      2.66      6.05      0.91      0.00      5.55    754.79      1.00\n",
      "lambda[124]      3.01      8.04      1.02      0.00      6.35    727.48      1.00\n",
      "lambda[125]      2.92      8.19      0.95      0.01      5.77    607.48      1.00\n",
      "lambda[126]      2.38      7.48      0.95      0.00      4.82    983.05      1.00\n",
      "lambda[127]      3.69     20.98      0.96      0.00      5.92    967.47      1.00\n",
      "lambda[128]      4.76     29.22      0.97      0.00      6.78    426.84      1.00\n",
      "lambda[129]      8.26    138.90      0.92      0.00      6.21    924.95      1.00\n",
      "lambda[130]      2.71      5.96      0.95      0.00      6.20    713.50      1.01\n",
      "lambda[131]      3.30     16.26      1.00      0.00      5.49    881.51      1.00\n",
      "lambda[132]      2.91     10.91      1.02      0.00      5.27    548.17      1.00\n",
      "lambda[133]      2.79      8.32      0.96      0.00      5.13    843.44      1.00\n",
      "lambda[134]      3.32      8.65      0.96      0.00      6.82    588.28      1.00\n",
      "lambda[135]      2.40      8.56      0.99      0.00      4.81   1000.44      1.00\n",
      "lambda[136]      2.89      7.29      0.93      0.00      6.48    825.49      1.00\n",
      "lambda[137]      2.94     10.20      0.97      0.00      5.11    703.98      1.00\n",
      "lambda[138]      3.59     12.26      1.00      0.00      5.80    684.02      1.00\n",
      "lambda[139]      2.71      6.52      0.98      0.00      5.69    758.52      1.00\n",
      "lambda[140]      3.33     13.82      0.94      0.00      6.46    921.61      1.00\n",
      "lambda[141]      2.97      7.98      0.96      0.00      6.06    588.18      1.00\n",
      "lambda[142]      3.57     10.99      0.98      0.00      6.43    886.32      1.00\n",
      "lambda[143]      2.32      5.71      0.97      0.00      4.76    840.17      1.00\n",
      "        msq    722.29  13491.70      3.96      0.14     96.53    813.99      1.00\n",
      "      sigma      3.35      4.10      1.63      0.01      8.84   1244.99      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    721.25      1.00\n",
      "       xisq      0.12      0.06      0.11      0.05      0.21    893.46      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 26.937888145446777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.22e-04 +- 1.83e-02\n",
      "[dimension 02/145]  inactive:\t-9.78e-04 +- 2.91e-02\n",
      "[dimension 03/145]  inactive:\t1.14e-04 +- 2.40e-02\n",
      "[dimension 04/145]  inactive:\t6.43e-03 +- 4.30e-02\n",
      "[dimension 05/145]  inactive:\t-9.71e-04 +- 2.66e-02\n",
      "[dimension 06/145]  inactive:\t4.56e-03 +- 4.81e-02\n",
      "[dimension 07/145]  inactive:\t4.79e-04 +- 1.96e-02\n",
      "[dimension 08/145]  inactive:\t1.61e-03 +- 3.05e-02\n",
      "[dimension 09/145]  inactive:\t2.25e-04 +- 2.47e-02\n",
      "[dimension 10/145]  inactive:\t3.36e-04 +- 2.35e-02\n",
      "[dimension 11/145]  inactive:\t-4.02e-04 +- 2.76e-02\n",
      "[dimension 12/145]  inactive:\t-2.06e-04 +- 3.06e-02\n",
      "[dimension 13/145]  inactive:\t5.47e-03 +- 4.19e-02\n",
      "[dimension 14/145]  inactive:\t-1.56e-03 +- 2.33e-02\n",
      "[dimension 15/145]  inactive:\t2.74e-03 +- 4.67e-02\n",
      "[dimension 16/145]  inactive:\t6.50e-04 +- 2.06e-02\n",
      "[dimension 17/145]  inactive:\t3.70e-04 +- 2.73e-02\n",
      "[dimension 18/145]  inactive:\t-7.12e-04 +- 2.93e-02\n",
      "[dimension 19/145]  inactive:\t-2.49e-03 +- 2.23e-02\n",
      "[dimension 20/145]  inactive:\t-1.58e-03 +- 2.91e-02\n",
      "[dimension 21/145]  inactive:\t-2.05e-03 +- 2.68e-02\n",
      "[dimension 22/145]  inactive:\t-3.71e-04 +- 2.61e-02\n",
      "[dimension 23/145]  inactive:\t-5.32e-04 +- 2.57e-02\n",
      "[dimension 24/145]  inactive:\t2.04e-03 +- 3.10e-02\n",
      "[dimension 25/145]  inactive:\t4.43e-03 +- 2.70e-02\n",
      "[dimension 26/145]  inactive:\t-6.02e-04 +- 2.80e-02\n",
      "[dimension 27/145]  inactive:\t7.10e-04 +- 2.40e-02\n",
      "[dimension 28/145]  inactive:\t7.84e-04 +- 2.07e-02\n",
      "[dimension 29/145]  inactive:\t-2.53e-04 +- 2.63e-02\n",
      "[dimension 30/145]  inactive:\t1.70e-03 +- 3.09e-02\n",
      "[dimension 31/145]  inactive:\t6.56e-03 +- 4.63e-02\n",
      "[dimension 32/145]  inactive:\t-1.56e-03 +- 3.05e-02\n",
      "[dimension 33/145]  inactive:\t3.99e-03 +- 4.54e-02\n",
      "[dimension 34/145]  inactive:\t7.39e-04 +- 1.98e-02\n",
      "[dimension 35/145]  inactive:\t3.78e-04 +- 2.66e-02\n",
      "[dimension 36/145]  inactive:\t9.39e-04 +- 2.66e-02\n",
      "[dimension 37/145]  inactive:\t5.21e-03 +- 3.21e-02\n",
      "[dimension 38/145]  inactive:\t-2.31e-03 +- 3.30e-02\n",
      "[dimension 39/145]  inactive:\t1.22e-03 +- 3.59e-02\n",
      "[dimension 40/145]  inactive:\t4.05e-03 +- 3.26e-02\n",
      "[dimension 41/145]  inactive:\t-1.67e-03 +- 2.89e-02\n",
      "[dimension 42/145]  inactive:\t1.35e-02 +- 8.79e-02\n",
      "[dimension 43/145]  inactive:\t-7.51e-04 +- 2.07e-02\n",
      "[dimension 44/145]  inactive:\t-7.58e-04 +- 3.46e-02\n",
      "[dimension 45/145]  inactive:\t-8.88e-04 +- 2.93e-02\n",
      "[dimension 46/145]  inactive:\t1.05e-03 +- 1.71e-02\n",
      "[dimension 47/145]  inactive:\t-1.79e-03 +- 2.68e-02\n",
      "[dimension 48/145]  inactive:\t1.11e-03 +- 2.42e-02\n",
      "[dimension 49/145]  inactive:\t4.30e-03 +- 3.17e-02\n",
      "[dimension 50/145]  inactive:\t-2.06e-03 +- 3.04e-02\n",
      "[dimension 51/145]  inactive:\t3.93e-03 +- 3.72e-02\n",
      "[dimension 52/145]  inactive:\t6.58e-03 +- 2.67e-02\n",
      "[dimension 53/145]  inactive:\t-1.18e-03 +- 2.39e-02\n",
      "[dimension 54/145]  inactive:\t7.59e-05 +- 2.44e-02\n",
      "[dimension 55/145]  inactive:\t4.91e-04 +- 1.73e-02\n",
      "[dimension 56/145]  inactive:\t-3.04e-03 +- 2.54e-02\n",
      "[dimension 57/145]  inactive:\t1.80e-03 +- 3.80e-02\n",
      "[dimension 58/145]  inactive:\t2.16e-02 +- 9.51e-02\n",
      "[dimension 59/145]  inactive:\t-5.24e-04 +- 1.78e-02\n",
      "[dimension 60/145]  inactive:\t1.85e-04 +- 2.51e-02\n",
      "[dimension 61/145]  inactive:\t2.90e-03 +- 2.59e-02\n",
      "[dimension 62/145]  inactive:\t-5.00e-04 +- 2.10e-02\n",
      "[dimension 63/145]  active:\t6.62e-01 +- 4.42e-01\n",
      "[dimension 64/145]  inactive:\t-3.24e-03 +- 2.88e-02\n",
      "[dimension 65/145]  inactive:\t-7.06e-04 +- 2.60e-02\n",
      "[dimension 66/145]  inactive:\t2.49e-05 +- 2.58e-02\n",
      "[dimension 67/145]  inactive:\t1.62e-03 +- 2.92e-02\n",
      "[dimension 68/145]  inactive:\t-1.26e-03 +- 3.55e-02\n",
      "[dimension 69/145]  inactive:\t4.89e-03 +- 4.95e-02\n",
      "[dimension 70/145]  inactive:\t4.92e-03 +- 2.88e-02\n",
      "[dimension 71/145]  inactive:\t2.18e-04 +- 2.61e-02\n",
      "[dimension 72/145]  inactive:\t6.83e-04 +- 2.56e-02\n",
      "[dimension 73/145]  inactive:\t6.19e-05 +- 1.97e-02\n",
      "[dimension 74/145]  inactive:\t-1.17e-03 +- 3.00e-02\n",
      "[dimension 75/145]  inactive:\t1.85e-04 +- 2.33e-02\n",
      "[dimension 76/145]  inactive:\t6.98e-03 +- 4.21e-02\n",
      "[dimension 77/145]  inactive:\t-1.79e-03 +- 3.10e-02\n",
      "[dimension 78/145]  inactive:\t9.02e-03 +- 7.49e-02\n",
      "[dimension 79/145]  inactive:\t6.26e-03 +- 3.45e-02\n",
      "[dimension 80/145]  inactive:\t-2.87e-04 +- 3.09e-02\n",
      "[dimension 81/145]  inactive:\t6.70e-04 +- 3.33e-02\n",
      "[dimension 82/145]  inactive:\t4.23e-04 +- 1.94e-02\n",
      "[dimension 83/145]  inactive:\t-2.18e-03 +- 2.04e-02\n",
      "[dimension 84/145]  inactive:\t-3.03e-03 +- 3.31e-02\n",
      "[dimension 85/145]  inactive:\t4.27e-03 +- 3.81e-02\n",
      "[dimension 86/145]  inactive:\t-7.74e-04 +- 1.94e-02\n",
      "[dimension 87/145]  inactive:\t4.55e-03 +- 5.56e-02\n",
      "[dimension 88/145]  inactive:\t2.46e-03 +- 2.29e-02\n",
      "[dimension 89/145]  inactive:\t-1.26e-03 +- 2.58e-02\n",
      "[dimension 90/145]  inactive:\t1.41e-01 +- 3.26e-01\n",
      "[dimension 91/145]  inactive:\t-1.04e-04 +- 1.99e-02\n",
      "[dimension 92/145]  inactive:\t-1.50e-03 +- 2.44e-02\n",
      "[dimension 93/145]  inactive:\t-9.00e-04 +- 3.11e-02\n",
      "[dimension 94/145]  inactive:\t1.54e-03 +- 2.41e-02\n",
      "[dimension 95/145]  inactive:\t-7.66e-04 +- 3.04e-02\n",
      "[dimension 96/145]  inactive:\t1.59e-03 +- 4.40e-02\n",
      "[dimension 97/145]  inactive:\t2.57e-03 +- 2.55e-02\n",
      "[dimension 98/145]  inactive:\t-1.42e-04 +- 2.51e-02\n",
      "[dimension 99/145]  inactive:\t3.44e-03 +- 4.47e-02\n",
      "[dimension 100/145]  inactive:\t-7.83e-04 +- 1.76e-02\n",
      "[dimension 101/145]  inactive:\t-2.79e-03 +- 2.24e-02\n",
      "[dimension 102/145]  inactive:\t-1.55e-03 +- 3.04e-02\n",
      "[dimension 103/145]  inactive:\t2.91e-04 +- 2.57e-02\n",
      "[dimension 104/145]  inactive:\t-1.36e-03 +- 1.97e-02\n",
      "[dimension 105/145]  inactive:\t-8.78e-04 +- 2.58e-02\n",
      "[dimension 106/145]  inactive:\t6.33e-03 +- 3.73e-02\n",
      "[dimension 107/145]  inactive:\t-1.93e-03 +- 2.35e-02\n",
      "[dimension 108/145]  inactive:\t6.76e-03 +- 6.57e-02\n",
      "[dimension 109/145]  inactive:\t-5.77e-04 +- 1.81e-02\n",
      "[dimension 110/145]  inactive:\t-1.11e-03 +- 3.45e-02\n",
      "[dimension 111/145]  inactive:\t3.35e-03 +- 3.93e-02\n",
      "[dimension 112/145]  inactive:\t9.48e-03 +- 6.47e-02\n",
      "[dimension 113/145]  inactive:\t-1.32e-03 +- 1.90e-02\n",
      "[dimension 114/145]  inactive:\t1.21e-03 +- 3.74e-02\n",
      "[dimension 115/145]  inactive:\t1.72e-03 +- 2.00e-02\n",
      "[dimension 116/145]  inactive:\t6.22e-04 +- 3.61e-02\n",
      "[dimension 117/145]  inactive:\t3.40e-03 +- 4.30e-02\n",
      "[dimension 118/145]  inactive:\t3.66e-03 +- 2.84e-02\n",
      "[dimension 119/145]  inactive:\t-2.26e-03 +- 3.06e-02\n",
      "[dimension 120/145]  inactive:\t-3.06e-04 +- 3.78e-02\n",
      "[dimension 121/145]  inactive:\t4.43e-03 +- 3.67e-02\n",
      "[dimension 122/145]  inactive:\t-2.97e-03 +- 3.28e-02\n",
      "[dimension 123/145]  inactive:\t2.97e-03 +- 5.74e-02\n",
      "[dimension 124/145]  inactive:\t-2.01e-03 +- 2.04e-02\n",
      "[dimension 125/145]  inactive:\t-2.30e-03 +- 2.94e-02\n",
      "[dimension 126/145]  inactive:\t-1.50e-03 +- 2.79e-02\n",
      "[dimension 127/145]  inactive:\t-5.24e-05 +- 1.61e-02\n",
      "[dimension 128/145]  inactive:\t-1.27e-03 +- 3.28e-02\n",
      "[dimension 129/145]  inactive:\t-3.79e-04 +- 3.24e-02\n",
      "[dimension 130/145]  inactive:\t5.19e-03 +- 3.65e-02\n",
      "[dimension 131/145]  inactive:\t-8.13e-04 +- 2.60e-02\n",
      "[dimension 132/145]  inactive:\t3.82e-03 +- 4.13e-02\n",
      "[dimension 133/145]  inactive:\t2.42e-03 +- 2.08e-02\n",
      "[dimension 134/145]  inactive:\t-7.66e-04 +- 2.57e-02\n",
      "[dimension 135/145]  inactive:\t1.85e-04 +- 2.98e-02\n",
      "[dimension 136/145]  inactive:\t9.83e-04 +- 2.04e-02\n",
      "[dimension 137/145]  inactive:\t-8.01e-04 +- 3.97e-02\n",
      "[dimension 138/145]  inactive:\t6.23e-04 +- 2.81e-02\n",
      "[dimension 139/145]  inactive:\t2.11e-04 +- 2.84e-02\n",
      "[dimension 140/145]  inactive:\t-1.31e-03 +- 3.04e-02\n",
      "[dimension 141/145]  inactive:\t1.48e-03 +- 2.88e-02\n",
      "[dimension 142/145]  inactive:\t1.80e-03 +- 2.18e-02\n",
      "[dimension 143/145]  inactive:\t1.77e-03 +- 4.10e-02\n",
      "[dimension 144/145]  inactive:\t2.80e-04 +- 2.10e-02\n",
      "[dimension 145/145]  inactive:\t-1.19e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00016001]\n",
      "cov_act[[1.3340265e-05]]\n",
      "Active_dimensions: [62]\n",
      "15, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:33<00:00, 45.22it/s, 31 steps of size 1.65e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    559.67      1.00\n",
      "  lambda[0]      2.33      5.74      0.96      0.00      5.16    495.41      1.00\n",
      "  lambda[1]      3.47     13.35      0.97      0.00      5.89    385.37      1.01\n",
      "  lambda[2]      8.17    123.50      1.05      0.00      5.53    545.14      1.00\n",
      "  lambda[3]      3.15      8.14      1.03      0.00      6.70    604.00      1.00\n",
      "  lambda[4]      3.14      9.41      1.06      0.00      6.32    598.55      1.00\n",
      "  lambda[5]     10.58    222.50      0.96      0.00      6.04    837.22      1.00\n",
      "  lambda[6]      3.47      9.98      1.03      0.00      6.51    521.19      1.00\n",
      "  lambda[7]      3.08      8.06      1.00      0.00      5.74    552.22      1.00\n",
      "  lambda[8]      2.61      7.27      1.03      0.00      5.19    653.40      1.00\n",
      "  lambda[9]      2.40      6.84      0.99      0.00      4.92    681.40      1.00\n",
      " lambda[10]      2.84      7.62      1.08      0.01      5.74    835.02      1.00\n",
      " lambda[11]      3.05      8.15      1.02      0.01      5.78    720.25      1.00\n",
      " lambda[12]      6.99     78.39      1.06      0.00      7.83    940.28      1.00\n",
      " lambda[13]      2.61      8.28      0.93      0.00      5.49    653.55      1.00\n",
      " lambda[14]      7.26     50.34      0.93      0.00      5.91    426.16      1.00\n",
      " lambda[15]      3.03      8.70      1.01      0.00      5.78    656.16      1.00\n",
      " lambda[16]      3.54      9.64      1.00      0.00      7.81    703.29      1.01\n",
      " lambda[17]      5.12     52.71      0.97      0.00      5.27    690.67      1.00\n",
      " lambda[18]      2.95      7.40      0.94      0.00      6.57    429.27      1.00\n",
      " lambda[19]      3.77     25.05      0.98      0.01      5.80    869.39      1.00\n",
      " lambda[20]      2.64      6.80      0.99      0.01      5.70    897.68      1.00\n",
      " lambda[21]      2.94      7.73      1.03      0.00      6.16    905.20      1.00\n",
      " lambda[22]      2.82     11.97      0.96      0.00      5.01    460.76      1.00\n",
      " lambda[23]      3.01      9.74      1.00      0.00      6.05    796.94      1.00\n",
      " lambda[24]      3.86     15.71      1.03      0.00      6.14    740.81      1.00\n",
      " lambda[25]      2.91      7.61      0.96      0.00      6.03    560.94      1.00\n",
      " lambda[26]      2.74     10.83      0.99      0.00      5.32    983.32      1.00\n",
      " lambda[27]      2.94      7.62      0.95      0.00      5.70    615.03      1.00\n",
      " lambda[28]      3.30     14.23      1.01      0.00      5.61    487.59      1.00\n",
      " lambda[29]      2.85      7.27      1.04      0.00      5.82    789.30      1.00\n",
      " lambda[30]      4.92     26.46      1.03      0.01      7.15    606.89      1.00\n",
      " lambda[31]      4.25     21.73      1.00      0.00      6.37    718.46      1.00\n",
      " lambda[32]      4.04     19.05      0.99      0.00      6.18    841.83      1.00\n",
      " lambda[33]      3.13     10.73      0.97      0.01      6.28    872.66      1.00\n",
      " lambda[34]      2.62      8.01      0.97      0.00      4.83    588.18      1.00\n",
      " lambda[35]      2.95     10.41      0.98      0.00      5.41    610.65      1.00\n",
      " lambda[36]      3.68     13.16      0.98      0.00      6.50    862.71      1.00\n",
      " lambda[37]      2.79      6.93      1.02      0.00      5.94    781.75      1.00\n",
      " lambda[38]      3.33     12.25      0.98      0.00      6.03    889.00      1.00\n",
      " lambda[39]      5.00     28.83      1.01      0.00      6.12    702.63      1.00\n",
      " lambda[40]      5.16     40.48      0.93      0.00      6.86    840.45      1.00\n",
      " lambda[41]     43.90    380.14      0.97      0.00     14.41    357.05      1.00\n",
      " lambda[42]      4.51     34.58      0.98      0.00      5.24    711.68      1.00\n",
      " lambda[43]      7.92    121.44      1.01      0.00      6.16   1007.48      1.00\n",
      " lambda[44]      2.64      9.71      0.93      0.00      5.65    821.55      1.00\n",
      " lambda[45]      2.41      5.39      0.99      0.00      4.78    709.37      1.00\n",
      " lambda[46]      2.78      9.03      1.03      0.00      4.61    667.11      1.00\n",
      " lambda[47]      2.44      4.80      0.94      0.01      5.84    497.58      1.00\n",
      " lambda[48]      2.83      8.43      0.97      0.00      5.86    673.87      1.00\n",
      " lambda[49]      3.21     10.82      0.96      0.00      6.00    715.53      1.00\n",
      " lambda[50]      3.02     15.30      0.94      0.00      4.82    754.63      1.00\n",
      " lambda[51]      5.99     30.98      1.08      0.00      9.51    840.07      1.00\n",
      " lambda[52]      3.21     11.84      0.92      0.00      6.01    760.45      1.00\n",
      " lambda[53]      2.98      7.48      0.98      0.00      5.95    726.41      1.00\n",
      " lambda[54]      2.02      4.03      0.92      0.00      4.54    760.48      1.00\n",
      " lambda[55]      3.54     15.32      0.98      0.00      5.33    613.34      1.00\n",
      " lambda[56]      2.78      7.35      0.95      0.00      5.44    700.81      1.00\n",
      " lambda[57]     15.47    220.57      1.03      0.00     10.43    838.41      1.00\n",
      " lambda[58]      2.26      4.72      0.97      0.00      4.87    647.65      1.00\n",
      " lambda[59]      3.24     10.33      0.96      0.00      6.39    596.63      1.00\n",
      " lambda[60]      4.09     18.25      0.99      0.00      6.52    768.05      1.00\n",
      " lambda[61]      2.37      5.25      0.98      0.00      5.04    747.86      1.00\n",
      " lambda[62]   2386.16  28390.50    172.94      0.00   2121.07    658.63      1.00\n",
      " lambda[63]      2.55      8.31      1.01      0.00      4.96    683.58      1.00\n",
      " lambda[64]      3.42     10.08      0.97      0.00      5.91    553.74      1.00\n",
      " lambda[65]      3.80     21.51      0.96      0.00      5.84    922.60      1.00\n",
      " lambda[66]      3.05      9.01      1.01      0.00      6.15    752.39      1.00\n",
      " lambda[67]      2.99     11.35      0.95      0.00      5.22    514.03      1.00\n",
      " lambda[68]      5.15     35.91      0.94      0.00      6.43    549.70      1.00\n",
      " lambda[69]      5.71     30.99      0.99      0.00      6.21    496.63      1.00\n",
      " lambda[70]      2.89      8.55      1.05      0.00      5.56    558.54      1.00\n",
      " lambda[71]      2.88     12.25      1.02      0.00      4.84    585.54      1.00\n",
      " lambda[72]      3.41     17.09      0.96      0.00      5.53    341.22      1.00\n",
      " lambda[73]      2.48      5.44      1.05      0.00      5.20    904.16      1.00\n",
      " lambda[74]      3.38     27.03      1.05      0.01      5.39    859.06      1.00\n",
      " lambda[75]      4.77     26.95      1.01      0.00      6.97    983.75      1.00\n",
      " lambda[76]      3.29     12.69      0.98      0.00      5.92    630.76      1.00\n",
      " lambda[77]     53.18   1359.76      1.09      0.00      7.74    893.51      1.00\n",
      " lambda[78]      5.20     39.09      1.12      0.00      7.03    839.28      1.00\n",
      " lambda[79]      3.65     19.08      0.97      0.00      5.75    885.75      1.00\n",
      " lambda[80]      6.95     77.37      1.04      0.01      6.79    994.36      1.00\n",
      " lambda[81]      2.28      5.69      0.95      0.00      4.95   1121.94      1.00\n",
      " lambda[82]      2.13      4.70      0.97      0.00      4.67    995.95      1.00\n",
      " lambda[83]      2.89      9.26      0.93      0.00      5.20    642.74      1.00\n",
      " lambda[84]      3.66     21.10      0.99      0.00      5.70    777.31      1.00\n",
      " lambda[85]      2.74      8.50      0.96      0.00      5.60    674.02      1.00\n",
      " lambda[86]      2.94      8.30      1.00      0.00      6.45   1035.48      1.00\n",
      " lambda[87]      3.74     17.59      0.95      0.00      6.64    817.83      1.00\n",
      " lambda[88]      2.60      6.29      0.98      0.00      5.72    709.91      1.00\n",
      " lambda[89]    109.18   1081.06      1.26      0.00    126.82    880.31      1.00\n",
      " lambda[90]      3.11      8.97      1.01      0.00      5.80    486.92      1.00\n",
      " lambda[91]      2.96     15.28      0.94      0.01      4.69    822.00      1.00\n",
      " lambda[92]      3.69     26.29      1.01      0.00      5.50    608.52      1.00\n",
      " lambda[93]      2.77      6.67      1.01      0.00      5.74    740.36      1.00\n",
      " lambda[94]      2.52      7.61      0.96      0.00      4.60    764.22      1.00\n",
      " lambda[95]      2.99      9.39      1.02      0.00      6.08    977.16      1.00\n",
      " lambda[96]      3.76     31.95      0.98      0.00      5.21    716.49      1.00\n",
      " lambda[97]      3.17     17.60      1.03      0.00      5.39    896.25      1.00\n",
      " lambda[98]     11.06     92.46      1.01      0.00      6.08    384.09      1.00\n",
      " lambda[99]      2.37      6.12      0.97      0.00      4.48    625.51      1.00\n",
      "lambda[100]      2.64      6.03      0.93      0.00      5.97    616.65      1.00\n",
      "lambda[101]      2.64      6.55      0.95      0.00      5.21    712.92      1.00\n",
      "lambda[102]      2.75      7.19      0.87      0.00      5.09    663.77      1.00\n",
      "lambda[103]      2.38      5.98      0.96      0.00      5.01    779.16      1.00\n",
      "lambda[104]      2.54      5.08      0.96      0.00      5.72    893.37      1.00\n",
      "lambda[105]      3.86     11.84      1.11      0.00      7.90    703.32      1.00\n",
      "lambda[106]      2.39      4.61      1.01      0.00      5.24    585.92      1.00\n",
      "lambda[107]      6.62     37.07      1.01      0.00      5.81    385.14      1.00\n",
      "lambda[108]      2.65     15.78      0.99      0.00      4.48    872.30      1.00\n",
      "lambda[109]      3.47     17.15      0.96      0.00      5.81    891.97      1.00\n",
      "lambda[110]      3.33     16.43      1.01      0.00      6.36    795.39      1.00\n",
      "lambda[111]      4.70     21.33      0.94      0.00      6.57    577.33      1.00\n",
      "lambda[112]      2.48      5.66      0.93      0.00      5.64    978.82      1.00\n",
      "lambda[113]      4.61     27.78      1.01      0.00      6.33    742.38      1.00\n",
      "lambda[114]      3.65     13.16      0.99      0.00      5.99    783.04      1.00\n",
      "lambda[115]      5.70     45.68      0.95      0.00      5.58    641.64      1.00\n",
      "lambda[116]     12.52    172.73      0.96      0.00      5.90    507.38      1.00\n",
      "lambda[117]      3.40     14.82      1.01      0.00      6.46    818.86      1.00\n",
      "lambda[118]      3.55     12.96      1.04      0.00      6.83    813.40      1.00\n",
      "lambda[119]      3.85     30.93      1.02      0.00      5.76    874.61      1.00\n",
      "lambda[120]      5.41     44.68      1.00      0.00      6.70    914.51      1.00\n",
      "lambda[121]      3.34     17.33      0.91      0.00      5.74    862.15      1.00\n",
      "lambda[122]      7.65    122.42      1.00      0.00      6.59    929.19      1.00\n",
      "lambda[123]      2.56      7.09      0.94      0.01      5.02    844.49      1.00\n",
      "lambda[124]      2.74     12.10      0.97      0.00      5.29    840.50      1.00\n",
      "lambda[125]      2.74      7.73      0.95      0.00      5.91    635.43      1.00\n",
      "lambda[126]      3.02     11.31      0.92      0.00      5.34    778.35      1.00\n",
      "lambda[127]      4.02     25.55      0.98      0.00      5.60    815.68      1.00\n",
      "lambda[128]      2.75     12.20      0.96      0.00      4.59    427.36      1.00\n",
      "lambda[129]      6.84    101.63      1.02      0.00      6.89   1002.62      1.00\n",
      "lambda[130]      3.10      8.35      0.92      0.00      6.16    770.73      1.00\n",
      "lambda[131]      3.76     15.09      1.01      0.00      7.42    584.37      1.00\n",
      "lambda[132]      3.28     14.11      0.96      0.00      5.85    891.65      1.00\n",
      "lambda[133]      2.83     17.63      1.01      0.00      5.04   1017.29      1.00\n",
      "lambda[134]      3.58      9.72      0.90      0.00      7.07    661.57      1.00\n",
      "lambda[135]      3.06     20.31      0.90      0.00      4.90    927.98      1.00\n",
      "lambda[136]      3.40     23.22      0.99      0.01      5.74    909.97      1.00\n",
      "lambda[137]      3.28     19.80      0.98      0.00      4.89    811.54      1.00\n",
      "lambda[138]      3.13     10.97      1.03      0.00      5.51    717.79      1.00\n",
      "lambda[139]      3.26     11.18      1.04      0.00      5.97    816.36      1.00\n",
      "lambda[140]      3.08     11.86      0.96      0.00      5.14   1000.29      1.00\n",
      "lambda[141]      2.48      5.97      1.00      0.00      5.13    803.55      1.00\n",
      "lambda[142]      4.53     20.11      0.98      0.01      6.58    883.75      1.00\n",
      "lambda[143]      2.47      6.28      0.91      0.01      5.87    627.15      1.00\n",
      "        msq      0.21      0.13      0.18      0.07      0.35    846.71      1.00\n",
      "      sigma      3.25      4.16      1.62      0.01      8.63   1225.20      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    833.99      1.00\n",
      "       xisq      0.11      0.06      0.10      0.04      0.18   1419.62      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 37.072752952575684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.69e-05 +- 1.46e-02\n",
      "[dimension 02/145]  inactive:\t1.87e-03 +- 2.84e-02\n",
      "[dimension 03/145]  inactive:\t1.97e-03 +- 2.93e-02\n",
      "[dimension 04/145]  inactive:\t3.69e-03 +- 2.76e-02\n",
      "[dimension 05/145]  inactive:\t3.85e-04 +- 2.44e-02\n",
      "[dimension 06/145]  inactive:\t2.70e-03 +- 3.16e-02\n",
      "[dimension 07/145]  inactive:\t1.13e-03 +- 1.86e-02\n",
      "[dimension 08/145]  inactive:\t2.40e-03 +- 2.82e-02\n",
      "[dimension 09/145]  inactive:\t1.25e-03 +- 2.22e-02\n",
      "[dimension 10/145]  inactive:\t7.70e-04 +- 1.65e-02\n",
      "[dimension 11/145]  inactive:\t9.24e-04 +- 2.20e-02\n",
      "[dimension 12/145]  inactive:\t1.43e-03 +- 2.69e-02\n",
      "[dimension 13/145]  inactive:\t4.83e-03 +- 3.81e-02\n",
      "[dimension 14/145]  inactive:\t8.58e-05 +- 2.01e-02\n",
      "[dimension 15/145]  inactive:\t3.55e-03 +- 4.03e-02\n",
      "[dimension 16/145]  inactive:\t8.19e-04 +- 2.22e-02\n",
      "[dimension 17/145]  inactive:\t2.73e-03 +- 3.51e-02\n",
      "[dimension 18/145]  inactive:\t2.15e-03 +- 3.15e-02\n",
      "[dimension 19/145]  inactive:\t-1.81e-03 +- 1.95e-02\n",
      "[dimension 20/145]  inactive:\t-1.73e-05 +- 2.17e-02\n",
      "[dimension 21/145]  inactive:\t-1.42e-03 +- 2.14e-02\n",
      "[dimension 22/145]  inactive:\t9.17e-05 +- 2.18e-02\n",
      "[dimension 23/145]  inactive:\t4.38e-04 +- 2.40e-02\n",
      "[dimension 24/145]  inactive:\t1.55e-03 +- 2.55e-02\n",
      "[dimension 25/145]  inactive:\t3.70e-03 +- 2.34e-02\n",
      "[dimension 26/145]  inactive:\t3.08e-04 +- 2.33e-02\n",
      "[dimension 27/145]  inactive:\t1.69e-03 +- 2.43e-02\n",
      "[dimension 28/145]  inactive:\t1.20e-03 +- 1.95e-02\n",
      "[dimension 29/145]  inactive:\t1.49e-03 +- 2.70e-02\n",
      "[dimension 30/145]  inactive:\t1.82e-03 +- 2.30e-02\n",
      "[dimension 31/145]  inactive:\t6.18e-03 +- 4.00e-02\n",
      "[dimension 32/145]  inactive:\t4.49e-04 +- 2.66e-02\n",
      "[dimension 33/145]  inactive:\t5.27e-03 +- 4.39e-02\n",
      "[dimension 34/145]  inactive:\t1.03e-03 +- 1.89e-02\n",
      "[dimension 35/145]  inactive:\t1.57e-03 +- 2.43e-02\n",
      "[dimension 36/145]  inactive:\t2.09e-03 +- 2.54e-02\n",
      "[dimension 37/145]  inactive:\t4.70e-03 +- 2.67e-02\n",
      "[dimension 38/145]  inactive:\t3.82e-04 +- 2.51e-02\n",
      "[dimension 39/145]  inactive:\t2.80e-03 +- 3.09e-02\n",
      "[dimension 40/145]  inactive:\t6.54e-03 +- 4.33e-02\n",
      "[dimension 41/145]  inactive:\t1.19e-04 +- 3.08e-02\n",
      "[dimension 42/145]  inactive:\t2.94e-02 +- 1.35e-01\n",
      "[dimension 43/145]  inactive:\t5.95e-04 +- 2.01e-02\n",
      "[dimension 44/145]  inactive:\t1.52e-03 +- 3.56e-02\n",
      "[dimension 45/145]  inactive:\t1.01e-03 +- 2.12e-02\n",
      "[dimension 46/145]  inactive:\t7.95e-04 +- 1.45e-02\n",
      "[dimension 47/145]  inactive:\t-4.19e-04 +- 2.26e-02\n",
      "[dimension 48/145]  inactive:\t2.20e-03 +- 2.48e-02\n",
      "[dimension 49/145]  inactive:\t2.20e-03 +- 2.23e-02\n",
      "[dimension 50/145]  inactive:\t-5.48e-04 +- 2.67e-02\n",
      "[dimension 51/145]  inactive:\t3.01e-03 +- 3.25e-02\n",
      "[dimension 52/145]  inactive:\t7.62e-03 +- 2.97e-02\n",
      "[dimension 53/145]  inactive:\t-3.24e-04 +- 2.44e-02\n",
      "[dimension 54/145]  inactive:\t1.41e-03 +- 2.16e-02\n",
      "[dimension 55/145]  inactive:\t6.17e-04 +- 1.37e-02\n",
      "[dimension 56/145]  inactive:\t-1.87e-03 +- 2.26e-02\n",
      "[dimension 57/145]  inactive:\t2.63e-03 +- 3.01e-02\n",
      "[dimension 58/145]  inactive:\t1.95e-02 +- 8.33e-02\n",
      "[dimension 59/145]  inactive:\t-1.48e-04 +- 1.42e-02\n",
      "[dimension 60/145]  inactive:\t2.98e-03 +- 3.13e-02\n",
      "[dimension 61/145]  inactive:\t4.36e-03 +- 3.10e-02\n",
      "[dimension 62/145]  inactive:\t4.22e-04 +- 2.04e-02\n",
      "[dimension 63/145]  active:\t5.30e-01 +- 4.15e-01\n",
      "[dimension 64/145]  inactive:\t-2.22e-03 +- 2.15e-02\n",
      "[dimension 65/145]  inactive:\t1.22e-03 +- 2.70e-02\n",
      "[dimension 66/145]  inactive:\t1.32e-03 +- 2.35e-02\n",
      "[dimension 67/145]  inactive:\t1.62e-03 +- 2.43e-02\n",
      "[dimension 68/145]  inactive:\t5.25e-04 +- 2.45e-02\n",
      "[dimension 69/145]  inactive:\t4.66e-03 +- 4.27e-02\n",
      "[dimension 70/145]  inactive:\t5.62e-03 +- 2.98e-02\n",
      "[dimension 71/145]  inactive:\t1.12e-03 +- 2.45e-02\n",
      "[dimension 72/145]  inactive:\t1.54e-03 +- 2.04e-02\n",
      "[dimension 73/145]  inactive:\t7.20e-04 +- 1.72e-02\n",
      "[dimension 74/145]  inactive:\t6.82e-04 +- 2.40e-02\n",
      "[dimension 75/145]  inactive:\t2.21e-03 +- 2.75e-02\n",
      "[dimension 76/145]  inactive:\t6.46e-03 +- 3.96e-02\n",
      "[dimension 77/145]  inactive:\t-6.12e-06 +- 2.56e-02\n",
      "[dimension 78/145]  inactive:\t1.34e-02 +- 8.64e-02\n",
      "[dimension 79/145]  inactive:\t7.92e-03 +- 3.92e-02\n",
      "[dimension 80/145]  inactive:\t1.28e-03 +- 2.87e-02\n",
      "[dimension 81/145]  inactive:\t3.57e-03 +- 3.50e-02\n",
      "[dimension 82/145]  inactive:\t3.98e-04 +- 1.38e-02\n",
      "[dimension 83/145]  inactive:\t-8.45e-04 +- 1.41e-02\n",
      "[dimension 84/145]  inactive:\t-1.06e-04 +- 2.17e-02\n",
      "[dimension 85/145]  inactive:\t2.89e-03 +- 2.91e-02\n",
      "[dimension 86/145]  inactive:\t-4.32e-04 +- 1.69e-02\n",
      "[dimension 87/145]  inactive:\t2.57e-03 +- 2.94e-02\n",
      "[dimension 88/145]  inactive:\t3.64e-03 +- 2.75e-02\n",
      "[dimension 89/145]  inactive:\t-2.30e-05 +- 1.85e-02\n",
      "[dimension 90/145]  inactive:\t1.07e-01 +- 2.57e-01\n",
      "[dimension 91/145]  inactive:\t2.12e-04 +- 1.86e-02\n",
      "[dimension 92/145]  inactive:\t-2.29e-04 +- 2.04e-02\n",
      "[dimension 93/145]  inactive:\t3.30e-04 +- 2.62e-02\n",
      "[dimension 94/145]  inactive:\t2.00e-03 +- 2.52e-02\n",
      "[dimension 95/145]  inactive:\t3.77e-04 +- 1.87e-02\n",
      "[dimension 96/145]  inactive:\t1.02e-03 +- 2.69e-02\n",
      "[dimension 97/145]  inactive:\t2.84e-03 +- 2.41e-02\n",
      "[dimension 98/145]  inactive:\t3.83e-04 +- 2.01e-02\n",
      "[dimension 99/145]  inactive:\t9.00e-03 +- 7.02e-02\n",
      "[dimension 100/145]  inactive:\t-1.59e-04 +- 1.36e-02\n",
      "[dimension 101/145]  inactive:\t-1.33e-03 +- 1.71e-02\n",
      "[dimension 102/145]  inactive:\t9.36e-04 +- 2.39e-02\n",
      "[dimension 103/145]  inactive:\t1.62e-03 +- 2.37e-02\n",
      "[dimension 104/145]  inactive:\t-3.89e-04 +- 1.56e-02\n",
      "[dimension 105/145]  inactive:\t1.12e-03 +- 2.33e-02\n",
      "[dimension 106/145]  inactive:\t7.15e-03 +- 3.87e-02\n",
      "[dimension 107/145]  inactive:\t-2.28e-04 +- 1.68e-02\n",
      "[dimension 108/145]  inactive:\t1.21e-02 +- 7.88e-02\n",
      "[dimension 109/145]  inactive:\t-1.05e-04 +- 1.59e-02\n",
      "[dimension 110/145]  inactive:\t1.03e-03 +- 2.68e-02\n",
      "[dimension 111/145]  inactive:\t2.74e-03 +- 3.00e-02\n",
      "[dimension 112/145]  inactive:\t5.45e-03 +- 4.42e-02\n",
      "[dimension 113/145]  inactive:\t-4.17e-04 +- 1.90e-02\n",
      "[dimension 114/145]  inactive:\t3.26e-03 +- 4.14e-02\n",
      "[dimension 115/145]  inactive:\t2.16e-03 +- 2.18e-02\n",
      "[dimension 116/145]  inactive:\t3.53e-03 +- 4.23e-02\n",
      "[dimension 117/145]  inactive:\t9.54e-03 +- 6.60e-02\n",
      "[dimension 118/145]  inactive:\t3.13e-03 +- 2.27e-02\n",
      "[dimension 119/145]  inactive:\t6.63e-05 +- 2.67e-02\n",
      "[dimension 120/145]  inactive:\t5.69e-04 +- 2.36e-02\n",
      "[dimension 121/145]  inactive:\t4.88e-03 +- 3.61e-02\n",
      "[dimension 122/145]  inactive:\t-9.60e-04 +- 2.74e-02\n",
      "[dimension 123/145]  inactive:\t3.84e-03 +- 3.94e-02\n",
      "[dimension 124/145]  inactive:\t-3.32e-04 +- 1.48e-02\n",
      "[dimension 125/145]  inactive:\t-1.71e-04 +- 1.99e-02\n",
      "[dimension 126/145]  inactive:\t-1.45e-04 +- 1.96e-02\n",
      "[dimension 127/145]  inactive:\t4.83e-04 +- 1.63e-02\n",
      "[dimension 128/145]  inactive:\t1.33e-03 +- 2.98e-02\n",
      "[dimension 129/145]  inactive:\t1.25e-03 +- 2.18e-02\n",
      "[dimension 130/145]  inactive:\t3.99e-03 +- 2.91e-02\n",
      "[dimension 131/145]  inactive:\t7.27e-04 +- 2.63e-02\n",
      "[dimension 132/145]  inactive:\t4.87e-03 +- 3.92e-02\n",
      "[dimension 133/145]  inactive:\t2.87e-03 +- 2.10e-02\n",
      "[dimension 134/145]  inactive:\t5.04e-04 +- 2.19e-02\n",
      "[dimension 135/145]  inactive:\t1.90e-03 +- 2.63e-02\n",
      "[dimension 136/145]  inactive:\t1.37e-03 +- 1.81e-02\n",
      "[dimension 137/145]  inactive:\t1.24e-03 +- 2.86e-02\n",
      "[dimension 138/145]  inactive:\t1.35e-03 +- 2.35e-02\n",
      "[dimension 139/145]  inactive:\t1.32e-03 +- 2.19e-02\n",
      "[dimension 140/145]  inactive:\t2.84e-04 +- 2.57e-02\n",
      "[dimension 141/145]  inactive:\t2.00e-03 +- 2.79e-02\n",
      "[dimension 142/145]  inactive:\t1.93e-03 +- 1.78e-02\n",
      "[dimension 143/145]  inactive:\t4.01e-03 +- 3.87e-02\n",
      "[dimension 144/145]  inactive:\t1.27e-03 +- 1.87e-02\n",
      "[dimension 145/145]  inactive:\t3.73e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.7741183]\n",
      "cov_act[[0.02206465]]\n",
      "Active_dimensions: [62]\n",
      "16, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:33<00:00, 44.77it/s, 31 steps of size 1.26e-01. acc. prob=0.96] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    675.45      1.00\n",
      "  lambda[0]      2.40      7.33      0.95      0.00      4.91    990.85      1.00\n",
      "  lambda[1]      3.01      8.96      0.98      0.00      6.06    626.29      1.01\n",
      "  lambda[2]      3.16     11.55      1.00      0.00      5.24    523.24      1.00\n",
      "  lambda[3]      4.06     17.47      1.07      0.01      6.88    669.95      1.00\n",
      "  lambda[4]      2.88      8.75      1.03      0.00      5.51    936.75      1.00\n",
      "  lambda[5]      2.81      8.00      0.93      0.00      5.12    806.09      1.00\n",
      "  lambda[6]      3.35     14.04      1.05      0.00      6.15    821.60      1.00\n",
      "  lambda[7]      2.74      6.45      0.93      0.00      5.91    636.98      1.00\n",
      "  lambda[8]      2.35      5.44      0.96      0.00      5.44   1074.57      1.00\n",
      "  lambda[9]      2.43      5.96      0.90      0.00      5.00    845.06      1.00\n",
      " lambda[10]      3.46     11.60      1.03      0.00      6.02    744.26      1.00\n",
      " lambda[11]      2.91      7.54      1.01      0.00      6.14    881.14      1.00\n",
      " lambda[12]      4.17     12.62      0.99      0.00      8.67    569.80      1.00\n",
      " lambda[13]      2.58      6.08      0.92      0.00      5.40    761.92      1.00\n",
      " lambda[14]      3.00      7.75      0.94      0.00      5.62    634.19      1.01\n",
      " lambda[15]      3.09      9.27      0.97      0.00      5.72    893.54      1.00\n",
      " lambda[16]      3.79     11.70      0.98      0.00      7.21    245.75      1.00\n",
      " lambda[17]      3.05      9.77      0.99      0.00      5.60    512.25      1.00\n",
      " lambda[18]      2.48      5.33      0.94      0.00      5.55   1019.08      1.01\n",
      " lambda[19]      4.67     26.39      1.04      0.01      6.82    615.75      1.00\n",
      " lambda[20]      2.85      7.08      1.00      0.00      5.99    891.95      1.00\n",
      " lambda[21]      3.52     12.18      0.99      0.00      6.44    693.87      1.00\n",
      " lambda[22]      2.65      7.33      0.96      0.00      5.22    456.96      1.00\n",
      " lambda[23]      2.98      7.11      1.03      0.00      5.98    709.47      1.00\n",
      " lambda[24]      3.88     17.90      0.98      0.00      6.25    622.27      1.00\n",
      " lambda[25]      2.93      6.79      0.95      0.01      6.36    654.70      1.00\n",
      " lambda[26]      2.93     11.55      1.00      0.00      5.67    913.62      1.00\n",
      " lambda[27]      2.88      7.64      0.95      0.00      5.79    662.04      1.00\n",
      " lambda[28]      2.54      5.72      1.02      0.01      5.15    837.79      1.00\n",
      " lambda[29]      2.80      7.94      0.96      0.00      5.36    726.28      1.00\n",
      " lambda[30]      3.40     14.82      1.04      0.01      6.64    880.54      1.00\n",
      " lambda[31]      3.01      9.10      0.99      0.00      5.50    566.31      1.00\n",
      " lambda[32]      3.01      9.61      1.01      0.00      5.75    909.62      1.00\n",
      " lambda[33]      3.06     10.01      0.98      0.01      6.14    850.01      1.00\n",
      " lambda[34]      2.53      6.56      1.00      0.00      4.63   1017.71      1.00\n",
      " lambda[35]      2.40      5.24      0.97      0.00      4.94    719.83      1.00\n",
      " lambda[36]      3.44     12.57      1.03      0.00      6.02    827.54      1.00\n",
      " lambda[37]      3.52     10.26      1.02      0.00      6.86    628.20      1.00\n",
      " lambda[38]      3.10     10.20      0.95      0.00      6.31    932.70      1.00\n",
      " lambda[39]      3.47     10.68      0.99      0.00      6.05    560.61      1.00\n",
      " lambda[40]      3.74     13.78      0.93      0.01      6.57   1009.07      1.00\n",
      " lambda[41]      5.22     20.74      0.91      0.00      9.27    531.48      1.01\n",
      " lambda[42]      2.81      6.95      0.99      0.00      6.02    795.97      1.00\n",
      " lambda[43]      2.86     12.43      0.98      0.00      5.56    989.73      1.00\n",
      " lambda[44]      2.52      7.02      0.95      0.00      5.02    649.10      1.00\n",
      " lambda[45]      2.37      5.14      0.95      0.00      5.33    844.87      1.00\n",
      " lambda[46]      2.67     10.41      1.01      0.00      4.87    853.98      1.00\n",
      " lambda[47]      2.43      4.72      0.95      0.00      5.75    653.82      1.00\n",
      " lambda[48]      2.88      8.71      1.02      0.01      5.52    781.09      1.00\n",
      " lambda[49]      3.17      8.82      0.94      0.00      5.84    793.57      1.00\n",
      " lambda[50]      2.96      9.34      1.02      0.00      5.33    674.08      1.00\n",
      " lambda[51]      4.29     15.21      1.02      0.00      6.61    770.84      1.00\n",
      " lambda[52]      2.66      7.10      0.93      0.00      5.25    760.41      1.00\n",
      " lambda[53]      2.87      6.90      0.93      0.00      5.98    839.42      1.01\n",
      " lambda[54]      2.22      4.22      0.96      0.00      5.01    704.76      1.00\n",
      " lambda[55]      3.43     11.32      0.98      0.00      6.94    838.86      1.00\n",
      " lambda[56]      2.29      4.74      0.98      0.00      4.52    822.97      1.00\n",
      " lambda[57]      4.40     17.66      1.01      0.00      7.18    672.78      1.00\n",
      " lambda[58]      2.33      5.30      0.95      0.00      4.67    765.14      1.00\n",
      " lambda[59]      2.90      7.49      0.96      0.00      5.76    694.51      1.00\n",
      " lambda[60]      2.48      5.54      0.98      0.00      5.67    591.21      1.00\n",
      " lambda[61]      3.15     12.71      1.01      0.00      5.63    995.12      1.00\n",
      " lambda[62]   1444.22  15802.65    223.60      0.01   1233.16    747.70      1.00\n",
      " lambda[63]      2.77     14.00      1.01      0.00      5.28    856.20      1.00\n",
      " lambda[64]      2.72      7.50      0.98      0.00      4.88    775.84      1.00\n",
      " lambda[65]      3.10     11.36      0.96      0.00      5.27    738.24      1.00\n",
      " lambda[66]      3.77     14.25      0.97      0.00      6.88    741.08      1.00\n",
      " lambda[67]      2.96      8.07      0.97      0.00      5.95    971.22      1.00\n",
      " lambda[68]      3.77     19.68      0.96      0.00      6.64    637.85      1.00\n",
      " lambda[69]      3.92     13.38      0.95      0.00      7.13    832.61      1.00\n",
      " lambda[70]      2.69      6.64      0.94      0.00      5.60    866.09      1.00\n",
      " lambda[71]      2.54      6.61      0.99      0.00      5.04    510.00      1.00\n",
      " lambda[72]      2.58      6.47      0.98      0.00      5.28    787.32      1.00\n",
      " lambda[73]      2.88     12.28      0.97      0.00      5.45    480.61      1.00\n",
      " lambda[74]      2.28      3.80      1.04      0.01      5.01    695.01      1.00\n",
      " lambda[75]      3.84     12.11      1.00      0.00      6.62    677.99      1.00\n",
      " lambda[76]      3.53     10.66      0.99      0.00      6.96    674.19      1.00\n",
      " lambda[77]      4.65     48.58      1.07      0.00      6.14    776.41      1.00\n",
      " lambda[78]      4.33     23.22      1.05      0.00      6.27    706.71      1.00\n",
      " lambda[79]      3.25      9.64      1.05      0.00      6.09    694.39      1.01\n",
      " lambda[80]      3.05      7.67      0.98      0.00      6.16   1001.94      1.00\n",
      " lambda[81]      2.58      8.46      0.97      0.00      5.06    862.27      1.00\n",
      " lambda[82]      2.74     10.04      0.94      0.00      4.81    475.07      1.00\n",
      " lambda[83]      2.42      6.35      0.89      0.00      4.66    820.24      1.00\n",
      " lambda[84]      4.37     37.59      1.00      0.00      5.76    872.51      1.00\n",
      " lambda[85]      2.78      7.69      0.93      0.00      5.27    538.98      1.00\n",
      " lambda[86]      3.27     11.00      0.99      0.00      5.58    853.78      1.00\n",
      " lambda[87]      3.23      9.93      0.96      0.00      6.15    682.48      1.00\n",
      " lambda[88]      2.84     11.95      0.99      0.00      5.38   1006.95      1.00\n",
      " lambda[89]     83.37   1138.36      1.17      0.00     82.78    681.12      1.00\n",
      " lambda[90]      2.63      6.90      1.00      0.00      5.16    810.03      1.00\n",
      " lambda[91]      2.68      7.32      0.95      0.01      5.60    693.71      1.00\n",
      " lambda[92]      2.60      7.74      0.97      0.00      5.53    651.23      1.00\n",
      " lambda[93]      2.32      4.70      0.96      0.00      5.01    666.84      1.00\n",
      " lambda[94]      2.54      7.10      0.97      0.00      5.04    708.14      1.00\n",
      " lambda[95]      2.89      9.25      1.05      0.00      5.11    733.22      1.00\n",
      " lambda[96]      2.65     10.23      0.94      0.00      4.91    606.92      1.00\n",
      " lambda[97]      3.63     17.46      0.95      0.00      5.28    497.74      1.00\n",
      " lambda[98]      4.81     33.81      0.97      0.00      5.53    643.38      1.00\n",
      " lambda[99]      2.85      8.15      0.99      0.00      5.70    525.76      1.00\n",
      "lambda[100]      4.05     24.51      0.94      0.00      7.26    945.70      1.00\n",
      "lambda[101]      2.46      5.91      0.97      0.00      5.07    669.27      1.00\n",
      "lambda[102]      2.69      7.61      0.89      0.00      5.02    792.65      1.00\n",
      "lambda[103]      2.55      6.65      0.98      0.00      5.58    888.84      1.00\n",
      "lambda[104]      2.66      6.53      1.00      0.00      5.52    665.75      1.00\n",
      "lambda[105]      3.29      9.96      0.98      0.00      6.46    727.91      1.00\n",
      "lambda[106]      2.57      5.82      1.01      0.00      5.32    760.33      1.00\n",
      "lambda[107]      5.51     30.45      1.02      0.00      7.42    307.56      1.00\n",
      "lambda[108]      2.68      8.78      0.96      0.00      5.14    837.56      1.00\n",
      "lambda[109]      3.43     14.58      1.00      0.00      6.38    455.23      1.00\n",
      "lambda[110]      3.30     11.25      1.04      0.01      5.93    924.38      1.00\n",
      "lambda[111]      3.23     11.02      0.97      0.01      6.06    683.79      1.00\n",
      "lambda[112]      2.84      9.16      0.96      0.00      5.66    695.29      1.00\n",
      "lambda[113]      3.62     14.73      1.00      0.00      6.36    780.52      1.00\n",
      "lambda[114]      3.29     11.54      0.95      0.00      6.79    667.88      1.00\n",
      "lambda[115]      3.42     14.25      0.92      0.00      5.78    692.31      1.00\n",
      "lambda[116]      3.26     12.18      0.99      0.00      5.49    515.53      1.00\n",
      "lambda[117]      3.43     11.93      0.96      0.00      7.30    799.31      1.00\n",
      "lambda[118]      3.59     15.25      0.98      0.00      6.39    713.63      1.00\n",
      "lambda[119]      2.63      5.78      1.05      0.01      5.45    643.45      1.00\n",
      "lambda[120]      4.05     16.61      0.96      0.00      6.58    681.80      1.00\n",
      "lambda[121]      3.40     17.71      0.90      0.00      5.71    920.61      1.00\n",
      "lambda[122]      3.35     14.37      0.98      0.00      5.81    890.33      1.00\n",
      "lambda[123]      2.65      6.84      0.89      0.00      5.70    937.85      1.00\n",
      "lambda[124]      3.80     23.50      0.99      0.00      6.81    530.93      1.00\n",
      "lambda[125]      2.63      7.61      0.98      0.01      5.48    674.11      1.00\n",
      "lambda[126]      2.26      4.88      0.96      0.00      4.92    747.99      1.00\n",
      "lambda[127]      4.94     22.93      1.03      0.00      7.10    592.15      1.00\n",
      "lambda[128]      3.01     16.20      0.97      0.00      5.26    889.85      1.00\n",
      "lambda[129]      3.85     14.50      1.00      0.00      6.48    994.21      1.00\n",
      "lambda[130]      3.27      9.85      1.01      0.00      6.66    817.76      1.00\n",
      "lambda[131]      3.75     16.97      1.03      0.00      5.79    696.11      1.00\n",
      "lambda[132]      2.56      5.68      0.94      0.00      5.98    884.83      1.00\n",
      "lambda[133]      2.54      5.72      1.02      0.00      5.37    959.29      1.00\n",
      "lambda[134]      3.60     11.70      1.04      0.00      7.32    826.92      1.00\n",
      "lambda[135]      3.18     14.47      1.00      0.00      5.40    632.15      1.00\n",
      "lambda[136]      2.97      8.16      1.02      0.00      5.71    585.93      1.00\n",
      "lambda[137]      2.63      8.26      0.98      0.00      4.78    870.54      1.00\n",
      "lambda[138]      3.44     15.63      1.00      0.00      5.16    739.80      1.00\n",
      "lambda[139]      3.30     10.14      1.00      0.00      5.99    926.48      1.00\n",
      "lambda[140]      3.11      9.61      1.00      0.00      5.89    776.98      1.00\n",
      "lambda[141]      2.39      5.23      0.99      0.00      4.76    643.39      1.00\n",
      "lambda[142]      6.09     65.32      0.93      0.01      6.03    609.07      1.00\n",
      "lambda[143]      2.29      4.51      1.00      0.00      4.91    645.34      1.00\n",
      "        msq   1313.36  14072.16      7.77      0.17    230.78    603.11      1.00\n",
      "      sigma      4.37      5.98      1.90      0.00     12.31   1048.65      1.00\n",
      "    var_obs      0.09      0.01      0.08      0.07      0.11   1356.46      1.00\n",
      "       xisq     24.77    239.52      1.49      0.07     17.74    658.58      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 37.34486413002014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.96e-04 +- 1.82e-02\n",
      "[dimension 02/145]  inactive:\t7.15e-05 +- 2.47e-02\n",
      "[dimension 03/145]  inactive:\t4.35e-04 +- 2.33e-02\n",
      "[dimension 04/145]  inactive:\t6.32e-03 +- 4.15e-02\n",
      "[dimension 05/145]  inactive:\t-8.99e-04 +- 2.12e-02\n",
      "[dimension 06/145]  inactive:\t1.34e-03 +- 2.90e-02\n",
      "[dimension 07/145]  inactive:\t6.76e-04 +- 1.72e-02\n",
      "[dimension 08/145]  inactive:\t8.67e-04 +- 2.55e-02\n",
      "[dimension 09/145]  inactive:\t-7.69e-05 +- 2.18e-02\n",
      "[dimension 10/145]  inactive:\t2.93e-04 +- 1.74e-02\n",
      "[dimension 11/145]  inactive:\t-1.84e-03 +- 2.58e-02\n",
      "[dimension 12/145]  inactive:\t-3.51e-04 +- 2.71e-02\n",
      "[dimension 13/145]  inactive:\t5.35e-03 +- 4.19e-02\n",
      "[dimension 14/145]  inactive:\t-1.41e-03 +- 2.22e-02\n",
      "[dimension 15/145]  inactive:\t6.64e-04 +- 3.32e-02\n",
      "[dimension 16/145]  inactive:\t5.30e-04 +- 2.08e-02\n",
      "[dimension 17/145]  inactive:\t-5.12e-04 +- 2.71e-02\n",
      "[dimension 18/145]  inactive:\t-4.81e-04 +- 2.47e-02\n",
      "[dimension 19/145]  inactive:\t-1.87e-03 +- 1.85e-02\n",
      "[dimension 20/145]  inactive:\t-1.45e-03 +- 2.82e-02\n",
      "[dimension 21/145]  inactive:\t-2.44e-03 +- 2.75e-02\n",
      "[dimension 22/145]  inactive:\t1.94e-04 +- 2.18e-02\n",
      "[dimension 23/145]  inactive:\t-6.85e-04 +- 2.65e-02\n",
      "[dimension 24/145]  inactive:\t1.54e-03 +- 2.62e-02\n",
      "[dimension 25/145]  inactive:\t3.49e-03 +- 2.39e-02\n",
      "[dimension 26/145]  inactive:\t-8.09e-04 +- 2.65e-02\n",
      "[dimension 27/145]  inactive:\t5.64e-04 +- 2.45e-02\n",
      "[dimension 28/145]  inactive:\t7.01e-04 +- 1.97e-02\n",
      "[dimension 29/145]  inactive:\t-3.98e-04 +- 2.51e-02\n",
      "[dimension 30/145]  inactive:\t9.29e-04 +- 2.58e-02\n",
      "[dimension 31/145]  inactive:\t4.29e-03 +- 3.27e-02\n",
      "[dimension 32/145]  inactive:\t-1.75e-03 +- 2.68e-02\n",
      "[dimension 33/145]  inactive:\t1.85e-03 +- 3.30e-02\n",
      "[dimension 34/145]  inactive:\t6.96e-04 +- 1.90e-02\n",
      "[dimension 35/145]  inactive:\t7.47e-04 +- 2.57e-02\n",
      "[dimension 36/145]  inactive:\t5.63e-04 +- 2.38e-02\n",
      "[dimension 37/145]  inactive:\t4.32e-03 +- 2.87e-02\n",
      "[dimension 38/145]  inactive:\t-2.02e-03 +- 3.25e-02\n",
      "[dimension 39/145]  inactive:\t6.56e-04 +- 2.60e-02\n",
      "[dimension 40/145]  inactive:\t4.80e-03 +- 3.54e-02\n",
      "[dimension 41/145]  inactive:\t-1.73e-03 +- 3.17e-02\n",
      "[dimension 42/145]  inactive:\t6.52e-03 +- 5.75e-02\n",
      "[dimension 43/145]  inactive:\t-4.10e-04 +- 2.13e-02\n",
      "[dimension 44/145]  inactive:\t-7.44e-04 +- 2.36e-02\n",
      "[dimension 45/145]  inactive:\t-3.16e-04 +- 2.13e-02\n",
      "[dimension 46/145]  inactive:\t1.20e-03 +- 1.58e-02\n",
      "[dimension 47/145]  inactive:\t-1.78e-03 +- 2.45e-02\n",
      "[dimension 48/145]  inactive:\t1.05e-03 +- 2.46e-02\n",
      "[dimension 49/145]  inactive:\t2.79e-03 +- 2.39e-02\n",
      "[dimension 50/145]  inactive:\t-1.95e-03 +- 2.95e-02\n",
      "[dimension 51/145]  inactive:\t2.41e-03 +- 2.75e-02\n",
      "[dimension 52/145]  inactive:\t6.27e-03 +- 2.70e-02\n",
      "[dimension 53/145]  inactive:\t-9.96e-04 +- 2.66e-02\n",
      "[dimension 54/145]  inactive:\t-1.42e-04 +- 2.16e-02\n",
      "[dimension 55/145]  inactive:\t4.28e-04 +- 1.60e-02\n",
      "[dimension 56/145]  inactive:\t-2.77e-03 +- 2.39e-02\n",
      "[dimension 57/145]  inactive:\t2.31e-04 +- 2.29e-02\n",
      "[dimension 58/145]  inactive:\t1.03e-02 +- 6.24e-02\n",
      "[dimension 59/145]  inactive:\t-1.03e-03 +- 1.94e-02\n",
      "[dimension 60/145]  inactive:\t4.72e-04 +- 3.14e-02\n",
      "[dimension 61/145]  inactive:\t1.73e-03 +- 2.15e-02\n",
      "[dimension 62/145]  inactive:\t-9.88e-04 +- 2.14e-02\n",
      "[dimension 63/145]  active:\t7.59e-01 +- 3.90e-01\n",
      "[dimension 64/145]  inactive:\t-2.58e-03 +- 2.64e-02\n",
      "[dimension 65/145]  inactive:\t-6.62e-04 +- 2.30e-02\n",
      "[dimension 66/145]  inactive:\t5.11e-04 +- 2.48e-02\n",
      "[dimension 67/145]  inactive:\t1.60e-03 +- 2.51e-02\n",
      "[dimension 68/145]  inactive:\t-6.99e-04 +- 2.51e-02\n",
      "[dimension 69/145]  inactive:\t3.31e-03 +- 4.05e-02\n",
      "[dimension 70/145]  inactive:\t3.87e-03 +- 2.47e-02\n",
      "[dimension 71/145]  inactive:\t-8.81e-05 +- 2.43e-02\n",
      "[dimension 72/145]  inactive:\t1.02e-04 +- 1.99e-02\n",
      "[dimension 73/145]  inactive:\t1.41e-04 +- 1.74e-02\n",
      "[dimension 74/145]  inactive:\t-1.47e-03 +- 3.14e-02\n",
      "[dimension 75/145]  inactive:\t3.16e-05 +- 1.83e-02\n",
      "[dimension 76/145]  inactive:\t5.51e-03 +- 3.90e-02\n",
      "[dimension 77/145]  inactive:\t-2.01e-03 +- 3.98e-02\n",
      "[dimension 78/145]  inactive:\t5.27e-03 +- 5.41e-02\n",
      "[dimension 79/145]  inactive:\t6.58e-03 +- 3.64e-02\n",
      "[dimension 80/145]  inactive:\t-9.01e-04 +- 3.08e-02\n",
      "[dimension 81/145]  inactive:\t8.78e-04 +- 2.76e-02\n",
      "[dimension 82/145]  inactive:\t2.22e-04 +- 1.50e-02\n",
      "[dimension 83/145]  inactive:\t-1.67e-03 +- 1.72e-02\n",
      "[dimension 84/145]  inactive:\t-1.09e-03 +- 2.07e-02\n",
      "[dimension 85/145]  inactive:\t2.10e-03 +- 2.62e-02\n",
      "[dimension 86/145]  inactive:\t-5.37e-04 +- 1.92e-02\n",
      "[dimension 87/145]  inactive:\t7.57e-04 +- 2.98e-02\n",
      "[dimension 88/145]  inactive:\t2.83e-03 +- 2.42e-02\n",
      "[dimension 89/145]  inactive:\t-8.05e-04 +- 1.97e-02\n",
      "[dimension 90/145]  inactive:\t1.07e-01 +- 2.87e-01\n",
      "[dimension 91/145]  inactive:\t-9.31e-07 +- 1.65e-02\n",
      "[dimension 92/145]  inactive:\t-1.62e-03 +- 2.42e-02\n",
      "[dimension 93/145]  inactive:\t-1.76e-04 +- 2.04e-02\n",
      "[dimension 94/145]  inactive:\t1.38e-03 +- 2.19e-02\n",
      "[dimension 95/145]  inactive:\t-3.64e-04 +- 2.27e-02\n",
      "[dimension 96/145]  inactive:\t4.55e-05 +- 2.98e-02\n",
      "[dimension 97/145]  inactive:\t1.76e-03 +- 1.95e-02\n",
      "[dimension 98/145]  inactive:\t-1.28e-03 +- 2.36e-02\n",
      "[dimension 99/145]  inactive:\t4.13e-03 +- 4.90e-02\n",
      "[dimension 100/145]  inactive:\t-7.82e-04 +- 1.66e-02\n",
      "[dimension 101/145]  inactive:\t-2.75e-03 +- 2.13e-02\n",
      "[dimension 102/145]  inactive:\t-7.63e-04 +- 2.22e-02\n",
      "[dimension 103/145]  inactive:\t5.94e-04 +- 2.13e-02\n",
      "[dimension 104/145]  inactive:\t-1.05e-03 +- 1.64e-02\n",
      "[dimension 105/145]  inactive:\t-2.89e-04 +- 2.21e-02\n",
      "[dimension 106/145]  inactive:\t5.25e-03 +- 3.39e-02\n",
      "[dimension 107/145]  inactive:\t-1.19e-03 +- 2.01e-02\n",
      "[dimension 108/145]  inactive:\t1.06e-02 +- 8.58e-02\n",
      "[dimension 109/145]  inactive:\t-3.26e-04 +- 1.81e-02\n",
      "[dimension 110/145]  inactive:\t-1.37e-03 +- 2.96e-02\n",
      "[dimension 111/145]  inactive:\t1.75e-03 +- 3.10e-02\n",
      "[dimension 112/145]  inactive:\t4.10e-03 +- 3.47e-02\n",
      "[dimension 113/145]  inactive:\t-1.40e-03 +- 2.34e-02\n",
      "[dimension 114/145]  inactive:\t-3.08e-04 +- 3.01e-02\n",
      "[dimension 115/145]  inactive:\t2.14e-03 +- 2.32e-02\n",
      "[dimension 116/145]  inactive:\t9.74e-04 +- 3.68e-02\n",
      "[dimension 117/145]  inactive:\t3.52e-03 +- 4.11e-02\n",
      "[dimension 118/145]  inactive:\t3.36e-03 +- 2.56e-02\n",
      "[dimension 119/145]  inactive:\t-2.65e-03 +- 3.45e-02\n",
      "[dimension 120/145]  inactive:\t1.22e-04 +- 2.76e-02\n",
      "[dimension 121/145]  inactive:\t3.95e-03 +- 3.43e-02\n",
      "[dimension 122/145]  inactive:\t-2.64e-03 +- 2.98e-02\n",
      "[dimension 123/145]  inactive:\t1.12e-03 +- 3.21e-02\n",
      "[dimension 124/145]  inactive:\t-1.57e-03 +- 1.84e-02\n",
      "[dimension 125/145]  inactive:\t-2.23e-03 +- 3.00e-02\n",
      "[dimension 126/145]  inactive:\t-1.31e-03 +- 2.20e-02\n",
      "[dimension 127/145]  inactive:\t-5.75e-05 +- 1.53e-02\n",
      "[dimension 128/145]  inactive:\t-2.42e-03 +- 3.48e-02\n",
      "[dimension 129/145]  inactive:\t-4.65e-04 +- 2.29e-02\n",
      "[dimension 130/145]  inactive:\t4.19e-03 +- 3.11e-02\n",
      "[dimension 131/145]  inactive:\t-1.23e-03 +- 2.86e-02\n",
      "[dimension 132/145]  inactive:\t2.20e-03 +- 3.05e-02\n",
      "[dimension 133/145]  inactive:\t2.19e-03 +- 1.89e-02\n",
      "[dimension 134/145]  inactive:\t-5.33e-04 +- 2.30e-02\n",
      "[dimension 135/145]  inactive:\t3.43e-04 +- 2.79e-02\n",
      "[dimension 136/145]  inactive:\t1.05e-03 +- 2.05e-02\n",
      "[dimension 137/145]  inactive:\t-3.86e-04 +- 3.42e-02\n",
      "[dimension 138/145]  inactive:\t2.13e-04 +- 1.94e-02\n",
      "[dimension 139/145]  inactive:\t5.81e-04 +- 2.19e-02\n",
      "[dimension 140/145]  inactive:\t-1.09e-03 +- 2.59e-02\n",
      "[dimension 141/145]  inactive:\t1.03e-03 +- 2.52e-02\n",
      "[dimension 142/145]  inactive:\t1.08e-03 +- 1.75e-02\n",
      "[dimension 143/145]  inactive:\t1.00e-03 +- 3.21e-02\n",
      "[dimension 144/145]  inactive:\t-3.63e-05 +- 1.80e-02\n",
      "[dimension 145/145]  inactive:\t-3.87e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9091377]\n",
      "cov_act[[0.03879517]]\n",
      "Active_dimensions: [62]\n",
      "17, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:31<00:00, 47.37it/s, 31 steps of size 1.86e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    270.54      1.02\n",
      "  lambda[0]      2.52      6.32      0.95      0.00      5.22    551.46      1.00\n",
      "  lambda[1]      4.03     32.27      0.99      0.00      5.70    706.85      1.00\n",
      "  lambda[2]      2.59      6.04      0.98      0.00      5.21    558.00      1.00\n",
      "  lambda[3]     11.53    113.67      1.00      0.00      6.11    568.33      1.00\n",
      "  lambda[4]      3.05     16.78      0.96      0.00      5.44    902.00      1.00\n",
      "  lambda[5]      5.71     43.62      0.96      0.00      5.97    535.37      1.00\n",
      "  lambda[6]      5.13     27.78      1.08      0.00      7.06    893.05      1.00\n",
      "  lambda[7]      2.78      6.41      1.01      0.01      6.06    859.47      1.00\n",
      "  lambda[8]      2.21      4.26      1.02      0.02      4.89    921.57      1.01\n",
      "  lambda[9]      2.44      6.58      1.02      0.00      4.90    669.01      1.00\n",
      " lambda[10]      3.37     13.40      1.04      0.00      5.72    889.08      1.00\n",
      " lambda[11]      2.96      9.85      1.02      0.00      5.95    695.06      1.00\n",
      " lambda[12]      4.17     16.95      1.01      0.01      7.76    904.10      1.01\n",
      " lambda[13]      2.50      5.91      1.02      0.01      5.19    777.84      1.00\n",
      " lambda[14]      6.15     57.08      0.98      0.00      5.05    658.13      1.00\n",
      " lambda[15]      3.89     15.71      0.97      0.00      6.14    819.61      1.00\n",
      " lambda[16]      3.51     10.55      1.00      0.00      7.01    633.36      1.00\n",
      " lambda[17]      4.69     42.47      0.98      0.00      6.43    700.51      1.00\n",
      " lambda[18]      2.78      7.31      0.92      0.00      6.00    790.24      1.00\n",
      " lambda[19]      4.78     40.46      0.97      0.00      6.27    516.08      1.00\n",
      " lambda[20]      2.42      4.76      0.95      0.00      5.29    986.63      1.00\n",
      " lambda[21]      3.19      9.29      0.98      0.00      6.51    595.11      1.00\n",
      " lambda[22]      2.72      6.99      0.97      0.00      5.51    720.32      1.00\n",
      " lambda[23]      3.44     12.14      1.00      0.00      6.34    821.70      1.00\n",
      " lambda[24]      5.79     41.36      0.98      0.00      6.31    282.87      1.00\n",
      " lambda[25]      2.79      6.35      0.91      0.00      5.87    513.48      1.00\n",
      " lambda[26]      3.13     10.89      0.98      0.00      6.22    853.13      1.00\n",
      " lambda[27]      2.81      9.72      0.89      0.00      5.36    473.79      1.00\n",
      " lambda[28]      2.65      9.23      0.99      0.01      5.17    735.15      1.00\n",
      " lambda[29]      2.82      7.36      0.98      0.00      5.72    844.41      1.00\n",
      " lambda[30]      3.26     10.49      0.99      0.01      6.75    763.10      1.00\n",
      " lambda[31]      3.06     12.74      0.94      0.00      5.76    563.25      1.00\n",
      " lambda[32]      5.28     45.22      0.95      0.00      6.41    864.22      1.00\n",
      " lambda[33]      3.33      9.15      0.99      0.00      6.79    670.91      1.00\n",
      " lambda[34]      2.72      7.28      0.97      0.00      5.14    601.60      1.00\n",
      " lambda[35]      2.53      7.77      0.94      0.00      5.31    718.66      1.00\n",
      " lambda[36]      3.04      9.37      0.97      0.00      6.26    903.93      1.00\n",
      " lambda[37]      4.12     21.98      1.00      0.00      6.41    927.77      1.00\n",
      " lambda[38]      3.94     36.19      0.91      0.00      5.38    983.37      1.00\n",
      " lambda[39]      9.69    142.94      1.04      0.00      6.62    542.29      1.00\n",
      " lambda[40]      4.19     26.57      1.01      0.00      6.23    946.75      1.00\n",
      " lambda[41]    259.48   4402.47      1.00      0.00      8.09    314.33      1.00\n",
      " lambda[42]      2.76     10.55      0.97      0.00      5.78    781.89      1.00\n",
      " lambda[43]      5.68     58.82      0.97      0.00      6.05    558.30      1.00\n",
      " lambda[44]      2.54      5.30      1.02      0.00      5.32    648.38      1.00\n",
      " lambda[45]      2.38      7.20      1.01      0.00      4.55    743.65      1.00\n",
      " lambda[46]      2.56      7.10      1.04      0.00      4.54    611.20      1.00\n",
      " lambda[47]      2.35      5.77      0.93      0.01      5.08    677.97      1.00\n",
      " lambda[48]      2.60      7.64      1.05      0.01      5.35    823.12      1.00\n",
      " lambda[49]      3.26      9.84      1.04      0.00      6.27    562.58      1.00\n",
      " lambda[50]      2.87      6.61      0.98      0.00      6.01    573.61      1.00\n",
      " lambda[51]      6.81     51.05      1.03      0.00      9.07    654.50      1.00\n",
      " lambda[52]      3.17     11.50      1.01      0.00      5.95    895.01      1.00\n",
      " lambda[53]      3.10      8.95      0.96      0.01      5.45    869.46      1.00\n",
      " lambda[54]      2.15      4.78      0.95      0.00      4.29    742.68      1.00\n",
      " lambda[55]      2.72      8.86      1.01      0.00      5.12    829.29      1.00\n",
      " lambda[56]      2.72      8.44      0.99      0.00      4.62    474.00      1.00\n",
      " lambda[57]      3.68     13.51      0.91      0.00      7.10    430.61      1.00\n",
      " lambda[58]      2.37      6.28      0.99      0.00      4.82    598.92      1.00\n",
      " lambda[59]      3.94     32.02      1.01      0.00      6.31    975.14      1.00\n",
      " lambda[60]      4.17     13.56      1.08      0.00      7.65    683.62      1.00\n",
      " lambda[61]      2.70      5.83      1.05      0.01      5.89    549.18      1.00\n",
      " lambda[62]   9766.32 155302.28    430.90      0.00   3759.35    958.27      1.00\n",
      " lambda[63]      2.35      6.26      0.95      0.00      4.95    948.40      1.00\n",
      " lambda[64]      2.60      6.40      0.97      0.00      5.37    677.18      1.00\n",
      " lambda[65]      4.90     60.82      0.99      0.00      5.79    986.75      1.00\n",
      " lambda[66]      4.28     24.73      1.08      0.00      7.67    798.06      1.00\n",
      " lambda[67]      2.54      6.15      0.90      0.00      5.70    543.97      1.00\n",
      " lambda[68]      2.67      8.18      0.91      0.01      4.78    542.16      1.00\n",
      " lambda[69]      4.72     37.72      0.93      0.00      5.73    713.40      1.00\n",
      " lambda[70]      2.58      7.21      0.99      0.01      5.42    771.89      1.00\n",
      " lambda[71]      3.89     19.31      0.94      0.00      5.47    310.14      1.00\n",
      " lambda[72]      2.57      8.44      1.00      0.00      4.10    539.74      1.00\n",
      " lambda[73]      2.76      6.79      0.99      0.00      5.18    611.30      1.00\n",
      " lambda[74]      2.47      4.20      1.09      0.02      6.02    833.26      1.00\n",
      " lambda[75]      4.11     19.73      0.93      0.00      7.42    795.08      1.00\n",
      " lambda[76]      2.79      9.66      0.93      0.00      5.06    612.35      1.00\n",
      " lambda[77]      7.59     69.56      1.02      0.00      7.13    396.47      1.00\n",
      " lambda[78]      4.30     31.89      0.96      0.00      6.35    606.12      1.00\n",
      " lambda[79]      3.33     14.74      1.03      0.00      5.26    552.51      1.00\n",
      " lambda[80]      3.47     15.31      0.97      0.00      5.73    696.78      1.00\n",
      " lambda[81]      2.36      5.05      0.96      0.00      4.98    823.24      1.00\n",
      " lambda[82]      2.45      6.01      0.94      0.01      5.11    583.78      1.00\n",
      " lambda[83]      2.71      7.70      0.92      0.00      5.31    741.84      1.00\n",
      " lambda[84]      3.52     15.25      1.01      0.00      5.92    424.03      1.00\n",
      " lambda[85]      2.47      6.02      0.95      0.00      5.24    585.45      1.00\n",
      " lambda[86]      3.57     24.82      1.00      0.00      5.78   1000.61      1.00\n",
      " lambda[87]      3.13      7.83      1.05      0.00      6.62    651.86      1.00\n",
      " lambda[88]      2.71      6.42      1.00      0.00      5.98    835.71      1.00\n",
      " lambda[89]    110.04   1338.01      1.07      0.00     18.70    674.03      1.00\n",
      " lambda[90]      2.96      7.24      1.01      0.00      6.23    624.69      1.00\n",
      " lambda[91]      2.71      6.77      1.02      0.01      5.90    759.57      1.00\n",
      " lambda[92]      2.87      6.44      1.04      0.00      5.75    729.70      1.00\n",
      " lambda[93]      2.85     11.57      1.02      0.00      5.29    844.31      1.00\n",
      " lambda[94]      2.61      8.19      0.93      0.00      5.25    925.30      1.00\n",
      " lambda[95]      3.91     19.90      0.95      0.00      5.96    762.24      1.00\n",
      " lambda[96]      2.41      5.31      0.93      0.00      5.09    776.39      1.00\n",
      " lambda[97]      4.24     20.91      1.00      0.00      6.87    580.03      1.00\n",
      " lambda[98]      8.43     75.38      1.06      0.00      6.06    672.76      1.00\n",
      " lambda[99]      2.68      8.74      0.95      0.00      5.06    845.88      1.00\n",
      "lambda[100]      3.25     12.85      0.93      0.00      5.16    808.21      1.00\n",
      "lambda[101]      2.37      5.33      0.92      0.00      4.67    786.24      1.00\n",
      "lambda[102]      3.37     11.69      0.97      0.00      5.76    528.00      1.00\n",
      "lambda[103]      2.42      5.23      0.94      0.00      5.90    702.98      1.00\n",
      "lambda[104]      3.04      8.39      0.95      0.00      5.55    775.62      1.00\n",
      "lambda[105]      4.29     17.95      1.06      0.00      7.66    699.92      1.00\n",
      "lambda[106]      2.53      5.75      1.00      0.00      5.50    754.38      1.00\n",
      "lambda[107]      5.50     38.82      1.01      0.00      5.39    334.38      1.00\n",
      "lambda[108]      2.33      4.84      0.97      0.00      4.96    869.80      1.00\n",
      "lambda[109]      6.25     89.17      0.98      0.00      5.51   1005.80      1.00\n",
      "lambda[110]      5.12     23.55      1.03      0.00      7.23    675.87      1.00\n",
      "lambda[111]      5.44     31.02      1.03      0.00      6.63    841.03      1.00\n",
      "lambda[112]      2.25      4.92      0.97      0.00      5.12   1111.00      1.00\n",
      "lambda[113]      3.24     10.50      1.01      0.00      6.48    647.81      1.00\n",
      "lambda[114]      5.33     25.52      1.02      0.00      8.26    538.79      1.00\n",
      "lambda[115]      7.81    141.12      1.05      0.00      5.93    998.33      1.00\n",
      "lambda[116]      5.83     50.85      0.93      0.00      6.41    589.73      1.00\n",
      "lambda[117]      4.89     34.69      0.94      0.00      6.19    654.14      1.00\n",
      "lambda[118]      2.73      7.36      0.99      0.00      5.33    887.37      1.00\n",
      "lambda[119]      2.98      8.19      0.95      0.00      6.28    656.20      1.00\n",
      "lambda[120]      7.80     86.48      1.00      0.00      6.93    533.44      1.00\n",
      "lambda[121]      2.80      8.59      0.97      0.00      5.76    627.92      1.00\n",
      "lambda[122]      3.57     17.95      0.91      0.00      5.16    540.58      1.00\n",
      "lambda[123]      2.75      7.96      0.95      0.00      6.50    731.91      1.00\n",
      "lambda[124]      2.71      5.66      0.99      0.01      6.26    851.85      1.00\n",
      "lambda[125]      2.51      5.24      1.00      0.00      5.67    552.16      1.00\n",
      "lambda[126]      2.50      7.35      0.96      0.00      4.88    894.55      1.00\n",
      "lambda[127]      3.70     15.46      0.95      0.00      5.38    800.80      1.00\n",
      "lambda[128]      3.01     10.06      0.99      0.00      5.37    612.82      1.00\n",
      "lambda[129]      4.51     35.10      1.02      0.00      6.01    917.16      1.00\n",
      "lambda[130]      3.39     10.38      0.93      0.00      5.98    776.50      1.01\n",
      "lambda[131]      2.95      9.95      0.96      0.01      5.67    863.44      1.00\n",
      "lambda[132]      2.68      6.32      1.02      0.00      5.48    683.27      1.00\n",
      "lambda[133]      2.91     12.58      0.96      0.00      5.21    948.05      1.00\n",
      "lambda[134]      2.90      6.72      0.94      0.00      6.97    702.03      1.00\n",
      "lambda[135]      2.90      9.26      0.93      0.00      4.84    671.10      1.00\n",
      "lambda[136]      3.96     27.00      0.96      0.00      6.00    899.23      1.00\n",
      "lambda[137]      2.37      5.22      0.97      0.00      4.77    799.02      1.00\n",
      "lambda[138]      3.04      8.29      0.96      0.00      5.74    652.88      1.00\n",
      "lambda[139]      2.96      7.44      1.02      0.01      6.29    499.79      1.00\n",
      "lambda[140]      4.11     18.99      0.98      0.00      6.61    832.69      1.00\n",
      "lambda[141]      2.49      6.17      0.84      0.00      5.28    910.86      1.00\n",
      "lambda[142]      5.03     25.68      0.99      0.00      7.38    695.41      1.00\n",
      "lambda[143]      2.38      4.78      0.98      0.01      5.10    679.42      1.00\n",
      "        msq      0.24      0.14      0.20      0.07      0.40   1085.49      1.00\n",
      "      sigma      4.10      5.71      1.47      0.00     12.14   1113.97      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    645.85      1.00\n",
      "       xisq      1.41      4.23      0.58      0.09      2.59    614.00      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 36.055034160614014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.12e-04 +- 1.25e-02\n",
      "[dimension 02/145]  inactive:\t4.40e-04 +- 1.67e-02\n",
      "[dimension 03/145]  inactive:\t5.72e-04 +- 1.39e-02\n",
      "[dimension 04/145]  inactive:\t5.87e-03 +- 4.67e-02\n",
      "[dimension 05/145]  inactive:\t4.02e-04 +- 1.58e-02\n",
      "[dimension 06/145]  inactive:\t2.47e-03 +- 3.03e-02\n",
      "[dimension 07/145]  inactive:\t1.28e-03 +- 1.64e-02\n",
      "[dimension 08/145]  inactive:\t1.07e-03 +- 1.85e-02\n",
      "[dimension 09/145]  inactive:\t4.10e-04 +- 1.21e-02\n",
      "[dimension 10/145]  inactive:\t3.91e-04 +- 1.07e-02\n",
      "[dimension 11/145]  inactive:\t5.88e-04 +- 1.99e-02\n",
      "[dimension 12/145]  inactive:\t4.27e-04 +- 1.61e-02\n",
      "[dimension 13/145]  inactive:\t3.03e-03 +- 2.81e-02\n",
      "[dimension 14/145]  inactive:\t7.56e-05 +- 1.34e-02\n",
      "[dimension 15/145]  inactive:\t3.61e-03 +- 4.25e-02\n",
      "[dimension 16/145]  inactive:\t8.48e-04 +- 1.63e-02\n",
      "[dimension 17/145]  inactive:\t7.77e-04 +- 1.87e-02\n",
      "[dimension 18/145]  inactive:\t2.60e-03 +- 3.74e-02\n",
      "[dimension 19/145]  inactive:\t-6.52e-04 +- 1.24e-02\n",
      "[dimension 20/145]  inactive:\t3.89e-04 +- 1.82e-02\n",
      "[dimension 21/145]  inactive:\t-2.87e-04 +- 1.21e-02\n",
      "[dimension 22/145]  inactive:\t2.83e-04 +- 1.64e-02\n",
      "[dimension 23/145]  inactive:\t4.45e-04 +- 1.66e-02\n",
      "[dimension 24/145]  inactive:\t1.58e-03 +- 2.27e-02\n",
      "[dimension 25/145]  inactive:\t3.61e-03 +- 2.50e-02\n",
      "[dimension 26/145]  inactive:\t2.42e-04 +- 1.61e-02\n",
      "[dimension 27/145]  inactive:\t1.08e-03 +- 2.08e-02\n",
      "[dimension 28/145]  inactive:\t6.99e-04 +- 1.22e-02\n",
      "[dimension 29/145]  inactive:\t9.06e-04 +- 1.88e-02\n",
      "[dimension 30/145]  inactive:\t1.23e-03 +- 1.86e-02\n",
      "[dimension 31/145]  inactive:\t2.34e-03 +- 2.20e-02\n",
      "[dimension 32/145]  inactive:\t4.97e-04 +- 1.74e-02\n",
      "[dimension 33/145]  inactive:\t2.55e-03 +- 3.37e-02\n",
      "[dimension 34/145]  inactive:\t9.12e-04 +- 1.46e-02\n",
      "[dimension 35/145]  inactive:\t6.29e-04 +- 1.35e-02\n",
      "[dimension 36/145]  inactive:\t6.54e-04 +- 1.27e-02\n",
      "[dimension 37/145]  inactive:\t2.58e-03 +- 1.94e-02\n",
      "[dimension 38/145]  inactive:\t6.12e-04 +- 2.25e-02\n",
      "[dimension 39/145]  inactive:\t1.36e-03 +- 1.98e-02\n",
      "[dimension 40/145]  inactive:\t7.26e-03 +- 5.28e-02\n",
      "[dimension 41/145]  inactive:\t1.65e-04 +- 1.82e-02\n",
      "[dimension 42/145]  inactive:\t1.91e-02 +- 1.15e-01\n",
      "[dimension 43/145]  inactive:\t2.85e-04 +- 1.27e-02\n",
      "[dimension 44/145]  inactive:\t8.15e-04 +- 2.31e-02\n",
      "[dimension 45/145]  inactive:\t4.90e-04 +- 1.44e-02\n",
      "[dimension 46/145]  inactive:\t3.93e-04 +- 9.14e-03\n",
      "[dimension 47/145]  inactive:\t1.08e-04 +- 1.53e-02\n",
      "[dimension 48/145]  inactive:\t4.93e-04 +- 1.49e-02\n",
      "[dimension 49/145]  inactive:\t1.17e-03 +- 1.73e-02\n",
      "[dimension 50/145]  inactive:\t-7.19e-05 +- 1.90e-02\n",
      "[dimension 51/145]  inactive:\t2.35e-03 +- 2.60e-02\n",
      "[dimension 52/145]  inactive:\t4.33e-03 +- 2.14e-02\n",
      "[dimension 53/145]  inactive:\t-7.88e-05 +- 1.47e-02\n",
      "[dimension 54/145]  inactive:\t4.05e-04 +- 1.27e-02\n",
      "[dimension 55/145]  inactive:\t4.89e-04 +- 1.08e-02\n",
      "[dimension 56/145]  inactive:\t-7.46e-04 +- 1.28e-02\n",
      "[dimension 57/145]  inactive:\t1.28e-03 +- 2.40e-02\n",
      "[dimension 58/145]  inactive:\t4.04e-03 +- 3.17e-02\n",
      "[dimension 59/145]  inactive:\t6.42e-05 +- 1.05e-02\n",
      "[dimension 60/145]  inactive:\t1.54e-03 +- 2.48e-02\n",
      "[dimension 61/145]  inactive:\t3.15e-03 +- 2.53e-02\n",
      "[dimension 62/145]  inactive:\t7.05e-05 +- 1.38e-02\n",
      "[dimension 63/145]  active:\t6.98e-01 +- 3.71e-01\n",
      "[dimension 64/145]  inactive:\t-9.10e-04 +- 1.33e-02\n",
      "[dimension 65/145]  inactive:\t2.93e-04 +- 1.66e-02\n",
      "[dimension 66/145]  inactive:\t8.37e-04 +- 1.67e-02\n",
      "[dimension 67/145]  inactive:\t1.19e-03 +- 2.22e-02\n",
      "[dimension 68/145]  inactive:\t4.31e-04 +- 1.70e-02\n",
      "[dimension 69/145]  inactive:\t2.32e-03 +- 2.91e-02\n",
      "[dimension 70/145]  inactive:\t2.79e-03 +- 1.95e-02\n",
      "[dimension 71/145]  inactive:\t7.27e-04 +- 1.88e-02\n",
      "[dimension 72/145]  inactive:\t1.18e-03 +- 1.82e-02\n",
      "[dimension 73/145]  inactive:\t4.33e-04 +- 1.10e-02\n",
      "[dimension 74/145]  inactive:\t1.44e-04 +- 1.77e-02\n",
      "[dimension 75/145]  inactive:\t5.31e-04 +- 1.39e-02\n",
      "[dimension 76/145]  inactive:\t4.95e-03 +- 3.96e-02\n",
      "[dimension 77/145]  inactive:\t3.95e-04 +- 1.94e-02\n",
      "[dimension 78/145]  inactive:\t7.31e-03 +- 6.06e-02\n",
      "[dimension 79/145]  inactive:\t4.01e-03 +- 2.49e-02\n",
      "[dimension 80/145]  inactive:\t1.21e-03 +- 2.38e-02\n",
      "[dimension 81/145]  inactive:\t2.45e-03 +- 2.90e-02\n",
      "[dimension 82/145]  inactive:\t3.08e-04 +- 1.09e-02\n",
      "[dimension 83/145]  inactive:\t-4.94e-04 +- 1.11e-02\n",
      "[dimension 84/145]  inactive:\t2.08e-04 +- 1.70e-02\n",
      "[dimension 85/145]  inactive:\t1.96e-03 +- 2.20e-02\n",
      "[dimension 86/145]  inactive:\t-1.58e-04 +- 1.13e-02\n",
      "[dimension 87/145]  inactive:\t1.71e-03 +- 2.48e-02\n",
      "[dimension 88/145]  inactive:\t1.97e-03 +- 1.76e-02\n",
      "[dimension 89/145]  inactive:\t4.70e-05 +- 1.22e-02\n",
      "[dimension 90/145]  inactive:\t5.29e-02 +- 1.96e-01\n",
      "[dimension 91/145]  inactive:\t1.68e-04 +- 1.34e-02\n",
      "[dimension 92/145]  inactive:\t-1.37e-04 +- 1.40e-02\n",
      "[dimension 93/145]  inactive:\t1.21e-04 +- 1.69e-02\n",
      "[dimension 94/145]  inactive:\t1.46e-03 +- 2.13e-02\n",
      "[dimension 95/145]  inactive:\t2.91e-04 +- 1.35e-02\n",
      "[dimension 96/145]  inactive:\t1.16e-03 +- 2.59e-02\n",
      "[dimension 97/145]  inactive:\t1.53e-03 +- 1.55e-02\n",
      "[dimension 98/145]  inactive:\t2.16e-04 +- 2.11e-02\n",
      "[dimension 99/145]  inactive:\t7.72e-03 +- 6.59e-02\n",
      "[dimension 100/145]  inactive:\t-4.78e-05 +- 1.07e-02\n",
      "[dimension 101/145]  inactive:\t-7.63e-04 +- 1.21e-02\n",
      "[dimension 102/145]  inactive:\t5.57e-04 +- 1.61e-02\n",
      "[dimension 103/145]  inactive:\t9.82e-04 +- 1.90e-02\n",
      "[dimension 104/145]  inactive:\t-2.09e-04 +- 1.17e-02\n",
      "[dimension 105/145]  inactive:\t1.52e-04 +- 1.60e-02\n",
      "[dimension 106/145]  inactive:\t4.51e-03 +- 2.89e-02\n",
      "[dimension 107/145]  inactive:\t-2.14e-04 +- 1.31e-02\n",
      "[dimension 108/145]  inactive:\t5.76e-03 +- 5.55e-02\n",
      "[dimension 109/145]  inactive:\t6.63e-05 +- 1.09e-02\n",
      "[dimension 110/145]  inactive:\t1.15e-03 +- 2.40e-02\n",
      "[dimension 111/145]  inactive:\t3.60e-03 +- 3.60e-02\n",
      "[dimension 112/145]  inactive:\t4.30e-03 +- 3.62e-02\n",
      "[dimension 113/145]  inactive:\t-1.50e-04 +- 1.44e-02\n",
      "[dimension 114/145]  inactive:\t1.34e-03 +- 2.27e-02\n",
      "[dimension 115/145]  inactive:\t2.42e-03 +- 2.10e-02\n",
      "[dimension 116/145]  inactive:\t3.45e-03 +- 4.86e-02\n",
      "[dimension 117/145]  inactive:\t5.57e-03 +- 4.67e-02\n",
      "[dimension 118/145]  inactive:\t2.20e-03 +- 1.90e-02\n",
      "[dimension 119/145]  inactive:\t-5.77e-05 +- 1.50e-02\n",
      "[dimension 120/145]  inactive:\t8.21e-04 +- 1.87e-02\n",
      "[dimension 121/145]  inactive:\t4.74e-03 +- 3.58e-02\n",
      "[dimension 122/145]  inactive:\t-2.07e-04 +- 1.42e-02\n",
      "[dimension 123/145]  inactive:\t2.54e-03 +- 3.17e-02\n",
      "[dimension 124/145]  inactive:\t-3.15e-04 +- 1.22e-02\n",
      "[dimension 125/145]  inactive:\t2.05e-05 +- 1.46e-02\n",
      "[dimension 126/145]  inactive:\t4.10e-04 +- 1.46e-02\n",
      "[dimension 127/145]  inactive:\t3.26e-04 +- 1.05e-02\n",
      "[dimension 128/145]  inactive:\t1.53e-03 +- 2.97e-02\n",
      "[dimension 129/145]  inactive:\t1.68e-03 +- 2.79e-02\n",
      "[dimension 130/145]  inactive:\t2.05e-03 +- 2.09e-02\n",
      "[dimension 131/145]  inactive:\t4.60e-04 +- 2.21e-02\n",
      "[dimension 132/145]  inactive:\t1.80e-03 +- 2.33e-02\n",
      "[dimension 133/145]  inactive:\t1.49e-03 +- 1.39e-02\n",
      "[dimension 134/145]  inactive:\t5.43e-04 +- 2.01e-02\n",
      "[dimension 135/145]  inactive:\t1.46e-03 +- 2.26e-02\n",
      "[dimension 136/145]  inactive:\t9.81e-04 +- 1.36e-02\n",
      "[dimension 137/145]  inactive:\t2.15e-03 +- 3.11e-02\n",
      "[dimension 138/145]  inactive:\t7.51e-04 +- 1.69e-02\n",
      "[dimension 139/145]  inactive:\t7.29e-04 +- 1.52e-02\n",
      "[dimension 140/145]  inactive:\t3.21e-04 +- 1.52e-02\n",
      "[dimension 141/145]  inactive:\t1.99e-03 +- 3.07e-02\n",
      "[dimension 142/145]  inactive:\t1.42e-03 +- 1.50e-02\n",
      "[dimension 143/145]  inactive:\t2.38e-03 +- 2.73e-02\n",
      "[dimension 144/145]  inactive:\t4.57e-04 +- 1.21e-02\n",
      "[dimension 145/145]  inactive:\t8.58e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.96140707]\n",
      "cov_act[[0.01265256]]\n",
      "Active_dimensions: [62]\n",
      "18, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:25<00:00, 60.00it/s, 15 steps of size 2.37e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    439.41      1.00\n",
      "  lambda[0]      2.57      8.53      0.96      0.00      5.11   1047.85      1.00\n",
      "  lambda[1]      4.64     37.59      0.96      0.01      5.96    324.19      1.00\n",
      "  lambda[2]      2.61      5.80      1.02      0.00      5.91    827.15      1.00\n",
      "  lambda[3]      4.68     24.79      1.05      0.00      7.82    880.47      1.00\n",
      "  lambda[4]      2.80      7.47      1.01      0.00      5.70    800.77      1.00\n",
      "  lambda[5]      3.76     21.00      0.97      0.00      5.50    544.68      1.00\n",
      "  lambda[6]      2.91      8.50      0.97      0.00      5.50    835.68      1.00\n",
      "  lambda[7]      2.66      6.41      0.90      0.00      5.83    792.79      1.00\n",
      "  lambda[8]      2.64      5.96      0.98      0.01      5.81    707.01      1.00\n",
      "  lambda[9]      2.92      8.14      1.02      0.00      5.50    777.04      1.00\n",
      " lambda[10]      3.14     11.02      1.02      0.00      5.99    781.69      1.00\n",
      " lambda[11]      3.23     11.91      0.97      0.01      5.83    643.89      1.00\n",
      " lambda[12]      4.50     27.57      0.95      0.00      6.59    491.87      1.00\n",
      " lambda[13]      2.72      8.19      0.95      0.00      5.08    620.53      1.00\n",
      " lambda[14]      3.41     11.40      1.02      0.00      6.42    681.55      1.00\n",
      " lambda[15]      2.73      6.97      1.02      0.00      5.80    919.06      1.00\n",
      " lambda[16]      2.61      7.12      0.94      0.00      5.29    998.78      1.00\n",
      " lambda[17]      2.86      7.13      1.03      0.00      5.80    852.48      1.00\n",
      " lambda[18]      2.97      8.77      0.95      0.00      5.89    669.16      1.00\n",
      " lambda[19]      2.67      7.01      1.06      0.00      5.48    991.63      1.00\n",
      " lambda[20]      3.24      9.08      1.08      0.00      6.72    700.51      1.00\n",
      " lambda[21]      2.54      5.02      0.99      0.00      5.73    577.99      1.00\n",
      " lambda[22]      2.44      6.64      0.99      0.00      5.00    985.98      1.00\n",
      " lambda[23]      3.24     16.22      0.99      0.00      5.38    971.46      1.00\n",
      " lambda[24]      3.41     14.07      1.03      0.00      6.70    919.17      1.00\n",
      " lambda[25]      2.69      8.92      0.98      0.00      5.21    629.68      1.00\n",
      " lambda[26]      2.64      6.35      0.97      0.00      5.82    912.88      1.00\n",
      " lambda[27]      2.55      5.84      0.92      0.00      5.64    884.84      1.00\n",
      " lambda[28]      2.46      5.21      0.99      0.01      6.20    693.22      1.00\n",
      " lambda[29]      3.00     13.89      0.95      0.01      5.68    969.07      1.00\n",
      " lambda[30]      3.20      9.72      0.99      0.00      6.04    547.89      1.00\n",
      " lambda[31]      3.10      9.67      0.96      0.00      5.73    737.97      1.00\n",
      " lambda[32]      3.44     10.45      1.00      0.00      6.91    587.17      1.00\n",
      " lambda[33]      2.43      5.13      0.94      0.00      5.56    799.68      1.00\n",
      " lambda[34]      2.72      7.42      1.02      0.00      5.66    686.47      1.00\n",
      " lambda[35]      2.69      7.29      1.01      0.00      5.53    887.68      1.00\n",
      " lambda[36]      2.96      7.06      0.99      0.00      6.35    626.64      1.00\n",
      " lambda[37]      3.21     12.18      1.01      0.00      5.73    865.03      1.00\n",
      " lambda[38]      5.40     72.46      0.98      0.00      6.24    930.20      1.00\n",
      " lambda[39]      3.70     15.92      0.99      0.00      6.86    878.74      1.00\n",
      " lambda[40]      2.62      6.16      0.95      0.00      6.55    962.34      1.00\n",
      " lambda[41]     10.24     58.43      1.03      0.00      8.84    324.67      1.00\n",
      " lambda[42]      2.28      5.44      0.94      0.00      4.45   1062.02      1.00\n",
      " lambda[43]      6.03     80.23      0.96      0.00      6.03    658.86      1.00\n",
      " lambda[44]      2.75      6.83      0.98      0.01      5.83    752.94      1.00\n",
      " lambda[45]      2.59      8.91      0.99      0.01      5.00    893.45      1.00\n",
      " lambda[46]      2.74      8.66      0.95      0.00      4.88    905.72      1.00\n",
      " lambda[47]      2.72      6.52      1.03      0.00      5.85    395.55      1.00\n",
      " lambda[48]      3.45     10.04      1.03      0.00      6.91    620.67      1.00\n",
      " lambda[49]      3.49      9.82      1.08      0.00      6.82    683.87      1.00\n",
      " lambda[50]      4.00     19.71      0.96      0.00      5.89    697.92      1.00\n",
      " lambda[51]      3.60     10.54      1.03      0.00      5.99    933.11      1.00\n",
      " lambda[52]      2.60      8.30      0.96      0.00      4.87    937.52      1.00\n",
      " lambda[53]      2.69      6.00      0.99      0.00      5.57    732.57      1.00\n",
      " lambda[54]      2.41      5.99      0.93      0.00      4.84    649.46      1.00\n",
      " lambda[55]      3.23     17.41      0.87      0.00      5.40    941.38      1.00\n",
      " lambda[56]      2.35      6.72      0.97      0.00      4.42    988.88      1.00\n",
      " lambda[57]      9.93     58.90      1.05      0.00     11.60    494.09      1.00\n",
      " lambda[58]      2.49      5.88      0.98      0.00      4.73    657.31      1.00\n",
      " lambda[59]      2.91      7.65      1.02      0.00      5.80    775.87      1.00\n",
      " lambda[60]      2.75      6.32      1.04      0.00      5.91    454.73      1.01\n",
      " lambda[61]      2.47      5.06      0.99      0.00      5.43    910.69      1.00\n",
      " lambda[62]   1029.50   7325.28    187.64      0.02   1324.69    716.41      1.00\n",
      " lambda[63]      2.63      7.36      0.93      0.00      5.23    544.27      1.00\n",
      " lambda[64]      2.70      8.89      0.96      0.00      5.31    949.46      1.00\n",
      " lambda[65]      2.74      9.35      0.94      0.00      4.85    769.30      1.00\n",
      " lambda[66]      3.24     10.44      0.96      0.00      6.02    788.04      1.00\n",
      " lambda[67]      2.93      8.36      1.05      0.00      6.08    916.30      1.00\n",
      " lambda[68]      3.33     10.83      0.99      0.00      6.24    987.62      1.00\n",
      " lambda[69]      3.40     10.06      1.01      0.00      6.52    643.11      1.00\n",
      " lambda[70]      2.96     13.36      0.94      0.00      5.09    783.54      1.00\n",
      " lambda[71]      3.22     11.52      1.07      0.00      5.97    483.59      1.00\n",
      " lambda[72]      2.38      7.19      0.99      0.00      4.67    810.50      1.00\n",
      " lambda[73]      3.08      9.78      0.98      0.00      5.42    655.33      1.01\n",
      " lambda[74]      2.60      5.93      0.96      0.00      5.87    714.22      1.00\n",
      " lambda[75]      4.67     22.32      1.08      0.00      7.01    707.14      1.00\n",
      " lambda[76]      2.69      6.08      0.96      0.00      5.94    721.51      1.00\n",
      " lambda[77]      4.18     21.28      1.01      0.00      6.01    538.92      1.00\n",
      " lambda[78]      2.79      7.05      1.02      0.00      5.34    704.78      1.00\n",
      " lambda[79]      2.66      9.86      0.92      0.01      4.95    777.99      1.00\n",
      " lambda[80]      3.66     11.95      0.95      0.00      7.18    615.60      1.00\n",
      " lambda[81]      2.76      6.75      0.98      0.00      5.86    626.28      1.00\n",
      " lambda[82]      2.45      5.13      0.96      0.00      5.53    652.15      1.00\n",
      " lambda[83]      3.38     10.43      0.99      0.00      6.59    750.63      1.00\n",
      " lambda[84]      3.57     23.34      0.98      0.00      4.99    877.71      1.00\n",
      " lambda[85]      3.23     19.84      0.91      0.00      5.90    537.13      1.00\n",
      " lambda[86]      3.98     20.34      1.01      0.00      5.67    981.15      1.00\n",
      " lambda[87]      3.14     18.61      0.96      0.00      4.94    919.14      1.00\n",
      " lambda[88]      2.76      6.07      1.02      0.00      6.38    603.74      1.00\n",
      " lambda[89]    127.17   1992.18      1.14      0.00     31.18    435.36      1.00\n",
      " lambda[90]      2.40      5.85      0.94      0.00      4.64    626.85      1.00\n",
      " lambda[91]      2.91     12.01      1.02      0.00      5.23    507.85      1.00\n",
      " lambda[92]      2.74      5.76      0.98      0.00      6.30    738.96      1.00\n",
      " lambda[93]      2.73      9.18      1.00      0.00      5.22    682.18      1.00\n",
      " lambda[94]      3.27      8.45      0.99      0.00      6.41    701.81      1.00\n",
      " lambda[95]      3.67     14.64      1.00      0.00      6.73    593.32      1.00\n",
      " lambda[96]      3.32      9.93      0.95      0.00      6.33    484.27      1.00\n",
      " lambda[97]      2.69      6.49      1.04      0.01      5.58    710.99      1.00\n",
      " lambda[98]      3.70     18.30      1.00      0.00      6.14    799.24      1.00\n",
      " lambda[99]      2.48      7.33      0.91      0.00      4.70   1009.15      1.00\n",
      "lambda[100]      3.05      8.48      1.00      0.00      6.56    723.68      1.00\n",
      "lambda[101]      3.27     12.30      1.00      0.00      5.40    570.45      1.00\n",
      "lambda[102]      2.87      8.94      0.88      0.00      5.62   1084.67      1.00\n",
      "lambda[103]      4.25     32.65      0.90      0.00      5.91    350.55      1.00\n",
      "lambda[104]      3.11     14.10      0.95      0.00      4.49    447.73      1.00\n",
      "lambda[105]      3.99     13.57      0.97      0.00      7.57    718.20      1.00\n",
      "lambda[106]      3.21     13.01      0.97      0.00      5.51    668.91      1.00\n",
      "lambda[107]      3.99     14.82      1.00      0.01      5.47    357.07      1.00\n",
      "lambda[108]      2.28      5.30      0.94      0.01      5.11    754.40      1.00\n",
      "lambda[109]      3.76     13.91      0.99      0.00      6.22    848.59      1.00\n",
      "lambda[110]      3.53     14.17      1.03      0.00      5.56    808.70      1.00\n",
      "lambda[111]     18.87    305.53      1.06      0.00      8.18    454.97      1.00\n",
      "lambda[112]      2.18      4.35      0.97      0.01      4.93    782.25      1.00\n",
      "lambda[113]      4.20     22.95      1.03      0.00      6.50    709.87      1.00\n",
      "lambda[114]      2.56      5.80      0.94      0.00      5.43    659.29      1.00\n",
      "lambda[115]      3.30     17.44      1.01      0.00      5.26    962.06      1.00\n",
      "lambda[116]      3.02     16.54      1.01      0.01      5.61    901.61      1.00\n",
      "lambda[117]      3.49     13.42      0.93      0.00      6.25    547.48      1.00\n",
      "lambda[118]      3.29     16.42      0.97      0.00      5.70    773.03      1.00\n",
      "lambda[119]      4.40     17.04      0.96      0.00      7.13    794.56      1.00\n",
      "lambda[120]      4.04     16.23      0.96      0.00      7.73    952.01      1.00\n",
      "lambda[121]      3.07     10.22      1.00      0.00      5.98    797.76      1.00\n",
      "lambda[122]      4.15     27.46      0.99      0.00      5.47    484.22      1.00\n",
      "lambda[123]      2.88      7.58      0.92      0.00      6.36    755.48      1.00\n",
      "lambda[124]      2.94      8.13      1.00      0.01      6.34    907.44      1.00\n",
      "lambda[125]      2.87      8.72      0.94      0.01      5.70    469.53      1.00\n",
      "lambda[126]      2.37      6.93      0.95      0.00      4.90    967.36      1.00\n",
      "lambda[127]      3.86     22.18      0.96      0.00      5.64    905.52      1.00\n",
      "lambda[128]      4.46     30.22      1.00      0.00      6.21    423.60      1.00\n",
      "lambda[129]      4.47     42.80      0.87      0.00      6.02    906.90      1.00\n",
      "lambda[130]      3.02     10.64      0.95      0.00      6.14    910.11      1.01\n",
      "lambda[131]      5.06     36.10      1.00      0.00      5.51    530.50      1.00\n",
      "lambda[132]      2.86      7.42      1.01      0.00      5.77    668.07      1.00\n",
      "lambda[133]      2.65      6.84      0.98      0.00      4.90    899.40      1.00\n",
      "lambda[134]      3.07      8.01      1.01      0.00      6.59    854.40      1.00\n",
      "lambda[135]      2.29      6.45      0.92      0.00      4.49   1007.83      1.00\n",
      "lambda[136]      2.55      6.45      0.95      0.00      5.54    771.07      1.00\n",
      "lambda[137]      2.82      9.06      1.01      0.00      5.14    778.78      1.00\n",
      "lambda[138]      3.19     11.32      0.97      0.00      6.08    690.82      1.00\n",
      "lambda[139]      2.60      6.02      0.94      0.00      5.03    672.01      1.00\n",
      "lambda[140]      3.00     10.02      0.98      0.00      5.99    931.87      1.00\n",
      "lambda[141]      2.77      6.84      0.94      0.00      6.41    666.62      1.00\n",
      "lambda[142]      3.51     11.34      0.97      0.00      6.15    911.85      1.00\n",
      "lambda[143]      2.50      7.15      0.96      0.00      5.73    769.38      1.00\n",
      "        msq   1699.26  39896.45      3.91      0.16     88.37    857.46      1.00\n",
      "      sigma      4.68      5.82      2.32      0.01     12.78   1162.07      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    572.56      1.00\n",
      "       xisq      0.13      0.07      0.11      0.04      0.21    786.73      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 28.85129404067993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.27e-05 +- 2.09e-02\n",
      "[dimension 02/145]  inactive:\t-1.04e-03 +- 3.06e-02\n",
      "[dimension 03/145]  inactive:\t2.64e-05 +- 2.30e-02\n",
      "[dimension 04/145]  inactive:\t6.82e-03 +- 4.23e-02\n",
      "[dimension 05/145]  inactive:\t-9.17e-04 +- 2.70e-02\n",
      "[dimension 06/145]  inactive:\t2.83e-03 +- 3.85e-02\n",
      "[dimension 07/145]  inactive:\t6.60e-04 +- 2.01e-02\n",
      "[dimension 08/145]  inactive:\t4.82e-04 +- 2.57e-02\n",
      "[dimension 09/145]  inactive:\t2.00e-04 +- 2.18e-02\n",
      "[dimension 10/145]  inactive:\t3.81e-04 +- 2.22e-02\n",
      "[dimension 11/145]  inactive:\t-1.02e-03 +- 2.94e-02\n",
      "[dimension 12/145]  inactive:\t1.20e-04 +- 3.19e-02\n",
      "[dimension 13/145]  inactive:\t5.18e-03 +- 4.03e-02\n",
      "[dimension 14/145]  inactive:\t-1.86e-03 +- 2.44e-02\n",
      "[dimension 15/145]  inactive:\t1.67e-03 +- 3.77e-02\n",
      "[dimension 16/145]  inactive:\t9.39e-04 +- 2.13e-02\n",
      "[dimension 17/145]  inactive:\t-1.42e-04 +- 2.89e-02\n",
      "[dimension 18/145]  inactive:\t-4.05e-04 +- 3.05e-02\n",
      "[dimension 19/145]  inactive:\t-2.16e-03 +- 2.02e-02\n",
      "[dimension 20/145]  inactive:\t-1.29e-03 +- 2.83e-02\n",
      "[dimension 21/145]  inactive:\t-1.23e-03 +- 2.38e-02\n",
      "[dimension 22/145]  inactive:\t-3.33e-05 +- 2.32e-02\n",
      "[dimension 23/145]  inactive:\t-6.00e-04 +- 2.46e-02\n",
      "[dimension 24/145]  inactive:\t1.78e-03 +- 2.84e-02\n",
      "[dimension 25/145]  inactive:\t3.69e-03 +- 2.45e-02\n",
      "[dimension 26/145]  inactive:\t-2.26e-04 +- 3.18e-02\n",
      "[dimension 27/145]  inactive:\t8.38e-04 +- 2.47e-02\n",
      "[dimension 28/145]  inactive:\t5.91e-04 +- 1.99e-02\n",
      "[dimension 29/145]  inactive:\t1.80e-04 +- 2.72e-02\n",
      "[dimension 30/145]  inactive:\t1.09e-03 +- 3.06e-02\n",
      "[dimension 31/145]  inactive:\t5.66e-03 +- 3.99e-02\n",
      "[dimension 32/145]  inactive:\t-1.69e-03 +- 2.76e-02\n",
      "[dimension 33/145]  inactive:\t4.61e-03 +- 4.67e-02\n",
      "[dimension 34/145]  inactive:\t8.97e-04 +- 1.95e-02\n",
      "[dimension 35/145]  inactive:\t1.73e-04 +- 2.37e-02\n",
      "[dimension 36/145]  inactive:\t4.99e-04 +- 2.32e-02\n",
      "[dimension 37/145]  inactive:\t4.40e-03 +- 2.66e-02\n",
      "[dimension 38/145]  inactive:\t-2.09e-03 +- 3.17e-02\n",
      "[dimension 39/145]  inactive:\t2.27e-03 +- 4.01e-02\n",
      "[dimension 40/145]  inactive:\t4.96e-03 +- 3.80e-02\n",
      "[dimension 41/145]  inactive:\t-1.65e-03 +- 2.87e-02\n",
      "[dimension 42/145]  inactive:\t1.90e-02 +- 1.14e-01\n",
      "[dimension 43/145]  inactive:\t-5.09e-04 +- 2.01e-02\n",
      "[dimension 44/145]  inactive:\t-9.57e-04 +- 3.27e-02\n",
      "[dimension 45/145]  inactive:\t-6.27e-04 +- 2.72e-02\n",
      "[dimension 46/145]  inactive:\t1.07e-03 +- 1.65e-02\n",
      "[dimension 47/145]  inactive:\t-1.82e-03 +- 3.31e-02\n",
      "[dimension 48/145]  inactive:\t1.31e-03 +- 2.50e-02\n",
      "[dimension 49/145]  inactive:\t4.04e-03 +- 2.83e-02\n",
      "[dimension 50/145]  inactive:\t-1.98e-03 +- 2.70e-02\n",
      "[dimension 51/145]  inactive:\t5.08e-03 +- 4.25e-02\n",
      "[dimension 52/145]  inactive:\t6.24e-03 +- 2.55e-02\n",
      "[dimension 53/145]  inactive:\t-1.01e-03 +- 2.46e-02\n",
      "[dimension 54/145]  inactive:\t5.91e-04 +- 2.13e-02\n",
      "[dimension 55/145]  inactive:\t4.60e-04 +- 1.79e-02\n",
      "[dimension 56/145]  inactive:\t-1.74e-03 +- 2.03e-02\n",
      "[dimension 57/145]  inactive:\t7.48e-04 +- 2.83e-02\n",
      "[dimension 58/145]  inactive:\t2.46e-02 +- 1.01e-01\n",
      "[dimension 59/145]  inactive:\t-6.90e-04 +- 2.04e-02\n",
      "[dimension 60/145]  inactive:\t2.79e-04 +- 2.59e-02\n",
      "[dimension 61/145]  inactive:\t2.44e-03 +- 2.25e-02\n",
      "[dimension 62/145]  inactive:\t-6.51e-04 +- 2.21e-02\n",
      "[dimension 63/145]  active:\t7.25e-01 +- 4.14e-01\n",
      "[dimension 64/145]  inactive:\t-3.45e-03 +- 2.86e-02\n",
      "[dimension 65/145]  inactive:\t-8.64e-04 +- 2.42e-02\n",
      "[dimension 66/145]  inactive:\t2.02e-04 +- 2.45e-02\n",
      "[dimension 67/145]  inactive:\t1.75e-03 +- 2.59e-02\n",
      "[dimension 68/145]  inactive:\t-1.58e-03 +- 3.28e-02\n",
      "[dimension 69/145]  inactive:\t4.14e-03 +- 4.49e-02\n",
      "[dimension 70/145]  inactive:\t3.86e-03 +- 2.44e-02\n",
      "[dimension 71/145]  inactive:\t-4.14e-04 +- 2.75e-02\n",
      "[dimension 72/145]  inactive:\t9.58e-04 +- 2.68e-02\n",
      "[dimension 73/145]  inactive:\t8.70e-05 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-2.63e-03 +- 3.09e-02\n",
      "[dimension 75/145]  inactive:\t6.61e-04 +- 2.65e-02\n",
      "[dimension 76/145]  inactive:\t6.67e-03 +- 4.35e-02\n",
      "[dimension 77/145]  inactive:\t-1.94e-03 +- 3.40e-02\n",
      "[dimension 78/145]  inactive:\t6.96e-03 +- 6.19e-02\n",
      "[dimension 79/145]  inactive:\t5.46e-03 +- 3.08e-02\n",
      "[dimension 80/145]  inactive:\t-5.74e-04 +- 3.30e-02\n",
      "[dimension 81/145]  inactive:\t1.40e-03 +- 3.92e-02\n",
      "[dimension 82/145]  inactive:\t4.50e-04 +- 1.93e-02\n",
      "[dimension 83/145]  inactive:\t-1.70e-03 +- 1.96e-02\n",
      "[dimension 84/145]  inactive:\t-2.06e-03 +- 2.94e-02\n",
      "[dimension 85/145]  inactive:\t3.68e-03 +- 3.45e-02\n",
      "[dimension 86/145]  inactive:\t-8.15e-04 +- 2.17e-02\n",
      "[dimension 87/145]  inactive:\t3.85e-03 +- 4.93e-02\n",
      "[dimension 88/145]  inactive:\t2.56e-03 +- 2.27e-02\n",
      "[dimension 89/145]  inactive:\t-1.07e-03 +- 2.22e-02\n",
      "[dimension 90/145]  inactive:\t7.57e-02 +- 2.46e-01\n",
      "[dimension 91/145]  inactive:\t-1.03e-05 +- 2.02e-02\n",
      "[dimension 92/145]  inactive:\t-1.38e-03 +- 2.36e-02\n",
      "[dimension 93/145]  inactive:\t-4.23e-04 +- 2.72e-02\n",
      "[dimension 94/145]  inactive:\t1.64e-03 +- 2.61e-02\n",
      "[dimension 95/145]  inactive:\t-5.46e-04 +- 3.15e-02\n",
      "[dimension 96/145]  inactive:\t1.49e-03 +- 4.20e-02\n",
      "[dimension 97/145]  inactive:\t3.42e-03 +- 2.84e-02\n",
      "[dimension 98/145]  inactive:\t-3.40e-04 +- 2.50e-02\n",
      "[dimension 99/145]  inactive:\t2.29e-03 +- 3.34e-02\n",
      "[dimension 100/145]  inactive:\t-7.04e-04 +- 1.84e-02\n",
      "[dimension 101/145]  inactive:\t-2.35e-03 +- 2.06e-02\n",
      "[dimension 102/145]  inactive:\t-1.53e-03 +- 2.92e-02\n",
      "[dimension 103/145]  inactive:\t8.88e-04 +- 2.81e-02\n",
      "[dimension 104/145]  inactive:\t-1.25e-03 +- 1.97e-02\n",
      "[dimension 105/145]  inactive:\t-3.67e-04 +- 2.44e-02\n",
      "[dimension 106/145]  inactive:\t5.20e-03 +- 3.32e-02\n",
      "[dimension 107/145]  inactive:\t-1.68e-03 +- 2.21e-02\n",
      "[dimension 108/145]  inactive:\t6.28e-03 +- 6.05e-02\n",
      "[dimension 109/145]  inactive:\t-3.76e-04 +- 1.66e-02\n",
      "[dimension 110/145]  inactive:\t-1.57e-03 +- 2.99e-02\n",
      "[dimension 111/145]  inactive:\t1.91e-03 +- 3.59e-02\n",
      "[dimension 112/145]  inactive:\t1.11e-02 +- 7.56e-02\n",
      "[dimension 113/145]  inactive:\t-1.45e-03 +- 2.15e-02\n",
      "[dimension 114/145]  inactive:\t2.58e-03 +- 4.95e-02\n",
      "[dimension 115/145]  inactive:\t2.01e-03 +- 2.06e-02\n",
      "[dimension 116/145]  inactive:\t1.90e-04 +- 3.07e-02\n",
      "[dimension 117/145]  inactive:\t2.77e-03 +- 4.07e-02\n",
      "[dimension 118/145]  inactive:\t3.57e-03 +- 2.76e-02\n",
      "[dimension 119/145]  inactive:\t-2.48e-03 +- 3.18e-02\n",
      "[dimension 120/145]  inactive:\t1.03e-03 +- 4.71e-02\n",
      "[dimension 121/145]  inactive:\t5.30e-03 +- 4.04e-02\n",
      "[dimension 122/145]  inactive:\t-2.56e-03 +- 3.31e-02\n",
      "[dimension 123/145]  inactive:\t1.72e-03 +- 4.99e-02\n",
      "[dimension 124/145]  inactive:\t-2.00e-03 +- 2.12e-02\n",
      "[dimension 125/145]  inactive:\t-1.99e-03 +- 2.85e-02\n",
      "[dimension 126/145]  inactive:\t-1.53e-03 +- 2.81e-02\n",
      "[dimension 127/145]  inactive:\t9.60e-05 +- 1.61e-02\n",
      "[dimension 128/145]  inactive:\t-1.55e-03 +- 3.18e-02\n",
      "[dimension 129/145]  inactive:\t1.64e-04 +- 2.80e-02\n",
      "[dimension 130/145]  inactive:\t3.84e-03 +- 3.05e-02\n",
      "[dimension 131/145]  inactive:\t-1.08e-03 +- 2.74e-02\n",
      "[dimension 132/145]  inactive:\t5.99e-03 +- 5.52e-02\n",
      "[dimension 133/145]  inactive:\t3.04e-03 +- 2.33e-02\n",
      "[dimension 134/145]  inactive:\t-7.44e-04 +- 2.43e-02\n",
      "[dimension 135/145]  inactive:\t3.24e-04 +- 2.68e-02\n",
      "[dimension 136/145]  inactive:\t7.27e-04 +- 1.84e-02\n",
      "[dimension 137/145]  inactive:\t-4.80e-04 +- 2.92e-02\n",
      "[dimension 138/145]  inactive:\t7.43e-05 +- 2.47e-02\n",
      "[dimension 139/145]  inactive:\t2.64e-04 +- 2.56e-02\n",
      "[dimension 140/145]  inactive:\t-1.24e-03 +- 3.08e-02\n",
      "[dimension 141/145]  inactive:\t1.45e-03 +- 3.03e-02\n",
      "[dimension 142/145]  inactive:\t1.48e-03 +- 1.98e-02\n",
      "[dimension 143/145]  inactive:\t1.22e-03 +- 3.71e-02\n",
      "[dimension 144/145]  inactive:\t1.66e-04 +- 2.01e-02\n",
      "[dimension 145/145]  inactive:\t-2.71e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.5422702e-05]\n",
      "cov_act[[2.1271408e-06]]\n",
      "Active_dimensions: [62]\n",
      "19, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.80it/s, 31 steps of size 1.69e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    444.40      1.00\n",
      "  lambda[0]      2.18      6.47      0.94      0.00      4.78   1049.80      1.00\n",
      "  lambda[1]      2.87      8.55      1.01      0.00      5.32    582.21      1.01\n",
      "  lambda[2]      3.07     12.53      0.96      0.00      5.73    622.87      1.00\n",
      "  lambda[3]      4.53     17.43      0.97      0.00      6.70    530.29      1.01\n",
      "  lambda[4]      2.45      6.39      0.99      0.01      5.13    974.51      1.00\n",
      "  lambda[5]      5.08     57.40      0.95      0.00      5.88    593.14      1.00\n",
      "  lambda[6]      4.48     21.03      1.00      0.00      6.64    804.90      1.00\n",
      "  lambda[7]      3.52      9.99      1.01      0.00      7.03    592.57      1.01\n",
      "  lambda[8]      2.41      5.62      0.97      0.00      5.02    717.80      1.00\n",
      "  lambda[9]      2.21      4.85      1.02      0.00      4.40    930.78      1.00\n",
      " lambda[10]      4.06     18.10      1.08      0.00      5.44    584.41      1.00\n",
      " lambda[11]      3.22     15.24      0.97      0.00      6.16    788.42      1.00\n",
      " lambda[12]      6.22     50.06      1.12      0.00      7.95    959.78      1.00\n",
      " lambda[13]      2.49      6.80      0.91      0.00      4.56    598.79      1.00\n",
      " lambda[14]      5.47     57.52      0.96      0.00      5.19    738.42      1.00\n",
      " lambda[15]      3.80     17.43      0.98      0.00      5.94    591.24      1.00\n",
      " lambda[16]      4.71     21.35      0.93      0.00      8.05    766.60      1.00\n",
      " lambda[17]      5.08     63.96      1.00      0.00      5.49    979.74      1.00\n",
      " lambda[18]      3.05     21.26      0.96      0.00      5.69   1025.14      1.00\n",
      " lambda[19]      4.19     27.63      0.99      0.01      5.66    594.65      1.00\n",
      " lambda[20]      2.38      5.20      0.92      0.01      4.95    847.04      1.00\n",
      " lambda[21]      3.02     21.20      0.97      0.01      5.42    972.80      1.00\n",
      " lambda[22]      2.77     11.93      0.98      0.00      4.90    396.59      1.00\n",
      " lambda[23]      3.08     10.03      0.97      0.00      5.79    822.55      1.00\n",
      " lambda[24]      4.37     29.86      1.04      0.00      5.89    831.88      1.00\n",
      " lambda[25]      2.75      9.01      0.91      0.01      5.12    410.03      1.00\n",
      " lambda[26]      3.17     12.65      0.99      0.00      5.23    306.99      1.00\n",
      " lambda[27]      2.82      7.69      0.97      0.00      5.60    710.37      1.00\n",
      " lambda[28]      2.87     11.84      1.01      0.00      5.27    734.27      1.00\n",
      " lambda[29]      5.73     55.58      0.95      0.00      5.82    500.09      1.00\n",
      " lambda[30]     20.19    420.96      1.03      0.00      7.00    686.81      1.00\n",
      " lambda[31]      3.50     15.83      0.95      0.00      5.53    850.87      1.00\n",
      " lambda[32]      3.81     15.87      1.00      0.00      6.73    973.31      1.00\n",
      " lambda[33]      3.09      9.85      0.97      0.00      5.93    687.27      1.00\n",
      " lambda[34]      3.10     12.26      0.97      0.00      5.50    614.25      1.00\n",
      " lambda[35]      2.79      8.85      1.05      0.00      5.26    828.71      1.00\n",
      " lambda[36]      3.71     16.55      1.01      0.00      6.24    677.26      1.00\n",
      " lambda[37]      2.69      8.65      0.95      0.00      5.37   1034.79      1.00\n",
      " lambda[38]      3.00      7.25      0.92      0.00      6.02    604.78      1.00\n",
      " lambda[39]      3.69     11.00      0.99      0.00      6.09    555.23      1.00\n",
      " lambda[40]      4.64     30.17      0.97      0.00      5.80    692.63      1.00\n",
      " lambda[41]    159.87   2283.96      1.04      0.00     25.29    528.17      1.00\n",
      " lambda[42]      4.03     31.43      0.96      0.00      4.80    676.17      1.00\n",
      " lambda[43]      5.66     70.39      0.98      0.00      5.80   1008.12      1.00\n",
      " lambda[44]      3.28     13.90      0.98      0.00      5.97    523.76      1.01\n",
      " lambda[45]      2.24      5.04      0.96      0.00      4.64    747.11      1.00\n",
      " lambda[46]      2.98     10.73      0.94      0.00      4.89    589.18      1.00\n",
      " lambda[47]      2.39      4.67      0.97      0.01      5.43    712.36      1.00\n",
      " lambda[48]      2.88      8.30      0.96      0.00      5.78    651.17      1.00\n",
      " lambda[49]      3.17     10.39      0.94      0.00      5.95    742.22      1.00\n",
      " lambda[50]      2.77      7.26      1.00      0.00      5.52    926.90      1.00\n",
      " lambda[51]     10.95    180.50      1.08      0.00      8.64    985.53      1.00\n",
      " lambda[52]      2.72      7.46      0.95      0.00      5.41    552.21      1.00\n",
      " lambda[53]      3.04      8.76      0.98      0.00      5.35    650.37      1.00\n",
      " lambda[54]      2.78     17.48      0.98      0.01      4.31    951.52      1.00\n",
      " lambda[55]      3.31     14.19      0.97      0.00      5.55    862.59      1.00\n",
      " lambda[56]      2.64      6.33      0.98      0.00      5.60    831.19      1.00\n",
      " lambda[57]      8.38     60.33      1.00      0.00      8.25    770.80      1.00\n",
      " lambda[58]      2.31      4.72      1.02      0.00      5.39    643.71      1.00\n",
      " lambda[59]      3.69     12.02      1.00      0.00      6.69    550.59      1.00\n",
      " lambda[60]      4.61     22.31      1.03      0.00      6.71    651.52      1.00\n",
      " lambda[61]      3.01      9.13      0.99      0.00      5.95    596.89      1.00\n",
      " lambda[62]   5031.66  73589.08    180.56      0.00   2017.20    575.78      1.00\n",
      " lambda[63]      2.61     14.99      1.00      0.00      4.84    817.13      1.00\n",
      " lambda[64]      3.16     11.54      0.97      0.00      5.31    674.17      1.00\n",
      " lambda[65]      3.75     24.65      0.95      0.00      5.45    956.78      1.00\n",
      " lambda[66]      2.97      7.22      1.05      0.00      6.04    741.64      1.00\n",
      " lambda[67]      2.37      5.07      0.91      0.00      5.04    727.54      1.00\n",
      " lambda[68]     13.16    177.94      0.96      0.00      5.92    469.18      1.00\n",
      " lambda[69]      4.88     34.11      0.97      0.00      6.97    727.65      1.00\n",
      " lambda[70]      2.66      6.46      1.01      0.01      5.07    693.43      1.00\n",
      " lambda[71]      3.25     12.41      0.98      0.00      6.01    633.89      1.00\n",
      " lambda[72]      2.62      8.47      0.98      0.01      4.76    496.79      1.00\n",
      " lambda[73]      3.55     19.19      1.01      0.00      6.00    609.75      1.00\n",
      " lambda[74]      2.35      5.61      1.02      0.01      5.67    904.12      1.00\n",
      " lambda[75]      5.17     28.11      0.98      0.00      7.39    931.46      1.00\n",
      " lambda[76]      3.19      9.41      0.93      0.00      6.48    863.14      1.00\n",
      " lambda[77]     14.59    131.02      1.05      0.00      7.68    524.71      1.00\n",
      " lambda[78]      4.38     20.45      1.05      0.00      6.68    529.18      1.00\n",
      " lambda[79]      3.37     11.26      1.01      0.00      5.92    483.45      1.00\n",
      " lambda[80]      5.18     44.86      1.02      0.00      6.18    993.63      1.00\n",
      " lambda[81]      2.54      8.34      0.94      0.00      5.38    736.51      1.00\n",
      " lambda[82]      2.50     12.19      0.89      0.00      4.25    750.84      1.00\n",
      " lambda[83]      2.58      7.09      0.90      0.00      5.37    951.00      1.00\n",
      " lambda[84]      3.86     17.66      1.04      0.00      6.27    683.05      1.00\n",
      " lambda[85]      2.38      6.37      0.93      0.00      4.96    390.79      1.00\n",
      " lambda[86]      2.97      9.71      1.05      0.01      5.59    922.43      1.00\n",
      " lambda[87]      3.53     13.30      0.97      0.01      6.00    580.27      1.00\n",
      " lambda[88]      2.59      6.56      0.98      0.01      5.59    745.94      1.00\n",
      " lambda[89]     88.67   1002.71      1.07      0.00     24.71    609.09      1.00\n",
      " lambda[90]      2.48      5.28      0.97      0.00      5.25    511.26      1.00\n",
      " lambda[91]      2.78     11.60      0.97      0.01      4.57    804.26      1.00\n",
      " lambda[92]      4.38     30.06      1.03      0.00      5.41    459.66      1.00\n",
      " lambda[93]      2.84      7.96      1.01      0.00      5.47    840.68      1.00\n",
      " lambda[94]      3.40     13.60      0.96      0.00      5.87    426.83      1.00\n",
      " lambda[95]      4.42     22.24      0.96      0.00      6.71    464.88      1.00\n",
      " lambda[96]      3.37     13.41      0.98      0.00      5.72    419.56      1.00\n",
      " lambda[97]      7.11     98.94      0.98      0.00      5.37    501.87      1.00\n",
      " lambda[98]      7.50     77.09      1.00      0.00      6.05    525.74      1.00\n",
      " lambda[99]      2.31      5.62      0.97      0.00      4.48    548.44      1.00\n",
      "lambda[100]      5.30     83.72      0.93      0.00      5.22    952.58      1.00\n",
      "lambda[101]      3.36     13.09      0.92      0.00      5.84    469.97      1.00\n",
      "lambda[102]      3.04      7.95      0.88      0.00      5.62    558.95      1.00\n",
      "lambda[103]      2.46      5.52      0.95      0.00      5.16    606.08      1.00\n",
      "lambda[104]      3.65     17.28      1.00      0.00      6.50    483.91      1.00\n",
      "lambda[105]      4.72     18.57      1.09      0.00      8.25    766.48      1.00\n",
      "lambda[106]      2.51      5.84      0.98      0.01      5.52    803.38      1.00\n",
      "lambda[107]     12.05    125.41      1.00      0.00      7.59    924.70      1.00\n",
      "lambda[108]      2.45      5.91      1.00      0.00      5.23    625.71      1.01\n",
      "lambda[109]      7.41    114.55      0.95      0.00      6.22    980.76      1.00\n",
      "lambda[110]      3.53     11.11      1.02      0.00      6.44    717.35      1.00\n",
      "lambda[111]      4.13     18.84      0.96      0.00      5.99    767.13      1.00\n",
      "lambda[112]      2.59      7.02      0.88      0.00      5.86   1075.85      1.00\n",
      "lambda[113]      6.88     68.79      1.06      0.00      7.71    846.03      1.00\n",
      "lambda[114]      3.84     13.99      0.99      0.00      6.69    681.50      1.00\n",
      "lambda[115]      4.35     25.19      0.95      0.00      5.70    633.24      1.00\n",
      "lambda[116]     15.29    193.86      0.93      0.00      6.08    278.18      1.00\n",
      "lambda[117]      3.77     16.89      0.98      0.00      6.42    639.12      1.00\n",
      "lambda[118]      3.20     12.90      0.97      0.00      5.51    976.11      1.00\n",
      "lambda[119]      3.14     17.05      1.01      0.00      5.49    997.89      1.00\n",
      "lambda[120]      5.75     58.36      0.96      0.00      6.37    943.58      1.00\n",
      "lambda[121]      3.01      9.64      0.90      0.00      6.08    822.54      1.00\n",
      "lambda[122]      4.56     28.44      1.00      0.00      7.03    812.85      1.00\n",
      "lambda[123]      2.51      5.86      0.89      0.00      5.30    680.10      1.00\n",
      "lambda[124]      2.75      8.78      1.00      0.01      5.59    659.53      1.00\n",
      "lambda[125]      2.67      6.98      0.91      0.01      5.22    475.94      1.00\n",
      "lambda[126]      2.43      6.66      0.94      0.00      4.29    845.24      1.00\n",
      "lambda[127]      5.00     24.15      0.99      0.00      7.07    639.12      1.00\n",
      "lambda[128]      3.07     11.57      0.94      0.00      4.68    509.65      1.00\n",
      "lambda[129]      4.21     18.96      0.98      0.00      6.97    921.55      1.00\n",
      "lambda[130]      3.29     11.35      0.94      0.00      6.01    800.12      1.01\n",
      "lambda[131]      3.49     12.14      0.93      0.01      5.80    660.80      1.00\n",
      "lambda[132]      2.70      5.90      0.93      0.00      5.75    970.18      1.00\n",
      "lambda[133]      2.41      5.26      0.97      0.00      5.18    793.55      1.00\n",
      "lambda[134]      3.86     12.45      0.93      0.00      7.50    601.14      1.01\n",
      "lambda[135]      6.84    115.26      0.96      0.00      4.75    800.38      1.00\n",
      "lambda[136]      2.94      8.19      1.00      0.00      5.90    755.11      1.00\n",
      "lambda[137]      3.34     12.47      0.95      0.00      5.33    592.64      1.00\n",
      "lambda[138]      3.67     21.97      1.02      0.00      5.48    963.44      1.00\n",
      "lambda[139]      3.28     11.69      0.95      0.00      5.98    890.49      1.00\n",
      "lambda[140]      5.69     64.41      0.96      0.00      6.11    934.79      1.00\n",
      "lambda[141]      3.08     13.80      0.93      0.00      5.22    615.79      1.00\n",
      "lambda[142]      5.71     41.76      0.96      0.01      6.47    716.17      1.00\n",
      "lambda[143]      2.39      5.89      0.93      0.01      5.00    431.94      1.00\n",
      "        msq      0.20      0.11      0.17      0.06      0.35   1093.11      1.00\n",
      "      sigma      4.44      6.09      2.04      0.01     12.80   1519.66      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    642.22      1.00\n",
      "       xisq      0.11      0.06      0.10      0.04      0.18   1481.18      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 32.02748417854309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-6.59e-05 +- 1.34e-02\n",
      "[dimension 02/145]  inactive:\t1.01e-03 +- 2.26e-02\n",
      "[dimension 03/145]  inactive:\t9.39e-04 +- 2.30e-02\n",
      "[dimension 04/145]  inactive:\t5.89e-03 +- 4.01e-02\n",
      "[dimension 05/145]  inactive:\t2.19e-04 +- 1.97e-02\n",
      "[dimension 06/145]  inactive:\t2.43e-03 +- 3.05e-02\n",
      "[dimension 07/145]  inactive:\t1.57e-03 +- 2.06e-02\n",
      "[dimension 08/145]  inactive:\t2.84e-03 +- 3.25e-02\n",
      "[dimension 09/145]  inactive:\t1.19e-03 +- 2.03e-02\n",
      "[dimension 10/145]  inactive:\t6.41e-04 +- 1.58e-02\n",
      "[dimension 11/145]  inactive:\t1.52e-03 +- 3.12e-02\n",
      "[dimension 12/145]  inactive:\t1.29e-03 +- 2.44e-02\n",
      "[dimension 13/145]  inactive:\t6.06e-03 +- 4.31e-02\n",
      "[dimension 14/145]  inactive:\t-2.05e-05 +- 1.80e-02\n",
      "[dimension 15/145]  inactive:\t3.33e-03 +- 3.85e-02\n",
      "[dimension 16/145]  inactive:\t9.47e-04 +- 2.29e-02\n",
      "[dimension 17/145]  inactive:\t4.43e-03 +- 4.50e-02\n",
      "[dimension 18/145]  inactive:\t2.39e-03 +- 3.43e-02\n",
      "[dimension 19/145]  inactive:\t-1.64e-03 +- 1.99e-02\n",
      "[dimension 20/145]  inactive:\t-1.05e-04 +- 2.31e-02\n",
      "[dimension 21/145]  inactive:\t-8.04e-04 +- 1.73e-02\n",
      "[dimension 22/145]  inactive:\t2.46e-05 +- 1.89e-02\n",
      "[dimension 23/145]  inactive:\t1.11e-04 +- 2.39e-02\n",
      "[dimension 24/145]  inactive:\t1.80e-03 +- 2.92e-02\n",
      "[dimension 25/145]  inactive:\t3.33e-03 +- 2.25e-02\n",
      "[dimension 26/145]  inactive:\t2.50e-04 +- 2.19e-02\n",
      "[dimension 27/145]  inactive:\t1.58e-03 +- 2.48e-02\n",
      "[dimension 28/145]  inactive:\t1.07e-03 +- 1.81e-02\n",
      "[dimension 29/145]  inactive:\t9.61e-04 +- 2.31e-02\n",
      "[dimension 30/145]  inactive:\t3.16e-03 +- 3.28e-02\n",
      "[dimension 31/145]  inactive:\t7.53e-03 +- 4.85e-02\n",
      "[dimension 32/145]  inactive:\t4.81e-04 +- 2.59e-02\n",
      "[dimension 33/145]  inactive:\t5.15e-03 +- 4.12e-02\n",
      "[dimension 34/145]  inactive:\t1.06e-03 +- 1.93e-02\n",
      "[dimension 35/145]  inactive:\t1.03e-03 +- 2.08e-02\n",
      "[dimension 36/145]  inactive:\t2.56e-03 +- 2.82e-02\n",
      "[dimension 37/145]  inactive:\t4.63e-03 +- 2.72e-02\n",
      "[dimension 38/145]  inactive:\t4.01e-04 +- 2.47e-02\n",
      "[dimension 39/145]  inactive:\t2.36e-03 +- 2.77e-02\n",
      "[dimension 40/145]  inactive:\t6.37e-03 +- 4.16e-02\n",
      "[dimension 41/145]  inactive:\t2.02e-04 +- 2.95e-02\n",
      "[dimension 42/145]  inactive:\t4.65e-02 +- 1.71e-01\n",
      "[dimension 43/145]  inactive:\t4.94e-04 +- 1.95e-02\n",
      "[dimension 44/145]  inactive:\t1.03e-03 +- 3.03e-02\n",
      "[dimension 45/145]  inactive:\t1.07e-03 +- 2.54e-02\n",
      "[dimension 46/145]  inactive:\t6.15e-04 +- 1.43e-02\n",
      "[dimension 47/145]  inactive:\t-3.56e-04 +- 2.39e-02\n",
      "[dimension 48/145]  inactive:\t1.46e-03 +- 2.15e-02\n",
      "[dimension 49/145]  inactive:\t2.40e-03 +- 2.46e-02\n",
      "[dimension 50/145]  inactive:\t-3.51e-04 +- 2.75e-02\n",
      "[dimension 51/145]  inactive:\t2.96e-03 +- 2.83e-02\n",
      "[dimension 52/145]  inactive:\t7.66e-03 +- 2.95e-02\n",
      "[dimension 53/145]  inactive:\t-1.76e-04 +- 1.96e-02\n",
      "[dimension 54/145]  inactive:\t1.37e-03 +- 2.11e-02\n",
      "[dimension 55/145]  inactive:\t8.48e-04 +- 1.46e-02\n",
      "[dimension 56/145]  inactive:\t-1.66e-03 +- 2.29e-02\n",
      "[dimension 57/145]  inactive:\t1.98e-03 +- 2.46e-02\n",
      "[dimension 58/145]  inactive:\t1.55e-02 +- 7.64e-02\n",
      "[dimension 59/145]  inactive:\t-1.76e-04 +- 1.54e-02\n",
      "[dimension 60/145]  inactive:\t3.95e-03 +- 3.54e-02\n",
      "[dimension 61/145]  inactive:\t4.52e-03 +- 3.13e-02\n",
      "[dimension 62/145]  inactive:\t8.16e-04 +- 2.58e-02\n",
      "[dimension 63/145]  active:\t5.41e-01 +- 4.11e-01\n",
      "[dimension 64/145]  inactive:\t-2.23e-03 +- 2.10e-02\n",
      "[dimension 65/145]  inactive:\t1.10e-03 +- 2.60e-02\n",
      "[dimension 66/145]  inactive:\t1.12e-03 +- 2.31e-02\n",
      "[dimension 67/145]  inactive:\t1.33e-03 +- 2.61e-02\n",
      "[dimension 68/145]  inactive:\t4.96e-04 +- 2.29e-02\n",
      "[dimension 69/145]  inactive:\t5.50e-03 +- 4.98e-02\n",
      "[dimension 70/145]  inactive:\t5.04e-03 +- 2.80e-02\n",
      "[dimension 71/145]  inactive:\t1.45e-03 +- 2.58e-02\n",
      "[dimension 72/145]  inactive:\t1.57e-03 +- 2.22e-02\n",
      "[dimension 73/145]  inactive:\t5.16e-04 +- 1.50e-02\n",
      "[dimension 74/145]  inactive:\t9.32e-04 +- 3.13e-02\n",
      "[dimension 75/145]  inactive:\t1.00e-03 +- 1.80e-02\n",
      "[dimension 76/145]  inactive:\t8.15e-03 +- 4.87e-02\n",
      "[dimension 77/145]  inactive:\t-7.77e-05 +- 2.69e-02\n",
      "[dimension 78/145]  inactive:\t1.68e-02 +- 9.72e-02\n",
      "[dimension 79/145]  inactive:\t7.59e-03 +- 3.76e-02\n",
      "[dimension 80/145]  inactive:\t1.52e-03 +- 3.05e-02\n",
      "[dimension 81/145]  inactive:\t3.54e-03 +- 3.50e-02\n",
      "[dimension 82/145]  inactive:\t5.59e-04 +- 1.49e-02\n",
      "[dimension 83/145]  inactive:\t-8.34e-04 +- 1.53e-02\n",
      "[dimension 84/145]  inactive:\t1.64e-04 +- 2.04e-02\n",
      "[dimension 85/145]  inactive:\t3.91e-03 +- 3.30e-02\n",
      "[dimension 86/145]  inactive:\t1.34e-04 +- 1.78e-02\n",
      "[dimension 87/145]  inactive:\t2.89e-03 +- 3.11e-02\n",
      "[dimension 88/145]  inactive:\t3.90e-03 +- 2.74e-02\n",
      "[dimension 89/145]  inactive:\t1.70e-04 +- 1.89e-02\n",
      "[dimension 90/145]  inactive:\t6.30e-02 +- 2.04e-01\n",
      "[dimension 91/145]  inactive:\t6.37e-05 +- 1.56e-02\n",
      "[dimension 92/145]  inactive:\t-1.52e-04 +- 2.10e-02\n",
      "[dimension 93/145]  inactive:\t2.65e-04 +- 2.82e-02\n",
      "[dimension 94/145]  inactive:\t2.05e-03 +- 2.62e-02\n",
      "[dimension 95/145]  inactive:\t7.42e-04 +- 2.21e-02\n",
      "[dimension 96/145]  inactive:\t2.85e-03 +- 4.19e-02\n",
      "[dimension 97/145]  inactive:\t3.32e-03 +- 2.58e-02\n",
      "[dimension 98/145]  inactive:\t1.01e-03 +- 2.62e-02\n",
      "[dimension 99/145]  inactive:\t6.54e-03 +- 5.24e-02\n",
      "[dimension 100/145]  inactive:\t-2.12e-05 +- 1.30e-02\n",
      "[dimension 101/145]  inactive:\t-1.62e-03 +- 2.08e-02\n",
      "[dimension 102/145]  inactive:\t1.40e-03 +- 3.05e-02\n",
      "[dimension 103/145]  inactive:\t2.13e-03 +- 2.66e-02\n",
      "[dimension 104/145]  inactive:\t-2.83e-04 +- 1.76e-02\n",
      "[dimension 105/145]  inactive:\t1.87e-03 +- 2.95e-02\n",
      "[dimension 106/145]  inactive:\t9.75e-03 +- 4.82e-02\n",
      "[dimension 107/145]  inactive:\t3.44e-04 +- 2.14e-02\n",
      "[dimension 108/145]  inactive:\t1.68e-02 +- 9.31e-02\n",
      "[dimension 109/145]  inactive:\t-4.42e-05 +- 1.80e-02\n",
      "[dimension 110/145]  inactive:\t1.47e-03 +- 3.01e-02\n",
      "[dimension 111/145]  inactive:\t3.28e-03 +- 3.37e-02\n",
      "[dimension 112/145]  inactive:\t4.48e-03 +- 3.78e-02\n",
      "[dimension 113/145]  inactive:\t-4.00e-04 +- 2.00e-02\n",
      "[dimension 114/145]  inactive:\t2.75e-03 +- 3.45e-02\n",
      "[dimension 115/145]  inactive:\t2.31e-03 +- 2.25e-02\n",
      "[dimension 116/145]  inactive:\t3.00e-03 +- 3.78e-02\n",
      "[dimension 117/145]  inactive:\t8.80e-03 +- 6.52e-02\n",
      "[dimension 118/145]  inactive:\t3.45e-03 +- 2.44e-02\n",
      "[dimension 119/145]  inactive:\t2.10e-04 +- 2.80e-02\n",
      "[dimension 120/145]  inactive:\t8.16e-04 +- 2.34e-02\n",
      "[dimension 121/145]  inactive:\t5.15e-03 +- 3.79e-02\n",
      "[dimension 122/145]  inactive:\t-8.61e-04 +- 2.76e-02\n",
      "[dimension 123/145]  inactive:\t4.07e-03 +- 4.18e-02\n",
      "[dimension 124/145]  inactive:\t-3.95e-04 +- 1.58e-02\n",
      "[dimension 125/145]  inactive:\t-7.74e-05 +- 2.30e-02\n",
      "[dimension 126/145]  inactive:\t1.76e-04 +- 2.00e-02\n",
      "[dimension 127/145]  inactive:\t4.24e-04 +- 1.54e-02\n",
      "[dimension 128/145]  inactive:\t1.16e-03 +- 3.46e-02\n",
      "[dimension 129/145]  inactive:\t1.56e-03 +- 2.64e-02\n",
      "[dimension 130/145]  inactive:\t3.67e-03 +- 2.92e-02\n",
      "[dimension 131/145]  inactive:\t5.42e-04 +- 2.62e-02\n",
      "[dimension 132/145]  inactive:\t4.62e-03 +- 4.14e-02\n",
      "[dimension 133/145]  inactive:\t2.71e-03 +- 2.06e-02\n",
      "[dimension 134/145]  inactive:\t2.15e-04 +- 2.21e-02\n",
      "[dimension 135/145]  inactive:\t2.33e-03 +- 2.89e-02\n",
      "[dimension 136/145]  inactive:\t1.70e-03 +- 1.99e-02\n",
      "[dimension 137/145]  inactive:\t6.95e-04 +- 2.91e-02\n",
      "[dimension 138/145]  inactive:\t1.57e-03 +- 2.46e-02\n",
      "[dimension 139/145]  inactive:\t1.16e-03 +- 2.09e-02\n",
      "[dimension 140/145]  inactive:\t4.20e-04 +- 2.38e-02\n",
      "[dimension 141/145]  inactive:\t2.10e-03 +- 2.94e-02\n",
      "[dimension 142/145]  inactive:\t2.32e-03 +- 1.98e-02\n",
      "[dimension 143/145]  inactive:\t3.80e-03 +- 3.77e-02\n",
      "[dimension 144/145]  inactive:\t1.17e-03 +- 1.85e-02\n",
      "[dimension 145/145]  inactive:\t1.91e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8716321]\n",
      "cov_act[[0.01408951]]\n",
      "Active_dimensions: [62]\n",
      "20, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:27<00:00, 55.41it/s, 31 steps of size 2.03e-01. acc. prob=0.89] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    329.63      1.00\n",
      "  lambda[0]      2.45      4.77      0.93      0.00      5.94    654.05      1.00\n",
      "  lambda[1]      3.00      8.74      0.92      0.00      5.77    808.36      1.00\n",
      "  lambda[2]      2.73      5.39      1.06      0.01      5.99    444.35      1.00\n",
      "  lambda[3]      4.00     18.04      0.99      0.00      5.59    434.85      1.00\n",
      "  lambda[4]      2.90      7.35      0.98      0.00      5.95    989.44      1.00\n",
      "  lambda[5]      3.87     14.42      1.11      0.01      6.31    502.77      1.00\n",
      "  lambda[6]      3.01     10.64      0.96      0.00      5.99    933.31      1.00\n",
      "  lambda[7]      2.50      5.05      0.92      0.00      5.53    899.79      1.00\n",
      "  lambda[8]      2.50      5.62      0.93      0.01      5.40    766.97      1.00\n",
      "  lambda[9]      2.42      5.04      1.01      0.00      4.77    706.82      1.00\n",
      " lambda[10]      3.26     11.09      0.99      0.00      6.43    735.63      1.00\n",
      " lambda[11]      2.77      7.29      0.99      0.00      5.82    692.44      1.00\n",
      " lambda[12]      4.33     22.33      1.00      0.01      7.18    506.13      1.00\n",
      " lambda[13]      3.12     13.59      1.00      0.00      5.86    894.83      1.00\n",
      " lambda[14]      2.92      8.26      1.03      0.00      5.89    888.63      1.00\n",
      " lambda[15]      2.87      7.15      1.03      0.00      5.30    719.79      1.00\n",
      " lambda[16]      3.24      9.07      1.04      0.00      5.91    530.71      1.00\n",
      " lambda[17]      3.06      8.28      0.99      0.00      5.99    851.16      1.00\n",
      " lambda[18]      2.97      7.51      0.94      0.00      5.69    585.20      1.00\n",
      " lambda[19]      2.89      6.42      1.01      0.00      6.78    652.49      1.01\n",
      " lambda[20]      2.89      8.64      0.96      0.00      5.20    570.05      1.00\n",
      " lambda[21]      2.78      7.10      0.97      0.00      5.79    487.16      1.00\n",
      " lambda[22]      2.51      6.26      1.03      0.00      5.61    648.56      1.00\n",
      " lambda[23]      3.53     20.76      1.00      0.00      5.82    789.72      1.00\n",
      " lambda[24]      3.69     12.29      0.99      0.00      7.15    319.30      1.00\n",
      " lambda[25]      2.67      7.52      0.93      0.00      6.02    714.70      1.00\n",
      " lambda[26]      2.91      7.82      1.02      0.00      5.87    771.25      1.00\n",
      " lambda[27]      2.57      6.17      0.94      0.00      5.07    568.31      1.00\n",
      " lambda[28]      2.57      5.37      0.96      0.00      6.28    768.41      1.00\n",
      " lambda[29]      3.28     13.77      0.91      0.01      6.34    922.62      1.00\n",
      " lambda[30]      3.83     13.84      1.02      0.00      6.97    558.81      1.00\n",
      " lambda[31]      3.28      9.33      0.92      0.00      5.72    727.06      1.00\n",
      " lambda[32]      2.72      6.87      1.02      0.00      5.99    852.78      1.00\n",
      " lambda[33]      2.35      4.69      0.96      0.00      5.03    771.75      1.00\n",
      " lambda[34]      2.89      7.84      0.96      0.00      5.74    638.48      1.00\n",
      " lambda[35]      2.77      6.63      0.98      0.00      6.09    868.02      1.00\n",
      " lambda[36]      3.44     10.80      0.98      0.00      6.90    719.51      1.00\n",
      " lambda[37]      3.21     10.85      1.03      0.01      6.24    808.67      1.00\n",
      " lambda[38]      5.75     97.29      0.98      0.00      5.66    992.87      1.00\n",
      " lambda[39]      4.21     20.03      1.06      0.00      6.66    602.22      1.00\n",
      " lambda[40]      3.24     11.64      0.97      0.00      6.06    721.78      1.00\n",
      " lambda[41]      8.04     44.87      1.03      0.00      8.64    522.72      1.00\n",
      " lambda[42]      2.77      6.43      0.97      0.00      6.66    889.68      1.00\n",
      " lambda[43]      2.62      5.83      0.99      0.00      5.84    718.45      1.00\n",
      " lambda[44]      2.99      7.98      0.94      0.00      6.48    852.39      1.00\n",
      " lambda[45]      3.06     11.24      0.99      0.00      5.58    685.86      1.00\n",
      " lambda[46]      2.93     11.16      0.98      0.00      4.69    812.96      1.00\n",
      " lambda[47]      2.40      4.37      1.02      0.00      5.62    707.96      1.00\n",
      " lambda[48]      2.75      6.06      1.03      0.00      6.12    733.89      1.00\n",
      " lambda[49]      2.99      9.18      1.02      0.00      5.91    543.48      1.00\n",
      " lambda[50]      4.33     22.10      0.98      0.00      6.04    488.88      1.00\n",
      " lambda[51]      3.45      9.77      0.99      0.00      6.57   1073.38      1.00\n",
      " lambda[52]      3.08      9.97      0.92      0.00      5.28    925.08      1.00\n",
      " lambda[53]      3.16     13.96      0.94      0.00      5.46    441.36      1.00\n",
      " lambda[54]      1.96      4.57      0.92      0.00      3.98    708.05      1.00\n",
      " lambda[55]      3.26     15.23      0.90      0.00      5.38    748.45      1.00\n",
      " lambda[56]      2.38      6.12      0.87      0.01      4.58    812.81      1.00\n",
      " lambda[57]      5.07     16.81      1.07      0.00      9.40    638.12      1.00\n",
      " lambda[58]      2.48      6.96      0.99      0.01      4.90    751.43      1.00\n",
      " lambda[59]      3.61     12.49      1.05      0.00      6.16    770.51      1.00\n",
      " lambda[60]      4.22     15.77      1.04      0.00      6.24    570.39      1.00\n",
      " lambda[61]      2.65      7.97      1.03      0.00      5.33    724.88      1.00\n",
      " lambda[62]   8210.60 163296.80    149.49      0.02   1297.09    532.89      1.00\n",
      " lambda[63]      3.56     29.78      0.93      0.00      5.78   1003.19      1.00\n",
      " lambda[64]      2.75      6.79      0.98      0.00      5.77    791.44      1.00\n",
      " lambda[65]      2.85      7.66      1.01      0.00      6.13    888.38      1.00\n",
      " lambda[66]      2.97      7.97      0.92      0.00      5.72    742.80      1.00\n",
      " lambda[67]      3.11     10.96      1.05      0.00      5.78    853.99      1.00\n",
      " lambda[68]      3.46     10.09      0.98      0.01      7.14    819.74      1.00\n",
      " lambda[69]      3.24     10.69      0.99      0.01      5.90    772.46      1.00\n",
      " lambda[70]      2.71      7.34      0.99      0.00      5.72    589.11      1.00\n",
      " lambda[71]      2.81      7.34      0.97      0.00      5.51    537.06      1.00\n",
      " lambda[72]      2.29      6.48      0.94      0.00      4.78    710.03      1.00\n",
      " lambda[73]      3.95     15.79      0.95      0.00      6.47    639.61      1.00\n",
      " lambda[74]      2.92      7.74      1.00      0.01      5.64    630.40      1.00\n",
      " lambda[75]      3.56     10.65      1.07      0.00      6.84    756.07      1.00\n",
      " lambda[76]      2.84      6.66      1.01      0.00      6.16    684.01      1.00\n",
      " lambda[77]      7.43     59.59      0.98      0.00      6.57    307.57      1.00\n",
      " lambda[78]      3.17      7.54      1.02      0.00      6.69    391.79      1.00\n",
      " lambda[79]      3.45     16.45      0.99      0.00      5.65    781.74      1.00\n",
      " lambda[80]      2.62      6.75      1.05      0.00      5.21    811.86      1.00\n",
      " lambda[81]      2.77      6.53      1.03      0.00      5.69    673.63      1.00\n",
      " lambda[82]      2.99     17.53      0.89      0.00      4.93    909.58      1.00\n",
      " lambda[83]      3.41     10.70      1.03      0.00      6.83    577.06      1.00\n",
      " lambda[84]      6.86     81.44      1.03      0.00      6.37    563.49      1.00\n",
      " lambda[85]      3.23     12.61      0.95      0.00      5.74    384.61      1.00\n",
      " lambda[86]      6.57     63.46      1.02      0.00      6.73    433.78      1.00\n",
      " lambda[87]      3.58     14.57      0.95      0.00      5.65    730.10      1.00\n",
      " lambda[88]      2.29      4.47      0.94      0.00      4.90    668.46      1.00\n",
      " lambda[89]    480.01   8605.24      1.37      0.00    134.58    482.52      1.00\n",
      " lambda[90]      2.29      4.59      0.88      0.00      4.58    810.39      1.00\n",
      " lambda[91]      2.66      6.38      1.02      0.01      5.55    674.18      1.00\n",
      " lambda[92]      3.15      8.01      0.98      0.00      6.77    858.80      1.00\n",
      " lambda[93]      2.58      7.17      1.02      0.00      5.53    691.38      1.00\n",
      " lambda[94]      3.17      9.95      0.99      0.00      5.71    755.28      1.00\n",
      " lambda[95]      3.37     11.76      0.95      0.00      5.77    781.17      1.00\n",
      " lambda[96]      2.96     11.29      0.93      0.00      5.74    471.44      1.00\n",
      " lambda[97]      2.85      7.83      0.91      0.00      5.76    627.79      1.00\n",
      " lambda[98]      3.29     11.79      0.96      0.00      5.54    808.77      1.00\n",
      " lambda[99]      2.82      8.92      0.97      0.00      6.00    867.34      1.00\n",
      "lambda[100]      3.22     11.10      1.00      0.00      5.82    490.47      1.00\n",
      "lambda[101]      3.02      8.66      0.97      0.00      5.63    481.58      1.00\n",
      "lambda[102]      2.65      6.32      0.97      0.00      5.86    773.48      1.00\n",
      "lambda[103]      2.38      5.30      0.92      0.00      5.42    916.65      1.00\n",
      "lambda[104]      2.49      8.02      0.92      0.00      4.93    876.56      1.00\n",
      "lambda[105]      2.72      6.50      1.00      0.00      5.89    708.20      1.00\n",
      "lambda[106]      3.21     12.65      0.96      0.00      5.63    427.24      1.00\n",
      "lambda[107]      5.55     24.57      1.04      0.00      7.38    324.44      1.00\n",
      "lambda[108]      2.21      4.03      0.95      0.00      5.20    844.04      1.00\n",
      "lambda[109]      9.23    157.24      1.02      0.00      6.01    997.99      1.00\n",
      "lambda[110]      3.38     11.33      1.05      0.00      6.06    825.31      1.00\n",
      "lambda[111]      4.01     21.62      1.00      0.00      6.69    897.57      1.00\n",
      "lambda[112]      2.17      3.89      0.97      0.01      4.86    850.93      1.00\n",
      "lambda[113]      4.02     12.96      1.02      0.00      7.54    505.17      1.00\n",
      "lambda[114]      2.71     12.66      0.94      0.00      5.19    643.67      1.00\n",
      "lambda[115]      3.19     10.03      0.94      0.00      6.17    920.81      1.00\n",
      "lambda[116]      3.74     35.25      1.02      0.01      5.82    939.18      1.00\n",
      "lambda[117]      3.07     13.21      0.88      0.00      5.31   1003.64      1.00\n",
      "lambda[118]      3.14     14.64      0.93      0.00      6.06    973.24      1.00\n",
      "lambda[119]      2.93      8.77      0.95      0.00      5.38    723.94      1.00\n",
      "lambda[120]      3.52     11.44      1.00      0.00      7.26    609.03      1.00\n",
      "lambda[121]      2.93     10.89      1.03      0.00      5.58    815.32      1.00\n",
      "lambda[122]      4.07     34.76      0.97      0.00      5.32    477.87      1.00\n",
      "lambda[123]      2.75      6.81      0.90      0.01      6.00    880.33      1.01\n",
      "lambda[124]      2.78      6.60      0.92      0.01      5.78    549.36      1.00\n",
      "lambda[125]      2.66     10.16      0.98      0.00      5.01    671.27      1.00\n",
      "lambda[126]      2.18      5.78      0.90      0.00      4.62    848.20      1.00\n",
      "lambda[127]      2.97      9.07      0.96      0.00      5.32    790.31      1.00\n",
      "lambda[128]      3.26      9.77      1.04      0.00      5.75    450.98      1.00\n",
      "lambda[129]      3.26     11.78      0.90      0.00      5.34    846.82      1.00\n",
      "lambda[130]      3.20     11.16      1.02      0.00      6.17    964.95      1.00\n",
      "lambda[131]      4.54     47.35      0.97      0.00      5.79    890.78      1.00\n",
      "lambda[132]      2.68      5.97      1.00      0.01      5.91    899.47      1.00\n",
      "lambda[133]      3.20      9.71      1.05      0.00      6.17    690.22      1.00\n",
      "lambda[134]      3.46     11.01      0.92      0.00      7.17    649.51      1.00\n",
      "lambda[135]      2.69      6.52      0.96      0.00      5.77    892.74      1.00\n",
      "lambda[136]      2.78      7.95      0.97      0.00      5.56    974.73      1.00\n",
      "lambda[137]      2.87     10.34      1.02      0.00      5.88    935.42      1.00\n",
      "lambda[138]      2.95      8.53      0.99      0.00      5.95    554.16      1.00\n",
      "lambda[139]      2.70      6.70      0.94      0.00      5.95    639.85      1.00\n",
      "lambda[140]      3.41     15.31      0.98      0.00      6.76    566.27      1.00\n",
      "lambda[141]      2.80      7.93      0.91      0.00      5.78    553.33      1.00\n",
      "lambda[142]      4.59     19.74      1.04      0.00      7.24    588.53      1.00\n",
      "lambda[143]      2.51      6.81      0.95      0.00      5.27    919.09      1.00\n",
      "        msq   7817.00 194787.94      8.17      0.15    215.50    900.82      1.00\n",
      "      sigma      5.76      7.60      2.48      0.00     16.08    917.86      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    519.17      1.00\n",
      "       xisq     19.47    246.16      1.39      0.08     16.84    918.75      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 30.775686979293823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.96e-04 +- 2.21e-02\n",
      "[dimension 02/145]  inactive:\t-1.31e-04 +- 2.66e-02\n",
      "[dimension 03/145]  inactive:\t2.63e-04 +- 2.60e-02\n",
      "[dimension 04/145]  inactive:\t6.54e-03 +- 4.60e-02\n",
      "[dimension 05/145]  inactive:\t-4.39e-04 +- 3.31e-02\n",
      "[dimension 06/145]  inactive:\t4.54e-03 +- 4.91e-02\n",
      "[dimension 07/145]  inactive:\t7.44e-04 +- 1.88e-02\n",
      "[dimension 08/145]  inactive:\t1.21e-03 +- 2.82e-02\n",
      "[dimension 09/145]  inactive:\t5.52e-04 +- 2.43e-02\n",
      "[dimension 10/145]  inactive:\t4.50e-04 +- 1.78e-02\n",
      "[dimension 11/145]  inactive:\t-8.33e-04 +- 2.71e-02\n",
      "[dimension 12/145]  inactive:\t-2.62e-04 +- 2.43e-02\n",
      "[dimension 13/145]  inactive:\t4.87e-03 +- 4.32e-02\n",
      "[dimension 14/145]  inactive:\t-1.66e-03 +- 2.72e-02\n",
      "[dimension 15/145]  inactive:\t6.38e-04 +- 3.05e-02\n",
      "[dimension 16/145]  inactive:\t6.70e-04 +- 2.07e-02\n",
      "[dimension 17/145]  inactive:\t-5.66e-04 +- 2.97e-02\n",
      "[dimension 18/145]  inactive:\t-3.88e-04 +- 3.03e-02\n",
      "[dimension 19/145]  inactive:\t-2.50e-03 +- 2.20e-02\n",
      "[dimension 20/145]  inactive:\t-1.11e-03 +- 2.27e-02\n",
      "[dimension 21/145]  inactive:\t-2.57e-03 +- 3.13e-02\n",
      "[dimension 22/145]  inactive:\t7.00e-05 +- 2.25e-02\n",
      "[dimension 23/145]  inactive:\t-6.82e-04 +- 2.52e-02\n",
      "[dimension 24/145]  inactive:\t2.58e-03 +- 3.23e-02\n",
      "[dimension 25/145]  inactive:\t4.28e-03 +- 2.65e-02\n",
      "[dimension 26/145]  inactive:\t-8.03e-04 +- 3.08e-02\n",
      "[dimension 27/145]  inactive:\t9.89e-04 +- 2.59e-02\n",
      "[dimension 28/145]  inactive:\t9.05e-04 +- 1.86e-02\n",
      "[dimension 29/145]  inactive:\t-2.95e-04 +- 2.45e-02\n",
      "[dimension 30/145]  inactive:\t1.66e-03 +- 2.94e-02\n",
      "[dimension 31/145]  inactive:\t8.12e-03 +- 5.64e-02\n",
      "[dimension 32/145]  inactive:\t-4.63e-04 +- 3.61e-02\n",
      "[dimension 33/145]  inactive:\t2.42e-03 +- 3.37e-02\n",
      "[dimension 34/145]  inactive:\t7.66e-04 +- 1.84e-02\n",
      "[dimension 35/145]  inactive:\t6.00e-04 +- 2.68e-02\n",
      "[dimension 36/145]  inactive:\t1.32e-03 +- 2.55e-02\n",
      "[dimension 37/145]  inactive:\t6.61e-03 +- 3.85e-02\n",
      "[dimension 38/145]  inactive:\t-1.57e-03 +- 3.18e-02\n",
      "[dimension 39/145]  inactive:\t1.01e-03 +- 3.00e-02\n",
      "[dimension 40/145]  inactive:\t5.93e-03 +- 4.27e-02\n",
      "[dimension 41/145]  inactive:\t-1.44e-03 +- 2.77e-02\n",
      "[dimension 42/145]  inactive:\t1.24e-02 +- 8.48e-02\n",
      "[dimension 43/145]  inactive:\t-1.36e-04 +- 2.18e-02\n",
      "[dimension 44/145]  inactive:\t-6.43e-04 +- 2.48e-02\n",
      "[dimension 45/145]  inactive:\t-6.17e-04 +- 2.75e-02\n",
      "[dimension 46/145]  inactive:\t1.34e-03 +- 1.59e-02\n",
      "[dimension 47/145]  inactive:\t-1.69e-03 +- 2.74e-02\n",
      "[dimension 48/145]  inactive:\t1.93e-03 +- 2.79e-02\n",
      "[dimension 49/145]  inactive:\t2.78e-03 +- 2.30e-02\n",
      "[dimension 50/145]  inactive:\t-1.94e-03 +- 2.70e-02\n",
      "[dimension 51/145]  inactive:\t3.73e-03 +- 3.61e-02\n",
      "[dimension 52/145]  inactive:\t5.65e-03 +- 2.41e-02\n",
      "[dimension 53/145]  inactive:\t-1.45e-03 +- 2.67e-02\n",
      "[dimension 54/145]  inactive:\t5.50e-04 +- 2.29e-02\n",
      "[dimension 55/145]  inactive:\t4.80e-04 +- 1.45e-02\n",
      "[dimension 56/145]  inactive:\t-2.15e-03 +- 2.29e-02\n",
      "[dimension 57/145]  inactive:\t1.79e-03 +- 3.27e-02\n",
      "[dimension 58/145]  inactive:\t1.41e-02 +- 7.16e-02\n",
      "[dimension 59/145]  inactive:\t-8.20e-04 +- 2.02e-02\n",
      "[dimension 60/145]  inactive:\t2.09e-03 +- 3.66e-02\n",
      "[dimension 61/145]  inactive:\t3.09e-03 +- 2.66e-02\n",
      "[dimension 62/145]  inactive:\t-6.98e-04 +- 2.01e-02\n",
      "[dimension 63/145]  active:\t6.59e-01 +- 4.45e-01\n",
      "[dimension 64/145]  inactive:\t-5.66e-03 +- 4.16e-02\n",
      "[dimension 65/145]  inactive:\t-4.35e-04 +- 2.46e-02\n",
      "[dimension 66/145]  inactive:\t3.38e-04 +- 2.31e-02\n",
      "[dimension 67/145]  inactive:\t1.67e-03 +- 2.80e-02\n",
      "[dimension 68/145]  inactive:\t-1.10e-03 +- 3.14e-02\n",
      "[dimension 69/145]  inactive:\t4.63e-03 +- 4.58e-02\n",
      "[dimension 70/145]  inactive:\t4.11e-03 +- 2.66e-02\n",
      "[dimension 71/145]  inactive:\t3.51e-04 +- 2.57e-02\n",
      "[dimension 72/145]  inactive:\t7.71e-04 +- 2.28e-02\n",
      "[dimension 73/145]  inactive:\t1.59e-04 +- 1.67e-02\n",
      "[dimension 74/145]  inactive:\t-2.59e-03 +- 3.35e-02\n",
      "[dimension 75/145]  inactive:\t8.27e-04 +- 2.90e-02\n",
      "[dimension 76/145]  inactive:\t5.73e-03 +- 3.82e-02\n",
      "[dimension 77/145]  inactive:\t-1.72e-03 +- 2.80e-02\n",
      "[dimension 78/145]  inactive:\t9.41e-03 +- 7.71e-02\n",
      "[dimension 79/145]  inactive:\t7.15e-03 +- 3.64e-02\n",
      "[dimension 80/145]  inactive:\t7.01e-05 +- 2.85e-02\n",
      "[dimension 81/145]  inactive:\t7.42e-04 +- 2.48e-02\n",
      "[dimension 82/145]  inactive:\t4.10e-04 +- 1.84e-02\n",
      "[dimension 83/145]  inactive:\t-2.24e-03 +- 2.22e-02\n",
      "[dimension 84/145]  inactive:\t-1.89e-03 +- 3.05e-02\n",
      "[dimension 85/145]  inactive:\t4.53e-03 +- 3.75e-02\n",
      "[dimension 86/145]  inactive:\t-1.05e-03 +- 2.13e-02\n",
      "[dimension 87/145]  inactive:\t5.39e-03 +- 6.55e-02\n",
      "[dimension 88/145]  inactive:\t4.05e-03 +- 3.08e-02\n",
      "[dimension 89/145]  inactive:\t-7.85e-04 +- 1.72e-02\n",
      "[dimension 90/145]  inactive:\t1.40e-01 +- 3.25e-01\n",
      "[dimension 91/145]  inactive:\t1.38e-04 +- 1.81e-02\n",
      "[dimension 92/145]  inactive:\t-1.52e-03 +- 2.57e-02\n",
      "[dimension 93/145]  inactive:\t-5.21e-04 +- 2.81e-02\n",
      "[dimension 94/145]  inactive:\t1.50e-03 +- 2.46e-02\n",
      "[dimension 95/145]  inactive:\t-6.12e-04 +- 2.65e-02\n",
      "[dimension 96/145]  inactive:\t2.95e-04 +- 3.81e-02\n",
      "[dimension 97/145]  inactive:\t2.17e-03 +- 2.22e-02\n",
      "[dimension 98/145]  inactive:\t-5.15e-04 +- 2.53e-02\n",
      "[dimension 99/145]  inactive:\t2.53e-03 +- 3.49e-02\n",
      "[dimension 100/145]  inactive:\t-6.04e-04 +- 1.81e-02\n",
      "[dimension 101/145]  inactive:\t-2.90e-03 +- 2.24e-02\n",
      "[dimension 102/145]  inactive:\t-1.42e-03 +- 2.62e-02\n",
      "[dimension 103/145]  inactive:\t1.14e-03 +- 2.49e-02\n",
      "[dimension 104/145]  inactive:\t-1.09e-03 +- 1.69e-02\n",
      "[dimension 105/145]  inactive:\t-3.02e-04 +- 2.33e-02\n",
      "[dimension 106/145]  inactive:\t3.57e-03 +- 2.53e-02\n",
      "[dimension 107/145]  inactive:\t-1.33e-03 +- 2.10e-02\n",
      "[dimension 108/145]  inactive:\t1.62e-02 +- 1.01e-01\n",
      "[dimension 109/145]  inactive:\t-4.56e-04 +- 1.88e-02\n",
      "[dimension 110/145]  inactive:\t-9.58e-04 +- 3.51e-02\n",
      "[dimension 111/145]  inactive:\t2.49e-03 +- 3.67e-02\n",
      "[dimension 112/145]  inactive:\t6.23e-03 +- 4.94e-02\n",
      "[dimension 113/145]  inactive:\t-1.43e-03 +- 2.25e-02\n",
      "[dimension 114/145]  inactive:\t3.01e-03 +- 4.96e-02\n",
      "[dimension 115/145]  inactive:\t1.41e-03 +- 1.98e-02\n",
      "[dimension 116/145]  inactive:\t2.57e-04 +- 3.05e-02\n",
      "[dimension 117/145]  inactive:\t2.11e-03 +- 3.09e-02\n",
      "[dimension 118/145]  inactive:\t2.37e-03 +- 2.04e-02\n",
      "[dimension 119/145]  inactive:\t-2.73e-03 +- 3.57e-02\n",
      "[dimension 120/145]  inactive:\t-3.04e-04 +- 3.17e-02\n",
      "[dimension 121/145]  inactive:\t4.26e-03 +- 3.60e-02\n",
      "[dimension 122/145]  inactive:\t-1.82e-03 +- 2.72e-02\n",
      "[dimension 123/145]  inactive:\t3.00e-03 +- 4.70e-02\n",
      "[dimension 124/145]  inactive:\t-1.99e-03 +- 2.16e-02\n",
      "[dimension 125/145]  inactive:\t-1.85e-03 +- 2.60e-02\n",
      "[dimension 126/145]  inactive:\t-8.21e-04 +- 2.08e-02\n",
      "[dimension 127/145]  inactive:\t2.41e-04 +- 1.47e-02\n",
      "[dimension 128/145]  inactive:\t-1.02e-03 +- 3.10e-02\n",
      "[dimension 129/145]  inactive:\t-1.46e-04 +- 2.86e-02\n",
      "[dimension 130/145]  inactive:\t3.04e-03 +- 2.73e-02\n",
      "[dimension 131/145]  inactive:\t-9.95e-04 +- 2.84e-02\n",
      "[dimension 132/145]  inactive:\t6.50e-03 +- 5.26e-02\n",
      "[dimension 133/145]  inactive:\t3.11e-03 +- 2.21e-02\n",
      "[dimension 134/145]  inactive:\t-9.50e-04 +- 2.38e-02\n",
      "[dimension 135/145]  inactive:\t-2.61e-04 +- 3.05e-02\n",
      "[dimension 136/145]  inactive:\t1.43e-03 +- 2.08e-02\n",
      "[dimension 137/145]  inactive:\t-3.29e-04 +- 3.10e-02\n",
      "[dimension 138/145]  inactive:\t9.05e-04 +- 2.46e-02\n",
      "[dimension 139/145]  inactive:\t2.72e-04 +- 2.58e-02\n",
      "[dimension 140/145]  inactive:\t-9.49e-04 +- 3.33e-02\n",
      "[dimension 141/145]  inactive:\t1.33e-03 +- 2.97e-02\n",
      "[dimension 142/145]  inactive:\t1.57e-03 +- 1.81e-02\n",
      "[dimension 143/145]  inactive:\t2.53e-03 +- 4.32e-02\n",
      "[dimension 144/145]  inactive:\t3.34e-04 +- 1.92e-02\n",
      "[dimension 145/145]  inactive:\t2.65e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[7.727742e-05]\n",
      "cov_act[[6.73905e-06]]\n",
      "Active_dimensions: [62]\n",
      "21, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:25<00:00, 58.81it/s, 15 steps of size 2.47e-01. acc. prob=0.89] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    220.99      1.01\n",
      "  lambda[0]      2.60      9.94      0.97      0.00      5.09    967.04      1.00\n",
      "  lambda[1]     19.03    420.52      0.94      0.00      5.21    659.34      1.00\n",
      "  lambda[2]      3.01      7.61      1.01      0.01      6.24    551.23      1.00\n",
      "  lambda[3]      4.22     19.89      1.00      0.00      6.81    586.50      1.00\n",
      "  lambda[4]      2.86      8.07      1.01      0.00      5.75    967.83      1.00\n",
      "  lambda[5]      3.76     30.66      0.98      0.00      5.85   1005.95      1.00\n",
      "  lambda[6]      3.75     12.65      1.04      0.00      6.79    752.39      1.00\n",
      "  lambda[7]      2.80      7.13      0.94      0.00      5.88    738.73      1.00\n",
      "  lambda[8]      2.79      6.76      0.98      0.00      5.52    679.94      1.00\n",
      "  lambda[9]      3.33      8.64      1.09      0.00      6.84    560.03      1.00\n",
      " lambda[10]      3.14      9.19      1.03      0.00      6.09    559.55      1.00\n",
      " lambda[11]      2.72      7.11      0.95      0.00      5.65    788.42      1.00\n",
      " lambda[12]      4.01     13.11      0.98      0.00      6.60    546.26      1.01\n",
      " lambda[13]      3.07     11.60      0.90      0.00      6.30    377.79      1.00\n",
      " lambda[14]      3.31      8.83      1.04      0.00      7.27    644.20      1.00\n",
      " lambda[15]      3.60     12.63      1.04      0.00      6.76    942.16      1.00\n",
      " lambda[16]      2.88      7.33      0.98      0.01      5.76    768.86      1.00\n",
      " lambda[17]      7.32    137.03      1.04      0.00      6.25    960.16      1.00\n",
      " lambda[18]      2.88     10.13      0.95      0.00      5.16    679.95      1.00\n",
      " lambda[19]      2.72      6.49      1.03      0.00      6.06    874.64      1.00\n",
      " lambda[20]      3.01      7.78      1.03      0.00      6.33    643.76      1.00\n",
      " lambda[21]      2.50      5.26      0.94      0.00      6.03    641.96      1.00\n",
      " lambda[22]      2.31      4.15      1.04      0.01      5.01    958.98      1.00\n",
      " lambda[23]      5.17     73.53      0.99      0.01      5.34    962.16      1.00\n",
      " lambda[24]      3.99     15.93      1.01      0.00      6.73    705.53      1.00\n",
      " lambda[25]      2.77     12.88      0.98      0.01      4.66    591.86      1.00\n",
      " lambda[26]      3.65     23.98      0.98      0.00      5.04    600.35      1.00\n",
      " lambda[27]      2.97      7.93      0.93      0.00      6.27    584.46      1.00\n",
      " lambda[28]      2.54      5.11      1.02      0.00      6.46    633.32      1.00\n",
      " lambda[29]      3.32     15.96      0.93      0.00      5.99    930.67      1.00\n",
      " lambda[30]      3.29     12.19      0.95      0.00      6.07    615.04      1.00\n",
      " lambda[31]      3.09      8.59      0.97      0.00      6.32    751.45      1.00\n",
      " lambda[32]      3.41     12.19      0.97      0.00      7.31    510.55      1.00\n",
      " lambda[33]      2.94      7.19      0.94      0.00      5.96    603.14      1.00\n",
      " lambda[34]      2.99     11.21      1.06      0.00      4.85    683.12      1.00\n",
      " lambda[35]      4.03     23.20      1.01      0.00      5.35    323.61      1.00\n",
      " lambda[36]      4.12     24.09      1.01      0.01      6.93    520.93      1.00\n",
      " lambda[37]      2.98     10.21      1.01      0.00      5.89    985.01      1.00\n",
      " lambda[38]     14.11    293.95      0.96      0.00      6.28    956.64      1.00\n",
      " lambda[39]      4.28     26.16      0.96      0.00      6.42    723.94      1.00\n",
      " lambda[40]      2.59      5.79      0.97      0.00      6.07    815.53      1.00\n",
      " lambda[41]     19.09    170.00      1.01      0.00      7.74    367.53      1.00\n",
      " lambda[42]      2.31      5.52      0.97      0.00      4.76    993.18      1.00\n",
      " lambda[43]      7.27    123.26      0.97      0.00      5.29    769.99      1.00\n",
      " lambda[44]      2.86      6.68      0.94      0.00      6.00    670.39      1.00\n",
      " lambda[45]      2.51      7.10      0.96      0.01      5.05    926.84      1.00\n",
      " lambda[46]      2.44      6.86      0.90      0.00      4.38    949.36      1.00\n",
      " lambda[47]      2.55      4.81      1.05      0.00      5.79    838.76      1.00\n",
      " lambda[48]      3.21      8.98      0.97      0.00      6.64    583.86      1.00\n",
      " lambda[49]      2.88      7.13      1.03      0.00      6.14    845.33      1.00\n",
      " lambda[50]     10.83    159.28      0.97      0.01      5.89    450.61      1.00\n",
      " lambda[51]      4.72     19.27      1.07      0.00      8.05    808.31      1.00\n",
      " lambda[52]      2.52      7.36      0.96      0.01      5.14    739.76      1.00\n",
      " lambda[53]      3.86     20.21      0.98      0.00      5.47    372.84      1.00\n",
      " lambda[54]      2.29      5.25      0.94      0.00      4.95    698.91      1.00\n",
      " lambda[55]      3.98     42.85      0.85      0.00      5.04   1007.11      1.00\n",
      " lambda[56]      2.42      7.26      0.97      0.00      4.48   1009.59      1.00\n",
      " lambda[57]      5.17     20.77      1.03      0.01      7.69    430.67      1.00\n",
      " lambda[58]      2.20      4.52      0.94      0.00      4.57    702.14      1.00\n",
      " lambda[59]      3.54     14.17      1.04      0.00      5.75    609.36      1.00\n",
      " lambda[60]      4.12     15.47      1.08      0.00      7.87    563.62      1.01\n",
      " lambda[61]      2.86     10.07      0.95      0.00      5.85    712.13      1.00\n",
      " lambda[62]   2614.19  25195.51    301.52      0.00   3622.22    753.94      1.00\n",
      " lambda[63]      2.24      4.86      0.94      0.00      4.89    816.53      1.00\n",
      " lambda[64]      2.88     14.53      0.99      0.00      5.43   1016.84      1.00\n",
      " lambda[65]      3.13     12.09      0.99      0.00      5.49    849.94      1.00\n",
      " lambda[66]      3.32     10.18      0.94      0.00      6.25    860.78      1.00\n",
      " lambda[67]      3.07      9.87      1.02      0.00      6.20    985.48      1.00\n",
      " lambda[68]      3.02      7.97      0.99      0.00      5.54    869.51      1.00\n",
      " lambda[69]      4.30     17.90      0.99      0.00      7.12    825.53      1.00\n",
      " lambda[70]      2.93     13.35      0.92      0.00      5.08    850.35      1.00\n",
      " lambda[71]      3.36     13.28      1.02      0.00      6.24    781.60      1.00\n",
      " lambda[72]      2.33      5.93      1.03      0.00      4.87    829.78      1.00\n",
      " lambda[73]      3.13     16.49      1.00      0.00      5.46    975.71      1.00\n",
      " lambda[74]      2.65      8.73      0.96      0.01      6.02    737.13      1.00\n",
      " lambda[75]      7.04     58.36      1.06      0.00      7.80    568.63      1.00\n",
      " lambda[76]      2.66      6.08      1.02      0.00      5.49    595.62      1.00\n",
      " lambda[77]     22.03    374.34      0.96      0.00      6.46    743.30      1.00\n",
      " lambda[78]      3.00      7.99      1.04      0.00      5.88    382.47      1.00\n",
      " lambda[79]      2.97     14.32      0.90      0.00      5.00    778.59      1.00\n",
      " lambda[80]      4.03     18.07      0.95      0.00      7.37    376.91      1.00\n",
      " lambda[81]      2.51      5.03      1.02      0.00      5.75    719.34      1.00\n",
      " lambda[82]      2.36      5.07      0.96      0.00      5.18    637.10      1.00\n",
      " lambda[83]      3.34     10.41      1.03      0.00      6.60    925.07      1.00\n",
      " lambda[84]      4.33     32.34      0.94      0.00      5.03    821.92      1.00\n",
      " lambda[85]      3.06      9.49      0.94      0.00      5.86    421.67      1.00\n",
      " lambda[86]      3.97     23.23      0.94      0.00      5.67    445.52      1.00\n",
      " lambda[87]      3.04     11.98      0.91      0.00      5.19    769.09      1.00\n",
      " lambda[88]      2.99      7.23      0.99      0.00      6.51    657.44      1.00\n",
      " lambda[89]    417.15   4465.84      1.53      0.00    422.30    372.38      1.00\n",
      " lambda[90]      2.45      6.08      0.90      0.00      4.72    601.61      1.00\n",
      " lambda[91]      2.82     10.10      1.01      0.00      5.27    575.00      1.00\n",
      " lambda[92]      2.97      8.27      0.96      0.00      6.29    804.99      1.00\n",
      " lambda[93]      2.51      7.75      0.97      0.00      5.18    597.80      1.00\n",
      " lambda[94]      3.96     12.98      1.00      0.00      6.99    538.84      1.00\n",
      " lambda[95]      3.76     15.00      1.00      0.00      6.95    738.44      1.00\n",
      " lambda[96]      2.98      7.34      0.97      0.00      6.43    667.22      1.00\n",
      " lambda[97]      2.36      4.86      0.98      0.00      5.09   1018.74      1.00\n",
      " lambda[98]      8.36    162.90      0.98      0.00      5.66    814.38      1.00\n",
      " lambda[99]      2.46      7.24      0.92      0.00      4.89   1021.20      1.00\n",
      "lambda[100]      2.86      7.45      0.99      0.00      6.43    584.42      1.00\n",
      "lambda[101]      4.59     41.81      1.04      0.00      5.42    731.69      1.00\n",
      "lambda[102]      2.66      6.96      0.96      0.00      5.61    866.90      1.00\n",
      "lambda[103]      2.96     10.32      0.93      0.00      5.37    473.27      1.00\n",
      "lambda[104]      9.58    139.74      0.98      0.00      4.44    358.83      1.00\n",
      "lambda[105]      3.47      9.81      1.00      0.00      6.62    762.09      1.00\n",
      "lambda[106]      3.10     15.38      0.95      0.00      4.85    640.96      1.00\n",
      "lambda[107]      2.82     10.77      0.98      0.00      4.84    815.97      1.00\n",
      "lambda[108]      2.36      5.66      0.94      0.00      5.12    820.44      1.00\n",
      "lambda[109]      6.11     39.51      1.03      0.00      6.94    418.56      1.00\n",
      "lambda[110]      3.11     10.20      1.01      0.00      5.98    820.05      1.00\n",
      "lambda[111]    159.65   3110.71      1.04      0.00      8.75    420.13      1.00\n",
      "lambda[112]      2.21      4.71      0.99      0.01      4.60    612.75      1.00\n",
      "lambda[113]      3.97     13.53      1.00      0.00      6.00    561.50      1.00\n",
      "lambda[114]      3.36      9.22      0.97      0.00      6.53    647.50      1.00\n",
      "lambda[115]      4.25     25.44      1.02      0.00      6.50    670.12      1.00\n",
      "lambda[116]      4.04     31.20      1.01      0.00      6.38    909.73      1.00\n",
      "lambda[117]      3.18     11.92      0.93      0.00      5.44    828.00      1.00\n",
      "lambda[118]      3.49     33.54      0.91      0.00      4.68    858.55      1.00\n",
      "lambda[119]      4.06     15.53      0.98      0.00      6.76    621.57      1.00\n",
      "lambda[120]      3.54     13.48      1.00      0.00      6.87    829.21      1.00\n",
      "lambda[121]      2.91      6.97      1.03      0.00      6.62    688.77      1.00\n",
      "lambda[122]      3.73     18.10      0.96      0.00      5.61    580.34      1.00\n",
      "lambda[123]      2.60      5.58      0.90      0.00      5.87    797.14      1.00\n",
      "lambda[124]      2.87      6.67      0.97      0.01      6.53    893.33      1.00\n",
      "lambda[125]      2.61      6.54      0.92      0.01      5.28    494.85      1.00\n",
      "lambda[126]      2.28      5.52      0.97      0.00      4.88    788.41      1.00\n",
      "lambda[127]      3.62     16.19      1.01      0.00      5.37    821.14      1.00\n",
      "lambda[128]      3.87     23.73      0.93      0.00      5.68    406.67      1.00\n",
      "lambda[129]      3.63     18.44      0.90      0.00      5.33    733.50      1.00\n",
      "lambda[130]      2.80      7.90      0.97      0.00      5.90    728.35      1.01\n",
      "lambda[131]      2.93      8.43      1.00      0.00      5.89    650.42      1.00\n",
      "lambda[132]      3.07      9.30      1.04      0.00      5.77    717.78      1.00\n",
      "lambda[133]      2.48      7.03      0.93      0.00      5.04    920.54      1.00\n",
      "lambda[134]      3.16      7.99      1.00      0.00      6.68    884.02      1.00\n",
      "lambda[135]      2.37      6.03      0.96      0.00      4.64    838.79      1.00\n",
      "lambda[136]      2.63      6.66      0.94      0.00      5.53    656.07      1.00\n",
      "lambda[137]      2.82      7.75      1.04      0.00      5.30    646.64      1.00\n",
      "lambda[138]      2.97      8.72      0.97      0.00      6.40    704.54      1.00\n",
      "lambda[139]      2.53      5.94      0.94      0.00      5.41    632.27      1.00\n",
      "lambda[140]      3.33     16.80      0.94      0.00      5.51    577.16      1.00\n",
      "lambda[141]      3.14      8.85      1.02      0.00      6.96    519.97      1.00\n",
      "lambda[142]      3.58     14.70      0.97      0.00      6.25    587.81      1.00\n",
      "lambda[143]      2.57     10.49      0.94      0.00      4.57    922.87      1.00\n",
      "        msq      0.24      0.16      0.20      0.06      0.41    882.88      1.00\n",
      "      sigma      5.06      7.43      1.83      0.00     14.37    978.02      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    499.94      1.00\n",
      "       xisq      1.60      4.85      0.57      0.07      2.60    377.33      1.01\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 29.42568612098694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.10e-04 +- 1.20e-02\n",
      "[dimension 02/145]  inactive:\t1.34e-03 +- 2.22e-02\n",
      "[dimension 03/145]  inactive:\t6.41e-04 +- 1.67e-02\n",
      "[dimension 04/145]  inactive:\t3.68e-03 +- 3.07e-02\n",
      "[dimension 05/145]  inactive:\t2.91e-04 +- 1.46e-02\n",
      "[dimension 06/145]  inactive:\t2.23e-03 +- 2.95e-02\n",
      "[dimension 07/145]  inactive:\t9.81e-04 +- 1.44e-02\n",
      "[dimension 08/145]  inactive:\t1.15e-03 +- 1.66e-02\n",
      "[dimension 09/145]  inactive:\t1.09e-03 +- 1.85e-02\n",
      "[dimension 10/145]  inactive:\t9.87e-04 +- 1.64e-02\n",
      "[dimension 11/145]  inactive:\t1.35e-03 +- 2.16e-02\n",
      "[dimension 12/145]  inactive:\t9.53e-04 +- 1.91e-02\n",
      "[dimension 13/145]  inactive:\t3.18e-03 +- 2.80e-02\n",
      "[dimension 14/145]  inactive:\t1.20e-03 +- 2.62e-02\n",
      "[dimension 15/145]  inactive:\t1.64e-03 +- 2.46e-02\n",
      "[dimension 16/145]  inactive:\t6.58e-04 +- 1.52e-02\n",
      "[dimension 17/145]  inactive:\t2.30e-03 +- 3.10e-02\n",
      "[dimension 18/145]  inactive:\t1.84e-03 +- 2.83e-02\n",
      "[dimension 19/145]  inactive:\t-4.93e-04 +- 1.15e-02\n",
      "[dimension 20/145]  inactive:\t1.23e-04 +- 1.68e-02\n",
      "[dimension 21/145]  inactive:\t-2.08e-04 +- 1.33e-02\n",
      "[dimension 22/145]  inactive:\t3.33e-04 +- 1.33e-02\n",
      "[dimension 23/145]  inactive:\t2.32e-04 +- 1.31e-02\n",
      "[dimension 24/145]  inactive:\t1.20e-03 +- 1.90e-02\n",
      "[dimension 25/145]  inactive:\t2.74e-03 +- 2.01e-02\n",
      "[dimension 26/145]  inactive:\t3.64e-04 +- 1.86e-02\n",
      "[dimension 27/145]  inactive:\t1.33e-03 +- 2.10e-02\n",
      "[dimension 28/145]  inactive:\t8.41e-04 +- 1.37e-02\n",
      "[dimension 29/145]  inactive:\t8.61e-04 +- 1.60e-02\n",
      "[dimension 30/145]  inactive:\t1.85e-03 +- 2.30e-02\n",
      "[dimension 31/145]  inactive:\t4.25e-03 +- 3.79e-02\n",
      "[dimension 32/145]  inactive:\t4.09e-04 +- 1.67e-02\n",
      "[dimension 33/145]  inactive:\t3.13e-03 +- 3.35e-02\n",
      "[dimension 34/145]  inactive:\t7.72e-04 +- 1.36e-02\n",
      "[dimension 35/145]  inactive:\t1.34e-03 +- 2.42e-02\n",
      "[dimension 36/145]  inactive:\t2.44e-03 +- 2.89e-02\n",
      "[dimension 37/145]  inactive:\t3.56e-03 +- 2.23e-02\n",
      "[dimension 38/145]  inactive:\t4.45e-04 +- 2.03e-02\n",
      "[dimension 39/145]  inactive:\t3.46e-03 +- 3.38e-02\n",
      "[dimension 40/145]  inactive:\t3.46e-03 +- 3.03e-02\n",
      "[dimension 41/145]  inactive:\t2.83e-05 +- 1.47e-02\n",
      "[dimension 42/145]  inactive:\t1.29e-02 +- 9.07e-02\n",
      "[dimension 43/145]  inactive:\t3.85e-04 +- 1.35e-02\n",
      "[dimension 44/145]  inactive:\t8.42e-04 +- 2.00e-02\n",
      "[dimension 45/145]  inactive:\t6.50e-04 +- 1.68e-02\n",
      "[dimension 46/145]  inactive:\t4.99e-04 +- 1.15e-02\n",
      "[dimension 47/145]  inactive:\t-1.49e-04 +- 1.60e-02\n",
      "[dimension 48/145]  inactive:\t6.47e-04 +- 1.39e-02\n",
      "[dimension 49/145]  inactive:\t1.60e-03 +- 1.96e-02\n",
      "[dimension 50/145]  inactive:\t-6.46e-05 +- 1.76e-02\n",
      "[dimension 51/145]  inactive:\t4.08e-03 +- 4.34e-02\n",
      "[dimension 52/145]  inactive:\t4.62e-03 +- 2.21e-02\n",
      "[dimension 53/145]  inactive:\t-9.07e-06 +- 1.46e-02\n",
      "[dimension 54/145]  inactive:\t1.66e-03 +- 2.35e-02\n",
      "[dimension 55/145]  inactive:\t4.14e-04 +- 1.13e-02\n",
      "[dimension 56/145]  inactive:\t-1.09e-03 +- 1.67e-02\n",
      "[dimension 57/145]  inactive:\t1.22e-03 +- 1.86e-02\n",
      "[dimension 58/145]  inactive:\t7.23e-03 +- 4.92e-02\n",
      "[dimension 59/145]  inactive:\t-2.00e-04 +- 1.16e-02\n",
      "[dimension 60/145]  inactive:\t3.14e-03 +- 3.66e-02\n",
      "[dimension 61/145]  inactive:\t3.02e-03 +- 2.35e-02\n",
      "[dimension 62/145]  inactive:\t2.79e-05 +- 1.38e-02\n",
      "[dimension 63/145]  active:\t5.93e-01 +- 4.28e-01\n",
      "[dimension 64/145]  inactive:\t-7.80e-04 +- 1.26e-02\n",
      "[dimension 65/145]  inactive:\t3.16e-04 +- 1.46e-02\n",
      "[dimension 66/145]  inactive:\t5.75e-04 +- 1.70e-02\n",
      "[dimension 67/145]  inactive:\t1.06e-03 +- 1.74e-02\n",
      "[dimension 68/145]  inactive:\t8.21e-04 +- 2.37e-02\n",
      "[dimension 69/145]  inactive:\t2.68e-03 +- 2.94e-02\n",
      "[dimension 70/145]  inactive:\t3.94e-03 +- 2.37e-02\n",
      "[dimension 71/145]  inactive:\t7.39e-04 +- 1.67e-02\n",
      "[dimension 72/145]  inactive:\t1.56e-03 +- 2.13e-02\n",
      "[dimension 73/145]  inactive:\t4.30e-04 +- 1.19e-02\n",
      "[dimension 74/145]  inactive:\t4.40e-04 +- 2.32e-02\n",
      "[dimension 75/145]  inactive:\t1.18e-03 +- 1.77e-02\n",
      "[dimension 76/145]  inactive:\t5.77e-03 +- 4.12e-02\n",
      "[dimension 77/145]  inactive:\t4.05e-04 +- 1.74e-02\n",
      "[dimension 78/145]  inactive:\t1.01e-02 +- 7.68e-02\n",
      "[dimension 79/145]  inactive:\t3.67e-03 +- 2.40e-02\n",
      "[dimension 80/145]  inactive:\t2.07e-03 +- 3.01e-02\n",
      "[dimension 81/145]  inactive:\t2.66e-03 +- 2.91e-02\n",
      "[dimension 82/145]  inactive:\t3.22e-04 +- 1.19e-02\n",
      "[dimension 83/145]  inactive:\t-6.99e-04 +- 1.13e-02\n",
      "[dimension 84/145]  inactive:\t-3.16e-04 +- 1.99e-02\n",
      "[dimension 85/145]  inactive:\t2.60e-03 +- 2.87e-02\n",
      "[dimension 86/145]  inactive:\t-4.52e-04 +- 1.32e-02\n",
      "[dimension 87/145]  inactive:\t1.81e-03 +- 2.63e-02\n",
      "[dimension 88/145]  inactive:\t1.81e-03 +- 1.74e-02\n",
      "[dimension 89/145]  inactive:\t-4.80e-04 +- 1.54e-02\n",
      "[dimension 90/145]  inactive:\t1.53e-01 +- 3.10e-01\n",
      "[dimension 91/145]  inactive:\t1.15e-04 +- 1.36e-02\n",
      "[dimension 92/145]  inactive:\t-7.66e-05 +- 1.40e-02\n",
      "[dimension 93/145]  inactive:\t7.85e-05 +- 1.62e-02\n",
      "[dimension 94/145]  inactive:\t8.48e-04 +- 1.51e-02\n",
      "[dimension 95/145]  inactive:\t1.01e-03 +- 2.31e-02\n",
      "[dimension 96/145]  inactive:\t9.93e-04 +- 2.78e-02\n",
      "[dimension 97/145]  inactive:\t2.12e-03 +- 1.78e-02\n",
      "[dimension 98/145]  inactive:\t2.24e-04 +- 1.55e-02\n",
      "[dimension 99/145]  inactive:\t1.76e-03 +- 2.59e-02\n",
      "[dimension 100/145]  inactive:\t-1.82e-04 +- 1.07e-02\n",
      "[dimension 101/145]  inactive:\t-9.67e-04 +- 1.29e-02\n",
      "[dimension 102/145]  inactive:\t4.97e-04 +- 2.02e-02\n",
      "[dimension 103/145]  inactive:\t5.42e-04 +- 1.38e-02\n",
      "[dimension 104/145]  inactive:\t-3.46e-04 +- 1.10e-02\n",
      "[dimension 105/145]  inactive:\t4.72e-05 +- 1.30e-02\n",
      "[dimension 106/145]  inactive:\t3.53e-03 +- 2.53e-02\n",
      "[dimension 107/145]  inactive:\t-5.26e-04 +- 1.64e-02\n",
      "[dimension 108/145]  inactive:\t2.01e-03 +- 2.92e-02\n",
      "[dimension 109/145]  inactive:\t9.55e-05 +- 1.19e-02\n",
      "[dimension 110/145]  inactive:\t4.21e-03 +- 4.54e-02\n",
      "[dimension 111/145]  inactive:\t1.81e-03 +- 2.33e-02\n",
      "[dimension 112/145]  inactive:\t1.15e-02 +- 8.43e-02\n",
      "[dimension 113/145]  inactive:\t-1.16e-04 +- 1.09e-02\n",
      "[dimension 114/145]  inactive:\t2.33e-03 +- 3.17e-02\n",
      "[dimension 115/145]  inactive:\t1.85e-03 +- 1.72e-02\n",
      "[dimension 116/145]  inactive:\t3.17e-03 +- 4.13e-02\n",
      "[dimension 117/145]  inactive:\t3.49e-03 +- 3.61e-02\n",
      "[dimension 118/145]  inactive:\t1.82e-03 +- 1.73e-02\n",
      "[dimension 119/145]  inactive:\t3.26e-04 +- 2.17e-02\n",
      "[dimension 120/145]  inactive:\t1.28e-03 +- 2.46e-02\n",
      "[dimension 121/145]  inactive:\t2.77e-03 +- 2.55e-02\n",
      "[dimension 122/145]  inactive:\t-2.08e-04 +- 1.78e-02\n",
      "[dimension 123/145]  inactive:\t2.40e-03 +- 3.28e-02\n",
      "[dimension 124/145]  inactive:\t-3.39e-04 +- 1.21e-02\n",
      "[dimension 125/145]  inactive:\t-1.31e-04 +- 1.58e-02\n",
      "[dimension 126/145]  inactive:\t6.94e-04 +- 1.95e-02\n",
      "[dimension 127/145]  inactive:\t3.09e-04 +- 1.07e-02\n",
      "[dimension 128/145]  inactive:\t7.67e-04 +- 2.05e-02\n",
      "[dimension 129/145]  inactive:\t8.17e-04 +- 1.99e-02\n",
      "[dimension 130/145]  inactive:\t2.13e-03 +- 2.07e-02\n",
      "[dimension 131/145]  inactive:\t4.19e-04 +- 1.77e-02\n",
      "[dimension 132/145]  inactive:\t1.88e-03 +- 2.13e-02\n",
      "[dimension 133/145]  inactive:\t1.75e-03 +- 1.58e-02\n",
      "[dimension 134/145]  inactive:\t2.49e-04 +- 1.42e-02\n",
      "[dimension 135/145]  inactive:\t1.39e-03 +- 2.31e-02\n",
      "[dimension 136/145]  inactive:\t8.10e-04 +- 1.29e-02\n",
      "[dimension 137/145]  inactive:\t6.41e-04 +- 1.69e-02\n",
      "[dimension 138/145]  inactive:\t6.13e-04 +- 1.53e-02\n",
      "[dimension 139/145]  inactive:\t5.85e-04 +- 1.74e-02\n",
      "[dimension 140/145]  inactive:\t2.58e-04 +- 1.59e-02\n",
      "[dimension 141/145]  inactive:\t1.58e-03 +- 2.43e-02\n",
      "[dimension 142/145]  inactive:\t1.97e-03 +- 1.91e-02\n",
      "[dimension 143/145]  inactive:\t2.88e-03 +- 3.52e-02\n",
      "[dimension 144/145]  inactive:\t7.58e-04 +- 1.38e-02\n",
      "[dimension 145/145]  inactive:\t-3.31e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[7.1525574e-06]\n",
      "cov_act[[1.0840595e-06]]\n",
      "Active_dimensions: [62]\n",
      "22, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.16it/s, 31 steps of size 1.64e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    617.51      1.00\n",
      "  lambda[0]      2.45      8.31      0.96      0.00      4.99   1017.28      1.00\n",
      "  lambda[1]      2.95      8.92      1.06      0.00      5.75    613.76      1.00\n",
      "  lambda[2]      2.84      8.68      1.01      0.00      5.37    629.20      1.00\n",
      "  lambda[3]      4.98     24.18      0.97      0.00      7.69    508.82      1.00\n",
      "  lambda[4]      2.60      7.10      1.02      0.00      4.95    865.04      1.00\n",
      "  lambda[5]      4.29     28.36      1.00      0.00      6.40    619.98      1.00\n",
      "  lambda[6]      3.30     15.53      0.97      0.00      5.68    931.60      1.00\n",
      "  lambda[7]      3.05      7.97      0.98      0.00      6.16    605.66      1.00\n",
      "  lambda[8]      2.19      3.73      0.97      0.00      5.04    934.25      1.00\n",
      "  lambda[9]      2.38      6.80      0.91      0.00      4.69    744.63      1.00\n",
      " lambda[10]      3.06     10.14      1.04      0.00      5.40    719.28      1.00\n",
      " lambda[11]      2.70      6.37      1.00      0.00      6.02    734.27      1.00\n",
      " lambda[12]      4.01     11.64      1.07      0.00      7.11    673.27      1.00\n",
      " lambda[13]      3.07     10.53      0.95      0.00      5.37    492.43      1.00\n",
      " lambda[14]      4.24     26.01      0.96      0.00      5.38    626.30      1.00\n",
      " lambda[15]      2.77      8.47      1.01      0.00      5.12    616.73      1.00\n",
      " lambda[16]      3.56      9.85      0.99      0.00      7.94    725.12      1.00\n",
      " lambda[17]      3.23     22.16      0.94      0.00      5.33    780.13      1.00\n",
      " lambda[18]      2.78      6.24      0.97      0.00      6.36    663.00      1.00\n",
      " lambda[19]      3.48     18.52      0.99      0.01      6.17    898.86      1.00\n",
      " lambda[20]      3.07      8.38      1.03      0.00      5.90    857.84      1.00\n",
      " lambda[21]      2.85      7.36      0.99      0.00      6.02    951.92      1.00\n",
      " lambda[22]      2.43      5.33      1.04      0.00      5.05    752.87      1.00\n",
      " lambda[23]      2.94      8.51      0.97      0.00      6.24    850.09      1.00\n",
      " lambda[24]      3.30      9.31      1.04      0.00      6.54    589.63      1.00\n",
      " lambda[25]      3.12     10.04      0.98      0.00      6.14    494.26      1.00\n",
      " lambda[26]      3.29     15.04      0.95      0.00      5.22    369.42      1.00\n",
      " lambda[27]      2.79      6.90      1.00      0.00      5.30    631.62      1.00\n",
      " lambda[28]      2.89     10.28      0.99      0.00      5.19    786.64      1.00\n",
      " lambda[29]      3.03      8.47      0.97      0.00      5.84    469.05      1.00\n",
      " lambda[30]      4.03     18.23      0.99      0.01      6.77    709.73      1.00\n",
      " lambda[31]      3.65     14.44      0.97      0.00      5.63    638.87      1.00\n",
      " lambda[32]      3.15     12.06      0.97      0.00      5.68   1012.08      1.00\n",
      " lambda[33]      2.79      6.97      0.96      0.01      6.01    807.91      1.00\n",
      " lambda[34]      2.76      7.50      0.95      0.00      5.53    599.93      1.00\n",
      " lambda[35]      2.68      8.01      0.99      0.00      4.81    897.69      1.00\n",
      " lambda[36]      3.69     16.33      1.02      0.00      6.15    960.06      1.00\n",
      " lambda[37]      3.09     13.90      0.96      0.00      5.28   1019.07      1.00\n",
      " lambda[38]      3.35     10.38      0.92      0.00      6.03    928.54      1.00\n",
      " lambda[39]      3.46     11.21      0.99      0.00      5.93    606.93      1.00\n",
      " lambda[40]      5.49     37.09      0.95      0.00      6.18    904.20      1.00\n",
      " lambda[41]     71.28   1271.33      1.01      0.00     10.25    417.96      1.00\n",
      " lambda[42]      2.57      5.60      0.97      0.00      5.48    815.37      1.00\n",
      " lambda[43]      4.22     38.36      0.98      0.00      6.31   1013.10      1.00\n",
      " lambda[44]      3.33     11.75      0.96      0.00      6.69    679.96      1.00\n",
      " lambda[45]      2.68      6.97      0.98      0.00      5.04    803.14      1.00\n",
      " lambda[46]      3.11      9.91      0.97      0.00      5.69    696.67      1.00\n",
      " lambda[47]      2.70      5.95      0.95      0.01      6.07    669.83      1.00\n",
      " lambda[48]      3.10     11.90      1.00      0.00      5.01    733.09      1.00\n",
      " lambda[49]      3.43     11.32      0.92      0.00      6.27    799.23      1.00\n",
      " lambda[50]      2.93      7.93      0.98      0.00      5.74    532.68      1.00\n",
      " lambda[51]      7.84    143.50      1.03      0.00      6.86    966.90      1.00\n",
      " lambda[52]      2.72      7.48      0.97      0.00      5.24    803.90      1.00\n",
      " lambda[53]      3.26     12.10      1.00      0.00      5.17    434.81      1.00\n",
      " lambda[54]      2.33      5.59      0.96      0.00      4.83    420.24      1.00\n",
      " lambda[55]      3.34     14.96      0.97      0.01      6.28    662.61      1.00\n",
      " lambda[56]      2.61      6.86      0.98      0.00      5.14    683.73      1.00\n",
      " lambda[57]      5.79     26.39      0.93      0.00      7.52    706.66      1.00\n",
      " lambda[58]      2.29      5.22      0.93      0.00      4.64    631.51      1.00\n",
      " lambda[59]      3.05      7.76      0.95      0.00      6.53    547.23      1.00\n",
      " lambda[60]      2.99      9.93      0.92      0.00      5.43    805.85      1.00\n",
      " lambda[61]      2.85      7.07      0.96      0.00      5.60    610.75      1.01\n",
      " lambda[62]   1300.54   9703.29    178.70      0.00   1381.62    874.51      1.00\n",
      " lambda[63]      2.51      6.35      0.98      0.00      4.62    889.05      1.00\n",
      " lambda[64]      2.96      7.73      0.98      0.01      5.30    691.44      1.00\n",
      " lambda[65]      3.04      8.07      0.98      0.00      6.32    527.85      1.00\n",
      " lambda[66]      3.22      9.00      1.02      0.00      6.51    684.20      1.00\n",
      " lambda[67]      2.83      6.70      0.93      0.00      6.63    823.60      1.00\n",
      " lambda[68]      5.95     53.66      0.95      0.00      5.74    472.89      1.00\n",
      " lambda[69]      3.68     12.51      0.96      0.00      6.58    898.24      1.00\n",
      " lambda[70]      2.74      6.07      1.01      0.01      5.53    453.89      1.00\n",
      " lambda[71]      3.89     23.50      0.96      0.00      5.58    431.92      1.00\n",
      " lambda[72]      2.55      7.30      0.96      0.00      4.96    665.67      1.00\n",
      " lambda[73]      2.78      6.48      1.02      0.00      5.63    713.45      1.00\n",
      " lambda[74]      2.31      4.38      1.00      0.01      5.38    823.99      1.00\n",
      " lambda[75]      5.18     33.21      0.97      0.00      7.52    866.47      1.00\n",
      " lambda[76]      3.05      8.66      0.99      0.00      5.67    712.52      1.00\n",
      " lambda[77]      3.72     20.35      1.02      0.00      7.10    866.00      1.00\n",
      " lambda[78]      4.01     16.29      1.03      0.00      6.97    655.48      1.00\n",
      " lambda[79]      3.51     16.57      0.98      0.00      5.57    818.98      1.00\n",
      " lambda[80]      5.25     39.69      1.05      0.00      6.03    631.10      1.00\n",
      " lambda[81]      2.52      6.76      0.99      0.00      4.60    589.35      1.00\n",
      " lambda[82]      2.34      6.37      0.95      0.00      4.43    927.90      1.00\n",
      " lambda[83]      3.72     13.74      0.94      0.00      6.14    678.22      1.00\n",
      " lambda[84]      3.81     14.71      0.98      0.00      6.26    633.56      1.00\n",
      " lambda[85]      2.83      9.93      0.96      0.00      4.92    348.31      1.00\n",
      " lambda[86]      2.29      4.26      0.98      0.00      5.41    949.22      1.00\n",
      " lambda[87]      3.25      9.68      0.96      0.00      6.21    634.76      1.00\n",
      " lambda[88]      2.72      7.53      0.94      0.00      5.66    761.40      1.00\n",
      " lambda[89]    293.79   4286.55      1.20      0.00    139.11    429.06      1.00\n",
      " lambda[90]      2.40      5.41      0.97      0.00      4.85    910.27      1.00\n",
      " lambda[91]      2.67      6.74      0.97      0.02      5.30    677.19      1.00\n",
      " lambda[92]      2.55      6.08      1.04      0.00      5.06    802.30      1.00\n",
      " lambda[93]      2.62      7.01      1.05      0.00      4.67    571.69      1.00\n",
      " lambda[94]      2.47      6.20      1.01      0.00      4.67    625.95      1.00\n",
      " lambda[95]      3.56     13.47      1.03      0.00      7.21    677.16      1.00\n",
      " lambda[96]      3.58     18.08      0.98      0.00      5.42    522.84      1.00\n",
      " lambda[97]      3.40     16.72      0.95      0.00      5.61    685.55      1.00\n",
      " lambda[98]      5.35     36.78      0.97      0.00      5.82    556.48      1.00\n",
      " lambda[99]      2.40      7.06      0.98      0.00      4.33    732.81      1.00\n",
      "lambda[100]      3.55     19.33      0.95      0.00      5.68    820.66      1.00\n",
      "lambda[101]      2.99      8.27      0.98      0.00      6.23    611.11      1.00\n",
      "lambda[102]      2.78      7.57      0.92      0.00      5.48    750.11      1.00\n",
      "lambda[103]      2.49      5.55      1.02      0.00      5.00    664.12      1.00\n",
      "lambda[104]      4.06     30.82      0.97      0.00      6.46    679.09      1.00\n",
      "lambda[105]      3.41     13.66      1.02      0.01      6.43    863.05      1.00\n",
      "lambda[106]      2.53      5.20      1.04      0.01      5.47    636.67      1.00\n",
      "lambda[107]      4.43     24.18      0.99      0.00      6.10    455.67      1.00\n",
      "lambda[108]      2.44      6.33      0.97      0.01      4.96    696.53      1.01\n",
      "lambda[109]      4.55     37.57      0.98      0.00      7.05    964.51      1.00\n",
      "lambda[110]      3.59     15.32      0.99      0.00      6.44    809.03      1.00\n",
      "lambda[111]      3.55     15.25      0.92      0.00      6.05    638.18      1.00\n",
      "lambda[112]      3.36     15.92      0.96      0.00      6.20    957.91      1.00\n",
      "lambda[113]      7.35     65.74      1.05      0.00      6.19    573.56      1.00\n",
      "lambda[114]      3.77     11.81      0.95      0.00      6.56    800.83      1.00\n",
      "lambda[115]      4.20     27.89      0.95      0.00      5.78    613.30      1.00\n",
      "lambda[116]      5.18     47.48      0.98      0.00      5.32    379.27      1.00\n",
      "lambda[117]      3.52     12.44      0.95      0.00      7.59    752.92      1.00\n",
      "lambda[118]      3.53     15.54      1.00      0.00      6.42    784.46      1.00\n",
      "lambda[119]      2.68      8.83      1.00      0.00      5.32    869.10      1.00\n",
      "lambda[120]      5.65     37.41      0.92      0.00      7.58    818.85      1.00\n",
      "lambda[121]      3.75     19.08      0.92      0.00      5.70    537.96      1.00\n",
      "lambda[122]      3.78     26.82      0.97      0.00      6.26    830.44      1.00\n",
      "lambda[123]      2.90      8.26      0.92      0.00      5.86    645.60      1.00\n",
      "lambda[124]      2.61      5.28      1.00      0.00      5.65    573.67      1.00\n",
      "lambda[125]      2.69      6.56      0.95      0.01      5.47    698.64      1.00\n",
      "lambda[126]      2.59      7.93      0.91      0.00      5.00    870.21      1.00\n",
      "lambda[127]      4.47     21.59      1.02      0.00      6.74    727.32      1.00\n",
      "lambda[128]      3.18     13.23      0.99      0.00      4.93    635.83      1.00\n",
      "lambda[129]      4.35     28.48      1.02      0.00      6.48    969.06      1.00\n",
      "lambda[130]      3.46     10.92      0.95      0.00      6.80    737.53      1.00\n",
      "lambda[131]      3.04      9.08      1.00      0.01      5.90    670.85      1.00\n",
      "lambda[132]      3.02      8.21      0.98      0.00      6.89    883.99      1.00\n",
      "lambda[133]      2.67      7.44      1.00      0.00      4.94    757.10      1.00\n",
      "lambda[134]      3.61      8.64      0.90      0.00      7.91    591.43      1.00\n",
      "lambda[135]      2.79     11.49      0.89      0.00      4.84    910.34      1.00\n",
      "lambda[136]      2.77      7.37      1.01      0.00      5.52    523.43      1.00\n",
      "lambda[137]      2.72      7.68      0.96      0.00      5.09    686.06      1.00\n",
      "lambda[138]      3.39     13.57      1.02      0.00      5.73    735.66      1.00\n",
      "lambda[139]      3.25     10.94      0.97      0.00      6.65    776.01      1.01\n",
      "lambda[140]      2.74      6.99      0.93      0.00      5.23    915.49      1.00\n",
      "lambda[141]      2.27      5.26      0.88      0.00      4.81    910.86      1.00\n",
      "lambda[142]      3.76     16.70      0.97      0.01      6.01    786.06      1.00\n",
      "lambda[143]      2.50      6.58      0.94      0.00      5.30    470.23      1.00\n",
      "        msq    339.83   3578.20      3.22      0.14     82.65    909.93      1.00\n",
      "      sigma      5.87      8.41      2.45      0.00     16.66   1308.64      1.00\n",
      "    var_obs      0.09      0.01      0.09      0.07      0.11   1245.94      1.00\n",
      "       xisq      0.12      0.07      0.10      0.04      0.20   1245.33      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.69720387458801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.13e-04 +- 1.97e-02\n",
      "[dimension 02/145]  inactive:\t-5.50e-04 +- 2.57e-02\n",
      "[dimension 03/145]  inactive:\t3.56e-04 +- 2.52e-02\n",
      "[dimension 04/145]  inactive:\t7.72e-03 +- 4.75e-02\n",
      "[dimension 05/145]  inactive:\t-9.14e-04 +- 2.35e-02\n",
      "[dimension 06/145]  inactive:\t2.30e-03 +- 3.79e-02\n",
      "[dimension 07/145]  inactive:\t5.92e-04 +- 1.96e-02\n",
      "[dimension 08/145]  inactive:\t4.39e-04 +- 2.77e-02\n",
      "[dimension 09/145]  inactive:\t-1.25e-04 +- 2.17e-02\n",
      "[dimension 10/145]  inactive:\t4.42e-04 +- 1.77e-02\n",
      "[dimension 11/145]  inactive:\t-7.38e-04 +- 2.21e-02\n",
      "[dimension 12/145]  inactive:\t-5.58e-04 +- 2.85e-02\n",
      "[dimension 13/145]  inactive:\t4.45e-03 +- 3.73e-02\n",
      "[dimension 14/145]  inactive:\t-1.71e-03 +- 2.68e-02\n",
      "[dimension 15/145]  inactive:\t4.16e-04 +- 3.29e-02\n",
      "[dimension 16/145]  inactive:\t8.62e-04 +- 2.06e-02\n",
      "[dimension 17/145]  inactive:\t-1.70e-04 +- 3.32e-02\n",
      "[dimension 18/145]  inactive:\t-2.20e-06 +- 3.06e-02\n",
      "[dimension 19/145]  inactive:\t-3.65e-03 +- 2.80e-02\n",
      "[dimension 20/145]  inactive:\t-1.38e-03 +- 2.90e-02\n",
      "[dimension 21/145]  inactive:\t-3.56e-03 +- 3.70e-02\n",
      "[dimension 22/145]  inactive:\t-4.07e-04 +- 2.55e-02\n",
      "[dimension 23/145]  inactive:\t-7.28e-04 +- 2.40e-02\n",
      "[dimension 24/145]  inactive:\t1.54e-03 +- 2.75e-02\n",
      "[dimension 25/145]  inactive:\t3.49e-03 +- 2.33e-02\n",
      "[dimension 26/145]  inactive:\t-9.40e-04 +- 3.02e-02\n",
      "[dimension 27/145]  inactive:\t6.92e-04 +- 2.79e-02\n",
      "[dimension 28/145]  inactive:\t9.79e-04 +- 2.24e-02\n",
      "[dimension 29/145]  inactive:\t-3.19e-04 +- 3.02e-02\n",
      "[dimension 30/145]  inactive:\t8.65e-04 +- 2.99e-02\n",
      "[dimension 31/145]  inactive:\t6.16e-03 +- 4.41e-02\n",
      "[dimension 32/145]  inactive:\t-2.15e-03 +- 3.41e-02\n",
      "[dimension 33/145]  inactive:\t1.97e-03 +- 3.42e-02\n",
      "[dimension 34/145]  inactive:\t7.76e-04 +- 2.16e-02\n",
      "[dimension 35/145]  inactive:\t2.29e-04 +- 2.45e-02\n",
      "[dimension 36/145]  inactive:\t1.02e-03 +- 2.52e-02\n",
      "[dimension 37/145]  inactive:\t4.79e-03 +- 3.07e-02\n",
      "[dimension 38/145]  inactive:\t-1.93e-03 +- 3.16e-02\n",
      "[dimension 39/145]  inactive:\t1.09e-03 +- 3.17e-02\n",
      "[dimension 40/145]  inactive:\t5.24e-03 +- 3.86e-02\n",
      "[dimension 41/145]  inactive:\t-2.31e-03 +- 3.85e-02\n",
      "[dimension 42/145]  inactive:\t2.16e-02 +- 1.22e-01\n",
      "[dimension 43/145]  inactive:\t-7.00e-04 +- 1.99e-02\n",
      "[dimension 44/145]  inactive:\t-4.47e-04 +- 3.04e-02\n",
      "[dimension 45/145]  inactive:\t-5.79e-04 +- 3.00e-02\n",
      "[dimension 46/145]  inactive:\t1.30e-03 +- 1.83e-02\n",
      "[dimension 47/145]  inactive:\t-2.27e-03 +- 3.18e-02\n",
      "[dimension 48/145]  inactive:\t1.88e-03 +- 2.78e-02\n",
      "[dimension 49/145]  inactive:\t2.95e-03 +- 2.55e-02\n",
      "[dimension 50/145]  inactive:\t-2.00e-03 +- 3.26e-02\n",
      "[dimension 51/145]  inactive:\t2.47e-03 +- 2.63e-02\n",
      "[dimension 52/145]  inactive:\t6.16e-03 +- 2.59e-02\n",
      "[dimension 53/145]  inactive:\t-8.55e-04 +- 2.54e-02\n",
      "[dimension 54/145]  inactive:\t-7.12e-05 +- 2.10e-02\n",
      "[dimension 55/145]  inactive:\t7.40e-04 +- 1.70e-02\n",
      "[dimension 56/145]  inactive:\t-3.10e-03 +- 2.52e-02\n",
      "[dimension 57/145]  inactive:\t1.02e-03 +- 2.93e-02\n",
      "[dimension 58/145]  inactive:\t1.52e-02 +- 7.86e-02\n",
      "[dimension 59/145]  inactive:\t-6.18e-04 +- 1.74e-02\n",
      "[dimension 60/145]  inactive:\t6.92e-04 +- 3.45e-02\n",
      "[dimension 61/145]  inactive:\t2.58e-03 +- 2.60e-02\n",
      "[dimension 62/145]  inactive:\t-1.14e-03 +- 2.77e-02\n",
      "[dimension 63/145]  active:\t7.05e-01 +- 4.26e-01\n",
      "[dimension 64/145]  inactive:\t-3.13e-03 +- 2.75e-02\n",
      "[dimension 65/145]  inactive:\t-2.83e-04 +- 2.86e-02\n",
      "[dimension 66/145]  inactive:\t7.43e-04 +- 2.43e-02\n",
      "[dimension 67/145]  inactive:\t1.76e-03 +- 2.75e-02\n",
      "[dimension 68/145]  inactive:\t-1.11e-03 +- 3.13e-02\n",
      "[dimension 69/145]  inactive:\t5.08e-03 +- 5.37e-02\n",
      "[dimension 70/145]  inactive:\t4.10e-03 +- 2.60e-02\n",
      "[dimension 71/145]  inactive:\t-2.10e-05 +- 2.59e-02\n",
      "[dimension 72/145]  inactive:\t8.86e-05 +- 2.23e-02\n",
      "[dimension 73/145]  inactive:\t2.53e-04 +- 1.93e-02\n",
      "[dimension 74/145]  inactive:\t-1.66e-03 +- 3.54e-02\n",
      "[dimension 75/145]  inactive:\t-2.50e-05 +- 2.03e-02\n",
      "[dimension 76/145]  inactive:\t7.15e-03 +- 4.49e-02\n",
      "[dimension 77/145]  inactive:\t-1.61e-03 +- 3.15e-02\n",
      "[dimension 78/145]  inactive:\t4.12e-03 +- 4.63e-02\n",
      "[dimension 79/145]  inactive:\t7.30e-03 +- 3.66e-02\n",
      "[dimension 80/145]  inactive:\t-6.55e-04 +- 3.53e-02\n",
      "[dimension 81/145]  inactive:\t8.62e-04 +- 3.08e-02\n",
      "[dimension 82/145]  inactive:\t3.54e-04 +- 1.69e-02\n",
      "[dimension 83/145]  inactive:\t-1.73e-03 +- 1.93e-02\n",
      "[dimension 84/145]  inactive:\t-2.39e-03 +- 3.52e-02\n",
      "[dimension 85/145]  inactive:\t3.56e-03 +- 3.68e-02\n",
      "[dimension 86/145]  inactive:\t-5.10e-04 +- 2.22e-02\n",
      "[dimension 87/145]  inactive:\t1.68e-03 +- 3.50e-02\n",
      "[dimension 88/145]  inactive:\t3.30e-03 +- 2.77e-02\n",
      "[dimension 89/145]  inactive:\t-1.05e-03 +- 2.34e-02\n",
      "[dimension 90/145]  inactive:\t1.23e-01 +- 3.07e-01\n",
      "[dimension 91/145]  inactive:\t-2.19e-04 +- 1.71e-02\n",
      "[dimension 92/145]  inactive:\t-1.23e-03 +- 2.60e-02\n",
      "[dimension 93/145]  inactive:\t-4.50e-04 +- 2.68e-02\n",
      "[dimension 94/145]  inactive:\t1.76e-03 +- 2.57e-02\n",
      "[dimension 95/145]  inactive:\t-3.71e-04 +- 2.08e-02\n",
      "[dimension 96/145]  inactive:\t9.94e-04 +- 4.57e-02\n",
      "[dimension 97/145]  inactive:\t2.61e-03 +- 2.51e-02\n",
      "[dimension 98/145]  inactive:\t-1.22e-03 +- 2.75e-02\n",
      "[dimension 99/145]  inactive:\t4.36e-03 +- 4.99e-02\n",
      "[dimension 100/145]  inactive:\t-7.02e-04 +- 1.61e-02\n",
      "[dimension 101/145]  inactive:\t-2.82e-03 +- 2.49e-02\n",
      "[dimension 102/145]  inactive:\t-6.42e-04 +- 2.90e-02\n",
      "[dimension 103/145]  inactive:\t6.87e-04 +- 2.35e-02\n",
      "[dimension 104/145]  inactive:\t-8.68e-04 +- 2.13e-02\n",
      "[dimension 105/145]  inactive:\t-9.41e-04 +- 3.09e-02\n",
      "[dimension 106/145]  inactive:\t4.90e-03 +- 3.14e-02\n",
      "[dimension 107/145]  inactive:\t-1.45e-03 +- 2.08e-02\n",
      "[dimension 108/145]  inactive:\t6.84e-03 +- 7.37e-02\n",
      "[dimension 109/145]  inactive:\t-7.06e-04 +- 2.15e-02\n",
      "[dimension 110/145]  inactive:\t-1.98e-03 +- 3.24e-02\n",
      "[dimension 111/145]  inactive:\t1.79e-03 +- 3.42e-02\n",
      "[dimension 112/145]  inactive:\t4.81e-03 +- 4.02e-02\n",
      "[dimension 113/145]  inactive:\t-2.04e-03 +- 2.86e-02\n",
      "[dimension 114/145]  inactive:\t2.92e-03 +- 5.55e-02\n",
      "[dimension 115/145]  inactive:\t2.62e-03 +- 2.48e-02\n",
      "[dimension 116/145]  inactive:\t1.83e-03 +- 4.69e-02\n",
      "[dimension 117/145]  inactive:\t3.99e-03 +- 4.22e-02\n",
      "[dimension 118/145]  inactive:\t3.46e-03 +- 2.61e-02\n",
      "[dimension 119/145]  inactive:\t-2.62e-03 +- 4.09e-02\n",
      "[dimension 120/145]  inactive:\t-2.32e-04 +- 2.54e-02\n",
      "[dimension 121/145]  inactive:\t5.98e-03 +- 4.38e-02\n",
      "[dimension 122/145]  inactive:\t-3.48e-03 +- 3.66e-02\n",
      "[dimension 123/145]  inactive:\t2.13e-03 +- 3.64e-02\n",
      "[dimension 124/145]  inactive:\t-2.28e-03 +- 2.24e-02\n",
      "[dimension 125/145]  inactive:\t-1.68e-03 +- 2.71e-02\n",
      "[dimension 126/145]  inactive:\t-1.46e-03 +- 2.67e-02\n",
      "[dimension 127/145]  inactive:\t4.73e-05 +- 1.95e-02\n",
      "[dimension 128/145]  inactive:\t-2.53e-03 +- 3.91e-02\n",
      "[dimension 129/145]  inactive:\t-1.55e-04 +- 2.67e-02\n",
      "[dimension 130/145]  inactive:\t4.16e-03 +- 3.02e-02\n",
      "[dimension 131/145]  inactive:\t-1.34e-03 +- 3.39e-02\n",
      "[dimension 132/145]  inactive:\t3.08e-03 +- 3.47e-02\n",
      "[dimension 133/145]  inactive:\t3.24e-03 +- 2.46e-02\n",
      "[dimension 134/145]  inactive:\t-9.74e-04 +- 2.70e-02\n",
      "[dimension 135/145]  inactive:\t1.20e-05 +- 3.31e-02\n",
      "[dimension 136/145]  inactive:\t1.36e-03 +- 2.10e-02\n",
      "[dimension 137/145]  inactive:\t-4.09e-04 +- 2.97e-02\n",
      "[dimension 138/145]  inactive:\t1.28e-03 +- 3.18e-02\n",
      "[dimension 139/145]  inactive:\t6.27e-04 +- 2.35e-02\n",
      "[dimension 140/145]  inactive:\t-1.14e-03 +- 2.90e-02\n",
      "[dimension 141/145]  inactive:\t1.08e-03 +- 2.62e-02\n",
      "[dimension 142/145]  inactive:\t1.18e-03 +- 1.73e-02\n",
      "[dimension 143/145]  inactive:\t1.28e-03 +- 3.52e-02\n",
      "[dimension 144/145]  inactive:\t4.43e-05 +- 2.21e-02\n",
      "[dimension 145/145]  inactive:\t-5.66e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.7177823]\n",
      "cov_act[[0.03501621]]\n",
      "Active_dimensions: [62]\n",
      "23, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.70it/s, 15 steps of size 1.97e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    494.76      1.00\n",
      "  lambda[0]      2.67      8.98      0.95      0.00      5.20    772.56      1.00\n",
      "  lambda[1]      7.60    148.29      0.94      0.00      5.36    884.90      1.00\n",
      "  lambda[2]      2.77      6.10      1.03      0.00      5.89    570.90      1.00\n",
      "  lambda[3]      9.75    165.74      1.01      0.00      7.94    943.17      1.00\n",
      "  lambda[4]      3.14     12.34      1.01      0.00      4.94    669.95      1.00\n",
      "  lambda[5]      3.09     11.07      0.98      0.00      6.41    578.22      1.00\n",
      "  lambda[6]      4.11     33.91      1.03      0.00      7.09   1006.87      1.00\n",
      "  lambda[7]      2.78      7.52      0.96      0.00      5.63    737.56      1.00\n",
      "  lambda[8]      2.76      7.04      1.00      0.01      6.06    559.93      1.01\n",
      "  lambda[9]      2.18      4.78      0.99      0.01      4.92   1014.15      1.00\n",
      " lambda[10]      3.14      7.45      1.02      0.00      7.08    796.89      1.01\n",
      " lambda[11]      3.19      9.45      1.05      0.01      6.31    488.31      1.00\n",
      " lambda[12]      9.60     79.95      1.04      0.00      8.06    553.66      1.01\n",
      " lambda[13]      4.24     41.23      0.93      0.00      4.86   1010.80      1.00\n",
      " lambda[14]      4.46     41.81      0.99      0.00      5.43    995.75      1.00\n",
      " lambda[15]      3.60     22.10      1.00      0.00      5.86    881.49      1.00\n",
      " lambda[16]      3.40     12.61      1.01      0.00      6.18    634.50      1.00\n",
      " lambda[17]      6.98    138.80      1.03      0.00      5.39    966.79      1.00\n",
      " lambda[18]      2.87      7.52      0.96      0.00      5.60    703.00      1.00\n",
      " lambda[19]      3.01      8.75      1.07      0.01      6.08    622.16      1.00\n",
      " lambda[20]      2.59      6.10      0.96      0.00      5.67    737.92      1.00\n",
      " lambda[21]      2.78      7.05      0.98      0.00      6.32    440.11      1.00\n",
      " lambda[22]      2.73      7.00      1.00      0.00      5.29    614.91      1.00\n",
      " lambda[23]     10.08     95.58      1.02      0.01      5.72    195.33      1.00\n",
      " lambda[24]      3.58     11.75      0.97      0.01      6.17    433.45      1.00\n",
      " lambda[25]      2.47      5.71      1.00      0.01      5.19    537.35      1.00\n",
      " lambda[26]      4.03     18.68      1.02      0.00      5.42    543.46      1.00\n",
      " lambda[27]      2.59      5.97      0.99      0.00      5.91    763.27      1.00\n",
      " lambda[28]      2.84     10.11      1.09      0.00      5.76    728.18      1.00\n",
      " lambda[29]      5.71     36.48      0.95      0.00      6.20    517.51      1.00\n",
      " lambda[30]      4.22     24.70      0.99      0.00      6.62    922.04      1.00\n",
      " lambda[31]      3.91     23.24      0.99      0.00      4.95    598.13      1.00\n",
      " lambda[32]      4.38     30.28      0.99      0.00      6.33    681.17      1.00\n",
      " lambda[33]      2.97     13.63      0.96      0.00      5.34    949.19      1.00\n",
      " lambda[34]      2.60     10.71      0.96      0.00      4.99    873.14      1.00\n",
      " lambda[35]      2.80      8.78      1.00      0.00      5.63    556.09      1.00\n",
      " lambda[36]      6.70    113.97      0.89      0.00      5.08    710.78      1.00\n",
      " lambda[37]      4.67     34.44      1.08      0.00      6.04    448.26      1.00\n",
      " lambda[38]      2.92      6.85      0.99      0.00      6.01    791.95      1.00\n",
      " lambda[39]      3.78     17.61      0.96      0.00      5.97    453.27      1.00\n",
      " lambda[40]      3.43     14.84      0.99      0.00      5.55    926.10      1.00\n",
      " lambda[41]     26.89    254.39      1.06      0.00     10.43    471.16      1.00\n",
      " lambda[42]      3.15     14.00      0.91      0.00      5.63    737.98      1.00\n",
      " lambda[43]      3.87     17.72      1.02      0.00      7.18    714.72      1.00\n",
      " lambda[44]      2.88      7.81      0.99      0.00      6.19    807.81      1.00\n",
      " lambda[45]      2.46      6.35      0.91      0.00      4.84    628.27      1.01\n",
      " lambda[46]      4.07     24.89      1.04      0.00      5.56    703.74      1.00\n",
      " lambda[47]      2.27      5.08      1.03      0.00      4.71    673.08      1.00\n",
      " lambda[48]      2.62      5.91      1.01      0.02      5.13    648.24      1.00\n",
      " lambda[49]      4.10     19.65      1.02      0.00      5.71    776.16      1.00\n",
      " lambda[50]      4.14     16.46      0.96      0.00      5.65    460.56      1.00\n",
      " lambda[51]      4.58     18.49      0.98      0.00      7.85    798.56      1.00\n",
      " lambda[52]      3.11     11.64      0.96      0.00      5.65    954.07      1.00\n",
      " lambda[53]      2.65      6.49      0.98      0.00      5.26    830.52      1.00\n",
      " lambda[54]      2.08      4.75      0.95      0.00      4.36    939.31      1.00\n",
      " lambda[55]      3.12     18.78      0.89      0.00      4.87    527.92      1.00\n",
      " lambda[56]      3.15      9.56      1.01      0.01      6.12    673.96      1.00\n",
      " lambda[57]      9.84     61.30      1.01      0.00      8.27    369.09      1.00\n",
      " lambda[58]      2.46      6.05      0.91      0.00      5.19    783.04      1.00\n",
      " lambda[59]      4.22     18.69      1.02      0.00      7.14    602.39      1.00\n",
      " lambda[60]      3.99     17.31      0.98      0.00      6.06    724.58      1.00\n",
      " lambda[61]      2.41      8.78      0.97      0.00      4.86    953.62      1.00\n",
      " lambda[62]   5583.34  87917.92    303.69      0.01   2510.44    736.03      1.00\n",
      " lambda[63]      3.18     17.27      0.94      0.00      5.36    893.28      1.00\n",
      " lambda[64]      2.71      5.78      1.03      0.00      5.98    803.60      1.00\n",
      " lambda[65]      2.85      8.28      0.98      0.00      5.00    760.68      1.00\n",
      " lambda[66]      2.81      6.41      0.99      0.00      5.63    699.81      1.00\n",
      " lambda[67]      3.03     11.17      1.00      0.00      5.91    548.18      1.00\n",
      " lambda[68]     19.66    508.44      1.02      0.00      5.66    949.00      1.00\n",
      " lambda[69]      4.69     17.75      0.98      0.00      8.59    652.95      1.00\n",
      " lambda[70]      2.85      9.34      0.99      0.01      5.61    810.50      1.00\n",
      " lambda[71]      4.56     34.85      0.95      0.00      5.57    913.52      1.00\n",
      " lambda[72]      2.39      6.55      0.97      0.00      4.21    710.33      1.00\n",
      " lambda[73]      3.50     10.71      1.00      0.00      5.79    665.28      1.00\n",
      " lambda[74]      3.02      8.63      1.00      0.01      5.92    601.79      1.00\n",
      " lambda[75]      5.12     19.35      1.08      0.00      8.44    468.34      1.01\n",
      " lambda[76]      3.19      9.73      0.98      0.00      5.98    586.17      1.00\n",
      " lambda[77]     10.22    104.48      1.05      0.00      7.88    553.69      1.00\n",
      " lambda[78]      3.53     10.96      1.02      0.01      5.92    598.08      1.00\n",
      " lambda[79]      2.86      7.89      1.00      0.01      5.23   1022.29      1.00\n",
      " lambda[80]      7.96     65.43      1.06      0.00      6.54    357.43      1.00\n",
      " lambda[81]      2.55      6.38      0.88      0.00      5.50    884.77      1.00\n",
      " lambda[82]      2.28      5.07      0.92      0.00      4.91    910.95      1.00\n",
      " lambda[83]      3.00      8.70      1.02      0.00      5.93    826.82      1.00\n",
      " lambda[84]      9.62    200.44      1.05      0.00      6.33    877.78      1.00\n",
      " lambda[85]      3.45     13.11      1.01      0.00      6.52    645.13      1.00\n",
      " lambda[86]      3.39     10.59      1.06      0.00      5.73    529.57      1.00\n",
      " lambda[87]      3.04      9.46      0.93      0.00      5.77    617.95      1.00\n",
      " lambda[88]      2.58      6.74      0.91      0.01      5.40    917.83      1.00\n",
      " lambda[89]     59.43    573.19      1.16      0.00     15.20    516.82      1.00\n",
      " lambda[90]      2.83     11.24      0.87      0.00      5.41    582.85      1.00\n",
      " lambda[91]      3.48     19.48      1.00      0.00      5.38    401.72      1.00\n",
      " lambda[92]      3.68     18.97      0.96      0.00      5.66    864.54      1.00\n",
      " lambda[93]      3.10      8.11      0.93      0.00      6.51    390.29      1.01\n",
      " lambda[94]      2.68      7.23      1.01      0.00      5.55    863.85      1.00\n",
      " lambda[95]      7.41     93.29      0.97      0.00      6.22    488.77      1.00\n",
      " lambda[96]      7.07    121.19      0.98      0.00      5.89    847.40      1.00\n",
      " lambda[97]      2.40      5.06      1.00      0.00      5.25    634.19      1.00\n",
      " lambda[98]      9.32    122.22      1.06      0.00      5.55    508.09      1.00\n",
      " lambda[99]      2.77      9.11      0.94      0.01      4.88    446.79      1.00\n",
      "lambda[100]      3.10     10.32      0.92      0.00      6.26    623.60      1.00\n",
      "lambda[101]      3.15      9.84      0.96      0.00      5.79    546.57      1.00\n",
      "lambda[102]      2.58      6.72      0.98      0.00      5.10    810.70      1.00\n",
      "lambda[103]      2.15      4.45      0.96      0.00      4.72    732.07      1.00\n",
      "lambda[104]      3.33     12.97      0.92      0.00      5.38    549.96      1.00\n",
      "lambda[105]      3.56     12.92      1.05      0.00      5.86    661.42      1.00\n",
      "lambda[106]      3.33     13.87      0.99      0.00      6.31    304.15      1.00\n",
      "lambda[107]      3.31      9.08      1.01      0.00      6.25    450.04      1.00\n",
      "lambda[108]      2.36      4.94      0.91      0.01      5.77    708.08      1.00\n",
      "lambda[109]      5.41     48.01      0.98      0.00      6.35    932.54      1.00\n",
      "lambda[110]      4.07     21.46      0.98      0.00      6.05    809.35      1.00\n",
      "lambda[111]     13.10    177.99      1.01      0.00      7.98    952.63      1.00\n",
      "lambda[112]      2.38      5.02      0.95      0.01      4.93    695.81      1.00\n",
      "lambda[113]      4.14     14.41      1.02      0.00      7.34    623.82      1.00\n",
      "lambda[114]      7.64    144.60      0.95      0.00      5.12   1003.35      1.00\n",
      "lambda[115]      4.03     18.89      0.99      0.00      6.37    560.74      1.00\n",
      "lambda[116]      5.66     64.26      1.02      0.01      6.16    656.87      1.00\n",
      "lambda[117]      3.67     23.33      0.92      0.00      5.44    915.41      1.00\n",
      "lambda[118]      2.67      7.75      0.91      0.00      5.16    755.34      1.00\n",
      "lambda[119]      3.05     11.23      1.01      0.00      5.70    688.60      1.00\n",
      "lambda[120]      8.89    113.80      1.02      0.00      8.60    863.32      1.00\n",
      "lambda[121]      2.72      7.25      1.00      0.00      5.88    753.57      1.00\n",
      "lambda[122]      4.13     23.19      0.93      0.00      5.99    871.30      1.00\n",
      "lambda[123]      2.53      5.66      0.99      0.00      5.45    649.49      1.01\n",
      "lambda[124]      2.50      5.80      0.98      0.00      5.24    582.92      1.00\n",
      "lambda[125]      2.26      4.75      0.98      0.01      4.85    547.14      1.00\n",
      "lambda[126]      2.40      6.83      0.99      0.00      4.61    855.33      1.00\n",
      "lambda[127]      3.47     12.98      0.98      0.00      5.55    579.82      1.00\n",
      "lambda[128]      2.91      7.51      0.96      0.00      5.65    430.90      1.00\n",
      "lambda[129]      5.28     36.04      0.96      0.00      7.04    919.83      1.00\n",
      "lambda[130]      3.67     22.59      0.91      0.00      5.80    905.81      1.00\n",
      "lambda[131]      7.73     72.38      0.96      0.00      5.33    700.39      1.00\n",
      "lambda[132]      3.37     13.35      1.02      0.00      5.78    793.37      1.00\n",
      "lambda[133]      3.18     10.07      1.01      0.00      5.38    827.45      1.00\n",
      "lambda[134]      2.83      6.43      1.02      0.00      6.33    921.75      1.00\n",
      "lambda[135]      3.04     26.34      0.92      0.00      4.03    674.15      1.00\n",
      "lambda[136]      3.18      9.11      0.98      0.00      7.19    836.75      1.00\n",
      "lambda[137]      3.10     10.89      0.98      0.00      5.67    961.09      1.00\n",
      "lambda[138]      3.55     19.28      0.92      0.00      5.25    760.85      1.00\n",
      "lambda[139]      3.13     13.51      0.96      0.00      5.53    583.59      1.00\n",
      "lambda[140]      4.21     16.42      0.98      0.00      7.28    690.85      1.00\n",
      "lambda[141]      2.93     11.28      0.95      0.00      5.70    832.90      1.00\n",
      "lambda[142]      4.78     35.54      0.97      0.00      6.99    566.60      1.00\n",
      "lambda[143]      2.59      6.20      0.96      0.00      5.17    523.78      1.00\n",
      "        msq      0.21      0.13      0.18      0.06      0.36    713.71      1.00\n",
      "      sigma      5.55      7.61      2.40      0.00     16.12   1067.94      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11   1068.47      1.00\n",
      "       xisq      0.11      0.06      0.10      0.04      0.19    834.60      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.25268602371216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.18e-04 +- 1.66e-02\n",
      "[dimension 02/145]  inactive:\t4.64e-04 +- 1.96e-02\n",
      "[dimension 03/145]  inactive:\t7.63e-04 +- 2.13e-02\n",
      "[dimension 04/145]  inactive:\t5.15e-03 +- 3.48e-02\n",
      "[dimension 05/145]  inactive:\t1.44e-04 +- 2.11e-02\n",
      "[dimension 06/145]  inactive:\t2.20e-03 +- 2.84e-02\n",
      "[dimension 07/145]  inactive:\t1.02e-03 +- 1.73e-02\n",
      "[dimension 08/145]  inactive:\t1.75e-03 +- 2.70e-02\n",
      "[dimension 09/145]  inactive:\t1.00e-03 +- 2.08e-02\n",
      "[dimension 10/145]  inactive:\t5.99e-04 +- 1.43e-02\n",
      "[dimension 11/145]  inactive:\t5.53e-04 +- 2.24e-02\n",
      "[dimension 12/145]  inactive:\t1.29e-03 +- 2.62e-02\n",
      "[dimension 13/145]  inactive:\t6.11e-03 +- 4.30e-02\n",
      "[dimension 14/145]  inactive:\t1.53e-04 +- 2.66e-02\n",
      "[dimension 15/145]  inactive:\t2.02e-03 +- 2.99e-02\n",
      "[dimension 16/145]  inactive:\t7.76e-04 +- 1.92e-02\n",
      "[dimension 17/145]  inactive:\t2.17e-03 +- 3.40e-02\n",
      "[dimension 18/145]  inactive:\t7.00e-04 +- 2.25e-02\n",
      "[dimension 19/145]  inactive:\t-1.29e-03 +- 1.73e-02\n",
      "[dimension 20/145]  inactive:\t-2.12e-04 +- 2.22e-02\n",
      "[dimension 21/145]  inactive:\t-8.83e-04 +- 1.72e-02\n",
      "[dimension 22/145]  inactive:\t2.34e-04 +- 1.94e-02\n",
      "[dimension 23/145]  inactive:\t2.81e-04 +- 2.17e-02\n",
      "[dimension 24/145]  inactive:\t2.85e-03 +- 3.19e-02\n",
      "[dimension 25/145]  inactive:\t3.15e-03 +- 2.08e-02\n",
      "[dimension 26/145]  inactive:\t4.50e-04 +- 2.50e-02\n",
      "[dimension 27/145]  inactive:\t1.49e-03 +- 2.22e-02\n",
      "[dimension 28/145]  inactive:\t9.50e-04 +- 1.72e-02\n",
      "[dimension 29/145]  inactive:\t1.25e-03 +- 2.39e-02\n",
      "[dimension 30/145]  inactive:\t2.72e-03 +- 3.22e-02\n",
      "[dimension 31/145]  inactive:\t4.91e-03 +- 3.51e-02\n",
      "[dimension 32/145]  inactive:\t8.80e-04 +- 2.89e-02\n",
      "[dimension 33/145]  inactive:\t3.97e-03 +- 3.82e-02\n",
      "[dimension 34/145]  inactive:\t7.93e-04 +- 1.82e-02\n",
      "[dimension 35/145]  inactive:\t8.38e-04 +- 1.94e-02\n",
      "[dimension 36/145]  inactive:\t2.17e-03 +- 2.61e-02\n",
      "[dimension 37/145]  inactive:\t3.18e-03 +- 2.30e-02\n",
      "[dimension 38/145]  inactive:\t-6.81e-05 +- 2.62e-02\n",
      "[dimension 39/145]  inactive:\t2.16e-03 +- 2.60e-02\n",
      "[dimension 40/145]  inactive:\t4.19e-03 +- 3.00e-02\n",
      "[dimension 41/145]  inactive:\t-3.53e-04 +- 2.09e-02\n",
      "[dimension 42/145]  inactive:\t2.09e-02 +- 1.12e-01\n",
      "[dimension 43/145]  inactive:\t3.16e-04 +- 1.72e-02\n",
      "[dimension 44/145]  inactive:\t8.55e-04 +- 2.64e-02\n",
      "[dimension 45/145]  inactive:\t3.56e-04 +- 2.15e-02\n",
      "[dimension 46/145]  inactive:\t6.73e-04 +- 1.23e-02\n",
      "[dimension 47/145]  inactive:\t-4.43e-04 +- 2.76e-02\n",
      "[dimension 48/145]  inactive:\t8.27e-04 +- 1.70e-02\n",
      "[dimension 49/145]  inactive:\t1.80e-03 +- 1.84e-02\n",
      "[dimension 50/145]  inactive:\t-4.09e-04 +- 2.87e-02\n",
      "[dimension 51/145]  inactive:\t3.24e-03 +- 3.08e-02\n",
      "[dimension 52/145]  inactive:\t6.08e-03 +- 2.63e-02\n",
      "[dimension 53/145]  inactive:\t-4.95e-04 +- 2.38e-02\n",
      "[dimension 54/145]  inactive:\t1.08e-03 +- 1.88e-02\n",
      "[dimension 55/145]  inactive:\t6.46e-04 +- 1.37e-02\n",
      "[dimension 56/145]  inactive:\t-1.02e-03 +- 1.62e-02\n",
      "[dimension 57/145]  inactive:\t1.82e-03 +- 2.55e-02\n",
      "[dimension 58/145]  inactive:\t1.48e-02 +- 7.55e-02\n",
      "[dimension 59/145]  inactive:\t3.52e-05 +- 1.73e-02\n",
      "[dimension 60/145]  inactive:\t4.12e-03 +- 3.78e-02\n",
      "[dimension 61/145]  inactive:\t3.35e-03 +- 2.61e-02\n",
      "[dimension 62/145]  inactive:\t9.39e-05 +- 1.49e-02\n",
      "[dimension 63/145]  active:\t6.69e-01 +- 3.55e-01\n",
      "[dimension 64/145]  inactive:\t-1.36e-03 +- 1.70e-02\n",
      "[dimension 65/145]  inactive:\t2.83e-04 +- 1.94e-02\n",
      "[dimension 66/145]  inactive:\t5.44e-04 +- 1.98e-02\n",
      "[dimension 67/145]  inactive:\t1.34e-03 +- 2.03e-02\n",
      "[dimension 68/145]  inactive:\t-4.87e-05 +- 2.65e-02\n",
      "[dimension 69/145]  inactive:\t3.79e-03 +- 3.77e-02\n",
      "[dimension 70/145]  inactive:\t5.31e-03 +- 2.82e-02\n",
      "[dimension 71/145]  inactive:\t5.57e-04 +- 2.17e-02\n",
      "[dimension 72/145]  inactive:\t1.64e-03 +- 2.46e-02\n",
      "[dimension 73/145]  inactive:\t6.91e-04 +- 1.67e-02\n",
      "[dimension 74/145]  inactive:\t3.31e-04 +- 2.54e-02\n",
      "[dimension 75/145]  inactive:\t1.11e-03 +- 2.14e-02\n",
      "[dimension 76/145]  inactive:\t7.29e-03 +- 4.34e-02\n",
      "[dimension 77/145]  inactive:\t1.22e-05 +- 2.77e-02\n",
      "[dimension 78/145]  inactive:\t9.99e-03 +- 6.70e-02\n",
      "[dimension 79/145]  inactive:\t6.49e-03 +- 3.68e-02\n",
      "[dimension 80/145]  inactive:\t9.44e-04 +- 2.41e-02\n",
      "[dimension 81/145]  inactive:\t4.36e-03 +- 3.98e-02\n",
      "[dimension 82/145]  inactive:\t5.03e-04 +- 1.46e-02\n",
      "[dimension 83/145]  inactive:\t-8.32e-04 +- 1.51e-02\n",
      "[dimension 84/145]  inactive:\t6.49e-05 +- 2.24e-02\n",
      "[dimension 85/145]  inactive:\t2.11e-03 +- 2.30e-02\n",
      "[dimension 86/145]  inactive:\t-2.20e-04 +- 1.88e-02\n",
      "[dimension 87/145]  inactive:\t2.33e-03 +- 2.74e-02\n",
      "[dimension 88/145]  inactive:\t2.38e-03 +- 2.07e-02\n",
      "[dimension 89/145]  inactive:\t-1.31e-04 +- 1.48e-02\n",
      "[dimension 90/145]  inactive:\t4.17e-02 +- 1.65e-01\n",
      "[dimension 91/145]  inactive:\t1.31e-04 +- 1.59e-02\n",
      "[dimension 92/145]  inactive:\t-8.85e-05 +- 2.15e-02\n",
      "[dimension 93/145]  inactive:\t-7.36e-05 +- 2.24e-02\n",
      "[dimension 94/145]  inactive:\t1.77e-03 +- 2.29e-02\n",
      "[dimension 95/145]  inactive:\t5.94e-04 +- 2.02e-02\n",
      "[dimension 96/145]  inactive:\t1.72e-03 +- 3.36e-02\n",
      "[dimension 97/145]  inactive:\t3.07e-03 +- 2.44e-02\n",
      "[dimension 98/145]  inactive:\t1.53e-04 +- 1.70e-02\n",
      "[dimension 99/145]  inactive:\t4.46e-03 +- 3.94e-02\n",
      "[dimension 100/145]  inactive:\t-1.36e-04 +- 1.46e-02\n",
      "[dimension 101/145]  inactive:\t-1.10e-03 +- 1.52e-02\n",
      "[dimension 102/145]  inactive:\t2.57e-04 +- 2.30e-02\n",
      "[dimension 103/145]  inactive:\t1.09e-03 +- 1.97e-02\n",
      "[dimension 104/145]  inactive:\t-4.95e-04 +- 1.68e-02\n",
      "[dimension 105/145]  inactive:\t1.29e-03 +- 2.57e-02\n",
      "[dimension 106/145]  inactive:\t5.09e-03 +- 3.27e-02\n",
      "[dimension 107/145]  inactive:\t-2.72e-04 +- 1.57e-02\n",
      "[dimension 108/145]  inactive:\t3.87e-03 +- 3.91e-02\n",
      "[dimension 109/145]  inactive:\t-1.11e-04 +- 1.68e-02\n",
      "[dimension 110/145]  inactive:\t1.17e-03 +- 2.52e-02\n",
      "[dimension 111/145]  inactive:\t2.62e-03 +- 3.01e-02\n",
      "[dimension 112/145]  inactive:\t6.71e-03 +- 4.84e-02\n",
      "[dimension 113/145]  inactive:\t-5.15e-04 +- 1.68e-02\n",
      "[dimension 114/145]  inactive:\t1.65e-03 +- 3.06e-02\n",
      "[dimension 115/145]  inactive:\t1.55e-03 +- 1.91e-02\n",
      "[dimension 116/145]  inactive:\t1.78e-03 +- 2.99e-02\n",
      "[dimension 117/145]  inactive:\t4.19e-03 +- 3.85e-02\n",
      "[dimension 118/145]  inactive:\t2.38e-03 +- 1.93e-02\n",
      "[dimension 119/145]  inactive:\t4.55e-04 +- 2.65e-02\n",
      "[dimension 120/145]  inactive:\t8.21e-04 +- 2.42e-02\n",
      "[dimension 121/145]  inactive:\t5.70e-03 +- 4.35e-02\n",
      "[dimension 122/145]  inactive:\t-5.19e-04 +- 2.01e-02\n",
      "[dimension 123/145]  inactive:\t3.23e-03 +- 3.72e-02\n",
      "[dimension 124/145]  inactive:\t-5.48e-04 +- 1.60e-02\n",
      "[dimension 125/145]  inactive:\t-4.34e-04 +- 1.94e-02\n",
      "[dimension 126/145]  inactive:\t-9.44e-05 +- 1.83e-02\n",
      "[dimension 127/145]  inactive:\t3.59e-04 +- 1.33e-02\n",
      "[dimension 128/145]  inactive:\t1.22e-03 +- 3.05e-02\n",
      "[dimension 129/145]  inactive:\t3.18e-04 +- 2.13e-02\n",
      "[dimension 130/145]  inactive:\t3.83e-03 +- 2.94e-02\n",
      "[dimension 131/145]  inactive:\t4.48e-04 +- 2.65e-02\n",
      "[dimension 132/145]  inactive:\t3.44e-03 +- 3.18e-02\n",
      "[dimension 133/145]  inactive:\t2.70e-03 +- 2.06e-02\n",
      "[dimension 134/145]  inactive:\t3.37e-04 +- 2.42e-02\n",
      "[dimension 135/145]  inactive:\t1.02e-03 +- 2.11e-02\n",
      "[dimension 136/145]  inactive:\t6.62e-04 +- 1.56e-02\n",
      "[dimension 137/145]  inactive:\t8.48e-04 +- 2.73e-02\n",
      "[dimension 138/145]  inactive:\t1.07e-03 +- 2.33e-02\n",
      "[dimension 139/145]  inactive:\t1.22e-03 +- 2.56e-02\n",
      "[dimension 140/145]  inactive:\t3.35e-04 +- 2.42e-02\n",
      "[dimension 141/145]  inactive:\t2.23e-03 +- 2.84e-02\n",
      "[dimension 142/145]  inactive:\t1.99e-03 +- 1.87e-02\n",
      "[dimension 143/145]  inactive:\t1.77e-03 +- 2.82e-02\n",
      "[dimension 144/145]  inactive:\t1.16e-03 +- 2.03e-02\n",
      "[dimension 145/145]  inactive:\t-1.52e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8421211]\n",
      "cov_act[[0.02689996]]\n",
      "Active_dimensions: [62]\n",
      "24, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.49it/s, 31 steps of size 1.70e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    638.25      1.00\n",
      "  lambda[0]      2.27      5.47      0.94      0.00      4.93    741.75      1.00\n",
      "  lambda[1]      2.71      7.30      0.97      0.00      5.39    626.47      1.01\n",
      "  lambda[2]      3.13      9.48      1.04      0.00      5.63    651.96      1.00\n",
      "  lambda[3]      5.36     29.54      0.97      0.00      7.87    539.20      1.00\n",
      "  lambda[4]      2.75      7.26      1.06      0.00      6.03    754.52      1.00\n",
      "  lambda[5]      3.80     11.84      1.03      0.00      7.34    688.06      1.00\n",
      "  lambda[6]      3.02      8.28      1.01      0.00      6.62    537.25      1.00\n",
      "  lambda[7]      3.15      8.86      0.94      0.00      6.25    628.56      1.01\n",
      "  lambda[8]      2.40      5.03      0.94      0.00      5.51    867.19      1.00\n",
      "  lambda[9]      2.73      8.70      0.92      0.00      4.96    642.85      1.00\n",
      " lambda[10]      3.69     17.39      1.04      0.00      5.37    398.94      1.00\n",
      " lambda[11]      3.09      9.59      0.96      0.01      6.40    850.71      1.00\n",
      " lambda[12]      4.32     11.62      1.07      0.00      8.68    506.51      1.00\n",
      " lambda[13]      3.10     10.80      0.97      0.00      5.71    480.01      1.00\n",
      " lambda[14]      4.05     24.20      0.90      0.00      4.61    528.23      1.00\n",
      " lambda[15]      2.96      8.42      0.97      0.00      5.74    793.14      1.00\n",
      " lambda[16]      3.17      8.49      1.01      0.00      6.64    758.87      1.00\n",
      " lambda[17]      2.77      7.80      0.96      0.01      5.53    596.54      1.00\n",
      " lambda[18]      2.74      6.29      0.96      0.00      5.81    397.63      1.00\n",
      " lambda[19]      3.44     19.11      1.00      0.00      6.10    932.10      1.00\n",
      " lambda[20]      2.91      7.74      0.92      0.01      6.06    687.40      1.00\n",
      " lambda[21]      2.81      7.89      1.01      0.01      5.98    731.17      1.00\n",
      " lambda[22]      2.51      5.79      0.97      0.00      5.49    739.43      1.00\n",
      " lambda[23]      3.04      8.28      0.99      0.00      5.79    727.84      1.00\n",
      " lambda[24]      3.49     12.99      1.00      0.00      6.64    797.33      1.00\n",
      " lambda[25]      2.95      7.53      0.99      0.01      6.00    641.38      1.00\n",
      " lambda[26]      2.96     10.41      1.01      0.01      4.61    543.75      1.00\n",
      " lambda[27]      2.83      7.27      1.00      0.00      5.78    680.30      1.00\n",
      " lambda[28]      2.88      9.56      0.98      0.00      5.45    510.67      1.00\n",
      " lambda[29]      3.16     12.40      0.95      0.00      6.13    694.51      1.00\n",
      " lambda[30]      3.29     11.68      1.00      0.01      5.91    969.00      1.00\n",
      " lambda[31]      4.01     17.86      0.95      0.00      6.72    692.95      1.00\n",
      " lambda[32]      2.96      8.04      1.01      0.00      6.25    945.31      1.00\n",
      " lambda[33]      3.07     11.47      0.93      0.00      6.34    786.48      1.00\n",
      " lambda[34]      3.02     10.07      0.98      0.00      5.62    612.45      1.00\n",
      " lambda[35]      3.93     33.83      1.09      0.00      5.52    500.43      1.00\n",
      " lambda[36]      3.82     16.74      1.05      0.00      6.57    703.73      1.00\n",
      " lambda[37]      3.23     12.49      1.00      0.00      5.51    873.41      1.00\n",
      " lambda[38]      3.07      8.56      0.90      0.00      6.18    799.57      1.00\n",
      " lambda[39]      3.34      8.91      0.96      0.00      5.94    688.74      1.00\n",
      " lambda[40]      5.05     34.06      0.89      0.00      6.22    665.00      1.00\n",
      " lambda[41]     11.53    100.60      0.94      0.00      7.64    520.41      1.01\n",
      " lambda[42]      2.75      6.59      0.96      0.00      5.87    586.64      1.00\n",
      " lambda[43]      5.47     70.03      0.97      0.00      6.00   1010.34      1.00\n",
      " lambda[44]      2.69      5.72      0.98      0.00      6.16    729.62      1.00\n",
      " lambda[45]      2.75      8.03      0.98      0.00      5.08    769.88      1.00\n",
      " lambda[46]      2.79      7.88      1.04      0.00      5.39    690.50      1.00\n",
      " lambda[47]      2.70      7.31      0.92      0.00      5.55    610.15      1.00\n",
      " lambda[48]      2.84      9.02      0.97      0.01      5.07    750.40      1.00\n",
      " lambda[49]      3.60     12.19      0.96      0.00      6.69    789.82      1.00\n",
      " lambda[50]      4.02     18.85      0.97      0.00      6.10    722.57      1.00\n",
      " lambda[51]      3.89     11.76      1.01      0.00      7.31    649.30      1.00\n",
      " lambda[52]      3.05      8.57      0.95      0.00      6.23    649.94      1.00\n",
      " lambda[53]      3.09     13.33      0.97      0.00      5.18    857.68      1.00\n",
      " lambda[54]      2.60      8.72      1.02      0.00      4.76    668.32      1.00\n",
      " lambda[55]      2.91     12.18      0.96      0.00      4.87    893.24      1.00\n",
      " lambda[56]      2.69      6.21      0.97      0.00      5.57    721.71      1.00\n",
      " lambda[57]      6.08     35.72      1.01      0.00      7.83    351.97      1.00\n",
      " lambda[58]      2.44      5.26      0.96      0.00      5.56    665.70      1.00\n",
      " lambda[59]      3.53     13.56      0.94      0.00      6.57    699.48      1.00\n",
      " lambda[60]      3.02      9.87      0.89      0.00      5.58    872.23      1.00\n",
      " lambda[61]      2.79      9.26      0.97      0.00      5.30    532.74      1.00\n",
      " lambda[62]    758.38  10262.81    171.89      0.00    964.40    975.49      1.00\n",
      " lambda[63]      2.45      5.83      1.00      0.00      4.94    801.83      1.00\n",
      " lambda[64]      2.98      8.48      0.96      0.00      5.21    710.59      1.00\n",
      " lambda[65]      2.80      7.53      0.98      0.00      5.50    812.24      1.00\n",
      " lambda[66]      3.16      7.86      1.01      0.00      7.03    576.46      1.00\n",
      " lambda[67]      2.52      6.87      0.92      0.00      5.19    753.51      1.00\n",
      " lambda[68]      4.57     39.76      0.99      0.00      5.96    632.72      1.00\n",
      " lambda[69]      3.44     14.79      0.88      0.00      5.46    888.81      1.00\n",
      " lambda[70]      2.61      6.77      1.02      0.01      5.47    529.38      1.00\n",
      " lambda[71]      3.50     11.39      0.97      0.00      5.77    460.28      1.00\n",
      " lambda[72]      2.60      7.62      0.98      0.01      5.27    455.97      1.00\n",
      " lambda[73]      2.58      5.70      1.04      0.00      5.26    775.67      1.00\n",
      " lambda[74]      2.61      5.63      1.06      0.00      5.40    857.55      1.00\n",
      " lambda[75]      3.75     12.61      0.97      0.00      6.83    731.86      1.00\n",
      " lambda[76]      3.34     11.25      1.05      0.00      6.10    757.31      1.00\n",
      " lambda[77]      4.72     47.13      1.05      0.00      6.60    739.36      1.00\n",
      " lambda[78]      2.81      5.91      1.02      0.00      6.66    857.35      1.00\n",
      " lambda[79]      2.67      6.64      1.03      0.00      5.33    712.36      1.01\n",
      " lambda[80]      3.63     19.41      1.00      0.00      6.64    553.54      1.00\n",
      " lambda[81]      2.47      5.89      0.89      0.00      5.00    904.71      1.00\n",
      " lambda[82]      2.59      8.95      0.93      0.00      4.71    683.45      1.00\n",
      " lambda[83]      3.11     11.39      0.90      0.00      5.73    854.12      1.00\n",
      " lambda[84]      4.56     28.03      1.00      0.00      6.80    783.22      1.00\n",
      " lambda[85]      2.61      7.83      0.94      0.00      5.93    776.17      1.00\n",
      " lambda[86]      3.41     10.38      0.96      0.00      6.36    705.59      1.00\n",
      " lambda[87]      3.52     16.47      0.99      0.00      6.40    658.37      1.00\n",
      " lambda[88]      2.79      7.47      0.99      0.00      5.85    840.79      1.00\n",
      " lambda[89]     53.76    251.21      1.30      0.00     77.54    339.16      1.00\n",
      " lambda[90]      2.43      5.59      0.95      0.00      5.20    902.32      1.00\n",
      " lambda[91]      2.71      7.26      1.01      0.00      5.33    824.07      1.00\n",
      " lambda[92]      2.51      5.56      1.02      0.00      5.30    699.87      1.00\n",
      " lambda[93]      2.78      6.83      1.01      0.00      6.07    479.94      1.00\n",
      " lambda[94]      2.51      7.22      1.01      0.00      5.19    851.05      1.00\n",
      " lambda[95]      3.76     21.95      0.97      0.00      5.56    511.81      1.00\n",
      " lambda[96]      2.52      5.69      0.96      0.00      5.27    680.89      1.00\n",
      " lambda[97]      3.36     12.12      0.95      0.00      5.89    578.71      1.01\n",
      " lambda[98]      4.43     41.75      0.97      0.00      6.27    924.28      1.00\n",
      " lambda[99]      2.59      6.78      0.93      0.00      5.38    724.24      1.00\n",
      "lambda[100]      4.08     36.01      0.97      0.00      6.14    946.61      1.00\n",
      "lambda[101]      2.85      8.41      0.93      0.00      5.60    649.30      1.00\n",
      "lambda[102]      3.33     12.26      0.99      0.00      5.72    562.33      1.00\n",
      "lambda[103]      2.43      5.61      1.01      0.00      4.95    684.73      1.00\n",
      "lambda[104]      3.25     11.53      0.98      0.00      6.07    412.84      1.00\n",
      "lambda[105]      3.18      8.14      1.04      0.00      6.68    590.11      1.00\n",
      "lambda[106]      2.58      6.20      0.98      0.00      5.83    738.56      1.00\n",
      "lambda[107]      3.73     13.52      0.98      0.00      6.14    680.61      1.00\n",
      "lambda[108]      2.39      5.19      0.92      0.00      5.29    531.43      1.00\n",
      "lambda[109]      6.76     99.54      0.95      0.00      6.17    980.61      1.00\n",
      "lambda[110]      3.69     14.55      0.95      0.00      6.40    746.36      1.00\n",
      "lambda[111]      4.39     31.22      1.00      0.00      6.57    763.76      1.00\n",
      "lambda[112]      2.52      5.49      0.94      0.01      5.51    796.43      1.00\n",
      "lambda[113]      3.42     11.92      1.05      0.00      5.85    637.62      1.00\n",
      "lambda[114]      3.32     12.63      0.96      0.00      5.96    954.16      1.00\n",
      "lambda[115]      4.19     23.45      0.94      0.00      5.98    563.26      1.00\n",
      "lambda[116]      4.41     34.64      1.00      0.00      5.42    471.87      1.00\n",
      "lambda[117]      3.58     13.28      0.96      0.00      7.03    787.36      1.00\n",
      "lambda[118]      3.35     11.34      1.04      0.00      6.10    745.82      1.00\n",
      "lambda[119]      2.89     10.67      1.01      0.00      5.75    857.23      1.00\n",
      "lambda[120]      4.59     24.15      1.03      0.00      7.68    955.76      1.00\n",
      "lambda[121]      3.34     12.19      0.92      0.00      6.24    788.28      1.00\n",
      "lambda[122]      3.00      8.47      0.96      0.00      6.55    827.44      1.00\n",
      "lambda[123]      2.77      7.60      0.92      0.00      5.66    725.39      1.00\n",
      "lambda[124]      2.78      6.96      0.96      0.00      6.57    886.51      1.00\n",
      "lambda[125]      3.13      9.85      1.01      0.00      6.03    570.94      1.00\n",
      "lambda[126]      2.40      6.02      0.94      0.00      4.71    790.75      1.00\n",
      "lambda[127]      3.56     14.35      0.99      0.00      6.05    785.10      1.00\n",
      "lambda[128]      2.37      4.49      0.97      0.00      5.39    532.66      1.00\n",
      "lambda[129]      4.32     29.80      1.05      0.00      6.83    974.21      1.00\n",
      "lambda[130]      3.40     14.50      0.97      0.00      5.83    793.85      1.00\n",
      "lambda[131]      3.70     13.76      1.01      0.00      6.87    607.55      1.00\n",
      "lambda[132]      2.75      6.44      1.03      0.00      5.73    596.53      1.00\n",
      "lambda[133]      2.55      6.62      1.00      0.00      4.97    864.25      1.00\n",
      "lambda[134]      3.85     11.02      0.93      0.00      7.72    562.45      1.01\n",
      "lambda[135]      3.07     11.59      0.91      0.00      5.87    746.67      1.00\n",
      "lambda[136]      2.85      6.94      0.99      0.00      5.72    712.58      1.00\n",
      "lambda[137]      3.27     11.32      0.98      0.00      4.82    451.01      1.00\n",
      "lambda[138]      2.84      7.71      1.01      0.00      5.61    890.68      1.00\n",
      "lambda[139]      3.40     12.13      1.01      0.00      6.53    740.51      1.00\n",
      "lambda[140]      3.10      8.73      1.02      0.00      6.18    831.63      1.00\n",
      "lambda[141]      2.35      5.51      0.88      0.00      5.02    797.19      1.00\n",
      "lambda[142]      4.16     19.67      0.95      0.01      6.66    669.61      1.00\n",
      "lambda[143]      2.10      4.44      0.97      0.00      4.78    737.84      1.00\n",
      "        msq   6529.95  71385.22     31.04      0.73    819.53    585.96      1.00\n",
      "      sigma      3.42      4.40      1.68      0.01      8.74   1353.67      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1051.25      1.00\n",
      "       xisq     54.94    619.83      2.02      0.08     23.60    940.59      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 34.1065719127655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-8.77e-05 +- 1.65e-02\n",
      "[dimension 02/145]  inactive:\t-7.85e-04 +- 2.49e-02\n",
      "[dimension 03/145]  inactive:\t6.02e-04 +- 2.91e-02\n",
      "[dimension 04/145]  inactive:\t7.38e-03 +- 4.55e-02\n",
      "[dimension 05/145]  inactive:\t-6.48e-04 +- 2.62e-02\n",
      "[dimension 06/145]  inactive:\t2.99e-03 +- 4.08e-02\n",
      "[dimension 07/145]  inactive:\t8.89e-04 +- 2.03e-02\n",
      "[dimension 08/145]  inactive:\t6.11e-04 +- 3.08e-02\n",
      "[dimension 09/145]  inactive:\t2.11e-04 +- 2.23e-02\n",
      "[dimension 10/145]  inactive:\t4.41e-04 +- 1.97e-02\n",
      "[dimension 11/145]  inactive:\t-1.38e-03 +- 2.64e-02\n",
      "[dimension 12/145]  inactive:\t2.04e-04 +- 3.16e-02\n",
      "[dimension 13/145]  inactive:\t5.76e-03 +- 4.44e-02\n",
      "[dimension 14/145]  inactive:\t-2.07e-03 +- 2.68e-02\n",
      "[dimension 15/145]  inactive:\t4.37e-04 +- 3.32e-02\n",
      "[dimension 16/145]  inactive:\t9.36e-04 +- 2.26e-02\n",
      "[dimension 17/145]  inactive:\t-4.45e-04 +- 2.91e-02\n",
      "[dimension 18/145]  inactive:\t-2.15e-04 +- 2.94e-02\n",
      "[dimension 19/145]  inactive:\t-2.70e-03 +- 2.49e-02\n",
      "[dimension 20/145]  inactive:\t-1.87e-03 +- 3.04e-02\n",
      "[dimension 21/145]  inactive:\t-1.89e-03 +- 2.78e-02\n",
      "[dimension 22/145]  inactive:\t1.90e-04 +- 2.07e-02\n",
      "[dimension 23/145]  inactive:\t-6.13e-04 +- 2.69e-02\n",
      "[dimension 24/145]  inactive:\t1.97e-03 +- 3.03e-02\n",
      "[dimension 25/145]  inactive:\t3.11e-03 +- 2.27e-02\n",
      "[dimension 26/145]  inactive:\t-1.34e-03 +- 3.02e-02\n",
      "[dimension 27/145]  inactive:\t6.14e-04 +- 2.43e-02\n",
      "[dimension 28/145]  inactive:\t7.79e-04 +- 2.16e-02\n",
      "[dimension 29/145]  inactive:\t-2.71e-04 +- 2.98e-02\n",
      "[dimension 30/145]  inactive:\t1.67e-03 +- 3.18e-02\n",
      "[dimension 31/145]  inactive:\t5.38e-03 +- 4.45e-02\n",
      "[dimension 32/145]  inactive:\t-2.17e-03 +- 2.83e-02\n",
      "[dimension 33/145]  inactive:\t2.08e-03 +- 3.66e-02\n",
      "[dimension 34/145]  inactive:\t9.97e-04 +- 2.03e-02\n",
      "[dimension 35/145]  inactive:\t1.06e-04 +- 2.34e-02\n",
      "[dimension 36/145]  inactive:\t1.67e-03 +- 3.02e-02\n",
      "[dimension 37/145]  inactive:\t4.42e-03 +- 2.83e-02\n",
      "[dimension 38/145]  inactive:\t-2.04e-03 +- 2.96e-02\n",
      "[dimension 39/145]  inactive:\t1.17e-03 +- 3.05e-02\n",
      "[dimension 40/145]  inactive:\t5.41e-03 +- 3.95e-02\n",
      "[dimension 41/145]  inactive:\t-2.41e-03 +- 4.07e-02\n",
      "[dimension 42/145]  inactive:\t1.39e-02 +- 9.39e-02\n",
      "[dimension 43/145]  inactive:\t-4.22e-04 +- 2.22e-02\n",
      "[dimension 44/145]  inactive:\t-5.87e-04 +- 3.10e-02\n",
      "[dimension 45/145]  inactive:\t-5.53e-04 +- 2.62e-02\n",
      "[dimension 46/145]  inactive:\t1.27e-03 +- 1.76e-02\n",
      "[dimension 47/145]  inactive:\t-2.53e-03 +- 3.34e-02\n",
      "[dimension 48/145]  inactive:\t1.46e-03 +- 2.46e-02\n",
      "[dimension 49/145]  inactive:\t2.65e-03 +- 2.39e-02\n",
      "[dimension 50/145]  inactive:\t-2.58e-03 +- 3.54e-02\n",
      "[dimension 51/145]  inactive:\t4.57e-03 +- 3.95e-02\n",
      "[dimension 52/145]  inactive:\t6.40e-03 +- 2.78e-02\n",
      "[dimension 53/145]  inactive:\t-1.28e-03 +- 2.89e-02\n",
      "[dimension 54/145]  inactive:\t3.01e-04 +- 2.17e-02\n",
      "[dimension 55/145]  inactive:\t5.74e-04 +- 1.66e-02\n",
      "[dimension 56/145]  inactive:\t-2.01e-03 +- 2.22e-02\n",
      "[dimension 57/145]  inactive:\t5.08e-04 +- 2.76e-02\n",
      "[dimension 58/145]  inactive:\t1.68e-02 +- 8.44e-02\n",
      "[dimension 59/145]  inactive:\t-5.91e-04 +- 1.84e-02\n",
      "[dimension 60/145]  inactive:\t1.31e-03 +- 3.72e-02\n",
      "[dimension 61/145]  inactive:\t2.81e-03 +- 2.65e-02\n",
      "[dimension 62/145]  inactive:\t-5.95e-04 +- 2.37e-02\n",
      "[dimension 63/145]  active:\t7.07e-01 +- 4.20e-01\n",
      "[dimension 64/145]  inactive:\t-1.85e-03 +- 2.09e-02\n",
      "[dimension 65/145]  inactive:\t-6.50e-04 +- 2.60e-02\n",
      "[dimension 66/145]  inactive:\t5.11e-04 +- 2.42e-02\n",
      "[dimension 67/145]  inactive:\t1.74e-03 +- 2.95e-02\n",
      "[dimension 68/145]  inactive:\t-5.74e-04 +- 2.42e-02\n",
      "[dimension 69/145]  inactive:\t4.28e-03 +- 4.62e-02\n",
      "[dimension 70/145]  inactive:\t3.43e-03 +- 2.43e-02\n",
      "[dimension 71/145]  inactive:\t1.45e-04 +- 2.30e-02\n",
      "[dimension 72/145]  inactive:\t1.22e-03 +- 2.76e-02\n",
      "[dimension 73/145]  inactive:\t3.26e-04 +- 1.81e-02\n",
      "[dimension 74/145]  inactive:\t-1.20e-03 +- 2.91e-02\n",
      "[dimension 75/145]  inactive:\t8.14e-04 +- 2.73e-02\n",
      "[dimension 76/145]  inactive:\t5.00e-03 +- 3.52e-02\n",
      "[dimension 77/145]  inactive:\t-1.81e-03 +- 3.35e-02\n",
      "[dimension 78/145]  inactive:\t4.92e-03 +- 5.31e-02\n",
      "[dimension 79/145]  inactive:\t4.67e-03 +- 2.83e-02\n",
      "[dimension 80/145]  inactive:\t-3.85e-04 +- 2.64e-02\n",
      "[dimension 81/145]  inactive:\t1.25e-03 +- 3.04e-02\n",
      "[dimension 82/145]  inactive:\t2.01e-04 +- 1.71e-02\n",
      "[dimension 83/145]  inactive:\t-1.65e-03 +- 1.73e-02\n",
      "[dimension 84/145]  inactive:\t-1.20e-03 +- 2.77e-02\n",
      "[dimension 85/145]  inactive:\t4.45e-03 +- 4.00e-02\n",
      "[dimension 86/145]  inactive:\t-6.17e-04 +- 2.00e-02\n",
      "[dimension 87/145]  inactive:\t3.57e-03 +- 4.37e-02\n",
      "[dimension 88/145]  inactive:\t2.79e-03 +- 2.48e-02\n",
      "[dimension 89/145]  inactive:\t-1.07e-03 +- 2.39e-02\n",
      "[dimension 90/145]  inactive:\t1.07e-01 +- 2.89e-01\n",
      "[dimension 91/145]  inactive:\t-1.70e-04 +- 1.79e-02\n",
      "[dimension 92/145]  inactive:\t-1.62e-03 +- 2.63e-02\n",
      "[dimension 93/145]  inactive:\t-5.63e-04 +- 2.78e-02\n",
      "[dimension 94/145]  inactive:\t2.34e-03 +- 3.19e-02\n",
      "[dimension 95/145]  inactive:\t-4.20e-04 +- 1.97e-02\n",
      "[dimension 96/145]  inactive:\t2.25e-03 +- 4.94e-02\n",
      "[dimension 97/145]  inactive:\t1.86e-03 +- 2.00e-02\n",
      "[dimension 98/145]  inactive:\t-9.56e-04 +- 2.77e-02\n",
      "[dimension 99/145]  inactive:\t3.22e-03 +- 4.06e-02\n",
      "[dimension 100/145]  inactive:\t-7.12e-04 +- 1.71e-02\n",
      "[dimension 101/145]  inactive:\t-2.88e-03 +- 2.33e-02\n",
      "[dimension 102/145]  inactive:\t-4.70e-04 +- 2.57e-02\n",
      "[dimension 103/145]  inactive:\t9.84e-04 +- 2.55e-02\n",
      "[dimension 104/145]  inactive:\t-8.59e-04 +- 1.91e-02\n",
      "[dimension 105/145]  inactive:\t-2.62e-04 +- 2.63e-02\n",
      "[dimension 106/145]  inactive:\t5.22e-03 +- 3.47e-02\n",
      "[dimension 107/145]  inactive:\t-1.15e-03 +- 2.00e-02\n",
      "[dimension 108/145]  inactive:\t7.09e-03 +- 7.33e-02\n",
      "[dimension 109/145]  inactive:\t-2.54e-04 +- 1.86e-02\n",
      "[dimension 110/145]  inactive:\t-1.49e-03 +- 3.32e-02\n",
      "[dimension 111/145]  inactive:\t2.09e-03 +- 3.20e-02\n",
      "[dimension 112/145]  inactive:\t5.70e-03 +- 4.86e-02\n",
      "[dimension 113/145]  inactive:\t-1.38e-03 +- 2.21e-02\n",
      "[dimension 114/145]  inactive:\t4.49e-04 +- 3.13e-02\n",
      "[dimension 115/145]  inactive:\t1.96e-03 +- 2.36e-02\n",
      "[dimension 116/145]  inactive:\t2.18e-03 +- 5.68e-02\n",
      "[dimension 117/145]  inactive:\t4.87e-03 +- 5.34e-02\n",
      "[dimension 118/145]  inactive:\t3.17e-03 +- 2.57e-02\n",
      "[dimension 119/145]  inactive:\t-2.07e-03 +- 2.89e-02\n",
      "[dimension 120/145]  inactive:\t-8.91e-05 +- 2.53e-02\n",
      "[dimension 121/145]  inactive:\t5.75e-03 +- 4.39e-02\n",
      "[dimension 122/145]  inactive:\t-3.36e-03 +- 4.62e-02\n",
      "[dimension 123/145]  inactive:\t2.83e-03 +- 4.16e-02\n",
      "[dimension 124/145]  inactive:\t-1.26e-03 +- 2.00e-02\n",
      "[dimension 125/145]  inactive:\t-1.41e-03 +- 2.88e-02\n",
      "[dimension 126/145]  inactive:\t-5.11e-04 +- 2.68e-02\n",
      "[dimension 127/145]  inactive:\t1.14e-06 +- 1.83e-02\n",
      "[dimension 128/145]  inactive:\t-5.85e-04 +- 3.35e-02\n",
      "[dimension 129/145]  inactive:\t-6.85e-05 +- 2.60e-02\n",
      "[dimension 130/145]  inactive:\t3.64e-03 +- 2.83e-02\n",
      "[dimension 131/145]  inactive:\t-1.10e-03 +- 3.02e-02\n",
      "[dimension 132/145]  inactive:\t5.38e-03 +- 4.88e-02\n",
      "[dimension 133/145]  inactive:\t2.58e-03 +- 2.20e-02\n",
      "[dimension 134/145]  inactive:\t-9.56e-04 +- 2.93e-02\n",
      "[dimension 135/145]  inactive:\t5.12e-04 +- 3.23e-02\n",
      "[dimension 136/145]  inactive:\t1.21e-03 +- 2.17e-02\n",
      "[dimension 137/145]  inactive:\t-3.06e-04 +- 3.29e-02\n",
      "[dimension 138/145]  inactive:\t4.20e-04 +- 2.51e-02\n",
      "[dimension 139/145]  inactive:\t4.49e-04 +- 2.32e-02\n",
      "[dimension 140/145]  inactive:\t-1.40e-03 +- 2.95e-02\n",
      "[dimension 141/145]  inactive:\t1.45e-03 +- 3.03e-02\n",
      "[dimension 142/145]  inactive:\t1.34e-03 +- 1.78e-02\n",
      "[dimension 143/145]  inactive:\t2.38e-03 +- 4.64e-02\n",
      "[dimension 144/145]  inactive:\t4.59e-04 +- 1.97e-02\n",
      "[dimension 145/145]  inactive:\t-1.49e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8620695]\n",
      "cov_act[[0.02235064]]\n",
      "Active_dimensions: [62]\n",
      "25, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 48.69it/s, 31 steps of size 1.56e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    481.47      1.00\n",
      "  lambda[0]      2.17      4.45      0.93      0.00      4.61    667.71      1.00\n",
      "  lambda[1]      3.29     11.47      1.00      0.00      5.77    651.30      1.01\n",
      "  lambda[2]      2.64      6.87      0.99      0.00      5.79    654.91      1.00\n",
      "  lambda[3]      3.49     14.11      0.95      0.00      6.58    653.85      1.01\n",
      "  lambda[4]      2.50      5.57      1.03      0.00      4.86   1020.79      1.00\n",
      "  lambda[5]      4.64     39.09      0.99      0.00      6.17    716.19      1.00\n",
      "  lambda[6]      3.68     13.75      1.00      0.00      7.01    834.83      1.00\n",
      "  lambda[7]      3.69     12.29      0.99      0.00      6.23    490.68      1.01\n",
      "  lambda[8]      2.29      4.21      0.96      0.00      5.25   1046.31      1.00\n",
      "  lambda[9]      2.40      6.77      0.96      0.00      4.59    650.56      1.00\n",
      " lambda[10]      3.03      9.56      1.09      0.00      5.89    720.24      1.00\n",
      " lambda[11]      2.90      7.23      1.04      0.01      6.17    474.24      1.00\n",
      " lambda[12]      4.31     14.91      1.02      0.00      8.32    746.68      1.00\n",
      " lambda[13]      2.80     10.73      0.93      0.00      6.12    866.65      1.00\n",
      " lambda[14]      2.98     10.34      0.94      0.01      4.98    797.10      1.00\n",
      " lambda[15]      3.17     10.95      0.97      0.00      5.50    629.52      1.00\n",
      " lambda[16]      3.50      9.35      0.97      0.00      7.89    602.52      1.00\n",
      " lambda[17]      2.98     14.37      0.97      0.00      5.17    717.38      1.00\n",
      " lambda[18]      2.51      5.59      0.96      0.00      5.21    581.91      1.00\n",
      " lambda[19]      3.27     11.37      0.94      0.00      6.25    773.17      1.00\n",
      " lambda[20]      2.96      7.44      0.96      0.00      6.25    709.79      1.00\n",
      " lambda[21]      3.15      9.79      1.01      0.00      6.68    886.11      1.00\n",
      " lambda[22]      2.54      5.30      1.00      0.00      5.30    669.90      1.01\n",
      " lambda[23]      3.01      8.88      0.96      0.00      6.04    788.02      1.00\n",
      " lambda[24]      3.96     16.13      1.02      0.00      6.08    627.17      1.00\n",
      " lambda[25]      3.12      9.60      0.99      0.01      6.16    498.51      1.00\n",
      " lambda[26]      2.62      6.54      1.00      0.00      5.16    823.72      1.00\n",
      " lambda[27]      3.11      9.26      0.98      0.00      5.76    651.74      1.00\n",
      " lambda[28]      2.90      8.78      1.02      0.00      5.47    623.07      1.00\n",
      " lambda[29]      3.12     10.39      0.99      0.00      5.72    520.77      1.00\n",
      " lambda[30]      3.12      8.09      1.03      0.01      6.28    873.72      1.00\n",
      " lambda[31]      3.73     14.95      0.99      0.00      6.31    669.99      1.00\n",
      " lambda[32]      2.99      8.49      0.97      0.00      6.27    805.74      1.00\n",
      " lambda[33]      2.96      7.92      1.00      0.01      6.03    396.39      1.00\n",
      " lambda[34]      2.77     10.98      0.95      0.00      4.60    742.38      1.00\n",
      " lambda[35]      2.61      7.89      0.99      0.00      4.97    932.67      1.00\n",
      " lambda[36]      3.35     11.12      1.03      0.00      5.71    725.00      1.00\n",
      " lambda[37]      2.98     10.14      0.94      0.00      5.10    824.05      1.00\n",
      " lambda[38]      2.71      5.92      0.95      0.00      5.55    854.82      1.00\n",
      " lambda[39]      3.12     10.05      0.97      0.00      6.00    768.55      1.00\n",
      " lambda[40]      3.74     14.06      0.92      0.00      6.67    881.62      1.00\n",
      " lambda[41]     21.31    180.95      0.97      0.00     10.12    413.83      1.01\n",
      " lambda[42]      3.07     16.56      0.93      0.00      5.87   1027.09      1.00\n",
      " lambda[43]      3.46     22.11      1.01      0.00      5.97    973.43      1.00\n",
      " lambda[44]      2.63      5.70      0.94      0.00      6.12    443.09      1.00\n",
      " lambda[45]      2.55      6.03      0.99      0.00      5.03    882.14      1.00\n",
      " lambda[46]      2.64      7.44      1.00      0.00      5.12    859.52      1.00\n",
      " lambda[47]      2.59      5.78      0.95      0.00      6.06    726.59      1.00\n",
      " lambda[48]      2.64      8.49      0.99      0.01      5.11    791.39      1.00\n",
      " lambda[49]      3.20     10.26      0.94      0.00      6.25    784.88      1.00\n",
      " lambda[50]      2.82      7.78      0.97      0.00      6.14    744.71      1.00\n",
      " lambda[51]      4.40     16.73      1.00      0.00      8.71    761.76      1.00\n",
      " lambda[52]      3.54     17.01      0.93      0.00      5.47    664.78      1.00\n",
      " lambda[53]      3.48     13.62      0.95      0.00      6.05    645.98      1.00\n",
      " lambda[54]      2.12      4.68      0.93      0.00      4.59    624.13      1.00\n",
      " lambda[55]      4.02     21.42      0.97      0.00      5.86    649.79      1.00\n",
      " lambda[56]      2.70      6.01      0.97      0.00      5.33    757.16      1.00\n",
      " lambda[57]      3.40     10.92      1.01      0.00      5.94    628.90      1.00\n",
      " lambda[58]      2.35      4.91      0.97      0.00      5.15    568.63      1.00\n",
      " lambda[59]      2.81      6.90      0.96      0.00      6.06    609.12      1.00\n",
      " lambda[60]      3.59     13.39      1.00      0.00      5.74    676.05      1.00\n",
      " lambda[61]      2.40      4.68      0.98      0.00      5.64    855.44      1.00\n",
      " lambda[62]   3781.05  55070.33    236.46      0.00   1912.98    708.96      1.00\n",
      " lambda[63]      2.46      6.13      1.01      0.00      5.33    592.09      1.00\n",
      " lambda[64]      3.04      9.69      0.99      0.00      5.45    717.38      1.00\n",
      " lambda[65]      3.68     17.28      0.95      0.00      5.64    683.85      1.00\n",
      " lambda[66]      3.01      7.51      1.00      0.00      6.43    719.04      1.00\n",
      " lambda[67]      2.64      7.23      0.94      0.00      4.92    889.49      1.00\n",
      " lambda[68]      4.36     37.31      0.97      0.00      5.54    648.39      1.00\n",
      " lambda[69]      3.86     12.84      0.99      0.00      7.46    862.27      1.00\n",
      " lambda[70]      2.72      7.22      1.02      0.00      5.70    474.28      1.00\n",
      " lambda[71]      2.85      8.87      0.99      0.00      5.33    577.18      1.00\n",
      " lambda[72]      2.82      8.61      0.97      0.01      5.29    585.39      1.00\n",
      " lambda[73]      2.64      5.95      1.02      0.00      5.50    605.25      1.00\n",
      " lambda[74]      2.55      7.34      1.04      0.00      4.92    710.36      1.00\n",
      " lambda[75]      4.49     23.23      1.01      0.00      7.46    957.79      1.00\n",
      " lambda[76]      3.26      9.90      1.00      0.00      5.92    673.44      1.00\n",
      " lambda[77]      6.33     35.91      1.09      0.00      6.51    335.51      1.00\n",
      " lambda[78]      3.15      7.92      1.00      0.00      6.72    452.23      1.00\n",
      " lambda[79]      3.08      9.01      1.04      0.00      5.99    573.21      1.00\n",
      " lambda[80]      4.91     33.14      1.07      0.00      7.03    825.30      1.00\n",
      " lambda[81]      2.35      6.42      0.97      0.00      4.85   1075.85      1.00\n",
      " lambda[82]      5.70    104.89      0.95      0.00      4.92    985.24      1.00\n",
      " lambda[83]      2.87      7.97      0.93      0.00      5.79    800.46      1.00\n",
      " lambda[84]      3.44     17.19      0.97      0.00      5.85    906.33      1.00\n",
      " lambda[85]      2.84      7.47      0.92      0.00      6.61    607.32      1.00\n",
      " lambda[86]      3.97     17.36      1.01      0.01      6.29    716.51      1.00\n",
      " lambda[87]      4.20     30.94      0.95      0.00      5.97    915.62      1.00\n",
      " lambda[88]      2.67      6.75      0.93      0.00      5.55    850.34      1.00\n",
      " lambda[89]    227.18   3043.25      1.21      0.00    109.84    432.97      1.00\n",
      " lambda[90]      2.67      7.00      1.01      0.00      5.10    575.82      1.00\n",
      " lambda[91]      2.52      5.83      0.93      0.01      5.47    663.53      1.00\n",
      " lambda[92]      2.43      5.30      1.03      0.01      5.08    672.44      1.00\n",
      " lambda[93]      2.60      5.48      1.08      0.00      5.68    659.41      1.00\n",
      " lambda[94]      2.65      7.74      0.94      0.00      5.69    835.08      1.00\n",
      " lambda[95]      3.14     10.51      1.01      0.00      6.23    707.43      1.00\n",
      " lambda[96]      2.68      7.29      0.95      0.00      5.72    577.23      1.00\n",
      " lambda[97]      3.22     11.48      1.01      0.00      5.70    691.79      1.00\n",
      " lambda[98]      3.72     19.96      0.98      0.00      4.95    528.46      1.00\n",
      " lambda[99]      2.37      5.94      0.99      0.00      4.69    880.36      1.00\n",
      "lambda[100]      2.74      7.75      0.94      0.00      5.83    624.87      1.00\n",
      "lambda[101]      2.41      5.38      0.97      0.01      5.01    640.14      1.00\n",
      "lambda[102]      2.62      7.28      0.90      0.00      5.28    931.49      1.00\n",
      "lambda[103]      2.32      4.51      0.95      0.01      5.41    742.55      1.00\n",
      "lambda[104]      2.84      8.08      0.98      0.00      5.96    296.01      1.00\n",
      "lambda[105]      2.98      7.38      1.02      0.00      6.47    571.17      1.00\n",
      "lambda[106]      2.47      5.31      0.97      0.01      5.55    631.74      1.00\n",
      "lambda[107]      6.59     78.87      1.02      0.00      6.00    894.29      1.00\n",
      "lambda[108]      2.33      8.18      0.93      0.00      4.78    774.66      1.00\n",
      "lambda[109]      3.71     17.65      0.97      0.00      6.87    946.42      1.00\n",
      "lambda[110]      3.16      8.50      1.00      0.00      6.21    625.05      1.00\n",
      "lambda[111]      3.63     15.69      0.99      0.00      6.30    727.34      1.00\n",
      "lambda[112]      4.01     32.34      0.95      0.00      6.03    633.47      1.00\n",
      "lambda[113]      3.86     19.03      0.98      0.00      6.10    783.61      1.00\n",
      "lambda[114]      3.76     11.82      1.01      0.00      6.84    777.72      1.00\n",
      "lambda[115]      3.95     15.20      0.96      0.00      6.07    734.57      1.00\n",
      "lambda[116]      4.73     24.25      1.03      0.00      5.50    426.98      1.00\n",
      "lambda[117]      3.17     10.57      0.96      0.00      6.43    896.31      1.00\n",
      "lambda[118]      3.24     13.84      0.94      0.00      5.78    912.96      1.00\n",
      "lambda[119]      2.77     10.10      0.99      0.00      5.87    883.70      1.00\n",
      "lambda[120]      4.87     24.71      0.91      0.00      6.92    797.32      1.00\n",
      "lambda[121]      3.14     10.24      0.93      0.00      5.88    799.12      1.00\n",
      "lambda[122]      3.77     17.39      0.99      0.00      6.18    785.82      1.00\n",
      "lambda[123]      2.48      5.29      0.92      0.00      5.71    920.55      1.00\n",
      "lambda[124]      2.52      5.96      0.96      0.00      5.32    764.89      1.00\n",
      "lambda[125]      2.68      6.77      1.01      0.01      5.58    622.69      1.00\n",
      "lambda[126]      2.58      7.23      0.95      0.00      4.99    673.14      1.00\n",
      "lambda[127]      3.76     15.17      1.00      0.00      6.18    511.80      1.00\n",
      "lambda[128]      3.05     11.10      0.97      0.00      5.05    390.99      1.00\n",
      "lambda[129]      3.99     16.99      1.00      0.00      6.74    966.83      1.00\n",
      "lambda[130]      2.93      6.98      0.94      0.00      5.87    579.66      1.00\n",
      "lambda[131]      3.17      8.59      0.97      0.00      7.04    494.95      1.00\n",
      "lambda[132]      3.79     19.17      0.97      0.00      6.42    394.03      1.00\n",
      "lambda[133]      2.64      7.05      1.00      0.00      5.17    804.46      1.00\n",
      "lambda[134]      4.06     20.33      0.91      0.00      7.56    993.32      1.00\n",
      "lambda[135]      2.57      8.59      0.93      0.00      4.50    714.99      1.00\n",
      "lambda[136]      3.54     12.33      1.04      0.00      6.09    567.64      1.00\n",
      "lambda[137]      2.67      7.92      0.94      0.00      4.71    592.29      1.00\n",
      "lambda[138]      2.97      9.37      1.05      0.00      4.94    719.88      1.00\n",
      "lambda[139]      3.04     10.00      1.01      0.01      6.11    741.43      1.00\n",
      "lambda[140]      3.00      8.81      0.95      0.00      5.70    901.39      1.00\n",
      "lambda[141]      2.60      8.16      0.98      0.00      5.19    660.35      1.00\n",
      "lambda[142]      5.42     35.64      1.01      0.00      6.43    631.24      1.00\n",
      "lambda[143]      2.26      4.58      1.01      0.00      4.78    875.17      1.00\n",
      "        msq      1.45      0.80      1.26      0.46      2.49   1069.12      1.00\n",
      "      sigma      3.12      4.01      1.52      0.00      7.94   1646.09      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    633.41      1.00\n",
      "       xisq      3.05     13.51      0.88      0.08      4.95    931.73      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.9449520111084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.32e-05 +- 1.38e-02\n",
      "[dimension 02/145]  inactive:\t-6.79e-05 +- 2.16e-02\n",
      "[dimension 03/145]  inactive:\t2.86e-04 +- 1.85e-02\n",
      "[dimension 04/145]  inactive:\t3.22e-03 +- 2.70e-02\n",
      "[dimension 05/145]  inactive:\t-1.26e-04 +- 1.76e-02\n",
      "[dimension 06/145]  inactive:\t2.11e-03 +- 3.24e-02\n",
      "[dimension 07/145]  inactive:\t9.78e-04 +- 1.70e-02\n",
      "[dimension 08/145]  inactive:\t1.93e-03 +- 3.46e-02\n",
      "[dimension 09/145]  inactive:\t4.50e-04 +- 1.90e-02\n",
      "[dimension 10/145]  inactive:\t3.24e-04 +- 1.33e-02\n",
      "[dimension 11/145]  inactive:\t1.27e-04 +- 2.10e-02\n",
      "[dimension 12/145]  inactive:\t2.23e-04 +- 2.17e-02\n",
      "[dimension 13/145]  inactive:\t4.20e-03 +- 3.94e-02\n",
      "[dimension 14/145]  inactive:\t-4.85e-04 +- 2.26e-02\n",
      "[dimension 15/145]  inactive:\t5.53e-04 +- 2.38e-02\n",
      "[dimension 16/145]  inactive:\t7.71e-04 +- 1.92e-02\n",
      "[dimension 17/145]  inactive:\t3.16e-04 +- 2.37e-02\n",
      "[dimension 18/145]  inactive:\t1.19e-03 +- 2.80e-02\n",
      "[dimension 19/145]  inactive:\t-1.19e-03 +- 1.59e-02\n",
      "[dimension 20/145]  inactive:\t-6.06e-04 +- 2.29e-02\n",
      "[dimension 21/145]  inactive:\t-8.77e-04 +- 1.91e-02\n",
      "[dimension 22/145]  inactive:\t2.30e-04 +- 1.95e-02\n",
      "[dimension 23/145]  inactive:\t-2.82e-04 +- 1.99e-02\n",
      "[dimension 24/145]  inactive:\t8.65e-04 +- 2.51e-02\n",
      "[dimension 25/145]  inactive:\t2.79e-03 +- 2.08e-02\n",
      "[dimension 26/145]  inactive:\t1.14e-05 +- 2.15e-02\n",
      "[dimension 27/145]  inactive:\t1.20e-03 +- 2.10e-02\n",
      "[dimension 28/145]  inactive:\t8.85e-04 +- 1.85e-02\n",
      "[dimension 29/145]  inactive:\t6.52e-04 +- 2.37e-02\n",
      "[dimension 30/145]  inactive:\t1.25e-03 +- 2.28e-02\n",
      "[dimension 31/145]  inactive:\t4.30e-03 +- 3.60e-02\n",
      "[dimension 32/145]  inactive:\t-9.09e-04 +- 2.40e-02\n",
      "[dimension 33/145]  inactive:\t2.42e-03 +- 3.35e-02\n",
      "[dimension 34/145]  inactive:\t8.75e-04 +- 1.81e-02\n",
      "[dimension 35/145]  inactive:\t1.61e-03 +- 3.12e-02\n",
      "[dimension 36/145]  inactive:\t1.12e-03 +- 2.24e-02\n",
      "[dimension 37/145]  inactive:\t3.39e-03 +- 2.60e-02\n",
      "[dimension 38/145]  inactive:\t-7.46e-04 +- 2.56e-02\n",
      "[dimension 39/145]  inactive:\t9.14e-04 +- 2.22e-02\n",
      "[dimension 40/145]  inactive:\t4.17e-03 +- 3.61e-02\n",
      "[dimension 41/145]  inactive:\t-1.11e-04 +- 2.91e-02\n",
      "[dimension 42/145]  inactive:\t2.24e-02 +- 1.29e-01\n",
      "[dimension 43/145]  inactive:\t3.21e-04 +- 1.77e-02\n",
      "[dimension 44/145]  inactive:\t1.03e-04 +- 2.32e-02\n",
      "[dimension 45/145]  inactive:\t6.72e-05 +- 1.90e-02\n",
      "[dimension 46/145]  inactive:\t9.34e-04 +- 1.52e-02\n",
      "[dimension 47/145]  inactive:\t-8.63e-04 +- 2.04e-02\n",
      "[dimension 48/145]  inactive:\t1.46e-03 +- 2.48e-02\n",
      "[dimension 49/145]  inactive:\t1.89e-03 +- 2.01e-02\n",
      "[dimension 50/145]  inactive:\t-1.55e-03 +- 3.24e-02\n",
      "[dimension 51/145]  inactive:\t1.55e-03 +- 2.28e-02\n",
      "[dimension 52/145]  inactive:\t5.52e-03 +- 2.52e-02\n",
      "[dimension 53/145]  inactive:\t-4.07e-04 +- 2.43e-02\n",
      "[dimension 54/145]  inactive:\t3.16e-04 +- 1.81e-02\n",
      "[dimension 55/145]  inactive:\t5.10e-04 +- 1.35e-02\n",
      "[dimension 56/145]  inactive:\t-1.74e-03 +- 2.07e-02\n",
      "[dimension 57/145]  inactive:\t1.68e-03 +- 2.85e-02\n",
      "[dimension 58/145]  inactive:\t7.20e-03 +- 4.97e-02\n",
      "[dimension 59/145]  inactive:\t-1.87e-04 +- 1.60e-02\n",
      "[dimension 60/145]  inactive:\t7.72e-04 +- 2.41e-02\n",
      "[dimension 61/145]  inactive:\t2.98e-03 +- 2.56e-02\n",
      "[dimension 62/145]  inactive:\t-2.93e-04 +- 1.68e-02\n",
      "[dimension 63/145]  active:\t6.70e-01 +- 4.29e-01\n",
      "[dimension 64/145]  inactive:\t-2.10e-03 +- 2.18e-02\n",
      "[dimension 65/145]  inactive:\t1.55e-04 +- 2.29e-02\n",
      "[dimension 66/145]  inactive:\t8.79e-04 +- 2.41e-02\n",
      "[dimension 67/145]  inactive:\t1.18e-03 +- 2.09e-02\n",
      "[dimension 68/145]  inactive:\t-9.30e-05 +- 2.06e-02\n",
      "[dimension 69/145]  inactive:\t3.68e-03 +- 4.21e-02\n",
      "[dimension 70/145]  inactive:\t3.60e-03 +- 2.31e-02\n",
      "[dimension 71/145]  inactive:\t2.03e-04 +- 1.97e-02\n",
      "[dimension 72/145]  inactive:\t6.16e-04 +- 1.87e-02\n",
      "[dimension 73/145]  inactive:\t4.51e-04 +- 1.46e-02\n",
      "[dimension 74/145]  inactive:\t-2.84e-04 +- 2.38e-02\n",
      "[dimension 75/145]  inactive:\t7.79e-04 +- 2.39e-02\n",
      "[dimension 76/145]  inactive:\t5.27e-03 +- 3.60e-02\n",
      "[dimension 77/145]  inactive:\t-4.74e-04 +- 2.55e-02\n",
      "[dimension 78/145]  inactive:\t1.42e-02 +- 9.43e-02\n",
      "[dimension 79/145]  inactive:\t6.07e-03 +- 3.60e-02\n",
      "[dimension 80/145]  inactive:\t7.94e-04 +- 2.90e-02\n",
      "[dimension 81/145]  inactive:\t2.85e-03 +- 3.68e-02\n",
      "[dimension 82/145]  inactive:\t2.88e-04 +- 1.37e-02\n",
      "[dimension 83/145]  inactive:\t-8.90e-04 +- 1.38e-02\n",
      "[dimension 84/145]  inactive:\t-3.99e-04 +- 2.22e-02\n",
      "[dimension 85/145]  inactive:\t2.53e-03 +- 2.90e-02\n",
      "[dimension 86/145]  inactive:\t-2.27e-04 +- 1.64e-02\n",
      "[dimension 87/145]  inactive:\t3.42e-03 +- 4.47e-02\n",
      "[dimension 88/145]  inactive:\t2.94e-03 +- 2.71e-02\n",
      "[dimension 89/145]  inactive:\t-2.41e-06 +- 1.78e-02\n",
      "[dimension 90/145]  inactive:\t1.04e-01 +- 2.76e-01\n",
      "[dimension 91/145]  inactive:\t4.30e-05 +- 1.48e-02\n",
      "[dimension 92/145]  inactive:\t-5.06e-04 +- 1.90e-02\n",
      "[dimension 93/145]  inactive:\t-3.66e-04 +- 2.42e-02\n",
      "[dimension 94/145]  inactive:\t1.46e-03 +- 2.46e-02\n",
      "[dimension 95/145]  inactive:\t1.03e-04 +- 2.04e-02\n",
      "[dimension 96/145]  inactive:\t2.36e-03 +- 3.96e-02\n",
      "[dimension 97/145]  inactive:\t2.06e-03 +- 1.99e-02\n",
      "[dimension 98/145]  inactive:\t-4.35e-04 +- 2.21e-02\n",
      "[dimension 99/145]  inactive:\t2.25e-03 +- 3.32e-02\n",
      "[dimension 100/145]  inactive:\t-2.49e-04 +- 1.37e-02\n",
      "[dimension 101/145]  inactive:\t-1.32e-03 +- 1.55e-02\n",
      "[dimension 102/145]  inactive:\t1.90e-05 +- 2.00e-02\n",
      "[dimension 103/145]  inactive:\t7.48e-04 +- 1.74e-02\n",
      "[dimension 104/145]  inactive:\t-4.83e-04 +- 1.53e-02\n",
      "[dimension 105/145]  inactive:\t7.50e-04 +- 2.83e-02\n",
      "[dimension 106/145]  inactive:\t3.82e-03 +- 2.92e-02\n",
      "[dimension 107/145]  inactive:\t-6.05e-04 +- 1.78e-02\n",
      "[dimension 108/145]  inactive:\t1.15e-02 +- 8.41e-02\n",
      "[dimension 109/145]  inactive:\t-7.48e-05 +- 1.55e-02\n",
      "[dimension 110/145]  inactive:\t-4.30e-04 +- 2.74e-02\n",
      "[dimension 111/145]  inactive:\t1.80e-03 +- 2.83e-02\n",
      "[dimension 112/145]  inactive:\t3.29e-03 +- 3.16e-02\n",
      "[dimension 113/145]  inactive:\t-9.34e-04 +- 2.23e-02\n",
      "[dimension 114/145]  inactive:\t6.01e-04 +- 2.94e-02\n",
      "[dimension 115/145]  inactive:\t2.28e-03 +- 2.28e-02\n",
      "[dimension 116/145]  inactive:\t1.91e-03 +- 4.28e-02\n",
      "[dimension 117/145]  inactive:\t6.27e-03 +- 5.77e-02\n",
      "[dimension 118/145]  inactive:\t2.32e-03 +- 2.11e-02\n",
      "[dimension 119/145]  inactive:\t-1.09e-03 +- 2.62e-02\n",
      "[dimension 120/145]  inactive:\t-2.64e-05 +- 1.95e-02\n",
      "[dimension 121/145]  inactive:\t4.76e-03 +- 3.89e-02\n",
      "[dimension 122/145]  inactive:\t-1.44e-03 +- 2.62e-02\n",
      "[dimension 123/145]  inactive:\t2.00e-03 +- 3.53e-02\n",
      "[dimension 124/145]  inactive:\t-4.87e-04 +- 1.50e-02\n",
      "[dimension 125/145]  inactive:\t-6.89e-04 +- 2.02e-02\n",
      "[dimension 126/145]  inactive:\t-1.44e-04 +- 1.66e-02\n",
      "[dimension 127/145]  inactive:\t1.89e-04 +- 1.52e-02\n",
      "[dimension 128/145]  inactive:\t-3.08e-04 +- 2.62e-02\n",
      "[dimension 129/145]  inactive:\t1.34e-03 +- 2.60e-02\n",
      "[dimension 130/145]  inactive:\t3.16e-03 +- 2.66e-02\n",
      "[dimension 131/145]  inactive:\t-3.56e-04 +- 2.32e-02\n",
      "[dimension 132/145]  inactive:\t3.80e-03 +- 4.07e-02\n",
      "[dimension 133/145]  inactive:\t2.71e-03 +- 2.21e-02\n",
      "[dimension 134/145]  inactive:\t-1.15e-04 +- 2.19e-02\n",
      "[dimension 135/145]  inactive:\t1.74e-03 +- 2.95e-02\n",
      "[dimension 136/145]  inactive:\t9.39e-04 +- 1.58e-02\n",
      "[dimension 137/145]  inactive:\t4.82e-04 +- 3.15e-02\n",
      "[dimension 138/145]  inactive:\t3.65e-04 +- 1.76e-02\n",
      "[dimension 139/145]  inactive:\t6.34e-04 +- 2.00e-02\n",
      "[dimension 140/145]  inactive:\t-3.34e-04 +- 2.18e-02\n",
      "[dimension 141/145]  inactive:\t1.89e-03 +- 2.98e-02\n",
      "[dimension 142/145]  inactive:\t1.31e-03 +- 1.57e-02\n",
      "[dimension 143/145]  inactive:\t2.61e-03 +- 4.03e-02\n",
      "[dimension 144/145]  inactive:\t2.38e-04 +- 1.42e-02\n",
      "[dimension 145/145]  inactive:\t2.32e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8111826]\n",
      "cov_act[[0.02538896]]\n",
      "Active_dimensions: [62]\n",
      "26, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.61it/s, 15 steps of size 1.97e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    525.88      1.00\n",
      "  lambda[0]      2.31      5.19      0.94      0.00      5.00    780.76      1.00\n",
      "  lambda[1]      3.41     19.13      0.96      0.00      5.48    707.23      1.00\n",
      "  lambda[2]      3.22      9.99      1.08      0.00      6.27    501.51      1.00\n",
      "  lambda[3]      4.18     24.12      1.06      0.00      7.00    912.44      1.00\n",
      "  lambda[4]      2.84     11.33      0.99      0.00      6.03    927.92      1.00\n",
      "  lambda[5]      2.59      7.33      0.93      0.00      5.03    554.22      1.00\n",
      "  lambda[6]      2.82     11.43      0.94      0.00      5.52   1019.40      1.00\n",
      "  lambda[7]      2.60      7.28      0.94      0.00      5.05    835.80      1.00\n",
      "  lambda[8]      2.49      4.87      1.00      0.00      5.76    558.29      1.01\n",
      "  lambda[9]      2.75      7.48      1.08      0.00      5.54    555.09      1.01\n",
      " lambda[10]      3.57     12.73      1.06      0.00      6.27    594.92      1.00\n",
      " lambda[11]      2.87      7.55      0.98      0.00      6.55    632.50      1.00\n",
      " lambda[12]      4.84     20.35      0.97      0.00      7.84    535.53      1.00\n",
      " lambda[13]      3.16     10.85      0.97      0.00      5.34    611.96      1.00\n",
      " lambda[14]      3.97     20.08      1.00      0.00      5.32    837.44      1.00\n",
      " lambda[15]      2.64      7.13      0.99      0.00      4.84    675.72      1.00\n",
      " lambda[16]      2.73      7.75      0.96      0.00      5.33    754.33      1.00\n",
      " lambda[17]      2.71      7.03      1.05      0.00      5.51   1061.75      1.00\n",
      " lambda[18]      3.25      9.20      0.93      0.00      6.07    564.20      1.00\n",
      " lambda[19]      3.73     13.62      1.05      0.00      7.66    742.01      1.00\n",
      " lambda[20]      3.25     13.08      0.94      0.01      5.83    788.50      1.00\n",
      " lambda[21]      3.10     10.91      1.06      0.00      5.72    477.78      1.00\n",
      " lambda[22]      2.87      9.53      1.01      0.01      5.26    671.85      1.00\n",
      " lambda[23]      3.57     15.41      0.94      0.00      5.70    635.38      1.00\n",
      " lambda[24]      3.07      7.17      0.98      0.00      6.75    645.96      1.00\n",
      " lambda[25]      2.24      4.58      0.96      0.01      5.22    687.34      1.00\n",
      " lambda[26]      3.72     17.21      0.97      0.00      6.11    570.09      1.00\n",
      " lambda[27]      2.62      6.23      0.93      0.00      6.19    833.36      1.00\n",
      " lambda[28]      2.94     15.29      1.01      0.00      5.65    688.81      1.00\n",
      " lambda[29]      3.83     15.40      0.96      0.00      5.99    545.89      1.00\n",
      " lambda[30]      3.91     15.24      0.95      0.00      7.46    507.83      1.00\n",
      " lambda[31]      3.87     17.07      1.00      0.00      6.00    618.80      1.00\n",
      " lambda[32]      3.03      8.40      1.01      0.00      6.26    796.25      1.00\n",
      " lambda[33]      2.30      4.36      0.99      0.01      5.23    677.16      1.00\n",
      " lambda[34]      4.09     18.44      1.08      0.00      7.04    516.69      1.00\n",
      " lambda[35]      3.06      8.20      1.05      0.00      6.31    816.58      1.00\n",
      " lambda[36]      3.17      9.48      0.99      0.00      6.02    810.20      1.00\n",
      " lambda[37]      3.25      9.42      1.01      0.00      6.63    559.23      1.00\n",
      " lambda[38]      2.70      6.20      1.02      0.00      5.86    839.00      1.00\n",
      " lambda[39]      3.08     13.24      0.98      0.00      5.54    880.82      1.00\n",
      " lambda[40]      3.70     16.56      0.96      0.00      5.88    635.19      1.00\n",
      " lambda[41]     10.97     88.25      0.99      0.00      7.52    499.24      1.00\n",
      " lambda[42]      2.34      5.33      0.90      0.00      5.07    877.22      1.00\n",
      " lambda[43]      4.42     26.85      1.07      0.00      6.22    581.95      1.00\n",
      " lambda[44]      3.40     11.02      1.01      0.00      6.77    734.77      1.00\n",
      " lambda[45]      2.89      8.41      1.07      0.00      5.09    595.62      1.00\n",
      " lambda[46]      2.84     10.58      0.96      0.00      4.68    860.11      1.00\n",
      " lambda[47]      2.06      3.91      1.01      0.00      4.35   1035.87      1.00\n",
      " lambda[48]      3.06     10.43      0.99      0.00      5.84    865.50      1.00\n",
      " lambda[49]      2.49      5.86      0.92      0.00      5.11    716.23      1.00\n",
      " lambda[50]      3.16     11.19      0.94      0.00      5.48    823.40      1.00\n",
      " lambda[51]      3.91     13.31      1.10      0.00      7.03    649.22      1.00\n",
      " lambda[52]      2.88     10.94      0.97      0.00      5.64   1006.13      1.00\n",
      " lambda[53]      2.92      7.28      0.94      0.00      5.70    823.84      1.00\n",
      " lambda[54]      2.53      7.14      0.92      0.00      4.63    835.06      1.00\n",
      " lambda[55]      2.25      5.11      0.94      0.00      4.61    774.94      1.00\n",
      " lambda[56]      2.95      9.42      1.02      0.01      5.30    542.70      1.00\n",
      " lambda[57]      8.96     62.60      1.01      0.00      9.09    435.54      1.00\n",
      " lambda[58]      2.54      7.40      0.92      0.00      4.93    781.19      1.00\n",
      " lambda[59]      4.78     33.25      1.02      0.00      6.12    930.20      1.00\n",
      " lambda[60]      3.38     12.94      0.99      0.00      5.55    664.08      1.00\n",
      " lambda[61]      2.93      9.48      1.00      0.00      5.55    823.92      1.00\n",
      " lambda[62]   1469.79  21112.94    171.60      0.00   1133.29    875.82      1.00\n",
      " lambda[63]      2.84      7.84      0.96      0.00      6.07    888.95      1.00\n",
      " lambda[64]      3.10      8.20      0.95      0.00      6.56    766.86      1.00\n",
      " lambda[65]      2.81      8.17      1.02      0.00      5.70    446.97      1.00\n",
      " lambda[66]      3.08     10.10      0.99      0.00      5.48    762.45      1.00\n",
      " lambda[67]      2.88      8.75      0.98      0.00      5.64    912.91      1.00\n",
      " lambda[68]      3.61     11.46      1.04      0.00      7.04    711.19      1.00\n",
      " lambda[69]      2.64      6.98      0.92      0.00      5.10    753.15      1.00\n",
      " lambda[70]      2.69      7.08      0.99      0.00      5.27    527.74      1.00\n",
      " lambda[71]      2.75      7.00      1.02      0.00      5.32    900.44      1.00\n",
      " lambda[72]      2.23      4.71      0.97      0.00      4.95    790.27      1.00\n",
      " lambda[73]      4.63     42.80      1.02      0.00      5.82    990.45      1.00\n",
      " lambda[74]      2.94      7.97      0.99      0.00      6.01    752.21      1.00\n",
      " lambda[75]      5.43     27.14      1.04      0.00      7.47    528.49      1.01\n",
      " lambda[76]      3.06      8.25      1.04      0.00      5.96    687.78      1.00\n",
      " lambda[77]      4.01     15.12      1.05      0.00      6.27    817.05      1.00\n",
      " lambda[78]      3.09      8.85      1.00      0.00      5.61    835.47      1.00\n",
      " lambda[79]      3.14      9.61      0.98      0.00      5.64    791.18      1.00\n",
      " lambda[80]      3.21     10.68      0.94      0.00      5.87    797.74      1.00\n",
      " lambda[81]      2.89      6.95      0.92      0.00      6.39    724.64      1.00\n",
      " lambda[82]      2.73      7.05      0.92      0.00      5.41    688.53      1.00\n",
      " lambda[83]      3.40     13.11      1.05      0.00      5.06    533.64      1.00\n",
      " lambda[84]      3.73     17.18      1.04      0.00      6.45    730.38      1.00\n",
      " lambda[85]      2.88     10.11      0.98      0.00      5.16    760.90      1.00\n",
      " lambda[86]      3.69     11.31      0.97      0.00      6.56    673.74      1.00\n",
      " lambda[87]      3.09     10.05      0.96      0.00      6.18    765.23      1.00\n",
      " lambda[88]      2.73      9.71      0.98      0.00      5.37    721.61      1.00\n",
      " lambda[89]     48.99    363.02      1.22      0.00     32.40    494.88      1.00\n",
      " lambda[90]      2.44      5.11      0.93      0.00      4.79    567.62      1.00\n",
      " lambda[91]      2.79      6.93      0.95      0.00      5.71    711.81      1.00\n",
      " lambda[92]      2.95      7.72      1.06      0.00      5.99    818.65      1.00\n",
      " lambda[93]      2.77      7.81      0.98      0.00      5.56    620.40      1.00\n",
      " lambda[94]      3.24     12.18      1.00      0.00      6.43    813.00      1.00\n",
      " lambda[95]      2.89      8.38      0.95      0.01      5.87   1010.03      1.00\n",
      " lambda[96]      2.34      6.15      0.91      0.00      4.75    568.69      1.00\n",
      " lambda[97]      3.01      8.99      1.01      0.00      5.33    642.67      1.00\n",
      " lambda[98]      3.67     19.39      1.04      0.00      5.49    778.78      1.00\n",
      " lambda[99]      2.59      6.48      0.96      0.00      4.81    658.33      1.00\n",
      "lambda[100]      2.83      6.78      0.95      0.00      6.33    691.42      1.00\n",
      "lambda[101]      3.75     13.38      0.92      0.01      6.48    491.42      1.00\n",
      "lambda[102]      3.40     12.34      0.93      0.00      5.81    514.51      1.00\n",
      "lambda[103]      3.00      9.47      1.00      0.00      5.92    683.92      1.00\n",
      "lambda[104]      3.31     13.54      0.99      0.00      5.33    590.97      1.00\n",
      "lambda[105]      4.23     17.43      0.98      0.00      6.42    645.83      1.00\n",
      "lambda[106]      3.05     10.25      0.94      0.00      5.84    263.27      1.00\n",
      "lambda[107]      4.78     19.23      0.98      0.00      5.85    367.67      1.00\n",
      "lambda[108]      2.15      4.08      0.88      0.01      5.10    895.00      1.00\n",
      "lambda[109]      4.36     51.90      0.96      0.00      5.44   1008.13      1.00\n",
      "lambda[110]      3.36     12.24      1.02      0.00      6.19    825.13      1.00\n",
      "lambda[111]      9.18     85.10      1.09      0.00      7.94    592.86      1.00\n",
      "lambda[112]      2.37      4.85      1.05      0.01      5.32    672.67      1.00\n",
      "lambda[113]      4.41     18.39      0.95      0.00      7.35    812.05      1.00\n",
      "lambda[114]      3.14     18.60      0.87      0.00      5.52    967.14      1.00\n",
      "lambda[115]      2.85      7.74      0.94      0.00      5.94    654.34      1.00\n",
      "lambda[116]      3.86     22.56      1.07      0.00      6.50    747.13      1.00\n",
      "lambda[117]      3.18      8.95      0.95      0.00      6.01    610.57      1.00\n",
      "lambda[118]      3.35     25.80      0.95      0.00      5.85   1008.81      1.00\n",
      "lambda[119]      3.08     10.76      0.96      0.00      6.20    756.47      1.00\n",
      "lambda[120]      3.75     18.20      0.97      0.00      6.55    983.85      1.00\n",
      "lambda[121]      3.46     12.25      1.01      0.00      6.47    726.19      1.00\n",
      "lambda[122]      3.50     15.22      1.01      0.00      5.82    752.84      1.00\n",
      "lambda[123]      2.94      8.21      0.95      0.00      5.44    564.63      1.00\n",
      "lambda[124]      3.00      8.85      1.00      0.01      5.38    524.77      1.00\n",
      "lambda[125]      2.75      6.47      0.98      0.01      5.67    750.08      1.00\n",
      "lambda[126]      2.75     10.38      1.03      0.00      5.24   1017.31      1.00\n",
      "lambda[127]      3.28     11.09      0.93      0.00      5.77    717.21      1.00\n",
      "lambda[128]      2.87      9.35      0.92      0.00      5.15    317.27      1.00\n",
      "lambda[129]      4.38     30.20      0.94      0.00      5.64    937.27      1.00\n",
      "lambda[130]      2.60      6.59      0.95      0.00      5.18    923.92      1.00\n",
      "lambda[131]      4.67     27.45      0.95      0.00      5.63    926.09      1.00\n",
      "lambda[132]      3.35     10.73      1.09      0.00      6.31    498.57      1.00\n",
      "lambda[133]      2.54      6.25      0.91      0.00      4.98    725.42      1.00\n",
      "lambda[134]      3.33      8.96      0.99      0.00      6.89    520.22      1.00\n",
      "lambda[135]      2.87      9.78      0.93      0.00      5.12    796.25      1.00\n",
      "lambda[136]      2.83      9.76      0.93      0.00      4.65   1020.43      1.00\n",
      "lambda[137]      3.24     11.47      1.04      0.00      6.59    896.18      1.00\n",
      "lambda[138]      2.79      7.99      0.92      0.00      5.59    534.04      1.00\n",
      "lambda[139]      2.58      5.26      0.98      0.00      5.75    787.58      1.00\n",
      "lambda[140]      3.40     11.13      1.01      0.00      7.16    579.95      1.00\n",
      "lambda[141]      2.87      8.00      1.03      0.00      6.47    798.12      1.00\n",
      "lambda[142]      4.72     28.47      0.90      0.00      6.74    684.07      1.00\n",
      "lambda[143]      2.45      6.32      1.00      0.00      5.21    639.50      1.00\n",
      "        msq  29856.14 914141.69     20.05      1.13    465.04   1000.89      1.00\n",
      "      sigma      3.35      4.04      1.65      0.01      9.18   1076.45      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    783.71      1.00\n",
      "       xisq      0.13      0.07      0.11      0.04      0.21    750.31      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.59326195716858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.90e-04 +- 1.82e-02\n",
      "[dimension 02/145]  inactive:\t-9.99e-04 +- 3.10e-02\n",
      "[dimension 03/145]  inactive:\t6.99e-05 +- 3.22e-02\n",
      "[dimension 04/145]  inactive:\t6.66e-03 +- 4.63e-02\n",
      "[dimension 05/145]  inactive:\t-1.47e-03 +- 3.08e-02\n",
      "[dimension 06/145]  inactive:\t2.58e-03 +- 4.23e-02\n",
      "[dimension 07/145]  inactive:\t6.35e-04 +- 1.85e-02\n",
      "[dimension 08/145]  inactive:\t8.43e-04 +- 3.30e-02\n",
      "[dimension 09/145]  inactive:\t-4.86e-05 +- 2.20e-02\n",
      "[dimension 10/145]  inactive:\t5.78e-04 +- 2.12e-02\n",
      "[dimension 11/145]  inactive:\t-2.07e-03 +- 2.67e-02\n",
      "[dimension 12/145]  inactive:\t-9.28e-04 +- 2.92e-02\n",
      "[dimension 13/145]  inactive:\t4.97e-03 +- 4.29e-02\n",
      "[dimension 14/145]  inactive:\t-2.16e-03 +- 3.04e-02\n",
      "[dimension 15/145]  inactive:\t1.48e-03 +- 3.82e-02\n",
      "[dimension 16/145]  inactive:\t1.00e-03 +- 2.06e-02\n",
      "[dimension 17/145]  inactive:\t4.02e-06 +- 3.87e-02\n",
      "[dimension 18/145]  inactive:\t-1.42e-04 +- 2.57e-02\n",
      "[dimension 19/145]  inactive:\t-2.21e-03 +- 2.23e-02\n",
      "[dimension 20/145]  inactive:\t-2.05e-03 +- 3.42e-02\n",
      "[dimension 21/145]  inactive:\t-1.08e-03 +- 2.29e-02\n",
      "[dimension 22/145]  inactive:\t1.56e-05 +- 2.38e-02\n",
      "[dimension 23/145]  inactive:\t-1.45e-03 +- 2.83e-02\n",
      "[dimension 24/145]  inactive:\t1.76e-03 +- 3.59e-02\n",
      "[dimension 25/145]  inactive:\t3.95e-03 +- 2.55e-02\n",
      "[dimension 26/145]  inactive:\t-4.89e-04 +- 2.36e-02\n",
      "[dimension 27/145]  inactive:\t1.07e-03 +- 2.74e-02\n",
      "[dimension 28/145]  inactive:\t8.85e-04 +- 2.19e-02\n",
      "[dimension 29/145]  inactive:\t-4.17e-04 +- 2.47e-02\n",
      "[dimension 30/145]  inactive:\t1.69e-03 +- 3.74e-02\n",
      "[dimension 31/145]  inactive:\t7.19e-03 +- 4.89e-02\n",
      "[dimension 32/145]  inactive:\t-2.23e-03 +- 3.57e-02\n",
      "[dimension 33/145]  inactive:\t3.95e-03 +- 4.97e-02\n",
      "[dimension 34/145]  inactive:\t5.15e-04 +- 2.06e-02\n",
      "[dimension 35/145]  inactive:\t3.31e-04 +- 3.30e-02\n",
      "[dimension 36/145]  inactive:\t1.56e-03 +- 3.03e-02\n",
      "[dimension 37/145]  inactive:\t4.52e-03 +- 2.90e-02\n",
      "[dimension 38/145]  inactive:\t-1.36e-03 +- 3.35e-02\n",
      "[dimension 39/145]  inactive:\t7.78e-04 +- 2.76e-02\n",
      "[dimension 40/145]  inactive:\t3.46e-03 +- 2.84e-02\n",
      "[dimension 41/145]  inactive:\t-2.61e-03 +- 3.48e-02\n",
      "[dimension 42/145]  inactive:\t1.23e-02 +- 8.82e-02\n",
      "[dimension 43/145]  inactive:\t-2.45e-04 +- 2.00e-02\n",
      "[dimension 44/145]  inactive:\t-1.42e-03 +- 3.37e-02\n",
      "[dimension 45/145]  inactive:\t-8.98e-04 +- 3.04e-02\n",
      "[dimension 46/145]  inactive:\t1.36e-03 +- 1.81e-02\n",
      "[dimension 47/145]  inactive:\t-2.14e-03 +- 3.23e-02\n",
      "[dimension 48/145]  inactive:\t7.30e-04 +- 2.00e-02\n",
      "[dimension 49/145]  inactive:\t3.57e-03 +- 2.84e-02\n",
      "[dimension 50/145]  inactive:\t-2.20e-03 +- 2.99e-02\n",
      "[dimension 51/145]  inactive:\t3.12e-03 +- 3.13e-02\n",
      "[dimension 52/145]  inactive:\t5.76e-03 +- 2.57e-02\n",
      "[dimension 53/145]  inactive:\t-1.34e-03 +- 2.81e-02\n",
      "[dimension 54/145]  inactive:\t5.82e-04 +- 2.42e-02\n",
      "[dimension 55/145]  inactive:\t6.90e-04 +- 1.88e-02\n",
      "[dimension 56/145]  inactive:\t-1.58e-03 +- 2.21e-02\n",
      "[dimension 57/145]  inactive:\t7.65e-04 +- 3.23e-02\n",
      "[dimension 58/145]  inactive:\t1.52e-02 +- 7.66e-02\n",
      "[dimension 59/145]  inactive:\t-1.06e-03 +- 2.03e-02\n",
      "[dimension 60/145]  inactive:\t2.40e-03 +- 4.09e-02\n",
      "[dimension 61/145]  inactive:\t3.23e-03 +- 2.85e-02\n",
      "[dimension 62/145]  inactive:\t-9.33e-04 +- 2.61e-02\n",
      "[dimension 63/145]  active:\t7.32e-01 +- 4.11e-01\n",
      "[dimension 64/145]  inactive:\t-3.08e-03 +- 2.94e-02\n",
      "[dimension 65/145]  inactive:\t-8.40e-04 +- 3.25e-02\n",
      "[dimension 66/145]  inactive:\t6.23e-04 +- 2.31e-02\n",
      "[dimension 67/145]  inactive:\t1.91e-03 +- 3.12e-02\n",
      "[dimension 68/145]  inactive:\t-1.18e-03 +- 3.04e-02\n",
      "[dimension 69/145]  inactive:\t4.24e-03 +- 4.40e-02\n",
      "[dimension 70/145]  inactive:\t3.42e-03 +- 2.53e-02\n",
      "[dimension 71/145]  inactive:\t6.82e-04 +- 3.77e-02\n",
      "[dimension 72/145]  inactive:\t1.30e-04 +- 2.45e-02\n",
      "[dimension 73/145]  inactive:\t2.50e-04 +- 1.88e-02\n",
      "[dimension 74/145]  inactive:\t-2.88e-03 +- 3.64e-02\n",
      "[dimension 75/145]  inactive:\t5.38e-04 +- 2.84e-02\n",
      "[dimension 76/145]  inactive:\t6.68e-03 +- 4.45e-02\n",
      "[dimension 77/145]  inactive:\t-2.09e-03 +- 3.42e-02\n",
      "[dimension 78/145]  inactive:\t6.77e-03 +- 6.45e-02\n",
      "[dimension 79/145]  inactive:\t5.76e-03 +- 3.38e-02\n",
      "[dimension 80/145]  inactive:\t-9.30e-04 +- 3.01e-02\n",
      "[dimension 81/145]  inactive:\t1.02e-03 +- 3.39e-02\n",
      "[dimension 82/145]  inactive:\t3.85e-04 +- 1.98e-02\n",
      "[dimension 83/145]  inactive:\t-2.20e-03 +- 2.40e-02\n",
      "[dimension 84/145]  inactive:\t-1.41e-03 +- 2.88e-02\n",
      "[dimension 85/145]  inactive:\t3.37e-03 +- 3.36e-02\n",
      "[dimension 86/145]  inactive:\t-6.64e-04 +- 2.25e-02\n",
      "[dimension 87/145]  inactive:\t4.15e-03 +- 5.33e-02\n",
      "[dimension 88/145]  inactive:\t2.84e-03 +- 2.47e-02\n",
      "[dimension 89/145]  inactive:\t-3.97e-04 +- 2.53e-02\n",
      "[dimension 90/145]  inactive:\t8.29e-02 +- 2.58e-01\n",
      "[dimension 91/145]  inactive:\t1.26e-04 +- 2.08e-02\n",
      "[dimension 92/145]  inactive:\t-1.88e-03 +- 2.75e-02\n",
      "[dimension 93/145]  inactive:\t5.23e-05 +- 2.60e-02\n",
      "[dimension 94/145]  inactive:\t1.65e-03 +- 2.89e-02\n",
      "[dimension 95/145]  inactive:\t-2.88e-04 +- 3.29e-02\n",
      "[dimension 96/145]  inactive:\t4.27e-04 +- 3.87e-02\n",
      "[dimension 97/145]  inactive:\t1.93e-03 +- 2.20e-02\n",
      "[dimension 98/145]  inactive:\t-9.04e-04 +- 2.53e-02\n",
      "[dimension 99/145]  inactive:\t4.24e-03 +- 4.72e-02\n",
      "[dimension 100/145]  inactive:\t-5.32e-04 +- 2.00e-02\n",
      "[dimension 101/145]  inactive:\t-2.93e-03 +- 2.47e-02\n",
      "[dimension 102/145]  inactive:\t-1.04e-03 +- 3.23e-02\n",
      "[dimension 103/145]  inactive:\t2.01e-03 +- 3.04e-02\n",
      "[dimension 104/145]  inactive:\t-1.36e-03 +- 2.44e-02\n",
      "[dimension 105/145]  inactive:\t-8.27e-04 +- 2.51e-02\n",
      "[dimension 106/145]  inactive:\t5.55e-03 +- 3.64e-02\n",
      "[dimension 107/145]  inactive:\t-1.42e-03 +- 2.03e-02\n",
      "[dimension 108/145]  inactive:\t9.93e-03 +- 8.74e-02\n",
      "[dimension 109/145]  inactive:\t-3.50e-04 +- 1.88e-02\n",
      "[dimension 110/145]  inactive:\t-7.52e-04 +- 3.12e-02\n",
      "[dimension 111/145]  inactive:\t1.76e-03 +- 3.71e-02\n",
      "[dimension 112/145]  inactive:\t1.33e-02 +- 8.26e-02\n",
      "[dimension 113/145]  inactive:\t-1.79e-03 +- 2.23e-02\n",
      "[dimension 114/145]  inactive:\t1.37e-03 +- 3.97e-02\n",
      "[dimension 115/145]  inactive:\t1.66e-03 +- 2.16e-02\n",
      "[dimension 116/145]  inactive:\t1.39e-05 +- 3.32e-02\n",
      "[dimension 117/145]  inactive:\t5.46e-03 +- 5.55e-02\n",
      "[dimension 118/145]  inactive:\t3.39e-03 +- 2.71e-02\n",
      "[dimension 119/145]  inactive:\t-1.99e-03 +- 3.01e-02\n",
      "[dimension 120/145]  inactive:\t2.98e-04 +- 3.57e-02\n",
      "[dimension 121/145]  inactive:\t4.39e-03 +- 3.77e-02\n",
      "[dimension 122/145]  inactive:\t-2.39e-03 +- 3.11e-02\n",
      "[dimension 123/145]  inactive:\t1.39e-03 +- 3.74e-02\n",
      "[dimension 124/145]  inactive:\t-1.82e-03 +- 2.18e-02\n",
      "[dimension 125/145]  inactive:\t-1.98e-03 +- 2.70e-02\n",
      "[dimension 126/145]  inactive:\t-1.67e-03 +- 2.94e-02\n",
      "[dimension 127/145]  inactive:\t1.12e-04 +- 1.89e-02\n",
      "[dimension 128/145]  inactive:\t-1.51e-03 +- 3.27e-02\n",
      "[dimension 129/145]  inactive:\t-3.29e-04 +- 2.49e-02\n",
      "[dimension 130/145]  inactive:\t4.67e-03 +- 3.52e-02\n",
      "[dimension 131/145]  inactive:\t-1.10e-03 +- 2.40e-02\n",
      "[dimension 132/145]  inactive:\t6.66e-03 +- 5.59e-02\n",
      "[dimension 133/145]  inactive:\t3.00e-03 +- 2.41e-02\n",
      "[dimension 134/145]  inactive:\t-5.27e-04 +- 2.80e-02\n",
      "[dimension 135/145]  inactive:\t8.36e-04 +- 3.12e-02\n",
      "[dimension 136/145]  inactive:\t1.08e-03 +- 2.08e-02\n",
      "[dimension 137/145]  inactive:\t-5.78e-04 +- 3.28e-02\n",
      "[dimension 138/145]  inactive:\t4.76e-04 +- 2.37e-02\n",
      "[dimension 139/145]  inactive:\t4.83e-04 +- 2.56e-02\n",
      "[dimension 140/145]  inactive:\t-1.57e-03 +- 3.45e-02\n",
      "[dimension 141/145]  inactive:\t1.15e-03 +- 2.54e-02\n",
      "[dimension 142/145]  inactive:\t1.48e-03 +- 2.06e-02\n",
      "[dimension 143/145]  inactive:\t8.34e-04 +- 3.92e-02\n",
      "[dimension 144/145]  inactive:\t-4.32e-05 +- 2.09e-02\n",
      "[dimension 145/145]  inactive:\t8.08e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9468373]\n",
      "cov_act[[0.05176637]]\n",
      "Active_dimensions: [62]\n",
      "27, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:33<00:00, 44.36it/s, 31 steps of size 2.03e-01. acc. prob=0.79] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    408.17      1.00\n",
      "  lambda[0]      2.36      6.95      0.91      0.00      4.74    534.55      1.00\n",
      "  lambda[1]     15.91    368.77      0.97      0.00      5.97    828.92      1.00\n",
      "  lambda[2]      2.73      6.40      1.02      0.01      5.49    563.14      1.00\n",
      "  lambda[3]      7.64    118.87      0.94      0.00      6.59    759.99      1.00\n",
      "  lambda[4]      2.70      6.11      1.01      0.00      5.66    617.05      1.00\n",
      "  lambda[5]      3.59     15.33      1.02      0.00      6.12    760.66      1.00\n",
      "  lambda[6]      2.89      9.24      0.93      0.00      5.50    695.27      1.00\n",
      "  lambda[7]      2.91      6.01      0.93      0.00      6.74    720.05      1.00\n",
      "  lambda[8]      2.84      7.07      0.97      0.00      6.43    610.12      1.00\n",
      "  lambda[9]      2.69      6.59      1.03      0.00      5.31    697.38      1.00\n",
      " lambda[10]      3.70     13.49      1.00      0.00      5.89    528.94      1.00\n",
      " lambda[11]      2.54      9.08      0.99      0.01      4.70    845.43      1.00\n",
      " lambda[12]      4.86     24.82      1.04      0.01      7.59    352.14      1.00\n",
      " lambda[13]      2.66     13.58      0.95      0.00      4.62    893.69      1.00\n",
      " lambda[14]      4.33     17.28      1.11      0.00      7.19    882.22      1.00\n",
      " lambda[15]      3.08     10.30      1.04      0.00      5.04    575.20      1.00\n",
      " lambda[16]      3.13     11.65      0.92      0.00      5.60    659.54      1.00\n",
      " lambda[17]      3.48     18.83      1.05      0.01      6.45    741.10      1.00\n",
      " lambda[18]      2.97      8.72      0.97      0.00      5.91    637.38      1.00\n",
      " lambda[19]      2.91      8.26      1.05      0.00      5.78    986.61      1.00\n",
      " lambda[20]      3.05     10.57      0.95      0.00      5.63    385.92      1.00\n",
      " lambda[21]      2.47      4.92      0.95      0.01      5.73    590.14      1.00\n",
      " lambda[22]      2.62      7.98      1.06      0.00      5.13    921.09      1.00\n",
      " lambda[23]      3.37     15.98      0.94      0.00      5.36    845.60      1.00\n",
      " lambda[24]      3.20      8.74      1.01      0.00      6.17    513.08      1.00\n",
      " lambda[25]      2.11      3.55      0.99      0.01      4.85    921.73      1.00\n",
      " lambda[26]      2.77      7.30      0.97      0.00      5.59    934.18      1.00\n",
      " lambda[27]      2.85      7.29      0.92      0.00      6.48    685.95      1.00\n",
      " lambda[28]      2.60      5.47      0.99      0.01      5.89    755.27      1.00\n",
      " lambda[29]      3.36     17.46      0.99      0.00      5.30    401.71      1.00\n",
      " lambda[30]      4.92     23.53      0.94      0.00      7.18    547.65      1.00\n",
      " lambda[31]      3.39     14.66      0.96      0.01      4.88    540.81      1.00\n",
      " lambda[32]     18.78    467.34      0.97      0.00      5.87    919.16      1.00\n",
      " lambda[33]      2.76      6.19      0.99      0.00      6.19    631.80      1.00\n",
      " lambda[34]      2.79      9.79      0.99      0.00      4.90    663.06      1.00\n",
      " lambda[35]      2.75      6.08      0.98      0.00      5.93    609.49      1.00\n",
      " lambda[36]      4.32     27.64      1.10      0.00      7.55    996.73      1.00\n",
      " lambda[37]      3.70     20.57      1.03      0.00      6.14    863.94      1.00\n",
      " lambda[38]      4.31     35.56      1.02      0.00      6.41    996.61      1.00\n",
      " lambda[39]      2.65     10.16      0.91      0.00      5.21    964.93      1.00\n",
      " lambda[40]      3.59     16.44      1.00      0.00      6.07    768.03      1.00\n",
      " lambda[41]     11.40     91.07      0.99      0.00      8.12    339.13      1.00\n",
      " lambda[42]      2.93     11.17      0.99      0.00      5.75    709.72      1.00\n",
      " lambda[43]      2.53      7.26      0.90      0.00      5.09    566.81      1.00\n",
      " lambda[44]      2.75      6.77      1.01      0.00      5.71    700.97      1.00\n",
      " lambda[45]      2.03      3.94      0.83      0.00      4.19    665.77      1.00\n",
      " lambda[46]      3.93     24.53      0.97      0.00      4.98    579.85      1.00\n",
      " lambda[47]      2.23      4.19      0.97      0.00      4.84    734.89      1.00\n",
      " lambda[48]      2.87      6.37      1.03      0.00      6.75    472.53      1.00\n",
      " lambda[49]      3.03     11.34      0.94      0.00      5.24    776.69      1.00\n",
      " lambda[50]      5.10     44.80      1.02      0.00      6.65    966.45      1.00\n",
      " lambda[51]      3.34     12.67      0.97      0.00      6.09    878.75      1.00\n",
      " lambda[52]      3.50     15.46      0.96      0.00      5.02    715.69      1.00\n",
      " lambda[53]      4.14     16.79      0.97      0.00      6.23    379.31      1.00\n",
      " lambda[54]      2.05      3.80      0.94      0.00      4.56    720.55      1.00\n",
      " lambda[55]      2.92     11.37      0.93      0.00      5.97    749.23      1.00\n",
      " lambda[56]      2.87      8.63      0.98      0.01      5.79    950.79      1.00\n",
      " lambda[57]     18.38    181.88      1.09      0.01     11.12    323.25      1.00\n",
      " lambda[58]      2.41      5.52      0.95      0.00      4.87    822.45      1.00\n",
      " lambda[59]      3.05     11.02      0.98      0.00      5.60    605.73      1.00\n",
      " lambda[60]      3.19     10.82      0.98      0.00      5.98    708.87      1.00\n",
      " lambda[61]      2.30      6.61      0.88      0.00      4.80    775.48      1.00\n",
      " lambda[62]   1300.74   6856.01    135.66      0.01   1436.44    349.68      1.00\n",
      " lambda[63]      2.32      5.57      0.90      0.00      5.09    904.03      1.00\n",
      " lambda[64]      2.77      6.49      1.06      0.00      5.46    720.84      1.00\n",
      " lambda[65]      3.04      9.49      0.95      0.00      5.55    497.20      1.00\n",
      " lambda[66]      3.04     11.34      0.99      0.00      6.11    805.26      1.00\n",
      " lambda[67]      3.49     11.90      1.02      0.00      6.27    908.17      1.00\n",
      " lambda[68]      4.23     24.17      1.04      0.00      6.49    600.05      1.00\n",
      " lambda[69]      4.71     20.17      1.06      0.00      6.53    550.34      1.00\n",
      " lambda[70]      2.62      6.27      1.01      0.00      5.41    609.81      1.00\n",
      " lambda[71]      2.79      7.90      1.00      0.00      4.88    505.91      1.00\n",
      " lambda[72]      2.32      6.00      0.93      0.00      4.76    610.56      1.00\n",
      " lambda[73]      2.96     10.94      1.01      0.00      5.57    513.42      1.01\n",
      " lambda[74]      2.71      6.97      1.02      0.01      5.62    590.18      1.00\n",
      " lambda[75]      5.58     30.29      0.99      0.00      7.07    476.00      1.01\n",
      " lambda[76]      2.72      6.94      1.02      0.00      5.71    592.60      1.00\n",
      " lambda[77]      7.11     42.00      1.04      0.00      6.58    369.69      1.00\n",
      " lambda[78]      3.30     10.12      1.02      0.01      5.84    606.71      1.00\n",
      " lambda[79]      2.80      8.73      0.96      0.01      4.76    898.18      1.00\n",
      " lambda[80]      2.84     12.79      0.99      0.00      5.87    943.04      1.00\n",
      " lambda[81]      2.67      7.89      0.98      0.00      5.40    978.04      1.00\n",
      " lambda[82]      2.36      6.14      0.96      0.00      4.68    586.63      1.00\n",
      " lambda[83]      3.60     10.84      0.97      0.00      7.48    667.36      1.00\n",
      " lambda[84]      3.49     11.46      0.95      0.00      5.91    460.46      1.00\n",
      " lambda[85]      2.49      7.04      0.87      0.00      5.30    538.42      1.00\n",
      " lambda[86]    283.41   5104.35      0.97      0.00      7.57    336.20      1.00\n",
      " lambda[87]      2.95      9.59      0.97      0.00      5.72    962.73      1.00\n",
      " lambda[88]      2.64      5.62      0.96      0.00      5.30    684.45      1.00\n",
      " lambda[89]    213.08   1849.73      1.54      0.00    209.65    459.21      1.00\n",
      " lambda[90]      2.70      8.69      0.95      0.00      5.66    954.59      1.00\n",
      " lambda[91]      2.39      5.04      0.95      0.00      4.96    788.58      1.00\n",
      " lambda[92]      2.79      6.92      1.03      0.00      5.91    809.81      1.00\n",
      " lambda[93]      2.76      7.91      0.94      0.00      5.44    625.02      1.00\n",
      " lambda[94]      3.05      9.01      0.92      0.00      5.30    578.74      1.00\n",
      " lambda[95]      3.55     14.54      0.92      0.00      5.85    821.69      1.00\n",
      " lambda[96]      2.97      9.21      0.98      0.00      5.78    531.47      1.00\n",
      " lambda[97]      2.42      6.41      0.94      0.01      4.89    963.84      1.00\n",
      " lambda[98]      3.08     10.38      0.99      0.00      5.98    839.24      1.00\n",
      " lambda[99]      2.25      5.49      0.89      0.00      4.73    677.20      1.00\n",
      "lambda[100]      3.35      8.58      1.07      0.00      7.04    359.96      1.00\n",
      "lambda[101]      3.54     13.74      0.98      0.01      6.66    697.21      1.00\n",
      "lambda[102]      3.26      9.39      0.97      0.00      6.14    541.78      1.00\n",
      "lambda[103]      3.39     15.61      0.92      0.00      5.70    489.28      1.00\n",
      "lambda[104]      2.96      9.97      0.93      0.00      5.11    567.27      1.00\n",
      "lambda[105]      4.62     18.61      1.04      0.00      7.15    546.25      1.00\n",
      "lambda[106]      2.61      7.20      0.91      0.00      6.19    651.39      1.00\n",
      "lambda[107]      4.96     63.94      1.03      0.00      5.05    793.89      1.00\n",
      "lambda[108]      2.42      5.06      0.93      0.00      6.04    750.07      1.00\n",
      "lambda[109]      8.31    107.86      0.98      0.00      7.70    567.19      1.00\n",
      "lambda[110]      3.58     14.59      1.04      0.00      5.68    783.73      1.00\n",
      "lambda[111]      5.28     35.42      0.97      0.00      6.14    866.86      1.00\n",
      "lambda[112]      2.25      5.48      1.01      0.01      4.70    629.31      1.00\n",
      "lambda[113]      4.88     18.31      1.03      0.00      6.84    563.21      1.00\n",
      "lambda[114]      2.56      6.39      0.94      0.00      5.76    726.20      1.00\n",
      "lambda[115]      2.68      8.52      0.96      0.00      5.25    738.01      1.00\n",
      "lambda[116]      4.71     48.56      1.05      0.01      5.85    980.31      1.00\n",
      "lambda[117]      4.58     37.09      0.97      0.00      5.29    786.03      1.00\n",
      "lambda[118]      4.15     22.92      0.87      0.00      6.26    473.08      1.00\n",
      "lambda[119]      3.06      9.09      1.01      0.01      6.03    529.80      1.00\n",
      "lambda[120]      3.48     12.05      0.99      0.00      6.59    853.61      1.00\n",
      "lambda[121]      2.89     13.29      0.98      0.00      5.71    898.50      1.00\n",
      "lambda[122]      2.90      8.95      0.95      0.00      5.21    524.12      1.00\n",
      "lambda[123]      2.95      7.47      0.96      0.00      6.11    396.35      1.00\n",
      "lambda[124]      2.73      6.67      0.96      0.01      5.48    529.50      1.00\n",
      "lambda[125]      2.65      6.63      1.01      0.00      5.40    602.39      1.00\n",
      "lambda[126]      2.34      7.75      0.95      0.00      4.33    909.54      1.00\n",
      "lambda[127]      3.18      9.59      0.93      0.00      5.24    547.71      1.00\n",
      "lambda[128]      3.16      8.75      1.03      0.00      6.52    555.16      1.00\n",
      "lambda[129]     11.71    165.77      0.91      0.00      5.47    342.63      1.00\n",
      "lambda[130]      3.32      9.46      1.00      0.00      6.52    596.12      1.01\n",
      "lambda[131]      5.25     40.64      1.03      0.00      6.72    511.95      1.00\n",
      "lambda[132]      3.03     10.56      1.03      0.00      5.64    403.04      1.00\n",
      "lambda[133]      2.93      9.43      0.96      0.00      5.14    526.42      1.00\n",
      "lambda[134]      3.07      7.21      1.00      0.00      7.43    501.68      1.01\n",
      "lambda[135]      2.44      6.31      0.95      0.00      4.32    925.96      1.01\n",
      "lambda[136]      3.00     10.92      0.90      0.00      5.87    584.57      1.00\n",
      "lambda[137]      3.47     21.02      1.10      0.01      6.14    940.25      1.00\n",
      "lambda[138]      3.02      8.11      1.03      0.00      5.98    607.00      1.00\n",
      "lambda[139]      2.85      7.51      0.97      0.00      6.05    519.22      1.00\n",
      "lambda[140]      2.87      9.00      0.96      0.00      5.58    731.55      1.00\n",
      "lambda[141]      3.25     14.73      0.89      0.00      5.97    644.25      1.01\n",
      "lambda[142]      5.44     40.25      0.97      0.00      5.55    505.10      1.00\n",
      "lambda[143]      2.84      8.16      1.00      0.00      5.35    674.50      1.00\n",
      "        msq      1.38      0.84      1.18      0.47      2.31    582.33      1.00\n",
      "      sigma      3.21      3.94      1.67      0.01      8.32    784.19      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    399.65      1.01\n",
      "       xisq      0.12      0.06      0.11      0.04      0.21    457.93      1.00\n",
      "\n",
      "Number of divergences: 18\n",
      "\n",
      "MCMC elapsed time: 38.088685750961304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.55e-04 +- 2.05e-02\n",
      "[dimension 02/145]  inactive:\t8.31e-04 +- 3.71e-02\n",
      "[dimension 03/145]  inactive:\t4.08e-04 +- 2.69e-02\n",
      "[dimension 04/145]  inactive:\t6.48e-03 +- 4.73e-02\n",
      "[dimension 05/145]  inactive:\t4.74e-05 +- 2.98e-02\n",
      "[dimension 06/145]  inactive:\t3.02e-03 +- 4.16e-02\n",
      "[dimension 07/145]  inactive:\t6.81e-04 +- 2.04e-02\n",
      "[dimension 08/145]  inactive:\t1.62e-03 +- 3.26e-02\n",
      "[dimension 09/145]  inactive:\t7.83e-04 +- 2.78e-02\n",
      "[dimension 10/145]  inactive:\t5.40e-04 +- 2.21e-02\n",
      "[dimension 11/145]  inactive:\t-1.08e-03 +- 2.92e-02\n",
      "[dimension 12/145]  inactive:\t1.87e-04 +- 2.44e-02\n",
      "[dimension 13/145]  inactive:\t5.99e-03 +- 4.55e-02\n",
      "[dimension 14/145]  inactive:\t-1.04e-03 +- 2.52e-02\n",
      "[dimension 15/145]  inactive:\t3.47e-03 +- 5.06e-02\n",
      "[dimension 16/145]  inactive:\t9.34e-04 +- 2.18e-02\n",
      "[dimension 17/145]  inactive:\t2.11e-03 +- 4.02e-02\n",
      "[dimension 18/145]  inactive:\t1.65e-04 +- 2.86e-02\n",
      "[dimension 19/145]  inactive:\t-2.32e-03 +- 2.22e-02\n",
      "[dimension 20/145]  inactive:\t-1.03e-03 +- 2.79e-02\n",
      "[dimension 21/145]  inactive:\t-2.56e-03 +- 3.07e-02\n",
      "[dimension 22/145]  inactive:\t-3.18e-04 +- 2.42e-02\n",
      "[dimension 23/145]  inactive:\t-5.04e-04 +- 2.66e-02\n",
      "[dimension 24/145]  inactive:\t1.82e-03 +- 3.27e-02\n",
      "[dimension 25/145]  inactive:\t4.41e-03 +- 2.74e-02\n",
      "[dimension 26/145]  inactive:\t-2.56e-04 +- 2.33e-02\n",
      "[dimension 27/145]  inactive:\t1.20e-03 +- 2.80e-02\n",
      "[dimension 28/145]  inactive:\t1.01e-03 +- 2.21e-02\n",
      "[dimension 29/145]  inactive:\t6.49e-04 +- 2.85e-02\n",
      "[dimension 30/145]  inactive:\t1.92e-03 +- 3.07e-02\n",
      "[dimension 31/145]  inactive:\t8.39e-03 +- 5.88e-02\n",
      "[dimension 32/145]  inactive:\t-6.30e-04 +- 3.14e-02\n",
      "[dimension 33/145]  inactive:\t5.26e-03 +- 5.94e-02\n",
      "[dimension 34/145]  inactive:\t1.20e-03 +- 2.23e-02\n",
      "[dimension 35/145]  inactive:\t1.27e-03 +- 3.05e-02\n",
      "[dimension 36/145]  inactive:\t1.43e-03 +- 2.85e-02\n",
      "[dimension 37/145]  inactive:\t5.54e-03 +- 3.24e-02\n",
      "[dimension 38/145]  inactive:\t-1.55e-03 +- 3.51e-02\n",
      "[dimension 39/145]  inactive:\t2.19e-03 +- 3.57e-02\n",
      "[dimension 40/145]  inactive:\t2.82e-03 +- 2.63e-02\n",
      "[dimension 41/145]  inactive:\t-1.80e-03 +- 3.76e-02\n",
      "[dimension 42/145]  inactive:\t1.53e-02 +- 9.76e-02\n",
      "[dimension 43/145]  inactive:\t1.85e-04 +- 2.15e-02\n",
      "[dimension 44/145]  inactive:\t-8.19e-04 +- 3.00e-02\n",
      "[dimension 45/145]  inactive:\t-1.62e-04 +- 2.43e-02\n",
      "[dimension 46/145]  inactive:\t8.12e-04 +- 1.48e-02\n",
      "[dimension 47/145]  inactive:\t-2.03e-03 +- 3.28e-02\n",
      "[dimension 48/145]  inactive:\t1.76e-03 +- 2.48e-02\n",
      "[dimension 49/145]  inactive:\t3.64e-03 +- 3.04e-02\n",
      "[dimension 50/145]  inactive:\t-2.07e-03 +- 3.23e-02\n",
      "[dimension 51/145]  inactive:\t5.92e-03 +- 5.03e-02\n",
      "[dimension 52/145]  inactive:\t4.33e-03 +- 2.23e-02\n",
      "[dimension 53/145]  inactive:\t-1.19e-03 +- 2.78e-02\n",
      "[dimension 54/145]  inactive:\t5.91e-04 +- 2.62e-02\n",
      "[dimension 55/145]  inactive:\t7.57e-04 +- 1.69e-02\n",
      "[dimension 56/145]  inactive:\t-2.12e-03 +- 2.46e-02\n",
      "[dimension 57/145]  inactive:\t2.36e-03 +- 3.88e-02\n",
      "[dimension 58/145]  inactive:\t1.99e-02 +- 9.79e-02\n",
      "[dimension 59/145]  inactive:\t-7.19e-04 +- 2.17e-02\n",
      "[dimension 60/145]  inactive:\t1.71e-03 +- 2.99e-02\n",
      "[dimension 61/145]  inactive:\t3.87e-03 +- 3.16e-02\n",
      "[dimension 62/145]  inactive:\t-1.16e-04 +- 2.02e-02\n",
      "[dimension 63/145]  active:\t5.91e-01 +- 4.58e-01\n",
      "[dimension 64/145]  inactive:\t-2.12e-03 +- 2.34e-02\n",
      "[dimension 65/145]  inactive:\t-1.42e-04 +- 2.43e-02\n",
      "[dimension 66/145]  inactive:\t6.91e-04 +- 2.81e-02\n",
      "[dimension 67/145]  inactive:\t1.53e-03 +- 2.90e-02\n",
      "[dimension 68/145]  inactive:\t-1.64e-03 +- 3.76e-02\n",
      "[dimension 69/145]  inactive:\t3.25e-03 +- 3.87e-02\n",
      "[dimension 70/145]  inactive:\t4.41e-03 +- 2.67e-02\n",
      "[dimension 71/145]  inactive:\t6.27e-04 +- 2.90e-02\n",
      "[dimension 72/145]  inactive:\t5.59e-04 +- 2.39e-02\n",
      "[dimension 73/145]  inactive:\t3.64e-04 +- 1.86e-02\n",
      "[dimension 74/145]  inactive:\t-1.13e-03 +- 2.84e-02\n",
      "[dimension 75/145]  inactive:\t5.52e-04 +- 2.96e-02\n",
      "[dimension 76/145]  inactive:\t7.24e-03 +- 4.40e-02\n",
      "[dimension 77/145]  inactive:\t-1.22e-03 +- 3.10e-02\n",
      "[dimension 78/145]  inactive:\t1.63e-02 +- 9.99e-02\n",
      "[dimension 79/145]  inactive:\t6.67e-03 +- 3.63e-02\n",
      "[dimension 80/145]  inactive:\t3.71e-04 +- 3.32e-02\n",
      "[dimension 81/145]  inactive:\t1.33e-03 +- 2.92e-02\n",
      "[dimension 82/145]  inactive:\t4.16e-04 +- 1.85e-02\n",
      "[dimension 83/145]  inactive:\t-1.58e-03 +- 1.85e-02\n",
      "[dimension 84/145]  inactive:\t-1.76e-03 +- 3.25e-02\n",
      "[dimension 85/145]  inactive:\t5.18e-03 +- 4.33e-02\n",
      "[dimension 86/145]  inactive:\t-6.44e-04 +- 1.99e-02\n",
      "[dimension 87/145]  inactive:\t6.58e-03 +- 6.18e-02\n",
      "[dimension 88/145]  inactive:\t3.22e-03 +- 2.65e-02\n",
      "[dimension 89/145]  inactive:\t-7.81e-04 +- 2.75e-02\n",
      "[dimension 90/145]  inactive:\t1.56e-01 +- 3.34e-01\n",
      "[dimension 91/145]  inactive:\t7.08e-05 +- 2.08e-02\n",
      "[dimension 92/145]  inactive:\t-1.12e-03 +- 2.45e-02\n",
      "[dimension 93/145]  inactive:\t-3.89e-04 +- 2.31e-02\n",
      "[dimension 94/145]  inactive:\t1.86e-03 +- 2.53e-02\n",
      "[dimension 95/145]  inactive:\t-4.15e-04 +- 2.53e-02\n",
      "[dimension 96/145]  inactive:\t7.62e-04 +- 3.61e-02\n",
      "[dimension 97/145]  inactive:\t2.51e-03 +- 2.46e-02\n",
      "[dimension 98/145]  inactive:\t1.10e-04 +- 2.86e-02\n",
      "[dimension 99/145]  inactive:\t5.24e-03 +- 5.63e-02\n",
      "[dimension 100/145]  inactive:\t-5.35e-04 +- 1.74e-02\n",
      "[dimension 101/145]  inactive:\t-2.80e-03 +- 2.46e-02\n",
      "[dimension 102/145]  inactive:\t-1.41e-04 +- 2.71e-02\n",
      "[dimension 103/145]  inactive:\t1.84e-03 +- 2.75e-02\n",
      "[dimension 104/145]  inactive:\t-1.37e-03 +- 2.11e-02\n",
      "[dimension 105/145]  inactive:\t7.49e-04 +- 2.96e-02\n",
      "[dimension 106/145]  inactive:\t7.61e-03 +- 4.34e-02\n",
      "[dimension 107/145]  inactive:\t-7.23e-04 +- 2.26e-02\n",
      "[dimension 108/145]  inactive:\t5.23e-03 +- 5.43e-02\n",
      "[dimension 109/145]  inactive:\t-4.05e-04 +- 1.88e-02\n",
      "[dimension 110/145]  inactive:\t4.25e-04 +- 4.03e-02\n",
      "[dimension 111/145]  inactive:\t2.64e-03 +- 3.90e-02\n",
      "[dimension 112/145]  inactive:\t6.74e-03 +- 5.49e-02\n",
      "[dimension 113/145]  inactive:\t-1.11e-03 +- 2.09e-02\n",
      "[dimension 114/145]  inactive:\t2.25e-03 +- 5.06e-02\n",
      "[dimension 115/145]  inactive:\t1.61e-03 +- 2.18e-02\n",
      "[dimension 116/145]  inactive:\t7.80e-04 +- 3.44e-02\n",
      "[dimension 117/145]  inactive:\t4.60e-03 +- 4.64e-02\n",
      "[dimension 118/145]  inactive:\t3.53e-03 +- 2.86e-02\n",
      "[dimension 119/145]  inactive:\t-2.70e-03 +- 3.93e-02\n",
      "[dimension 120/145]  inactive:\t-1.60e-05 +- 2.93e-02\n",
      "[dimension 121/145]  inactive:\t4.47e-03 +- 3.81e-02\n",
      "[dimension 122/145]  inactive:\t-1.39e-03 +- 2.77e-02\n",
      "[dimension 123/145]  inactive:\t2.73e-03 +- 3.89e-02\n",
      "[dimension 124/145]  inactive:\t-1.17e-03 +- 2.06e-02\n",
      "[dimension 125/145]  inactive:\t-1.74e-03 +- 2.87e-02\n",
      "[dimension 126/145]  inactive:\t-3.97e-04 +- 2.43e-02\n",
      "[dimension 127/145]  inactive:\t-9.93e-05 +- 1.88e-02\n",
      "[dimension 128/145]  inactive:\t-7.86e-04 +- 2.61e-02\n",
      "[dimension 129/145]  inactive:\t-1.45e-04 +- 2.94e-02\n",
      "[dimension 130/145]  inactive:\t3.82e-03 +- 3.43e-02\n",
      "[dimension 131/145]  inactive:\t-1.04e-03 +- 3.08e-02\n",
      "[dimension 132/145]  inactive:\t6.83e-03 +- 5.74e-02\n",
      "[dimension 133/145]  inactive:\t2.81e-03 +- 2.33e-02\n",
      "[dimension 134/145]  inactive:\t-9.68e-04 +- 3.05e-02\n",
      "[dimension 135/145]  inactive:\t9.21e-04 +- 3.05e-02\n",
      "[dimension 136/145]  inactive:\t1.23e-03 +- 2.24e-02\n",
      "[dimension 137/145]  inactive:\t-2.18e-04 +- 2.90e-02\n",
      "[dimension 138/145]  inactive:\t6.10e-04 +- 2.67e-02\n",
      "[dimension 139/145]  inactive:\t5.92e-04 +- 2.67e-02\n",
      "[dimension 140/145]  inactive:\t-1.22e-03 +- 3.27e-02\n",
      "[dimension 141/145]  inactive:\t8.51e-04 +- 2.50e-02\n",
      "[dimension 142/145]  inactive:\t2.08e-03 +- 2.23e-02\n",
      "[dimension 143/145]  inactive:\t2.74e-03 +- 4.45e-02\n",
      "[dimension 144/145]  inactive:\t5.10e-04 +- 2.69e-02\n",
      "[dimension 145/145]  inactive:\t-6.56e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00745539]\n",
      "cov_act[[0.00069341]]\n",
      "Active_dimensions: [62]\n",
      "28, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:25<00:00, 58.87it/s, 15 steps of size 2.08e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    493.11      1.00\n",
      "  lambda[0]      3.05     15.49      0.97      0.00      5.85    977.90      1.00\n",
      "  lambda[1]      4.21     27.13      0.96      0.00      5.77    451.78      1.00\n",
      "  lambda[2]      3.60     11.39      1.01      0.01      6.38    435.54      1.00\n",
      "  lambda[3]      3.90     18.70      0.97      0.00      6.47    951.75      1.00\n",
      "  lambda[4]      2.76      6.29      1.05      0.00      6.47    807.53      1.00\n",
      "  lambda[5]      3.62     18.23      0.99      0.00      5.66    442.33      1.00\n",
      "  lambda[6]      2.76      6.75      0.95      0.00      5.84    813.83      1.00\n",
      "  lambda[7]      2.65      6.33      0.90      0.00      5.49    608.20      1.00\n",
      "  lambda[8]      2.89      7.23      0.95      0.01      6.32    741.12      1.00\n",
      "  lambda[9]      2.72      8.04      1.04      0.00      4.80    634.12      1.00\n",
      " lambda[10]      3.15     10.06      1.04      0.00      5.75    666.52      1.00\n",
      " lambda[11]      2.70      7.37      0.96      0.01      5.50    815.13      1.00\n",
      " lambda[12]      4.90     32.65      0.93      0.01      7.10    500.05      1.00\n",
      " lambda[13]      2.85      9.60      0.97      0.00      5.28    559.23      1.00\n",
      " lambda[14]      4.27     24.26      1.01      0.00      6.27    766.59      1.00\n",
      " lambda[15]      2.63      6.26      1.07      0.00      5.41    804.44      1.00\n",
      " lambda[16]      3.21     16.40      0.92      0.00      5.60    490.50      1.00\n",
      " lambda[17]      2.97      9.78      1.01      0.00      5.56    733.55      1.00\n",
      " lambda[18]      3.25     11.52      0.95      0.00      6.18    744.75      1.00\n",
      " lambda[19]      2.86      7.19      1.03      0.01      6.13    882.98      1.00\n",
      " lambda[20]      3.34      8.73      1.00      0.00      7.62    570.31      1.00\n",
      " lambda[21]      2.67      6.44      0.95      0.00      6.39    449.51      1.00\n",
      " lambda[22]      2.76      8.40      1.01      0.01      5.85    692.72      1.00\n",
      " lambda[23]      3.12     10.12      0.98      0.00      5.74    874.66      1.00\n",
      " lambda[24]      3.47     11.59      1.00      0.00      6.55    499.02      1.00\n",
      " lambda[25]      2.46      4.95      0.94      0.01      5.93    525.91      1.00\n",
      " lambda[26]      3.12     10.41      0.99      0.00      6.05    813.20      1.00\n",
      " lambda[27]      3.36     12.31      0.89      0.00      6.41    484.00      1.00\n",
      " lambda[28]      3.14     10.04      1.04      0.01      6.02    526.92      1.00\n",
      " lambda[29]      3.25     10.72      1.00      0.00      6.10    723.68      1.01\n",
      " lambda[30]      3.60     12.81      0.97      0.01      7.22    629.96      1.00\n",
      " lambda[31]      3.45     13.05      1.01      0.00      4.94    872.10      1.00\n",
      " lambda[32]      3.59     13.60      1.06      0.00      6.92    845.98      1.00\n",
      " lambda[33]      2.85     11.16      0.97      0.00      5.13    522.26      1.00\n",
      " lambda[34]      2.97      8.68      1.00      0.00      6.34    868.96      1.00\n",
      " lambda[35]      2.65      6.83      0.97      0.00      5.28    856.65      1.00\n",
      " lambda[36]      2.85      6.55      1.02      0.01      6.59    507.63      1.00\n",
      " lambda[37]      3.26      9.68      1.02      0.00      6.23    784.29      1.00\n",
      " lambda[38]      4.15     30.08      1.02      0.00      6.31    985.71      1.00\n",
      " lambda[39]      3.43     16.44      0.96      0.00      5.78    498.05      1.00\n",
      " lambda[40]      3.85     12.26      1.03      0.00      6.40    596.73      1.00\n",
      " lambda[41]     15.90    121.04      1.01      0.00      9.54    399.70      1.00\n",
      " lambda[42]      2.15      5.06      0.93      0.00      4.86   1011.65      1.00\n",
      " lambda[43]      4.56     40.96      1.01      0.00      5.79    528.54      1.00\n",
      " lambda[44]      2.87      8.41      0.99      0.01      6.09    895.59      1.00\n",
      " lambda[45]      2.79      9.29      0.95      0.00      4.99    784.01      1.00\n",
      " lambda[46]      2.22      5.06      0.95      0.00      4.43    869.29      1.00\n",
      " lambda[47]      2.90      6.45      1.04      0.00      6.58    751.47      1.00\n",
      " lambda[48]      3.25      8.30      1.00      0.00      7.05    549.61      1.00\n",
      " lambda[49]      2.74      7.89      0.96      0.00      5.26    767.48      1.00\n",
      " lambda[50]      3.97     21.04      0.95      0.00      6.22    668.65      1.00\n",
      " lambda[51]      3.17      8.66      0.98      0.00      6.67    775.51      1.00\n",
      " lambda[52]      3.14     11.62      0.97      0.00      5.43    568.84      1.00\n",
      " lambda[53]      2.78      7.52      0.91      0.01      5.51    516.40      1.00\n",
      " lambda[54]      2.27      7.48      0.91      0.00      4.46   1020.07      1.00\n",
      " lambda[55]      2.95     15.70      0.85      0.00      5.34    979.70      1.00\n",
      " lambda[56]      2.57      7.60      0.96      0.00      4.68    872.45      1.00\n",
      " lambda[57]     10.77     59.90      1.11      0.00     12.72    424.38      1.00\n",
      " lambda[58]      2.40      5.42      0.98      0.00      5.08    556.95      1.00\n",
      " lambda[59]      3.35      9.01      1.03      0.00      6.26    800.96      1.00\n",
      " lambda[60]      3.25     13.43      0.99      0.00      5.46    801.79      1.00\n",
      " lambda[61]      2.76      7.83      1.02      0.00      5.06    753.87      1.00\n",
      " lambda[62]    361.44    943.09    124.15      0.00    793.70    465.75      1.00\n",
      " lambda[63]      3.76     22.23      1.00      0.00      5.82    328.99      1.00\n",
      " lambda[64]      3.10     11.81      1.00      0.00      6.10    561.33      1.00\n",
      " lambda[65]      3.41     14.23      0.95      0.00      5.91    940.01      1.00\n",
      " lambda[66]      3.20      9.15      0.97      0.00      6.52    784.02      1.00\n",
      " lambda[67]      3.35     10.22      1.08      0.00      6.22    715.41      1.00\n",
      " lambda[68]      3.73     14.18      1.00      0.00      6.71    497.04      1.00\n",
      " lambda[69]      3.97     16.02      0.97      0.00      6.81    598.09      1.00\n",
      " lambda[70]      2.93     10.27      0.97      0.00      5.46    725.57      1.00\n",
      " lambda[71]      2.94     10.80      1.01      0.00      4.94    592.68      1.00\n",
      " lambda[72]      2.38      5.50      0.97      0.00      5.08    579.06      1.00\n",
      " lambda[73]      3.18     10.22      1.01      0.00      5.66    561.02      1.01\n",
      " lambda[74]      2.63      7.35      0.93      0.00      5.65    685.09      1.00\n",
      " lambda[75]      4.25     13.65      1.03      0.00      8.06    513.87      1.00\n",
      " lambda[76]      2.70      8.25      1.01      0.00      5.50    429.34      1.00\n",
      " lambda[77]      8.10     91.30      1.03      0.00      7.27    743.38      1.00\n",
      " lambda[78]      3.81     21.15      0.99      0.01      6.19    351.97      1.00\n",
      " lambda[79]      2.53     10.09      0.89      0.00      4.24    754.27      1.00\n",
      " lambda[80]      3.72     18.29      0.95      0.00      6.60    640.13      1.00\n",
      " lambda[81]      2.82      7.69      1.00      0.00      5.97    616.06      1.00\n",
      " lambda[82]      2.58      5.68      1.00      0.00      5.54    699.25      1.00\n",
      " lambda[83]      3.00      7.93      0.99      0.01      5.80    586.03      1.00\n",
      " lambda[84]      5.78     48.68      1.01      0.00      6.48    790.05      1.00\n",
      " lambda[85]      2.63      6.87      0.94      0.00      5.72    477.45      1.00\n",
      " lambda[86]      4.00     17.72      1.00      0.00      6.15    686.24      1.00\n",
      " lambda[87]      2.81      8.46      0.95      0.00      5.81    752.17      1.00\n",
      " lambda[88]      2.47      5.46      0.95      0.00      5.40    704.51      1.00\n",
      " lambda[89]     44.91    191.58      1.37      0.00     83.75    185.19      1.00\n",
      " lambda[90]      2.69      9.49      0.97      0.00      4.53    606.91      1.00\n",
      " lambda[91]      2.66      7.17      1.00      0.00      5.11    700.25      1.00\n",
      " lambda[92]      3.91     29.32      0.99      0.00      6.10    906.40      1.00\n",
      " lambda[93]      2.27      4.59      0.99      0.00      4.66    507.27      1.00\n",
      " lambda[94]      3.51     10.27      0.97      0.00      6.55    661.75      1.00\n",
      " lambda[95]      4.33     19.30      0.94      0.00      6.38    537.73      1.01\n",
      " lambda[96]      3.09      7.51      0.95      0.00      6.65    603.22      1.00\n",
      " lambda[97]      2.79      6.96      1.05      0.01      5.83    532.14      1.00\n",
      " lambda[98]      3.29     13.42      0.98      0.00      5.70    548.76      1.00\n",
      " lambda[99]      2.50      6.17      0.91      0.00      5.28    535.49      1.00\n",
      "lambda[100]      2.85      7.22      0.94      0.00      6.61    633.02      1.00\n",
      "lambda[101]      3.00      8.49      0.97      0.00      5.65    557.31      1.00\n",
      "lambda[102]      3.14     15.00      0.97      0.00      5.41    759.42      1.00\n",
      "lambda[103]      2.84     11.37      0.91      0.00      5.62    376.27      1.00\n",
      "lambda[104]      2.75      9.23      1.02      0.00      4.81    641.46      1.00\n",
      "lambda[105]      3.08      8.50      1.01      0.00      6.37    903.78      1.00\n",
      "lambda[106]      3.02     13.69      0.91      0.00      5.34    560.00      1.00\n",
      "lambda[107]      4.02     19.87      1.00      0.01      6.29    376.19      1.00\n",
      "lambda[108]      2.25      4.60      0.95      0.00      5.57    830.04      1.00\n",
      "lambda[109]      9.22    121.48      1.02      0.00      6.34    636.16      1.00\n",
      "lambda[110]      3.39     11.00      1.02      0.00      6.53    566.30      1.00\n",
      "lambda[111]      5.87     44.32      1.07      0.00      7.22    776.67      1.00\n",
      "lambda[112]      2.22      4.09      1.00      0.01      5.19    444.08      1.00\n",
      "lambda[113]      3.68     10.68      1.01      0.00      7.03    536.85      1.00\n",
      "lambda[114]      2.63      7.51      0.89      0.00      5.59    588.02      1.00\n",
      "lambda[115]      3.20      9.55      1.06      0.00      5.95    744.86      1.00\n",
      "lambda[116]      3.38     12.04      0.99      0.01      6.73    730.72      1.00\n",
      "lambda[117]      3.22     13.70      0.90      0.00      5.42    855.89      1.00\n",
      "lambda[118]      2.72      7.86      0.93      0.00      5.74    793.82      1.00\n",
      "lambda[119]      4.20     16.76      1.00      0.00      6.30    734.51      1.00\n",
      "lambda[120]      4.16     14.05      0.97      0.00      7.75    758.54      1.00\n",
      "lambda[121]      3.68     18.28      1.00      0.00      5.95    622.46      1.00\n",
      "lambda[122]      3.99     22.62      0.97      0.00      5.10    486.49      1.00\n",
      "lambda[123]      3.05      8.74      0.94      0.00      6.76    828.05      1.00\n",
      "lambda[124]      3.40     11.45      1.01      0.01      6.20    618.08      1.00\n",
      "lambda[125]      2.83      7.63      0.93      0.01      6.06    730.35      1.00\n",
      "lambda[126]      2.50      7.03      0.92      0.00      5.24    698.31      1.00\n",
      "lambda[127]      3.20     10.54      1.01      0.00      5.92    875.54      1.00\n",
      "lambda[128]      2.70      6.15      0.97      0.00      5.86    599.01      1.00\n",
      "lambda[129]      3.01     12.96      0.89      0.00      5.01    864.57      1.00\n",
      "lambda[130]      2.95     10.20      0.95      0.00      6.10    624.31      1.01\n",
      "lambda[131]      5.88     55.81      0.99      0.00      6.75    768.54      1.00\n",
      "lambda[132]      2.93      7.29      0.98      0.00      5.66    699.19      1.00\n",
      "lambda[133]      2.47      6.12      0.88      0.00      4.54    830.74      1.00\n",
      "lambda[134]      3.15      7.99      0.99      0.01      6.27    850.24      1.00\n",
      "lambda[135]      2.59      8.58      0.96      0.00      4.98    684.22      1.01\n",
      "lambda[136]      2.67      7.60      0.95      0.00      4.94    824.65      1.00\n",
      "lambda[137]      2.97     11.92      1.03      0.00      5.62    717.22      1.00\n",
      "lambda[138]      3.21     11.19      0.98      0.00      6.11    742.55      1.00\n",
      "lambda[139]      2.77      7.38      0.91      0.00      5.58    641.41      1.00\n",
      "lambda[140]      2.78      8.40      1.01      0.00      5.54    907.68      1.00\n",
      "lambda[141]      2.97      8.03      0.90      0.00      6.38    658.89      1.00\n",
      "lambda[142]      3.28     11.02      0.99      0.00      6.45    750.47      1.00\n",
      "lambda[143]      2.45      6.53      0.95      0.00      4.99    953.82      1.00\n",
      "        msq   3070.97  32467.12     34.91      1.38    834.47    652.04      1.00\n",
      "      sigma      4.70      5.99      2.17      0.02     12.17    840.62      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    687.57      1.00\n",
      "       xisq     75.37   1112.54      2.36      0.10     38.06    835.91      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 29.105117797851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.42e-04 +- 2.51e-02\n",
      "[dimension 02/145]  inactive:\t-1.02e-03 +- 3.13e-02\n",
      "[dimension 03/145]  inactive:\t2.38e-04 +- 3.46e-02\n",
      "[dimension 04/145]  inactive:\t6.55e-03 +- 4.47e-02\n",
      "[dimension 05/145]  inactive:\t-1.07e-03 +- 2.86e-02\n",
      "[dimension 06/145]  inactive:\t4.01e-03 +- 4.76e-02\n",
      "[dimension 07/145]  inactive:\t5.79e-04 +- 2.07e-02\n",
      "[dimension 08/145]  inactive:\t6.71e-04 +- 2.92e-02\n",
      "[dimension 09/145]  inactive:\t8.00e-04 +- 3.02e-02\n",
      "[dimension 10/145]  inactive:\t4.06e-04 +- 2.27e-02\n",
      "[dimension 11/145]  inactive:\t-7.45e-04 +- 2.60e-02\n",
      "[dimension 12/145]  inactive:\t1.70e-04 +- 3.30e-02\n",
      "[dimension 13/145]  inactive:\t5.77e-03 +- 4.68e-02\n",
      "[dimension 14/145]  inactive:\t-2.15e-03 +- 4.41e-02\n",
      "[dimension 15/145]  inactive:\t3.12e-03 +- 5.08e-02\n",
      "[dimension 16/145]  inactive:\t8.56e-04 +- 2.20e-02\n",
      "[dimension 17/145]  inactive:\t2.21e-03 +- 5.46e-02\n",
      "[dimension 18/145]  inactive:\t-3.14e-05 +- 3.13e-02\n",
      "[dimension 19/145]  inactive:\t-2.65e-03 +- 2.50e-02\n",
      "[dimension 20/145]  inactive:\t-1.21e-03 +- 3.03e-02\n",
      "[dimension 21/145]  inactive:\t-2.36e-03 +- 3.51e-02\n",
      "[dimension 22/145]  inactive:\t-2.70e-04 +- 2.59e-02\n",
      "[dimension 23/145]  inactive:\t-8.66e-04 +- 2.85e-02\n",
      "[dimension 24/145]  inactive:\t2.01e-03 +- 2.93e-02\n",
      "[dimension 25/145]  inactive:\t3.96e-03 +- 2.71e-02\n",
      "[dimension 26/145]  inactive:\t-4.77e-04 +- 3.35e-02\n",
      "[dimension 27/145]  inactive:\t1.53e-03 +- 3.02e-02\n",
      "[dimension 28/145]  inactive:\t1.06e-03 +- 2.21e-02\n",
      "[dimension 29/145]  inactive:\t9.88e-05 +- 3.35e-02\n",
      "[dimension 30/145]  inactive:\t1.97e-03 +- 3.42e-02\n",
      "[dimension 31/145]  inactive:\t6.49e-03 +- 5.16e-02\n",
      "[dimension 32/145]  inactive:\t-1.23e-03 +- 3.24e-02\n",
      "[dimension 33/145]  inactive:\t3.38e-03 +- 4.37e-02\n",
      "[dimension 34/145]  inactive:\t1.09e-03 +- 2.06e-02\n",
      "[dimension 35/145]  inactive:\t6.75e-04 +- 3.48e-02\n",
      "[dimension 36/145]  inactive:\t1.57e-03 +- 3.17e-02\n",
      "[dimension 37/145]  inactive:\t4.59e-03 +- 3.03e-02\n",
      "[dimension 38/145]  inactive:\t-2.15e-03 +- 3.40e-02\n",
      "[dimension 39/145]  inactive:\t2.55e-03 +- 4.27e-02\n",
      "[dimension 40/145]  inactive:\t4.21e-03 +- 3.46e-02\n",
      "[dimension 41/145]  inactive:\t-2.26e-03 +- 3.33e-02\n",
      "[dimension 42/145]  inactive:\t2.13e-02 +- 1.22e-01\n",
      "[dimension 43/145]  inactive:\t-4.45e-04 +- 2.01e-02\n",
      "[dimension 44/145]  inactive:\t-6.89e-04 +- 3.30e-02\n",
      "[dimension 45/145]  inactive:\t-1.97e-04 +- 3.07e-02\n",
      "[dimension 46/145]  inactive:\t9.65e-04 +- 1.73e-02\n",
      "[dimension 47/145]  inactive:\t-1.49e-03 +- 2.93e-02\n",
      "[dimension 48/145]  inactive:\t2.28e-03 +- 3.01e-02\n",
      "[dimension 49/145]  inactive:\t4.59e-03 +- 3.02e-02\n",
      "[dimension 50/145]  inactive:\t-1.29e-03 +- 2.45e-02\n",
      "[dimension 51/145]  inactive:\t4.61e-03 +- 4.18e-02\n",
      "[dimension 52/145]  inactive:\t5.85e-03 +- 2.62e-02\n",
      "[dimension 53/145]  inactive:\t-9.37e-04 +- 2.66e-02\n",
      "[dimension 54/145]  inactive:\t4.96e-04 +- 2.12e-02\n",
      "[dimension 55/145]  inactive:\t6.61e-04 +- 1.71e-02\n",
      "[dimension 56/145]  inactive:\t-2.09e-03 +- 2.33e-02\n",
      "[dimension 57/145]  inactive:\t9.43e-04 +- 3.19e-02\n",
      "[dimension 58/145]  inactive:\t2.76e-02 +- 1.15e-01\n",
      "[dimension 59/145]  inactive:\t-9.64e-04 +- 1.90e-02\n",
      "[dimension 60/145]  inactive:\t3.31e-03 +- 4.65e-02\n",
      "[dimension 61/145]  inactive:\t3.25e-03 +- 2.87e-02\n",
      "[dimension 62/145]  inactive:\t8.68e-05 +- 2.91e-02\n",
      "[dimension 63/145]  active:\t6.34e-01 +- 4.53e-01\n",
      "[dimension 64/145]  inactive:\t-3.08e-03 +- 2.84e-02\n",
      "[dimension 65/145]  inactive:\t-7.22e-04 +- 3.16e-02\n",
      "[dimension 66/145]  inactive:\t8.32e-04 +- 3.16e-02\n",
      "[dimension 67/145]  inactive:\t1.42e-03 +- 2.79e-02\n",
      "[dimension 68/145]  inactive:\t-1.29e-03 +- 4.14e-02\n",
      "[dimension 69/145]  inactive:\t4.76e-03 +- 4.60e-02\n",
      "[dimension 70/145]  inactive:\t4.14e-03 +- 2.56e-02\n",
      "[dimension 71/145]  inactive:\t1.34e-04 +- 3.25e-02\n",
      "[dimension 72/145]  inactive:\t6.81e-04 +- 2.45e-02\n",
      "[dimension 73/145]  inactive:\t3.47e-04 +- 1.76e-02\n",
      "[dimension 74/145]  inactive:\t-1.88e-03 +- 2.96e-02\n",
      "[dimension 75/145]  inactive:\t7.27e-05 +- 2.78e-02\n",
      "[dimension 76/145]  inactive:\t6.35e-03 +- 4.29e-02\n",
      "[dimension 77/145]  inactive:\t-1.78e-03 +- 3.32e-02\n",
      "[dimension 78/145]  inactive:\t1.22e-02 +- 8.72e-02\n",
      "[dimension 79/145]  inactive:\t7.23e-03 +- 3.93e-02\n",
      "[dimension 80/145]  inactive:\t-6.02e-04 +- 2.69e-02\n",
      "[dimension 81/145]  inactive:\t2.09e-03 +- 3.98e-02\n",
      "[dimension 82/145]  inactive:\t5.18e-04 +- 2.11e-02\n",
      "[dimension 83/145]  inactive:\t-1.93e-03 +- 2.11e-02\n",
      "[dimension 84/145]  inactive:\t-2.17e-03 +- 3.24e-02\n",
      "[dimension 85/145]  inactive:\t5.00e-03 +- 4.29e-02\n",
      "[dimension 86/145]  inactive:\t-1.15e-03 +- 2.47e-02\n",
      "[dimension 87/145]  inactive:\t5.99e-03 +- 6.76e-02\n",
      "[dimension 88/145]  inactive:\t2.32e-03 +- 2.32e-02\n",
      "[dimension 89/145]  inactive:\t-6.80e-04 +- 2.25e-02\n",
      "[dimension 90/145]  inactive:\t1.17e-01 +- 2.94e-01\n",
      "[dimension 91/145]  inactive:\t4.72e-05 +- 1.99e-02\n",
      "[dimension 92/145]  inactive:\t-1.43e-03 +- 2.65e-02\n",
      "[dimension 93/145]  inactive:\t-5.03e-04 +- 2.62e-02\n",
      "[dimension 94/145]  inactive:\t1.23e-03 +- 2.16e-02\n",
      "[dimension 95/145]  inactive:\t-7.65e-04 +- 3.15e-02\n",
      "[dimension 96/145]  inactive:\t2.03e-03 +- 4.87e-02\n",
      "[dimension 97/145]  inactive:\t3.13e-03 +- 2.67e-02\n",
      "[dimension 98/145]  inactive:\t7.35e-04 +- 3.97e-02\n",
      "[dimension 99/145]  inactive:\t4.02e-03 +- 4.35e-02\n",
      "[dimension 100/145]  inactive:\t-6.40e-04 +- 1.81e-02\n",
      "[dimension 101/145]  inactive:\t-2.50e-03 +- 2.44e-02\n",
      "[dimension 102/145]  inactive:\t-3.83e-04 +- 3.20e-02\n",
      "[dimension 103/145]  inactive:\t1.05e-03 +- 2.70e-02\n",
      "[dimension 104/145]  inactive:\t-9.68e-04 +- 2.01e-02\n",
      "[dimension 105/145]  inactive:\t-1.46e-04 +- 2.72e-02\n",
      "[dimension 106/145]  inactive:\t4.52e-03 +- 3.16e-02\n",
      "[dimension 107/145]  inactive:\t-1.28e-03 +- 2.11e-02\n",
      "[dimension 108/145]  inactive:\t7.22e-03 +- 6.58e-02\n",
      "[dimension 109/145]  inactive:\t-5.05e-04 +- 1.91e-02\n",
      "[dimension 110/145]  inactive:\t-1.00e-03 +- 4.61e-02\n",
      "[dimension 111/145]  inactive:\t4.31e-03 +- 4.75e-02\n",
      "[dimension 112/145]  inactive:\t1.13e-02 +- 7.65e-02\n",
      "[dimension 113/145]  inactive:\t-1.12e-03 +- 1.99e-02\n",
      "[dimension 114/145]  inactive:\t1.32e-03 +- 3.78e-02\n",
      "[dimension 115/145]  inactive:\t1.85e-03 +- 2.28e-02\n",
      "[dimension 116/145]  inactive:\t1.97e-03 +- 5.91e-02\n",
      "[dimension 117/145]  inactive:\t4.29e-03 +- 4.74e-02\n",
      "[dimension 118/145]  inactive:\t3.20e-03 +- 2.69e-02\n",
      "[dimension 119/145]  inactive:\t-1.77e-03 +- 3.03e-02\n",
      "[dimension 120/145]  inactive:\t-2.57e-04 +- 3.80e-02\n",
      "[dimension 121/145]  inactive:\t6.44e-03 +- 4.69e-02\n",
      "[dimension 122/145]  inactive:\t-2.82e-03 +- 3.53e-02\n",
      "[dimension 123/145]  inactive:\t3.59e-03 +- 4.88e-02\n",
      "[dimension 124/145]  inactive:\t-1.68e-03 +- 2.25e-02\n",
      "[dimension 125/145]  inactive:\t-2.29e-03 +- 3.12e-02\n",
      "[dimension 126/145]  inactive:\t-1.10e-03 +- 2.68e-02\n",
      "[dimension 127/145]  inactive:\t3.49e-05 +- 1.75e-02\n",
      "[dimension 128/145]  inactive:\t-8.77e-04 +- 3.29e-02\n",
      "[dimension 129/145]  inactive:\t2.52e-04 +- 2.85e-02\n",
      "[dimension 130/145]  inactive:\t3.59e-03 +- 3.05e-02\n",
      "[dimension 131/145]  inactive:\t-1.16e-03 +- 2.99e-02\n",
      "[dimension 132/145]  inactive:\t7.63e-03 +- 6.20e-02\n",
      "[dimension 133/145]  inactive:\t2.96e-03 +- 2.44e-02\n",
      "[dimension 134/145]  inactive:\t-1.41e-04 +- 2.86e-02\n",
      "[dimension 135/145]  inactive:\t9.97e-04 +- 3.37e-02\n",
      "[dimension 136/145]  inactive:\t1.08e-03 +- 1.91e-02\n",
      "[dimension 137/145]  inactive:\t-4.38e-04 +- 3.10e-02\n",
      "[dimension 138/145]  inactive:\t9.12e-04 +- 2.52e-02\n",
      "[dimension 139/145]  inactive:\t4.13e-04 +- 2.70e-02\n",
      "[dimension 140/145]  inactive:\t-9.87e-04 +- 3.02e-02\n",
      "[dimension 141/145]  inactive:\t1.24e-03 +- 2.88e-02\n",
      "[dimension 142/145]  inactive:\t1.86e-03 +- 2.14e-02\n",
      "[dimension 143/145]  inactive:\t1.47e-03 +- 4.35e-02\n",
      "[dimension 144/145]  inactive:\t4.67e-04 +- 2.27e-02\n",
      "[dimension 145/145]  inactive:\t3.34e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00422093]\n",
      "cov_act[[0.00045688]]\n",
      "Active_dimensions: [62]\n",
      "29, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 48.60it/s, 15 steps of size 1.96e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    552.42      1.00\n",
      "  lambda[0]      2.30      7.63      0.93      0.00      4.49   1001.47      1.00\n",
      "  lambda[1]      3.19     13.30      0.96      0.00      5.48    586.86      1.00\n",
      "  lambda[2]      2.75      7.05      1.02      0.01      5.71    544.55      1.00\n",
      "  lambda[3]      3.35     11.34      0.98      0.00      6.18    865.04      1.00\n",
      "  lambda[4]      2.66      6.35      0.94      0.00      5.51    666.78      1.00\n",
      "  lambda[5]      5.43     39.75      0.93      0.00      6.83    512.44      1.00\n",
      "  lambda[6]      3.73     13.92      0.95      0.00      7.21    654.11      1.00\n",
      "  lambda[7]      2.98      7.04      0.97      0.00      6.34    822.33      1.00\n",
      "  lambda[8]      2.68      7.88      1.03      0.01      5.74    891.74      1.00\n",
      "  lambda[9]      2.62      7.17      0.97      0.00      4.97    694.68      1.00\n",
      " lambda[10]      3.47     12.94      0.99      0.00      6.12    538.26      1.00\n",
      " lambda[11]      2.66      6.84      0.92      0.01      5.75    899.35      1.00\n",
      " lambda[12]      4.41     17.94      0.95      0.00      7.38    822.66      1.00\n",
      " lambda[13]      2.17      4.75      0.97      0.00      4.46    805.38      1.00\n",
      " lambda[14]      3.19      9.22      0.93      0.00      5.72    789.09      1.00\n",
      " lambda[15]      2.72      6.94      0.94      0.01      5.43    845.93      1.00\n",
      " lambda[16]      3.45     10.21      1.01      0.00      7.11    779.13      1.00\n",
      " lambda[17]      2.55      5.85      0.96      0.01      5.28    885.73      1.00\n",
      " lambda[18]      2.83      7.20      0.99      0.00      6.23    953.73      1.00\n",
      " lambda[19]      3.89     15.85      1.03      0.00      6.50    501.00      1.00\n",
      " lambda[20]      2.79      8.44      0.96      0.00      5.23    679.37      1.00\n",
      " lambda[21]      2.43      5.01      1.01      0.00      5.16    829.52      1.00\n",
      " lambda[22]      2.61      5.81      0.93      0.00      5.68    885.41      1.00\n",
      " lambda[23]      2.88      7.33      1.06      0.00      5.49    656.74      1.00\n",
      " lambda[24]      2.90      6.94      0.98      0.00      6.23    757.61      1.00\n",
      " lambda[25]      2.43      4.90      0.95      0.00      5.30    754.34      1.00\n",
      " lambda[26]      3.50     13.48      0.96      0.00      6.04    719.63      1.00\n",
      " lambda[27]      2.49      6.13      0.90      0.00      5.55    692.05      1.00\n",
      " lambda[28]      3.07     15.05      1.00      0.00      5.97    765.42      1.00\n",
      " lambda[29]      2.92      7.93      1.01      0.00      5.63    805.78      1.00\n",
      " lambda[30]      4.09     15.41      1.02      0.00      6.82    832.04      1.00\n",
      " lambda[31]      3.93     18.15      0.96      0.00      6.11    939.55      1.00\n",
      " lambda[32]      3.03      9.98      0.96      0.00      6.56    682.09      1.00\n",
      " lambda[33]      2.57      6.15      0.94      0.02      5.44    537.94      1.00\n",
      " lambda[34]      3.04     15.79      0.98      0.00      5.53    936.80      1.00\n",
      " lambda[35]      2.59      6.33      0.96      0.00      5.46    804.76      1.00\n",
      " lambda[36]      2.90      8.66      0.94      0.00      5.97    701.43      1.00\n",
      " lambda[37]      3.13     14.61      1.11      0.00      5.82    966.60      1.00\n",
      " lambda[38]      3.20      8.25      1.07      0.00      5.87    648.18      1.00\n",
      " lambda[39]      2.82      7.68      0.97      0.01      5.38    855.45      1.00\n",
      " lambda[40]      2.86      8.29      0.92      0.00      5.56    944.82      1.00\n",
      " lambda[41]     10.00     59.08      0.99      0.00     10.42    301.94      1.01\n",
      " lambda[42]      2.82      8.04      0.97      0.00      5.72    738.61      1.00\n",
      " lambda[43]      5.00     45.67      1.01      0.01      7.01    551.58      1.00\n",
      " lambda[44]      2.73      6.99      0.97      0.00      6.00    880.83      1.00\n",
      " lambda[45]      2.34      6.97      0.89      0.00      4.73    822.46      1.00\n",
      " lambda[46]      2.75      8.62      0.98      0.00      4.47    626.12      1.00\n",
      " lambda[47]      2.43      4.82      1.00      0.01      5.66    682.55      1.00\n",
      " lambda[48]      2.72     10.78      0.94      0.00      4.87    687.28      1.00\n",
      " lambda[49]      2.73      6.90      1.00      0.00      5.09    862.60      1.00\n",
      " lambda[50]      2.47      6.23      0.89      0.00      5.29    725.35      1.00\n",
      " lambda[51]      5.12     25.29      1.00      0.00      6.71    425.60      1.00\n",
      " lambda[52]      2.73      9.85      0.91      0.00      4.88   1039.24      1.00\n",
      " lambda[53]      2.67      6.59      0.94      0.00      5.54    918.61      1.00\n",
      " lambda[54]      2.14      4.31      0.96      0.00      4.32    721.50      1.00\n",
      " lambda[55]      2.25      5.40      0.92      0.00      4.22    737.60      1.00\n",
      " lambda[56]      2.89      7.32      0.96      0.01      5.31    588.47      1.00\n",
      " lambda[57]      8.31     74.48      1.00      0.00      8.42    892.25      1.00\n",
      " lambda[58]      2.44      5.30      0.93      0.01      5.66    786.27      1.00\n",
      " lambda[59]     17.60    445.12      1.05      0.00      5.75   1000.82      1.00\n",
      " lambda[60]      3.68     16.54      0.97      0.00      6.18    845.70      1.00\n",
      " lambda[61]      2.81      6.23      1.03      0.01      6.56    805.56      1.00\n",
      " lambda[62]  15096.76 430936.78    227.59      0.00   1863.37    965.42      1.00\n",
      " lambda[63]      2.57      7.17      0.94      0.00      5.06    563.09      1.00\n",
      " lambda[64]      2.79      6.88      0.96      0.00      5.36    619.56      1.00\n",
      " lambda[65]      2.64      6.89      1.03      0.01      5.21    816.90      1.00\n",
      " lambda[66]      3.06      7.52      1.00      0.00      7.10    862.23      1.00\n",
      " lambda[67]      2.76      7.35      0.93      0.00      6.08    668.25      1.00\n",
      " lambda[68]      3.20      8.02      1.08      0.00      6.08    704.59      1.00\n",
      " lambda[69]      3.67     13.60      0.99      0.00      5.58    603.23      1.00\n",
      " lambda[70]      2.55      7.08      0.99      0.00      5.36    566.31      1.00\n",
      " lambda[71]      2.46      5.82      0.93      0.00      4.93    369.40      1.00\n",
      " lambda[72]      2.54      6.85      0.96      0.01      5.04    570.26      1.00\n",
      " lambda[73]      3.83     18.34      0.99      0.00      6.66    957.94      1.00\n",
      " lambda[74]      3.76     14.41      0.96      0.00      6.02    661.33      1.00\n",
      " lambda[75]      6.30     42.35      1.06      0.00      7.16    920.52      1.00\n",
      " lambda[76]      3.24     12.89      0.94      0.00      5.41    739.03      1.00\n",
      " lambda[77]     20.24    188.78      1.05      0.00      8.61    322.60      1.00\n",
      " lambda[78]      3.40     10.70      1.04      0.01      6.34    505.23      1.00\n",
      " lambda[79]      2.56      7.74      0.87      0.01      4.92    922.88      1.00\n",
      " lambda[80]      4.84     47.82      1.08      0.00      6.16    980.28      1.00\n",
      " lambda[81]      2.97     12.51      1.01      0.00      5.14    571.21      1.00\n",
      " lambda[82]      2.84     10.71      0.94      0.00      4.80    414.85      1.00\n",
      " lambda[83]      3.18      9.49      1.04      0.00      6.21    813.39      1.00\n",
      " lambda[84]      2.77      6.15      1.08      0.00      5.92    547.89      1.00\n",
      " lambda[85]      2.91      8.39      0.92      0.00      5.46    668.64      1.00\n",
      " lambda[86]      3.02      9.16      1.02      0.00      5.77    844.26      1.00\n",
      " lambda[87]      4.09     24.54      0.97      0.00      6.33    739.64      1.00\n",
      " lambda[88]      2.63      6.44      0.94      0.00      4.85    761.12      1.00\n",
      " lambda[89]    132.51   1822.05      1.18      0.00     34.46    496.68      1.00\n",
      " lambda[90]      2.46      5.51      0.95      0.00      5.42    846.64      1.00\n",
      " lambda[91]      2.81      7.39      1.00      0.01      5.74    675.66      1.00\n",
      " lambda[92]      3.03      7.59      1.00      0.00      6.34    808.46      1.00\n",
      " lambda[93]      2.67      8.11      1.00      0.00      5.26    780.23      1.00\n",
      " lambda[94]      2.91      9.26      0.99      0.00      5.05    834.59      1.00\n",
      " lambda[95]      3.26      9.69      0.96      0.00      6.34    971.57      1.00\n",
      " lambda[96]      4.29     37.96      1.00      0.00      6.35    706.91      1.00\n",
      " lambda[97]      2.48      6.84      0.99      0.00      5.09    643.35      1.00\n",
      " lambda[98]     14.59    181.24      1.07      0.00      6.82    472.21      1.00\n",
      " lambda[99]      2.48      6.39      0.98      0.00      4.99    853.31      1.00\n",
      "lambda[100]      2.66      9.84      0.95      0.00      5.68   1060.94      1.00\n",
      "lambda[101]      2.91      8.86      0.93      0.00      5.45    629.52      1.00\n",
      "lambda[102]      2.65      6.66      0.99      0.00      5.04    918.71      1.00\n",
      "lambda[103]      2.48      6.66      0.97      0.00      5.35    709.23      1.00\n",
      "lambda[104]      2.58      7.64      0.94      0.00      4.77    980.45      1.00\n",
      "lambda[105]      2.86      6.70      0.98      0.00      6.21    852.56      1.00\n",
      "lambda[106]      2.32      5.03      0.91      0.01      5.06    808.38      1.00\n",
      "lambda[107]      4.20     23.11      1.00      0.00      5.74    561.82      1.00\n",
      "lambda[108]      2.74      8.85      0.93      0.00      5.09    645.41      1.00\n",
      "lambda[109]     10.36    178.74      0.95      0.00      6.83    647.84      1.00\n",
      "lambda[110]      3.09      9.37      1.02      0.00      5.88    618.29      1.01\n",
      "lambda[111]      3.44      8.92      1.00      0.00      7.85    826.05      1.00\n",
      "lambda[112]      2.23      4.67      0.97      0.01      4.95    860.76      1.00\n",
      "lambda[113]      3.04      9.18      0.96      0.00      5.93    708.03      1.00\n",
      "lambda[114]      4.43     50.69      0.98      0.00      6.05    836.76      1.00\n",
      "lambda[115]      3.52     20.15      0.97      0.00      5.74    983.66      1.00\n",
      "lambda[116]      7.44     71.55      1.04      0.00      6.36    290.73      1.00\n",
      "lambda[117]      5.79     80.66      0.92      0.00      5.82    847.42      1.00\n",
      "lambda[118]      2.92      7.85      0.95      0.00      5.80    788.39      1.00\n",
      "lambda[119]      2.77      8.10      0.98      0.00      5.72    835.57      1.00\n",
      "lambda[120]      5.61     60.13      1.09      0.00      7.65   1008.61      1.00\n",
      "lambda[121]      3.40     11.04      1.00      0.00      5.99    754.86      1.00\n",
      "lambda[122]      5.28     48.88      1.01      0.00      5.44    530.65      1.00\n",
      "lambda[123]      2.98      9.47      0.95      0.00      6.04    886.64      1.00\n",
      "lambda[124]      2.77      7.41      0.98      0.00      5.53    931.88      1.00\n",
      "lambda[125]      2.46      5.94      0.98      0.00      5.08    669.63      1.00\n",
      "lambda[126]      2.58      6.83      1.00      0.00      5.44    706.63      1.00\n",
      "lambda[127]      3.35     16.27      1.00      0.00      5.59    961.04      1.00\n",
      "lambda[128]      2.45      5.70      1.03      0.01      4.67    670.70      1.00\n",
      "lambda[129]      3.98     38.95      1.00      0.00      5.97    973.80      1.00\n",
      "lambda[130]      4.21     16.87      0.96      0.00      5.95    524.11      1.01\n",
      "lambda[131]      3.93     32.97      0.96      0.00      5.62    862.92      1.00\n",
      "lambda[132]      2.69      7.24      1.00      0.00      5.21    903.16      1.00\n",
      "lambda[133]      3.57     20.49      1.00      0.00      5.76    692.77      1.00\n",
      "lambda[134]      3.42     11.91      0.93      0.00      7.78    916.86      1.00\n",
      "lambda[135]      2.32      5.36      0.91      0.00      4.62    819.41      1.01\n",
      "lambda[136]      2.89      8.31      0.97      0.00      5.45    731.89      1.01\n",
      "lambda[137]      2.95     10.10      1.01      0.00      5.67    886.79      1.00\n",
      "lambda[138]      2.67      6.30      0.98      0.00      5.99    790.71      1.00\n",
      "lambda[139]      2.91      7.14      1.00      0.00      6.35    797.52      1.00\n",
      "lambda[140]      3.42     10.00      0.97      0.00      6.10    732.80      1.00\n",
      "lambda[141]      3.60     26.52      0.95      0.00      6.89    959.71      1.00\n",
      "lambda[142]      3.51     11.73      0.93      0.01      5.90    672.24      1.00\n",
      "lambda[143]      2.72     10.69      0.98      0.00      5.73    958.56      1.00\n",
      "        msq      1.46      0.85      1.28      0.46      2.49    936.71      1.00\n",
      "      sigma      4.12      5.45      1.74      0.00     12.13   1055.42      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    413.20      1.00\n",
      "       xisq      3.16      8.63      0.96      0.07      6.20    541.32      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.605247020721436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-5.34e-05 +- 1.38e-02\n",
      "[dimension 02/145]  inactive:\t5.95e-05 +- 2.21e-02\n",
      "[dimension 03/145]  inactive:\t2.46e-04 +- 1.92e-02\n",
      "[dimension 04/145]  inactive:\t3.93e-03 +- 3.58e-02\n",
      "[dimension 05/145]  inactive:\t-2.27e-04 +- 2.06e-02\n",
      "[dimension 06/145]  inactive:\t2.20e-03 +- 3.18e-02\n",
      "[dimension 07/145]  inactive:\t9.53e-04 +- 1.84e-02\n",
      "[dimension 08/145]  inactive:\t8.34e-04 +- 2.26e-02\n",
      "[dimension 09/145]  inactive:\t7.33e-04 +- 2.09e-02\n",
      "[dimension 10/145]  inactive:\t6.14e-04 +- 1.69e-02\n",
      "[dimension 11/145]  inactive:\t-1.37e-04 +- 2.65e-02\n",
      "[dimension 12/145]  inactive:\t4.07e-04 +- 2.34e-02\n",
      "[dimension 13/145]  inactive:\t4.71e-03 +- 3.99e-02\n",
      "[dimension 14/145]  inactive:\t-5.70e-04 +- 1.79e-02\n",
      "[dimension 15/145]  inactive:\t7.16e-04 +- 2.48e-02\n",
      "[dimension 16/145]  inactive:\t7.07e-04 +- 1.88e-02\n",
      "[dimension 17/145]  inactive:\t1.19e-03 +- 3.12e-02\n",
      "[dimension 18/145]  inactive:\t5.26e-05 +- 1.93e-02\n",
      "[dimension 19/145]  inactive:\t-1.24e-03 +- 1.67e-02\n",
      "[dimension 20/145]  inactive:\t-6.21e-04 +- 2.79e-02\n",
      "[dimension 21/145]  inactive:\t-8.88e-04 +- 2.06e-02\n",
      "[dimension 22/145]  inactive:\t2.69e-05 +- 1.46e-02\n",
      "[dimension 23/145]  inactive:\t-2.82e-04 +- 2.06e-02\n",
      "[dimension 24/145]  inactive:\t1.50e-03 +- 2.49e-02\n",
      "[dimension 25/145]  inactive:\t2.19e-03 +- 1.88e-02\n",
      "[dimension 26/145]  inactive:\t-2.95e-04 +- 2.11e-02\n",
      "[dimension 27/145]  inactive:\t8.03e-04 +- 2.16e-02\n",
      "[dimension 28/145]  inactive:\t5.54e-04 +- 1.47e-02\n",
      "[dimension 29/145]  inactive:\t3.33e-04 +- 2.30e-02\n",
      "[dimension 30/145]  inactive:\t7.95e-04 +- 2.24e-02\n",
      "[dimension 31/145]  inactive:\t5.66e-03 +- 4.36e-02\n",
      "[dimension 32/145]  inactive:\t-5.76e-04 +- 2.29e-02\n",
      "[dimension 33/145]  inactive:\t3.02e-03 +- 3.62e-02\n",
      "[dimension 34/145]  inactive:\t6.53e-04 +- 1.59e-02\n",
      "[dimension 35/145]  inactive:\t4.15e-04 +- 1.96e-02\n",
      "[dimension 36/145]  inactive:\t1.08e-03 +- 2.20e-02\n",
      "[dimension 37/145]  inactive:\t2.61e-03 +- 2.06e-02\n",
      "[dimension 38/145]  inactive:\t-5.53e-04 +- 2.36e-02\n",
      "[dimension 39/145]  inactive:\t1.66e-03 +- 3.07e-02\n",
      "[dimension 40/145]  inactive:\t2.98e-03 +- 2.77e-02\n",
      "[dimension 41/145]  inactive:\t-6.80e-04 +- 1.84e-02\n",
      "[dimension 42/145]  inactive:\t1.77e-02 +- 1.12e-01\n",
      "[dimension 43/145]  inactive:\t-4.48e-05 +- 1.74e-02\n",
      "[dimension 44/145]  inactive:\t-3.37e-04 +- 3.00e-02\n",
      "[dimension 45/145]  inactive:\t8.35e-05 +- 2.00e-02\n",
      "[dimension 46/145]  inactive:\t6.20e-04 +- 1.30e-02\n",
      "[dimension 47/145]  inactive:\t-1.09e-03 +- 2.71e-02\n",
      "[dimension 48/145]  inactive:\t7.99e-04 +- 1.80e-02\n",
      "[dimension 49/145]  inactive:\t1.68e-03 +- 1.92e-02\n",
      "[dimension 50/145]  inactive:\t-7.68e-04 +- 1.83e-02\n",
      "[dimension 51/145]  inactive:\t1.82e-03 +- 2.55e-02\n",
      "[dimension 52/145]  inactive:\t5.19e-03 +- 2.54e-02\n",
      "[dimension 53/145]  inactive:\t-4.03e-04 +- 1.85e-02\n",
      "[dimension 54/145]  inactive:\t5.31e-04 +- 1.89e-02\n",
      "[dimension 55/145]  inactive:\t4.27e-04 +- 1.26e-02\n",
      "[dimension 56/145]  inactive:\t-1.11e-03 +- 1.62e-02\n",
      "[dimension 57/145]  inactive:\t1.31e-03 +- 2.83e-02\n",
      "[dimension 58/145]  inactive:\t1.32e-02 +- 7.43e-02\n",
      "[dimension 59/145]  inactive:\t-5.57e-04 +- 1.62e-02\n",
      "[dimension 60/145]  inactive:\t2.80e-03 +- 3.45e-02\n",
      "[dimension 61/145]  inactive:\t2.29e-03 +- 2.34e-02\n",
      "[dimension 62/145]  inactive:\t-3.57e-04 +- 2.07e-02\n",
      "[dimension 63/145]  active:\t7.09e-01 +- 4.11e-01\n",
      "[dimension 64/145]  inactive:\t-1.33e-03 +- 1.77e-02\n",
      "[dimension 65/145]  inactive:\t-8.33e-05 +- 2.15e-02\n",
      "[dimension 66/145]  inactive:\t1.35e-04 +- 1.73e-02\n",
      "[dimension 67/145]  inactive:\t7.34e-04 +- 2.12e-02\n",
      "[dimension 68/145]  inactive:\t-2.90e-04 +- 2.44e-02\n",
      "[dimension 69/145]  inactive:\t3.14e-03 +- 3.58e-02\n",
      "[dimension 70/145]  inactive:\t2.99e-03 +- 2.16e-02\n",
      "[dimension 71/145]  inactive:\t1.87e-04 +- 2.29e-02\n",
      "[dimension 72/145]  inactive:\t9.17e-04 +- 2.01e-02\n",
      "[dimension 73/145]  inactive:\t3.94e-04 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-9.59e-04 +- 2.26e-02\n",
      "[dimension 75/145]  inactive:\t1.54e-03 +- 2.86e-02\n",
      "[dimension 76/145]  inactive:\t5.76e-03 +- 4.03e-02\n",
      "[dimension 77/145]  inactive:\t-8.43e-04 +- 2.34e-02\n",
      "[dimension 78/145]  inactive:\t2.06e-02 +- 1.17e-01\n",
      "[dimension 79/145]  inactive:\t5.08e-03 +- 3.21e-02\n",
      "[dimension 80/145]  inactive:\t-2.01e-04 +- 2.01e-02\n",
      "[dimension 81/145]  inactive:\t1.65e-03 +- 3.29e-02\n",
      "[dimension 82/145]  inactive:\t3.00e-04 +- 1.54e-02\n",
      "[dimension 83/145]  inactive:\t-9.64e-04 +- 1.51e-02\n",
      "[dimension 84/145]  inactive:\t-7.79e-04 +- 2.12e-02\n",
      "[dimension 85/145]  inactive:\t1.47e-03 +- 2.01e-02\n",
      "[dimension 86/145]  inactive:\t-2.67e-04 +- 1.82e-02\n",
      "[dimension 87/145]  inactive:\t1.72e-03 +- 3.11e-02\n",
      "[dimension 88/145]  inactive:\t2.35e-03 +- 2.34e-02\n",
      "[dimension 89/145]  inactive:\t-4.34e-04 +- 1.96e-02\n",
      "[dimension 90/145]  inactive:\t7.56e-02 +- 2.39e-01\n",
      "[dimension 91/145]  inactive:\t2.23e-05 +- 1.64e-02\n",
      "[dimension 92/145]  inactive:\t-9.79e-04 +- 2.19e-02\n",
      "[dimension 93/145]  inactive:\t-2.50e-04 +- 2.09e-02\n",
      "[dimension 94/145]  inactive:\t1.56e-03 +- 2.42e-02\n",
      "[dimension 95/145]  inactive:\t2.39e-06 +- 1.95e-02\n",
      "[dimension 96/145]  inactive:\t8.65e-04 +- 3.22e-02\n",
      "[dimension 97/145]  inactive:\t2.23e-03 +- 2.19e-02\n",
      "[dimension 98/145]  inactive:\t-2.18e-04 +- 1.68e-02\n",
      "[dimension 99/145]  inactive:\t9.67e-03 +- 7.74e-02\n",
      "[dimension 100/145]  inactive:\t-3.73e-04 +- 1.47e-02\n",
      "[dimension 101/145]  inactive:\t-1.27e-03 +- 1.64e-02\n",
      "[dimension 102/145]  inactive:\t-4.64e-04 +- 1.85e-02\n",
      "[dimension 103/145]  inactive:\t5.59e-04 +- 1.79e-02\n",
      "[dimension 104/145]  inactive:\t-6.26e-04 +- 1.52e-02\n",
      "[dimension 105/145]  inactive:\t2.65e-04 +- 2.06e-02\n",
      "[dimension 106/145]  inactive:\t3.70e-03 +- 2.75e-02\n",
      "[dimension 107/145]  inactive:\t-4.37e-04 +- 1.47e-02\n",
      "[dimension 108/145]  inactive:\t5.85e-03 +- 6.27e-02\n",
      "[dimension 109/145]  inactive:\t-1.89e-04 +- 1.72e-02\n",
      "[dimension 110/145]  inactive:\t1.02e-04 +- 3.16e-02\n",
      "[dimension 111/145]  inactive:\t1.97e-03 +- 3.01e-02\n",
      "[dimension 112/145]  inactive:\t4.09e-03 +- 3.72e-02\n",
      "[dimension 113/145]  inactive:\t-6.83e-04 +- 1.87e-02\n",
      "[dimension 114/145]  inactive:\t8.10e-04 +- 2.67e-02\n",
      "[dimension 115/145]  inactive:\t1.32e-03 +- 1.85e-02\n",
      "[dimension 116/145]  inactive:\t1.02e-03 +- 3.16e-02\n",
      "[dimension 117/145]  inactive:\t4.67e-03 +- 5.28e-02\n",
      "[dimension 118/145]  inactive:\t1.91e-03 +- 1.86e-02\n",
      "[dimension 119/145]  inactive:\t-6.33e-04 +- 2.65e-02\n",
      "[dimension 120/145]  inactive:\t8.34e-05 +- 1.88e-02\n",
      "[dimension 121/145]  inactive:\t3.75e-03 +- 3.65e-02\n",
      "[dimension 122/145]  inactive:\t-1.25e-03 +- 2.58e-02\n",
      "[dimension 123/145]  inactive:\t2.47e-03 +- 4.14e-02\n",
      "[dimension 124/145]  inactive:\t-8.82e-04 +- 1.68e-02\n",
      "[dimension 125/145]  inactive:\t-8.84e-04 +- 2.33e-02\n",
      "[dimension 126/145]  inactive:\t-2.05e-04 +- 1.65e-02\n",
      "[dimension 127/145]  inactive:\t3.73e-04 +- 1.48e-02\n",
      "[dimension 128/145]  inactive:\t-4.01e-04 +- 2.53e-02\n",
      "[dimension 129/145]  inactive:\t1.92e-04 +- 2.23e-02\n",
      "[dimension 130/145]  inactive:\t2.57e-03 +- 2.48e-02\n",
      "[dimension 131/145]  inactive:\t9.72e-04 +- 3.98e-02\n",
      "[dimension 132/145]  inactive:\t4.29e-03 +- 4.10e-02\n",
      "[dimension 133/145]  inactive:\t2.00e-03 +- 1.95e-02\n",
      "[dimension 134/145]  inactive:\t-1.84e-04 +- 2.55e-02\n",
      "[dimension 135/145]  inactive:\t6.43e-04 +- 2.36e-02\n",
      "[dimension 136/145]  inactive:\t7.45e-04 +- 1.50e-02\n",
      "[dimension 137/145]  inactive:\t8.82e-06 +- 2.37e-02\n",
      "[dimension 138/145]  inactive:\t3.67e-04 +- 1.99e-02\n",
      "[dimension 139/145]  inactive:\t3.85e-04 +- 1.86e-02\n",
      "[dimension 140/145]  inactive:\t-3.23e-04 +- 2.65e-02\n",
      "[dimension 141/145]  inactive:\t1.44e-03 +- 2.43e-02\n",
      "[dimension 142/145]  inactive:\t1.80e-03 +- 2.11e-02\n",
      "[dimension 143/145]  inactive:\t2.04e-03 +- 3.89e-02\n",
      "[dimension 144/145]  inactive:\t3.51e-04 +- 1.80e-02\n",
      "[dimension 145/145]  inactive:\t3.43e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.6125946]\n",
      "cov_act[[0.02378339]]\n",
      "Active_dimensions: [62]\n",
      "30, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:31<00:00, 47.23it/s, 15 steps of size 1.93e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    790.60      1.00\n",
      "  lambda[0]      2.60     10.83      0.98      0.01      5.27    981.12      1.00\n",
      "  lambda[1]      3.65     16.61      0.93      0.00      5.72    567.85      1.00\n",
      "  lambda[2]      2.58      5.58      1.03      0.00      5.45    637.19      1.00\n",
      "  lambda[3]      5.82     35.29      0.97      0.00      7.19    829.90      1.00\n",
      "  lambda[4]      2.60      6.87      1.05      0.00      5.80    730.19      1.00\n",
      "  lambda[5]      4.07     23.37      0.96      0.00      6.34    775.56      1.00\n",
      "  lambda[6]      3.04     13.08      0.94      0.00      5.63    963.36      1.00\n",
      "  lambda[7]      2.79      7.86      0.95      0.01      5.78    625.45      1.00\n",
      "  lambda[8]      2.58      5.84      0.99      0.02      5.95    862.00      1.00\n",
      "  lambda[9]      2.71     10.03      0.96      0.00      4.82    654.99      1.00\n",
      " lambda[10]      4.07     21.05      1.05      0.00      6.60    762.73      1.01\n",
      " lambda[11]      2.53      6.45      0.95      0.01      4.95    930.90      1.00\n",
      " lambda[12]      7.63     72.17      1.03      0.00      7.83    444.82      1.00\n",
      " lambda[13]      2.96      9.01      1.06      0.00      5.88    604.81      1.00\n",
      " lambda[14]      8.87    148.81      0.94      0.00      4.60    713.17      1.00\n",
      " lambda[15]      2.95     14.39      0.96      0.00      4.86    933.39      1.00\n",
      " lambda[16]      3.08      7.65      1.03      0.00      5.63    556.38      1.00\n",
      " lambda[17]      4.39     45.32      1.03      0.00      5.85    633.15      1.00\n",
      " lambda[18]      2.86      6.29      0.96      0.00      6.60    670.07      1.00\n",
      " lambda[19]      3.83     19.17      1.05      0.00      6.67    653.50      1.00\n",
      " lambda[20]      2.67      6.73      0.97      0.00      5.70    768.58      1.00\n",
      " lambda[21]      2.61      6.48      1.00      0.00      5.56    716.75      1.00\n",
      " lambda[22]      2.92      6.93      0.99      0.01      5.93    743.34      1.00\n",
      " lambda[23]      6.78     87.46      1.02      0.00      5.74    856.35      1.00\n",
      " lambda[24]      3.42     20.18      0.88      0.00      6.17    886.18      1.00\n",
      " lambda[25]      2.48      6.04      0.96      0.00      5.02    538.63      1.00\n",
      " lambda[26]      3.41     15.18      0.97      0.00      5.59    551.87      1.00\n",
      " lambda[27]      2.89      8.43      0.97      0.00      6.15    644.83      1.00\n",
      " lambda[28]      2.90     10.46      1.04      0.00      5.30    704.83      1.00\n",
      " lambda[29]      3.71     14.63      0.93      0.00      6.34    575.34      1.00\n",
      " lambda[30]      3.93     14.87      1.04      0.00      7.74    812.11      1.00\n",
      " lambda[31]      3.81     15.65      1.03      0.00      6.01    770.25      1.00\n",
      " lambda[32]      2.78      7.56      1.00      0.00      5.74   1020.50      1.00\n",
      " lambda[33]      3.01     10.79      1.03      0.00      5.23    799.89      1.00\n",
      " lambda[34]      3.27     10.99      0.95      0.00      6.08    715.66      1.00\n",
      " lambda[35]      3.19     11.85      1.02      0.00      5.71    413.61      1.00\n",
      " lambda[36]      2.91     10.21      1.01      0.00      4.93    886.43      1.00\n",
      " lambda[37]      4.53     43.98      1.08      0.00      6.20    987.29      1.00\n",
      " lambda[38]      3.17      9.19      0.96      0.00      5.59    626.31      1.00\n",
      " lambda[39]      2.90      8.95      0.95      0.00      6.05   1001.08      1.00\n",
      " lambda[40]      3.21     11.22      1.00      0.00      5.85    738.77      1.00\n",
      " lambda[41]     44.85    432.47      1.02      0.00     12.86    459.40      1.00\n",
      " lambda[42]      2.98      9.40      0.98      0.00      5.94    741.40      1.00\n",
      " lambda[43]      3.39     22.96      0.97      0.00      6.00   1001.26      1.00\n",
      " lambda[44]      3.09     10.84      0.96      0.00      5.62    703.20      1.00\n",
      " lambda[45]      2.79      6.85      1.04      0.00      5.79    528.05      1.00\n",
      " lambda[46]      2.82     12.24      0.99      0.00      4.66    798.08      1.00\n",
      " lambda[47]      2.93     10.21      1.00      0.00      5.53    782.90      1.00\n",
      " lambda[48]      2.39      9.24      1.02      0.00      4.81    964.97      1.00\n",
      " lambda[49]      3.22     10.88      0.98      0.00      5.65    813.31      1.00\n",
      " lambda[50]      2.96     10.06      0.97      0.00      4.82    758.27      1.00\n",
      " lambda[51]      5.60     67.25      0.95      0.00      6.38    936.24      1.00\n",
      " lambda[52]      3.34     16.10      0.95      0.00      5.78    715.70      1.00\n",
      " lambda[53]      2.41      6.24      0.96      0.00      4.60    705.92      1.00\n",
      " lambda[54]      2.49      7.84      0.96      0.00      4.63    749.76      1.00\n",
      " lambda[55]      2.66      8.47      1.03      0.00      5.43    677.49      1.00\n",
      " lambda[56]      2.54      5.75      0.92      0.01      5.35    755.85      1.00\n",
      " lambda[57]      8.49     50.23      0.98      0.00      9.15    628.89      1.00\n",
      " lambda[58]      2.18      5.12      0.98      0.00      4.97    566.60      1.00\n",
      " lambda[59]      3.38     16.95      0.98      0.00      6.09    922.07      1.00\n",
      " lambda[60]      3.09     10.78      0.94      0.00      5.39    764.69      1.00\n",
      " lambda[61]      3.72     31.88      1.02      0.01      5.13    914.42      1.00\n",
      " lambda[62]    510.27   1929.76    159.46      0.00    895.45    645.57      1.00\n",
      " lambda[63]      2.51      6.37      0.94      0.00      4.99    584.47      1.00\n",
      " lambda[64]      2.89      6.55      0.96      0.00      6.16    724.20      1.00\n",
      " lambda[65]      2.52      7.82      1.00      0.00      4.74    998.06      1.00\n",
      " lambda[66]      3.32      9.67      1.03      0.00      6.42    653.62      1.00\n",
      " lambda[67]      2.73      6.97      0.92      0.00      5.78    689.10      1.00\n",
      " lambda[68]      5.03     61.79      0.98      0.00      6.79    995.84      1.00\n",
      " lambda[69]      3.03     12.34      1.02      0.00      5.23    878.08      1.00\n",
      " lambda[70]      3.52     14.37      0.96      0.00      5.98    408.44      1.00\n",
      " lambda[71]      3.59     14.12      0.91      0.00      5.29    439.15      1.00\n",
      " lambda[72]      2.46      5.66      0.96      0.01      4.87    391.30      1.00\n",
      " lambda[73]      2.93      9.31      1.00      0.00      6.08    561.84      1.00\n",
      " lambda[74]      2.63      6.29      1.00      0.00      5.43    831.18      1.00\n",
      " lambda[75]      6.38     34.25      1.09      0.00      8.70    392.77      1.01\n",
      " lambda[76]      4.40     31.22      1.00      0.00      6.62    476.01      1.00\n",
      " lambda[77]      5.39     60.99      1.02      0.00      5.87    952.17      1.00\n",
      " lambda[78]      3.37     10.64      0.97      0.00      6.46    606.21      1.00\n",
      " lambda[79]      3.01     13.76      0.89      0.00      5.53    994.15      1.00\n",
      " lambda[80]      3.49     14.51      0.94      0.00      5.71    395.77      1.00\n",
      " lambda[81]      2.26      5.26      0.89      0.01      5.30    947.36      1.00\n",
      " lambda[82]      3.20     11.69      0.98      0.00      5.53    604.79      1.00\n",
      " lambda[83]      2.77      7.25      0.98      0.00      5.66    875.79      1.00\n",
      " lambda[84]      3.74     17.60      0.92      0.00      6.52    656.02      1.00\n",
      " lambda[85]      2.73      7.74      0.98      0.00      5.43    839.06      1.00\n",
      " lambda[86]      3.08      9.19      0.93      0.00      6.17    866.25      1.00\n",
      " lambda[87]      2.89      6.53      1.03      0.00      6.05    787.35      1.00\n",
      " lambda[88]      2.70      7.20      0.94      0.00      5.42    740.28      1.00\n",
      " lambda[89]     63.90    599.85      1.23      0.00     40.66    712.39      1.00\n",
      " lambda[90]      2.98     12.15      0.96      0.00      5.00    524.61      1.00\n",
      " lambda[91]      2.64      6.48      0.98      0.01      5.40    797.09      1.00\n",
      " lambda[92]      2.56      6.13      0.97      0.00      5.03    597.85      1.00\n",
      " lambda[93]      2.63      6.12      1.03      0.00      5.07    740.35      1.00\n",
      " lambda[94]      2.60      6.33      1.02      0.00      6.04    939.53      1.00\n",
      " lambda[95]      3.41     16.82      0.91      0.00      5.79    469.50      1.00\n",
      " lambda[96]      4.38     28.99      0.98      0.00      6.12    630.67      1.00\n",
      " lambda[97]      3.07      8.87      0.97      0.00      5.71    656.07      1.00\n",
      " lambda[98]      5.04     39.63      1.05      0.00      6.60    566.80      1.00\n",
      " lambda[99]      3.14      9.31      0.96      0.00      5.64    480.43      1.00\n",
      "lambda[100]      3.44     13.85      0.95      0.00      5.57    466.10      1.00\n",
      "lambda[101]      2.82      5.99      0.96      0.00      6.29    640.61      1.00\n",
      "lambda[102]      3.23     10.45      1.08      0.00      5.36    436.26      1.00\n",
      "lambda[103]      2.24      4.05      0.96      0.00      4.86    732.08      1.00\n",
      "lambda[104]      2.64      5.78      0.95      0.00      5.13    591.73      1.00\n",
      "lambda[105]      4.00     16.96      0.99      0.00      6.30    626.46      1.00\n",
      "lambda[106]      2.69      5.79      0.93      0.00      6.28    742.33      1.00\n",
      "lambda[107]      5.09     46.87      0.97      0.00      5.14    744.21      1.00\n",
      "lambda[108]      2.59      7.97      0.93      0.00      4.98    594.72      1.00\n",
      "lambda[109]      6.91    134.60      0.93      0.00      5.67   1004.40      1.00\n",
      "lambda[110]      3.58     16.85      0.98      0.00      6.04    841.46      1.00\n",
      "lambda[111]      4.97     20.88      0.95      0.00      7.72    497.90      1.00\n",
      "lambda[112]      2.66      7.52      0.97      0.00      5.31    682.99      1.00\n",
      "lambda[113]      4.01     13.89      1.02      0.00      7.55    718.40      1.00\n",
      "lambda[114]      3.99     32.65      0.89      0.00      5.15    978.47      1.00\n",
      "lambda[115]      3.78     13.90      1.02      0.00      6.45    861.69      1.00\n",
      "lambda[116]      2.73      5.79      1.05      0.01      6.92    818.31      1.00\n",
      "lambda[117]      3.22     11.30      0.97      0.00      5.53    927.41      1.00\n",
      "lambda[118]      2.99      7.46      0.98      0.00      6.45    864.36      1.00\n",
      "lambda[119]      2.83     15.20      1.01      0.00      5.18    863.35      1.00\n",
      "lambda[120]      4.10     13.97      1.04      0.00      7.12    859.22      1.00\n",
      "lambda[121]      2.99      9.38      0.91      0.00      6.24    752.14      1.00\n",
      "lambda[122]      3.20     10.22      0.95      0.00      5.85    666.17      1.00\n",
      "lambda[123]      2.80      8.41      0.98      0.00      5.48    943.46      1.00\n",
      "lambda[124]      2.59      5.78      1.02      0.00      5.91    724.46      1.00\n",
      "lambda[125]      3.04      7.14      0.95      0.01      6.69    628.43      1.00\n",
      "lambda[126]      2.92     10.73      0.94      0.00      4.98    387.33      1.00\n",
      "lambda[127]      2.87      7.40      0.97      0.00      5.80    769.96      1.00\n",
      "lambda[128]      2.66      7.24      0.99      0.00      5.15    853.72      1.00\n",
      "lambda[129]      4.50     36.08      1.02      0.00      6.03   1007.17      1.00\n",
      "lambda[130]      3.15     10.56      0.98      0.00      6.05    776.35      1.01\n",
      "lambda[131]      3.69     24.87      0.94      0.00      5.81    889.79      1.00\n",
      "lambda[132]      2.69      6.03      0.98      0.00      5.67    721.71      1.00\n",
      "lambda[133]      3.56     12.93      0.96      0.00      6.60    553.79      1.00\n",
      "lambda[134]      3.48      8.79      0.97      0.00      7.80    398.98      1.00\n",
      "lambda[135]      2.80     10.84      0.93      0.00      4.90    829.56      1.00\n",
      "lambda[136]      3.32     10.90      0.91      0.00      6.70    899.39      1.00\n",
      "lambda[137]      2.78      9.77      0.96      0.00      5.06    789.67      1.00\n",
      "lambda[138]      2.69      7.39      0.99      0.00      5.00    626.68      1.00\n",
      "lambda[139]      3.43     20.19      1.03      0.01      5.87    874.20      1.00\n",
      "lambda[140]      3.96     15.58      0.95      0.00      7.09    870.20      1.00\n",
      "lambda[141]      2.85      9.89      0.93      0.00      6.36    996.25      1.00\n",
      "lambda[142]      6.57     64.24      0.96      0.00      5.60    759.02      1.00\n",
      "lambda[143]      2.19      4.29      0.98      0.01      4.83    773.65      1.00\n",
      "        msq  17966.70 339276.56     20.54      0.87    671.26    962.20      1.00\n",
      "      sigma      4.46      5.95      2.19      0.01     11.90   1177.48      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1171.88      1.00\n",
      "       xisq      0.13      0.07      0.11      0.05      0.21    864.20      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 36.841567277908325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-5.01e-04 +- 2.13e-02\n",
      "[dimension 02/145]  inactive:\t-5.75e-04 +- 3.01e-02\n",
      "[dimension 03/145]  inactive:\t1.98e-04 +- 2.68e-02\n",
      "[dimension 04/145]  inactive:\t8.68e-03 +- 5.17e-02\n",
      "[dimension 05/145]  inactive:\t-1.13e-03 +- 2.73e-02\n",
      "[dimension 06/145]  inactive:\t2.87e-03 +- 4.18e-02\n",
      "[dimension 07/145]  inactive:\t5.89e-04 +- 2.11e-02\n",
      "[dimension 08/145]  inactive:\t4.68e-04 +- 3.11e-02\n",
      "[dimension 09/145]  inactive:\t5.00e-04 +- 2.45e-02\n",
      "[dimension 10/145]  inactive:\t3.72e-04 +- 2.12e-02\n",
      "[dimension 11/145]  inactive:\t-1.44e-03 +- 2.80e-02\n",
      "[dimension 12/145]  inactive:\t-7.56e-04 +- 2.45e-02\n",
      "[dimension 13/145]  inactive:\t9.73e-03 +- 6.94e-02\n",
      "[dimension 14/145]  inactive:\t-1.85e-03 +- 2.60e-02\n",
      "[dimension 15/145]  inactive:\t3.09e-03 +- 5.36e-02\n",
      "[dimension 16/145]  inactive:\t9.57e-04 +- 2.18e-02\n",
      "[dimension 17/145]  inactive:\t-2.34e-04 +- 3.28e-02\n",
      "[dimension 18/145]  inactive:\t-7.82e-04 +- 3.39e-02\n",
      "[dimension 19/145]  inactive:\t-2.52e-03 +- 2.31e-02\n",
      "[dimension 20/145]  inactive:\t-1.74e-03 +- 3.47e-02\n",
      "[dimension 21/145]  inactive:\t-2.02e-03 +- 2.69e-02\n",
      "[dimension 22/145]  inactive:\t9.16e-05 +- 2.21e-02\n",
      "[dimension 23/145]  inactive:\t-1.09e-03 +- 2.91e-02\n",
      "[dimension 24/145]  inactive:\t2.09e-03 +- 3.17e-02\n",
      "[dimension 25/145]  inactive:\t3.45e-03 +- 2.50e-02\n",
      "[dimension 26/145]  inactive:\t-5.93e-04 +- 2.75e-02\n",
      "[dimension 27/145]  inactive:\t1.04e-03 +- 2.75e-02\n",
      "[dimension 28/145]  inactive:\t9.08e-04 +- 2.18e-02\n",
      "[dimension 29/145]  inactive:\t-6.45e-04 +- 2.98e-02\n",
      "[dimension 30/145]  inactive:\t1.81e-03 +- 3.82e-02\n",
      "[dimension 31/145]  inactive:\t8.21e-03 +- 5.59e-02\n",
      "[dimension 32/145]  inactive:\t-2.47e-03 +- 3.18e-02\n",
      "[dimension 33/145]  inactive:\t1.02e-03 +- 3.24e-02\n",
      "[dimension 34/145]  inactive:\t8.50e-04 +- 2.17e-02\n",
      "[dimension 35/145]  inactive:\t4.93e-06 +- 3.10e-02\n",
      "[dimension 36/145]  inactive:\t9.73e-04 +- 2.56e-02\n",
      "[dimension 37/145]  inactive:\t3.73e-03 +- 2.54e-02\n",
      "[dimension 38/145]  inactive:\t-2.17e-03 +- 3.54e-02\n",
      "[dimension 39/145]  inactive:\t1.17e-03 +- 3.25e-02\n",
      "[dimension 40/145]  inactive:\t4.29e-03 +- 3.78e-02\n",
      "[dimension 41/145]  inactive:\t-1.95e-03 +- 3.10e-02\n",
      "[dimension 42/145]  inactive:\t3.34e-02 +- 1.53e-01\n",
      "[dimension 43/145]  inactive:\t-5.69e-04 +- 2.19e-02\n",
      "[dimension 44/145]  inactive:\t-9.78e-04 +- 3.18e-02\n",
      "[dimension 45/145]  inactive:\t-3.71e-04 +- 2.52e-02\n",
      "[dimension 46/145]  inactive:\t1.22e-03 +- 1.85e-02\n",
      "[dimension 47/145]  inactive:\t-2.40e-03 +- 3.31e-02\n",
      "[dimension 48/145]  inactive:\t2.07e-03 +- 2.95e-02\n",
      "[dimension 49/145]  inactive:\t2.89e-03 +- 2.53e-02\n",
      "[dimension 50/145]  inactive:\t-1.83e-03 +- 2.41e-02\n",
      "[dimension 51/145]  inactive:\t3.44e-03 +- 3.72e-02\n",
      "[dimension 52/145]  inactive:\t5.56e-03 +- 2.56e-02\n",
      "[dimension 53/145]  inactive:\t-1.42e-03 +- 2.85e-02\n",
      "[dimension 54/145]  inactive:\t2.83e-04 +- 1.97e-02\n",
      "[dimension 55/145]  inactive:\t6.28e-04 +- 1.92e-02\n",
      "[dimension 56/145]  inactive:\t-2.09e-03 +- 2.23e-02\n",
      "[dimension 57/145]  inactive:\t1.11e-03 +- 3.08e-02\n",
      "[dimension 58/145]  inactive:\t1.80e-02 +- 8.80e-02\n",
      "[dimension 59/145]  inactive:\t-3.06e-04 +- 1.79e-02\n",
      "[dimension 60/145]  inactive:\t1.48e-03 +- 3.54e-02\n",
      "[dimension 61/145]  inactive:\t2.66e-03 +- 2.58e-02\n",
      "[dimension 62/145]  inactive:\t-8.46e-04 +- 2.43e-02\n",
      "[dimension 63/145]  active:\t7.14e-01 +- 4.19e-01\n",
      "[dimension 64/145]  inactive:\t-2.46e-03 +- 2.35e-02\n",
      "[dimension 65/145]  inactive:\t-1.07e-03 +- 2.69e-02\n",
      "[dimension 66/145]  inactive:\t4.10e-04 +- 2.19e-02\n",
      "[dimension 67/145]  inactive:\t1.57e-03 +- 3.15e-02\n",
      "[dimension 68/145]  inactive:\t-1.30e-03 +- 4.05e-02\n",
      "[dimension 69/145]  inactive:\t3.45e-03 +- 4.04e-02\n",
      "[dimension 70/145]  inactive:\t2.94e-03 +- 2.31e-02\n",
      "[dimension 71/145]  inactive:\t1.36e-03 +- 3.92e-02\n",
      "[dimension 72/145]  inactive:\t9.44e-04 +- 2.93e-02\n",
      "[dimension 73/145]  inactive:\t1.48e-04 +- 1.86e-02\n",
      "[dimension 74/145]  inactive:\t-1.48e-03 +- 3.17e-02\n",
      "[dimension 75/145]  inactive:\t1.74e-04 +- 2.57e-02\n",
      "[dimension 76/145]  inactive:\t7.29e-03 +- 4.41e-02\n",
      "[dimension 77/145]  inactive:\t-2.59e-03 +- 3.67e-02\n",
      "[dimension 78/145]  inactive:\t6.76e-03 +- 6.68e-02\n",
      "[dimension 79/145]  inactive:\t6.00e-03 +- 3.23e-02\n",
      "[dimension 80/145]  inactive:\t-4.85e-04 +- 3.26e-02\n",
      "[dimension 81/145]  inactive:\t1.47e-03 +- 3.59e-02\n",
      "[dimension 82/145]  inactive:\t2.74e-04 +- 1.71e-02\n",
      "[dimension 83/145]  inactive:\t-2.12e-03 +- 2.03e-02\n",
      "[dimension 84/145]  inactive:\t-1.53e-03 +- 2.73e-02\n",
      "[dimension 85/145]  inactive:\t3.59e-03 +- 3.36e-02\n",
      "[dimension 86/145]  inactive:\t-5.45e-04 +- 2.47e-02\n",
      "[dimension 87/145]  inactive:\t1.74e-03 +- 3.61e-02\n",
      "[dimension 88/145]  inactive:\t2.96e-03 +- 2.61e-02\n",
      "[dimension 89/145]  inactive:\t-1.05e-03 +- 2.36e-02\n",
      "[dimension 90/145]  inactive:\t8.49e-02 +- 2.56e-01\n",
      "[dimension 91/145]  inactive:\t1.34e-04 +- 2.06e-02\n",
      "[dimension 92/145]  inactive:\t-1.45e-03 +- 2.65e-02\n",
      "[dimension 93/145]  inactive:\t-4.84e-04 +- 2.58e-02\n",
      "[dimension 94/145]  inactive:\t2.06e-03 +- 2.95e-02\n",
      "[dimension 95/145]  inactive:\t-6.11e-04 +- 2.56e-02\n",
      "[dimension 96/145]  inactive:\t1.55e-03 +- 4.84e-02\n",
      "[dimension 97/145]  inactive:\t3.43e-03 +- 3.04e-02\n",
      "[dimension 98/145]  inactive:\t-1.97e-04 +- 3.00e-02\n",
      "[dimension 99/145]  inactive:\t3.12e-03 +- 4.20e-02\n",
      "[dimension 100/145]  inactive:\t-7.98e-04 +- 2.04e-02\n",
      "[dimension 101/145]  inactive:\t-2.90e-03 +- 2.57e-02\n",
      "[dimension 102/145]  inactive:\t-1.15e-03 +- 2.87e-02\n",
      "[dimension 103/145]  inactive:\t8.24e-04 +- 2.68e-02\n",
      "[dimension 104/145]  inactive:\t-7.99e-04 +- 2.14e-02\n",
      "[dimension 105/145]  inactive:\t8.89e-04 +- 3.29e-02\n",
      "[dimension 106/145]  inactive:\t5.01e-03 +- 3.33e-02\n",
      "[dimension 107/145]  inactive:\t-1.15e-03 +- 2.25e-02\n",
      "[dimension 108/145]  inactive:\t5.43e-03 +- 6.38e-02\n",
      "[dimension 109/145]  inactive:\t-5.54e-04 +- 2.15e-02\n",
      "[dimension 110/145]  inactive:\t-1.61e-03 +- 3.14e-02\n",
      "[dimension 111/145]  inactive:\t1.83e-03 +- 3.40e-02\n",
      "[dimension 112/145]  inactive:\t8.82e-03 +- 5.78e-02\n",
      "[dimension 113/145]  inactive:\t-1.82e-03 +- 2.55e-02\n",
      "[dimension 114/145]  inactive:\t1.30e-03 +- 3.90e-02\n",
      "[dimension 115/145]  inactive:\t1.72e-03 +- 2.16e-02\n",
      "[dimension 116/145]  inactive:\t2.13e-07 +- 3.60e-02\n",
      "[dimension 117/145]  inactive:\t2.62e-03 +- 3.52e-02\n",
      "[dimension 118/145]  inactive:\t2.99e-03 +- 2.54e-02\n",
      "[dimension 119/145]  inactive:\t-3.15e-03 +- 4.06e-02\n",
      "[dimension 120/145]  inactive:\t4.73e-04 +- 3.47e-02\n",
      "[dimension 121/145]  inactive:\t5.25e-03 +- 4.17e-02\n",
      "[dimension 122/145]  inactive:\t-2.15e-03 +- 2.95e-02\n",
      "[dimension 123/145]  inactive:\t2.73e-03 +- 4.12e-02\n",
      "[dimension 124/145]  inactive:\t-1.31e-03 +- 2.00e-02\n",
      "[dimension 125/145]  inactive:\t-1.79e-03 +- 2.81e-02\n",
      "[dimension 126/145]  inactive:\t-1.87e-03 +- 3.09e-02\n",
      "[dimension 127/145]  inactive:\t3.79e-05 +- 2.01e-02\n",
      "[dimension 128/145]  inactive:\t-1.75e-03 +- 3.31e-02\n",
      "[dimension 129/145]  inactive:\t-1.99e-04 +- 2.41e-02\n",
      "[dimension 130/145]  inactive:\t4.17e-03 +- 3.20e-02\n",
      "[dimension 131/145]  inactive:\t-1.69e-03 +- 3.09e-02\n",
      "[dimension 132/145]  inactive:\t3.44e-03 +- 3.69e-02\n",
      "[dimension 133/145]  inactive:\t2.36e-03 +- 2.08e-02\n",
      "[dimension 134/145]  inactive:\t-1.31e-03 +- 3.37e-02\n",
      "[dimension 135/145]  inactive:\t3.00e-04 +- 3.25e-02\n",
      "[dimension 136/145]  inactive:\t9.96e-04 +- 2.00e-02\n",
      "[dimension 137/145]  inactive:\t-7.87e-04 +- 3.32e-02\n",
      "[dimension 138/145]  inactive:\t5.38e-04 +- 2.58e-02\n",
      "[dimension 139/145]  inactive:\t1.50e-04 +- 2.67e-02\n",
      "[dimension 140/145]  inactive:\t-1.51e-03 +- 3.17e-02\n",
      "[dimension 141/145]  inactive:\t1.78e-03 +- 3.07e-02\n",
      "[dimension 142/145]  inactive:\t1.61e-03 +- 2.06e-02\n",
      "[dimension 143/145]  inactive:\t1.45e-03 +- 4.16e-02\n",
      "[dimension 144/145]  inactive:\t-5.39e-06 +- 1.92e-02\n",
      "[dimension 145/145]  inactive:\t5.66e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.7590934]\n",
      "cov_act[[0.04014874]]\n",
      "Active_dimensions: [62]\n",
      "31, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.20it/s, 31 steps of size 1.82e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    721.12      1.00\n",
      "  lambda[0]      2.25      4.56      0.98      0.00      5.45    862.67      1.00\n",
      "  lambda[1]      3.24     11.05      0.95      0.00      5.65    546.80      1.01\n",
      "  lambda[2]      2.78      8.93      1.02      0.00      5.48    636.91      1.00\n",
      "  lambda[3]      4.94     24.97      1.03      0.00      7.23    713.33      1.00\n",
      "  lambda[4]      2.69      6.77      1.07      0.00      5.32    743.12      1.00\n",
      "  lambda[5]      3.88     19.17      0.98      0.00      6.12    799.25      1.00\n",
      "  lambda[6]      2.91      9.91      0.91      0.00      4.80    878.37      1.00\n",
      "  lambda[7]      2.98      7.63      0.95      0.00      6.01    656.60      1.00\n",
      "  lambda[8]      2.50      5.21      1.02      0.00      5.48    624.45      1.00\n",
      "  lambda[9]      2.47      6.21      1.01      0.00      4.78    779.27      1.00\n",
      " lambda[10]      3.03      9.68      1.02      0.00      5.30    736.96      1.00\n",
      " lambda[11]      2.49      6.00      0.97      0.00      4.98    833.85      1.00\n",
      " lambda[12]      3.61      9.07      1.05      0.00      6.84    646.82      1.00\n",
      " lambda[13]      3.43     13.06      0.95      0.00      5.86    325.80      1.00\n",
      " lambda[14]      4.36     32.87      0.97      0.00      5.36    617.62      1.00\n",
      " lambda[15]      2.87     12.24      0.94      0.00      5.34    966.21      1.00\n",
      " lambda[16]      3.36      9.03      0.99      0.00      7.35    640.69      1.01\n",
      " lambda[17]      2.72      7.07      1.00      0.00      5.76    693.22      1.00\n",
      " lambda[18]      3.39     10.29      0.98      0.00      6.27    672.88      1.00\n",
      " lambda[19]      2.50      7.68      0.99      0.00      5.27    936.09      1.00\n",
      " lambda[20]      2.95      9.18      0.98      0.00      6.41    914.60      1.00\n",
      " lambda[21]      2.73      7.28      1.00      0.00      5.53    778.56      1.00\n",
      " lambda[22]      2.55      6.00      0.97      0.00      5.26    864.47      1.00\n",
      " lambda[23]      3.59     15.79      0.99      0.00      5.54    620.54      1.00\n",
      " lambda[24]      2.96      7.83      0.99      0.01      6.02    790.52      1.00\n",
      " lambda[25]      2.87      7.46      1.04      0.00      5.85    656.61      1.00\n",
      " lambda[26]      2.84      8.44      0.98      0.00      5.64    356.72      1.01\n",
      " lambda[27]      2.41      5.92      0.96      0.00      5.06    787.67      1.00\n",
      " lambda[28]      2.76     10.65      1.01      0.00      4.77    521.51      1.00\n",
      " lambda[29]      2.91      9.02      0.96      0.00      5.09    397.42      1.00\n",
      " lambda[30]      3.74     13.43      1.10      0.01      6.54    981.08      1.00\n",
      " lambda[31]      3.77     19.95      0.97      0.00      5.84    615.28      1.00\n",
      " lambda[32]      3.02      9.59      0.96      0.00      5.59    896.79      1.00\n",
      " lambda[33]      2.84      8.60      0.94      0.01      5.03    523.83      1.00\n",
      " lambda[34]      2.55      5.92      0.94      0.01      4.89    649.66      1.00\n",
      " lambda[35]      2.56      6.18      0.96      0.00      4.83    631.10      1.00\n",
      " lambda[36]      3.48     16.76      1.01      0.00      4.99    778.47      1.00\n",
      " lambda[37]      3.47     11.84      0.91      0.00      5.63    751.06      1.00\n",
      " lambda[38]      2.99      6.89      0.97      0.00      6.21    642.22      1.00\n",
      " lambda[39]      3.34      9.53      1.00      0.00      5.65    592.92      1.00\n",
      " lambda[40]      3.42     12.11      0.89      0.00      6.84    834.19      1.00\n",
      " lambda[41]     66.16    724.03      0.96      0.00     11.85    304.58      1.01\n",
      " lambda[42]      3.62     26.17      0.97      0.00      5.78    946.77      1.00\n",
      " lambda[43]      3.73     30.40      1.05      0.00      5.58   1017.22      1.00\n",
      " lambda[44]      2.87      7.18      0.99      0.01      5.81    733.52      1.00\n",
      " lambda[45]      2.62      5.84      0.95      0.00      5.66    788.78      1.00\n",
      " lambda[46]      2.69      7.79      0.99      0.00      4.45    749.36      1.00\n",
      " lambda[47]      2.63      6.20      0.97      0.01      5.84    604.83      1.00\n",
      " lambda[48]      3.06      9.51      1.01      0.00      6.18    615.12      1.00\n",
      " lambda[49]      3.37     11.56      0.99      0.00      5.97    818.59      1.00\n",
      " lambda[50]      3.50     13.37      0.99      0.00      6.37    765.75      1.00\n",
      " lambda[51]      3.53     10.71      1.02      0.00      6.39    726.28      1.00\n",
      " lambda[52]      2.61      6.64      0.98      0.00      5.18    946.71      1.00\n",
      " lambda[53]      2.92      8.52      0.94      0.00      5.13    572.37      1.00\n",
      " lambda[54]      2.19      4.53      0.94      0.00      4.81    604.10      1.00\n",
      " lambda[55]      3.41     20.18      0.96      0.00      5.81    952.44      1.00\n",
      " lambda[56]      2.54      5.35      1.01      0.00      5.17    678.63      1.00\n",
      " lambda[57]      7.30     60.58      1.05      0.00      8.75    994.69      1.00\n",
      " lambda[58]      2.34      5.15      0.95      0.00      5.34    647.73      1.00\n",
      " lambda[59]      3.38     11.81      1.02      0.00      6.87    642.08      1.00\n",
      " lambda[60]      3.26     14.07      0.99      0.00      5.32    786.88      1.00\n",
      " lambda[61]      2.65      6.16      0.99      0.00      5.75    629.40      1.00\n",
      " lambda[62]   1411.05  13835.82    185.56      0.01   1550.07    573.53      1.00\n",
      " lambda[63]      2.46      7.12      1.00      0.00      4.87    871.64      1.00\n",
      " lambda[64]      3.18      9.84      0.98      0.00      5.81    509.74      1.01\n",
      " lambda[65]      2.80      7.27      1.03      0.00      5.47    689.30      1.00\n",
      " lambda[66]      2.86      6.52      0.99      0.01      6.76    674.40      1.00\n",
      " lambda[67]      2.77      6.43      0.89      0.00      5.96    653.12      1.00\n",
      " lambda[68]      3.29     17.93      0.95      0.00      4.99    755.71      1.00\n",
      " lambda[69]      3.19     10.14      0.93      0.00      5.52    693.13      1.00\n",
      " lambda[70]      2.44      5.53      0.97      0.00      5.18    664.59      1.00\n",
      " lambda[71]      3.25     19.35      0.90      0.00      5.34    632.52      1.00\n",
      " lambda[72]      2.54      7.73      0.99      0.01      4.51    568.33      1.00\n",
      " lambda[73]      2.80      6.85      1.08      0.00      5.87    710.46      1.00\n",
      " lambda[74]      2.41      6.71      0.99      0.00      5.25   1031.32      1.00\n",
      " lambda[75]      5.07     21.76      0.98      0.00      7.28    829.61      1.00\n",
      " lambda[76]      3.90     18.68      1.00      0.00      5.62    544.88      1.00\n",
      " lambda[77]      4.51     22.16      1.04      0.00      6.92    421.40      1.00\n",
      " lambda[78]      2.95      6.69      1.06      0.00      6.41    894.08      1.00\n",
      " lambda[79]      3.47     20.01      0.94      0.00      5.50    919.39      1.00\n",
      " lambda[80]      3.86     23.05      1.01      0.01      6.12    606.23      1.00\n",
      " lambda[81]      2.76      7.06      0.86      0.00      6.20    584.30      1.00\n",
      " lambda[82]      2.96      9.09      0.89      0.00      4.82    552.69      1.00\n",
      " lambda[83]      3.35     11.14      0.97      0.00      6.30    710.67      1.00\n",
      " lambda[84]      3.86     19.51      1.02      0.00      7.56    647.80      1.00\n",
      " lambda[85]      2.61      8.89      0.90      0.00      4.96    835.15      1.00\n",
      " lambda[86]      2.79      8.50      0.99      0.00      5.70    717.01      1.00\n",
      " lambda[87]      3.23     12.17      0.92      0.00      5.94    515.28      1.00\n",
      " lambda[88]      2.82      6.35      0.98      0.00      6.81    723.13      1.00\n",
      " lambda[89]     74.92    716.39      1.08      0.00     43.80    429.23      1.00\n",
      " lambda[90]      2.46      5.42      1.02      0.00      5.15    817.87      1.00\n",
      " lambda[91]      2.76      8.39      1.01      0.00      5.09    676.02      1.00\n",
      " lambda[92]      2.96      8.47      1.01      0.00      6.07    700.18      1.00\n",
      " lambda[93]      2.80      6.54      1.08      0.00      5.31    820.06      1.00\n",
      " lambda[94]      2.76      8.43      0.91      0.01      5.73    666.65      1.00\n",
      " lambda[95]      3.52     13.01      0.96      0.00      6.44    791.22      1.00\n",
      " lambda[96]      2.48      6.04      0.94      0.00      4.77    557.18      1.00\n",
      " lambda[97]      3.23     12.62      1.01      0.00      5.63    638.88      1.00\n",
      " lambda[98]     17.30    371.06      1.03      0.00      6.44    997.81      1.00\n",
      " lambda[99]      2.61      7.70      1.01      0.01      4.69    738.68      1.00\n",
      "lambda[100]      2.72      8.35      0.94      0.00      5.45    743.13      1.00\n",
      "lambda[101]      2.78      7.32      0.94      0.00      5.50    750.59      1.00\n",
      "lambda[102]      3.42     13.18      0.94      0.00      5.54    481.30      1.00\n",
      "lambda[103]      2.39      5.35      0.96      0.00      5.19    733.95      1.00\n",
      "lambda[104]      2.94      6.49      0.97      0.00      7.32    660.94      1.00\n",
      "lambda[105]      4.33     21.43      1.04      0.00      5.85    574.92      1.00\n",
      "lambda[106]      2.58      5.77      0.98      0.00      5.64    979.24      1.00\n",
      "lambda[107]      9.25     96.52      1.00      0.00      6.04    829.54      1.00\n",
      "lambda[108]      2.34      4.37      1.00      0.01      5.20    326.38      1.00\n",
      "lambda[109]      5.14     58.62      0.94      0.00      5.81    989.35      1.00\n",
      "lambda[110]      3.58     10.64      1.08      0.00      7.41    598.97      1.00\n",
      "lambda[111]      5.60     28.79      0.96      0.00      6.59    610.15      1.00\n",
      "lambda[112]      2.65      5.78      0.99      0.01      6.29    921.49      1.00\n",
      "lambda[113]      3.10      8.10      1.04      0.00      6.18    742.18      1.00\n",
      "lambda[114]      3.51     16.87      0.98      0.00      5.68    888.19      1.00\n",
      "lambda[115]      3.24     11.74      1.02      0.00      5.86    766.50      1.00\n",
      "lambda[116]      4.82     32.69      0.97      0.00      5.50    398.68      1.00\n",
      "lambda[117]      3.07      9.88      0.98      0.00      6.49    890.63      1.00\n",
      "lambda[118]      3.72     19.26      0.97      0.00      6.07    808.66      1.00\n",
      "lambda[119]      3.10     15.82      0.99      0.00      5.90    957.25      1.00\n",
      "lambda[120]      3.98     19.87      1.01      0.00      6.92    841.26      1.00\n",
      "lambda[121]      3.23     12.34      0.96      0.00      5.63    525.84      1.00\n",
      "lambda[122]      3.52     21.66      0.96      0.00      5.52    663.52      1.00\n",
      "lambda[123]      2.83      7.68      0.96      0.00      5.60    820.84      1.00\n",
      "lambda[124]      2.83      6.76      1.08      0.00      6.31    631.46      1.00\n",
      "lambda[125]      2.74      7.02      0.98      0.00      5.45    718.32      1.00\n",
      "lambda[126]      2.43      6.56      0.95      0.00      5.06    903.30      1.00\n",
      "lambda[127]      2.89      9.16      0.96      0.00      4.76    854.50      1.00\n",
      "lambda[128]      2.34      4.78      0.97      0.01      5.51    790.00      1.00\n",
      "lambda[129]      7.27    127.30      1.00      0.00      6.43   1004.56      1.00\n",
      "lambda[130]      3.02      7.06      1.00      0.00      5.99    574.68      1.01\n",
      "lambda[131]      4.07     16.00      1.07      0.00      6.34    546.04      1.00\n",
      "lambda[132]      2.69      7.50      1.07      0.00      5.26    826.10      1.00\n",
      "lambda[133]      2.54      5.69      1.02      0.00      5.69    881.90      1.00\n",
      "lambda[134]      3.39      9.06      0.88      0.00      6.90    673.42      1.00\n",
      "lambda[135]      3.84     33.55      0.95      0.00      5.65    961.77      1.00\n",
      "lambda[136]      3.04     13.73      0.97      0.00      5.44    795.26      1.00\n",
      "lambda[137]      2.99      8.78      0.99      0.00      5.34    595.58      1.00\n",
      "lambda[138]      3.03     10.76      1.04      0.00      5.49    760.46      1.00\n",
      "lambda[139]      3.35     12.55      0.96      0.00      6.46    723.12      1.00\n",
      "lambda[140]      2.75      7.37      0.93      0.00      6.14    935.27      1.00\n",
      "lambda[141]      2.45      6.55      0.87      0.00      5.57    783.48      1.00\n",
      "lambda[142]      4.16     18.44      1.01      0.00      6.35    664.12      1.00\n",
      "lambda[143]      2.12      3.82      0.97      0.00      4.86    938.90      1.00\n",
      "        msq      1.33      0.71      1.14      0.47      2.20   1002.44      1.00\n",
      "      sigma      4.49      5.84      2.11      0.00     12.35   1180.27      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    956.97      1.00\n",
      "       xisq      0.12      0.06      0.10      0.04      0.19   1045.17      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.34013485908508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.64e-05 +- 1.77e-02\n",
      "[dimension 02/145]  inactive:\t-1.57e-04 +- 2.84e-02\n",
      "[dimension 03/145]  inactive:\t5.30e-05 +- 2.53e-02\n",
      "[dimension 04/145]  inactive:\t6.82e-03 +- 4.48e-02\n",
      "[dimension 05/145]  inactive:\t-6.85e-04 +- 2.30e-02\n",
      "[dimension 06/145]  inactive:\t3.63e-03 +- 4.51e-02\n",
      "[dimension 07/145]  inactive:\t9.81e-04 +- 1.96e-02\n",
      "[dimension 08/145]  inactive:\t1.31e-03 +- 3.16e-02\n",
      "[dimension 09/145]  inactive:\t3.18e-04 +- 2.30e-02\n",
      "[dimension 10/145]  inactive:\t4.67e-04 +- 2.01e-02\n",
      "[dimension 11/145]  inactive:\t-7.67e-04 +- 2.41e-02\n",
      "[dimension 12/145]  inactive:\t-2.26e-04 +- 2.08e-02\n",
      "[dimension 13/145]  inactive:\t3.91e-03 +- 3.44e-02\n",
      "[dimension 14/145]  inactive:\t-1.91e-03 +- 2.50e-02\n",
      "[dimension 15/145]  inactive:\t9.69e-04 +- 3.66e-02\n",
      "[dimension 16/145]  inactive:\t9.37e-04 +- 2.07e-02\n",
      "[dimension 17/145]  inactive:\t-8.26e-05 +- 2.89e-02\n",
      "[dimension 18/145]  inactive:\t8.86e-05 +- 2.76e-02\n",
      "[dimension 19/145]  inactive:\t-2.94e-03 +- 2.64e-02\n",
      "[dimension 20/145]  inactive:\t-8.95e-04 +- 2.43e-02\n",
      "[dimension 21/145]  inactive:\t-1.80e-03 +- 2.64e-02\n",
      "[dimension 22/145]  inactive:\t-2.99e-04 +- 2.35e-02\n",
      "[dimension 23/145]  inactive:\t-3.20e-04 +- 2.60e-02\n",
      "[dimension 24/145]  inactive:\t1.32e-03 +- 3.10e-02\n",
      "[dimension 25/145]  inactive:\t3.38e-03 +- 2.38e-02\n",
      "[dimension 26/145]  inactive:\t-3.72e-04 +- 3.19e-02\n",
      "[dimension 27/145]  inactive:\t7.79e-04 +- 2.20e-02\n",
      "[dimension 28/145]  inactive:\t7.56e-04 +- 1.79e-02\n",
      "[dimension 29/145]  inactive:\t-2.41e-04 +- 2.79e-02\n",
      "[dimension 30/145]  inactive:\t6.95e-04 +- 2.53e-02\n",
      "[dimension 31/145]  inactive:\t6.25e-03 +- 4.57e-02\n",
      "[dimension 32/145]  inactive:\t-1.55e-03 +- 2.56e-02\n",
      "[dimension 33/145]  inactive:\t2.33e-03 +- 3.53e-02\n",
      "[dimension 34/145]  inactive:\t9.62e-04 +- 2.08e-02\n",
      "[dimension 35/145]  inactive:\t3.79e-04 +- 2.37e-02\n",
      "[dimension 36/145]  inactive:\t9.14e-04 +- 2.37e-02\n",
      "[dimension 37/145]  inactive:\t3.88e-03 +- 2.64e-02\n",
      "[dimension 38/145]  inactive:\t-1.59e-03 +- 3.62e-02\n",
      "[dimension 39/145]  inactive:\t1.97e-03 +- 3.55e-02\n",
      "[dimension 40/145]  inactive:\t5.87e-03 +- 4.39e-02\n",
      "[dimension 41/145]  inactive:\t-1.25e-03 +- 3.23e-02\n",
      "[dimension 42/145]  inactive:\t3.30e-02 +- 1.58e-01\n",
      "[dimension 43/145]  inactive:\t1.63e-04 +- 2.03e-02\n",
      "[dimension 44/145]  inactive:\t-1.54e-04 +- 3.47e-02\n",
      "[dimension 45/145]  inactive:\t1.10e-04 +- 2.42e-02\n",
      "[dimension 46/145]  inactive:\t1.25e-03 +- 1.81e-02\n",
      "[dimension 47/145]  inactive:\t-1.55e-03 +- 2.94e-02\n",
      "[dimension 48/145]  inactive:\t1.54e-03 +- 2.35e-02\n",
      "[dimension 49/145]  inactive:\t3.49e-03 +- 2.89e-02\n",
      "[dimension 50/145]  inactive:\t-1.99e-03 +- 3.03e-02\n",
      "[dimension 51/145]  inactive:\t4.06e-03 +- 3.72e-02\n",
      "[dimension 52/145]  inactive:\t6.05e-03 +- 2.65e-02\n",
      "[dimension 53/145]  inactive:\t-9.27e-04 +- 2.32e-02\n",
      "[dimension 54/145]  inactive:\t3.16e-04 +- 2.07e-02\n",
      "[dimension 55/145]  inactive:\t7.01e-04 +- 1.64e-02\n",
      "[dimension 56/145]  inactive:\t-2.39e-03 +- 2.72e-02\n",
      "[dimension 57/145]  inactive:\t1.55e-03 +- 3.02e-02\n",
      "[dimension 58/145]  inactive:\t1.31e-02 +- 7.27e-02\n",
      "[dimension 59/145]  inactive:\t-4.71e-04 +- 1.87e-02\n",
      "[dimension 60/145]  inactive:\t2.36e-03 +- 3.85e-02\n",
      "[dimension 61/145]  inactive:\t3.11e-03 +- 2.68e-02\n",
      "[dimension 62/145]  inactive:\t-2.19e-04 +- 2.52e-02\n",
      "[dimension 63/145]  active:\t6.78e-01 +- 4.24e-01\n",
      "[dimension 64/145]  inactive:\t-2.63e-03 +- 2.45e-02\n",
      "[dimension 65/145]  inactive:\t-4.42e-04 +- 2.87e-02\n",
      "[dimension 66/145]  inactive:\t3.19e-04 +- 2.15e-02\n",
      "[dimension 67/145]  inactive:\t1.50e-03 +- 2.78e-02\n",
      "[dimension 68/145]  inactive:\t-1.09e-03 +- 3.12e-02\n",
      "[dimension 69/145]  inactive:\t4.08e-03 +- 3.99e-02\n",
      "[dimension 70/145]  inactive:\t3.44e-03 +- 2.42e-02\n",
      "[dimension 71/145]  inactive:\t8.48e-05 +- 2.28e-02\n",
      "[dimension 72/145]  inactive:\t7.06e-04 +- 2.45e-02\n",
      "[dimension 73/145]  inactive:\t4.12e-04 +- 1.62e-02\n",
      "[dimension 74/145]  inactive:\t-7.76e-04 +- 2.94e-02\n",
      "[dimension 75/145]  inactive:\t4.76e-04 +- 2.24e-02\n",
      "[dimension 76/145]  inactive:\t7.67e-03 +- 4.85e-02\n",
      "[dimension 77/145]  inactive:\t-1.64e-03 +- 3.68e-02\n",
      "[dimension 78/145]  inactive:\t7.63e-03 +- 6.62e-02\n",
      "[dimension 79/145]  inactive:\t5.18e-03 +- 2.96e-02\n",
      "[dimension 80/145]  inactive:\t3.93e-05 +- 2.98e-02\n",
      "[dimension 81/145]  inactive:\t2.67e-03 +- 3.57e-02\n",
      "[dimension 82/145]  inactive:\t5.03e-04 +- 1.87e-02\n",
      "[dimension 83/145]  inactive:\t-1.41e-03 +- 2.19e-02\n",
      "[dimension 84/145]  inactive:\t-1.57e-03 +- 2.88e-02\n",
      "[dimension 85/145]  inactive:\t3.55e-03 +- 3.73e-02\n",
      "[dimension 86/145]  inactive:\t-5.58e-04 +- 2.02e-02\n",
      "[dimension 87/145]  inactive:\t2.79e-03 +- 3.77e-02\n",
      "[dimension 88/145]  inactive:\t3.26e-03 +- 2.61e-02\n",
      "[dimension 89/145]  inactive:\t-8.37e-04 +- 2.45e-02\n",
      "[dimension 90/145]  inactive:\t7.99e-02 +- 2.48e-01\n",
      "[dimension 91/145]  inactive:\t-9.81e-06 +- 1.70e-02\n",
      "[dimension 92/145]  inactive:\t-1.23e-03 +- 2.43e-02\n",
      "[dimension 93/145]  inactive:\t-6.54e-04 +- 3.27e-02\n",
      "[dimension 94/145]  inactive:\t2.01e-03 +- 2.82e-02\n",
      "[dimension 95/145]  inactive:\t3.64e-04 +- 2.56e-02\n",
      "[dimension 96/145]  inactive:\t1.00e-03 +- 4.57e-02\n",
      "[dimension 97/145]  inactive:\t2.24e-03 +- 2.16e-02\n",
      "[dimension 98/145]  inactive:\t-5.21e-04 +- 2.59e-02\n",
      "[dimension 99/145]  inactive:\t8.45e-03 +- 6.91e-02\n",
      "[dimension 100/145]  inactive:\t-4.73e-04 +- 1.66e-02\n",
      "[dimension 101/145]  inactive:\t-1.92e-03 +- 2.01e-02\n",
      "[dimension 102/145]  inactive:\t-1.69e-04 +- 2.80e-02\n",
      "[dimension 103/145]  inactive:\t1.75e-03 +- 2.93e-02\n",
      "[dimension 104/145]  inactive:\t-5.74e-04 +- 1.86e-02\n",
      "[dimension 105/145]  inactive:\t4.03e-04 +- 2.96e-02\n",
      "[dimension 106/145]  inactive:\t5.40e-03 +- 3.74e-02\n",
      "[dimension 107/145]  inactive:\t-9.80e-04 +- 2.36e-02\n",
      "[dimension 108/145]  inactive:\t1.50e-02 +- 9.95e-02\n",
      "[dimension 109/145]  inactive:\t-5.41e-04 +- 1.91e-02\n",
      "[dimension 110/145]  inactive:\t-4.23e-04 +- 3.71e-02\n",
      "[dimension 111/145]  inactive:\t1.94e-03 +- 3.44e-02\n",
      "[dimension 112/145]  inactive:\t7.36e-03 +- 5.48e-02\n",
      "[dimension 113/145]  inactive:\t-1.29e-03 +- 2.41e-02\n",
      "[dimension 114/145]  inactive:\t8.04e-04 +- 3.10e-02\n",
      "[dimension 115/145]  inactive:\t2.08e-03 +- 2.19e-02\n",
      "[dimension 116/145]  inactive:\t-3.27e-05 +- 3.03e-02\n",
      "[dimension 117/145]  inactive:\t6.80e-03 +- 6.14e-02\n",
      "[dimension 118/145]  inactive:\t3.58e-03 +- 2.77e-02\n",
      "[dimension 119/145]  inactive:\t-2.34e-03 +- 3.16e-02\n",
      "[dimension 120/145]  inactive:\t5.57e-04 +- 2.90e-02\n",
      "[dimension 121/145]  inactive:\t4.50e-03 +- 3.55e-02\n",
      "[dimension 122/145]  inactive:\t-1.94e-03 +- 2.60e-02\n",
      "[dimension 123/145]  inactive:\t2.79e-03 +- 4.34e-02\n",
      "[dimension 124/145]  inactive:\t-1.29e-03 +- 2.04e-02\n",
      "[dimension 125/145]  inactive:\t-1.43e-03 +- 2.80e-02\n",
      "[dimension 126/145]  inactive:\t-1.10e-03 +- 2.43e-02\n",
      "[dimension 127/145]  inactive:\t8.15e-05 +- 1.79e-02\n",
      "[dimension 128/145]  inactive:\t-5.99e-04 +- 2.81e-02\n",
      "[dimension 129/145]  inactive:\t-3.86e-04 +- 2.48e-02\n",
      "[dimension 130/145]  inactive:\t3.49e-03 +- 2.84e-02\n",
      "[dimension 131/145]  inactive:\t-5.60e-04 +- 2.89e-02\n",
      "[dimension 132/145]  inactive:\t7.06e-03 +- 6.25e-02\n",
      "[dimension 133/145]  inactive:\t2.65e-03 +- 2.17e-02\n",
      "[dimension 134/145]  inactive:\t-5.89e-04 +- 2.61e-02\n",
      "[dimension 135/145]  inactive:\t8.29e-04 +- 2.92e-02\n",
      "[dimension 136/145]  inactive:\t1.40e-03 +- 2.15e-02\n",
      "[dimension 137/145]  inactive:\t3.40e-04 +- 3.15e-02\n",
      "[dimension 138/145]  inactive:\t1.85e-03 +- 3.15e-02\n",
      "[dimension 139/145]  inactive:\t4.58e-04 +- 2.17e-02\n",
      "[dimension 140/145]  inactive:\t-1.00e-03 +- 3.16e-02\n",
      "[dimension 141/145]  inactive:\t1.48e-03 +- 2.80e-02\n",
      "[dimension 142/145]  inactive:\t1.45e-03 +- 1.74e-02\n",
      "[dimension 143/145]  inactive:\t2.68e-03 +- 4.66e-02\n",
      "[dimension 144/145]  inactive:\t1.90e-04 +- 1.80e-02\n",
      "[dimension 145/145]  inactive:\t4.77e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8589606]\n",
      "cov_act[[0.04229922]]\n",
      "Active_dimensions: [62]\n",
      "32, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:31<00:00, 48.14it/s, 31 steps of size 1.44e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    662.33      1.00\n",
      "  lambda[0]      2.47      7.27      0.97      0.00      5.35    989.09      1.00\n",
      "  lambda[1]      3.05     10.08      1.02      0.00      6.24    615.03      1.01\n",
      "  lambda[2]      3.13     13.06      1.03      0.00      5.62    594.22      1.00\n",
      "  lambda[3]      3.95     16.46      1.06      0.00      7.21    589.51      1.00\n",
      "  lambda[4]      2.74      8.62      1.05      0.00      5.39    986.69      1.00\n",
      "  lambda[5]      2.88      8.67      0.97      0.00      5.51    771.50      1.00\n",
      "  lambda[6]      3.25     14.81      0.98      0.00      6.05    834.08      1.00\n",
      "  lambda[7]      3.07      9.98      0.96      0.00      6.27    497.49      1.00\n",
      "  lambda[8]      2.34      5.00      0.97      0.00      5.18   1027.00      1.00\n",
      "  lambda[9]      2.47      6.98      0.93      0.00      5.09    933.22      1.00\n",
      " lambda[10]      3.05     10.15      1.08      0.00      5.59    932.66      1.00\n",
      " lambda[11]      2.92      7.71      0.99      0.00      6.06    985.96      1.00\n",
      " lambda[12]      3.99     12.38      1.01      0.00      7.08    686.16      1.00\n",
      " lambda[13]      2.81      9.27      0.95      0.00      5.36    744.30      1.00\n",
      " lambda[14]      4.35     21.13      0.94      0.00      6.18    579.54      1.00\n",
      " lambda[15]      2.69      7.57      0.99      0.00      4.52    576.00      1.00\n",
      " lambda[16]      3.83     11.49      0.98      0.00      8.06    702.72      1.00\n",
      " lambda[17]      3.05     16.43      0.96      0.00      4.75    624.19      1.00\n",
      " lambda[18]      2.66      6.17      0.92      0.00      5.50    856.24      1.01\n",
      " lambda[19]      3.72     19.33      0.99      0.01      6.59    694.99      1.00\n",
      " lambda[20]      3.05     10.97      1.01      0.01      5.73   1002.31      1.00\n",
      " lambda[21]      2.71      5.99      0.98      0.00      6.05    823.64      1.00\n",
      " lambda[22]      3.09     14.59      0.97      0.00      4.80    421.29      1.00\n",
      " lambda[23]      3.06      8.04      1.00      0.00      6.37    699.52      1.00\n",
      " lambda[24]      3.56     13.37      0.99      0.00      6.07    845.71      1.00\n",
      " lambda[25]      3.07      8.04      0.99      0.00      6.55    436.05      1.00\n",
      " lambda[26]      3.36     12.39      1.00      0.00      6.10    763.21      1.00\n",
      " lambda[27]      2.79      7.04      0.97      0.00      5.80    695.54      1.00\n",
      " lambda[28]      2.67      6.92      1.00      0.00      5.14    781.32      1.00\n",
      " lambda[29]      3.18     10.62      0.97      0.00      6.65    611.41      1.00\n",
      " lambda[30]      4.44     29.51      1.05      0.01      6.50    550.13      1.00\n",
      " lambda[31]      4.10     14.42      0.98      0.00      6.95    567.18      1.00\n",
      " lambda[32]      3.10      8.70      1.00      0.00      6.58    721.57      1.00\n",
      " lambda[33]      2.96     11.17      0.93      0.01      5.92    955.73      1.00\n",
      " lambda[34]      2.66      6.73      1.01      0.00      5.23    782.59      1.00\n",
      " lambda[35]      2.45      5.31      1.03      0.00      5.09    872.88      1.00\n",
      " lambda[36]      3.32     12.54      1.03      0.00      6.26    878.31      1.00\n",
      " lambda[37]      3.13      8.07      1.00      0.00      6.37    611.71      1.00\n",
      " lambda[38]      3.19     13.17      0.94      0.00      6.65    970.44      1.00\n",
      " lambda[39]      4.39     28.77      0.98      0.00      6.16    475.68      1.00\n",
      " lambda[40]      3.64     13.36      0.91      0.00      6.55    998.46      1.00\n",
      " lambda[41]      9.90     66.98      0.94      0.00      8.85    563.35      1.00\n",
      " lambda[42]      2.87     10.34      0.95      0.00      5.32    726.23      1.00\n",
      " lambda[43]      2.98     16.27      1.01      0.00      5.58    991.86      1.00\n",
      " lambda[44]      2.59      5.64      0.97      0.00      5.74    702.66      1.00\n",
      " lambda[45]      2.45      5.47      0.95      0.00      5.19    767.09      1.00\n",
      " lambda[46]      2.39      5.21      1.01      0.01      4.98    825.64      1.00\n",
      " lambda[47]      2.55      5.45      0.94      0.00      5.92    787.94      1.00\n",
      " lambda[48]      2.71      8.64      1.00      0.01      5.03    809.43      1.00\n",
      " lambda[49]      2.98      9.03      0.98      0.00      5.61    832.71      1.00\n",
      " lambda[50]      2.65      6.17      0.98      0.00      5.61    654.37      1.00\n",
      " lambda[51]      4.52     21.93      1.05      0.00      6.88    919.48      1.00\n",
      " lambda[52]      3.25     10.59      0.94      0.00      6.04    499.06      1.00\n",
      " lambda[53]      2.75      7.12      0.95      0.00      5.42    814.00      1.00\n",
      " lambda[54]      2.53     10.52      0.91      0.00      4.40    532.64      1.00\n",
      " lambda[55]      3.47     15.99      1.00      0.00      5.14    706.11      1.00\n",
      " lambda[56]      2.66      6.18      0.97      0.00      5.22    630.87      1.00\n",
      " lambda[57]      5.10     22.63      0.98      0.00      7.34    641.04      1.01\n",
      " lambda[58]      2.45      5.70      0.92      0.00      4.93    742.35      1.00\n",
      " lambda[59]      3.06      7.55      0.93      0.00      6.43    556.76      1.00\n",
      " lambda[60]      2.83      7.71      0.93      0.00      5.47    686.86      1.00\n",
      " lambda[61]      3.29     13.31      1.03      0.00      5.64    952.36      1.00\n",
      " lambda[62]    598.26   3420.40    155.50      0.00    967.42    673.21      1.00\n",
      " lambda[63]      2.27      4.39      1.00      0.01      5.27    703.89      1.00\n",
      " lambda[64]      3.08      9.55      1.04      0.01      5.65    924.33      1.00\n",
      " lambda[65]      3.41     11.63      0.98      0.00      6.26    735.71      1.00\n",
      " lambda[66]      3.35     10.43      1.00      0.00      7.00    707.33      1.00\n",
      " lambda[67]      2.43      6.54      0.94      0.00      4.67    777.53      1.00\n",
      " lambda[68]      4.08     32.30      0.96      0.00      6.05    699.53      1.00\n",
      " lambda[69]      3.30     10.07      0.92      0.00      6.52    922.98      1.00\n",
      " lambda[70]      2.75      8.03      0.99      0.00      5.41    593.52      1.00\n",
      " lambda[71]      3.22     18.39      1.01      0.00      4.86    691.29      1.00\n",
      " lambda[72]      2.54      7.02      0.98      0.00      4.96    740.83      1.00\n",
      " lambda[73]      2.72      5.72      1.10      0.00      5.66    748.52      1.00\n",
      " lambda[74]      2.46      4.89      1.00      0.01      5.66    687.96      1.00\n",
      " lambda[75]      3.94     11.86      1.06      0.00      7.03    990.59      1.00\n",
      " lambda[76]      3.47     12.71      0.98      0.00      6.94    753.75      1.00\n",
      " lambda[77]      6.47     40.59      1.11      0.00      7.94    456.79      1.00\n",
      " lambda[78]      3.92     16.36      1.04      0.00      6.65    731.20      1.00\n",
      " lambda[79]      3.05      9.23      1.02      0.00      5.85    631.35      1.01\n",
      " lambda[80]      4.93     36.61      1.06      0.00      6.59    682.33      1.00\n",
      " lambda[81]      2.66     10.57      0.96      0.00      5.12    668.39      1.00\n",
      " lambda[82]      2.62      6.59      0.96      0.00      5.17    655.95      1.00\n",
      " lambda[83]      2.76      7.61      0.94      0.00      5.32    635.91      1.00\n",
      " lambda[84]      4.18     38.81      1.03      0.00      5.81    955.56      1.00\n",
      " lambda[85]      2.62      7.39      0.95      0.00      5.30    402.36      1.00\n",
      " lambda[86]      2.88      6.57      1.02      0.00      6.25    782.70      1.00\n",
      " lambda[87]      3.73     14.59      0.97      0.00      6.45    500.86      1.00\n",
      " lambda[88]      2.80      9.24      0.99      0.00      5.49    864.59      1.00\n",
      " lambda[89]     46.13    202.66      1.23      0.00     78.40    180.01      1.01\n",
      " lambda[90]      3.57     11.50      1.03      0.00      6.35    516.02      1.00\n",
      " lambda[91]      2.75      9.89      0.94      0.00      5.13    817.36      1.00\n",
      " lambda[92]      2.32      4.47      1.06      0.00      4.90    795.60      1.00\n",
      " lambda[93]      2.85     11.24      0.97      0.00      4.86    582.72      1.00\n",
      " lambda[94]      2.71      7.58      0.97      0.00      5.10    716.04      1.00\n",
      " lambda[95]      3.31     11.54      1.05      0.00      6.17    629.41      1.00\n",
      " lambda[96]      3.01     14.98      0.99      0.00      4.74    506.53      1.00\n",
      " lambda[97]      3.15     11.36      1.00      0.00      5.62    605.68      1.00\n",
      " lambda[98]      3.83     18.79      0.96      0.00      5.13    592.19      1.00\n",
      " lambda[99]      2.75      8.14      1.01      0.00      4.82    564.68      1.00\n",
      "lambda[100]      3.88     26.97      0.88      0.00      5.76    958.73      1.00\n",
      "lambda[101]      2.54      6.56      0.95      0.00      5.42    658.32      1.00\n",
      "lambda[102]      2.78      7.52      0.89      0.00      5.47    708.32      1.00\n",
      "lambda[103]      2.33      5.69      0.93      0.00      5.47    913.97      1.00\n",
      "lambda[104]      2.96      9.81      0.98      0.00      5.73    633.23      1.00\n",
      "lambda[105]      3.86     12.84      1.04      0.00      7.68    709.27      1.00\n",
      "lambda[106]      2.42      5.22      1.00      0.00      5.39    712.24      1.00\n",
      "lambda[107]      3.69     13.25      1.03      0.00      5.74    297.72      1.00\n",
      "lambda[108]      2.37      6.20      0.96      0.00      5.05    597.11      1.01\n",
      "lambda[109]      3.33     11.69      0.96      0.00      5.71    822.29      1.00\n",
      "lambda[110]      3.53     13.24      1.00      0.00      5.82    880.42      1.00\n",
      "lambda[111]      4.15     23.02      0.93      0.00      6.22    659.50      1.00\n",
      "lambda[112]      2.96     11.37      0.97      0.00      5.91    847.71      1.00\n",
      "lambda[113]      3.73     15.45      1.04      0.00      6.26    739.02      1.00\n",
      "lambda[114]      3.30      9.71      0.97      0.00      6.12    779.33      1.00\n",
      "lambda[115]      3.90     18.08      0.95      0.00      5.67    637.65      1.00\n",
      "lambda[116]      3.39     14.98      0.97      0.00      6.04    543.17      1.00\n",
      "lambda[117]      3.35     12.29      0.97      0.00      6.88    799.17      1.00\n",
      "lambda[118]      3.43     11.16      0.94      0.00      6.79    683.64      1.00\n",
      "lambda[119]      2.68      6.38      1.02      0.00      5.62    842.40      1.00\n",
      "lambda[120]      4.36     22.14      1.02      0.00      5.99    813.43      1.00\n",
      "lambda[121]      3.02      8.14      0.89      0.00      6.45    722.39      1.00\n",
      "lambda[122]      3.78     14.91      0.97      0.00      6.22    610.77      1.00\n",
      "lambda[123]      2.63      6.03      0.92      0.00      5.82    590.58      1.01\n",
      "lambda[124]      2.55      5.55      0.96      0.00      5.46    651.14      1.00\n",
      "lambda[125]      2.92      9.16      0.99      0.01      6.29    582.85      1.00\n",
      "lambda[126]      2.38      6.01      0.94      0.00      4.51    713.60      1.00\n",
      "lambda[127]      4.10     17.11      0.98      0.00      6.32    634.76      1.00\n",
      "lambda[128]      3.28     15.43      0.96      0.00      5.23    538.23      1.00\n",
      "lambda[129]      3.68     15.79      0.96      0.00      6.46    985.77      1.00\n",
      "lambda[130]      3.14      7.58      0.96      0.00      6.80    685.82      1.00\n",
      "lambda[131]      3.63     10.80      0.98      0.00      7.07    648.31      1.00\n",
      "lambda[132]      3.06     12.46      0.90      0.00      6.31    876.11      1.00\n",
      "lambda[133]      2.55      6.94      1.00      0.00      5.28    891.70      1.00\n",
      "lambda[134]      3.53      9.64      0.98      0.00      7.46    799.71      1.00\n",
      "lambda[135]      3.17     13.71      0.93      0.00      5.13    604.95      1.00\n",
      "lambda[136]      2.93      7.78      0.99      0.00      5.52    628.21      1.00\n",
      "lambda[137]      2.71      8.85      1.01      0.00      5.03    823.67      1.00\n",
      "lambda[138]      3.48     15.40      0.99      0.00      5.52    695.62      1.00\n",
      "lambda[139]      3.31      9.73      1.02      0.00      6.18    922.41      1.00\n",
      "lambda[140]      3.04      8.91      0.96      0.00      5.47    723.64      1.00\n",
      "lambda[141]      2.68      9.52      0.88      0.00      5.08    576.56      1.00\n",
      "lambda[142]      4.59     29.03      0.96      0.01      5.51    895.41      1.00\n",
      "lambda[143]      2.34      5.15      0.98      0.00      4.73    760.68      1.00\n",
      "        msq   2205.56  25915.68     29.90      0.84    711.30    926.39      1.00\n",
      "      sigma      5.67      7.71      2.41      0.01     16.82   1515.85      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1168.47      1.00\n",
      "       xisq     35.17    275.53      1.65      0.11     22.18    738.32      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.98770523071289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.02e-04 +- 2.03e-02\n",
      "[dimension 02/145]  inactive:\t-5.95e-04 +- 2.53e-02\n",
      "[dimension 03/145]  inactive:\t4.38e-04 +- 2.66e-02\n",
      "[dimension 04/145]  inactive:\t6.07e-03 +- 4.16e-02\n",
      "[dimension 05/145]  inactive:\t-1.04e-03 +- 2.94e-02\n",
      "[dimension 06/145]  inactive:\t1.85e-03 +- 3.39e-02\n",
      "[dimension 07/145]  inactive:\t6.70e-04 +- 2.08e-02\n",
      "[dimension 08/145]  inactive:\t9.75e-04 +- 2.91e-02\n",
      "[dimension 09/145]  inactive:\t1.12e-04 +- 2.24e-02\n",
      "[dimension 10/145]  inactive:\t4.39e-04 +- 1.91e-02\n",
      "[dimension 11/145]  inactive:\t-1.32e-03 +- 2.45e-02\n",
      "[dimension 12/145]  inactive:\t-9.06e-04 +- 3.00e-02\n",
      "[dimension 13/145]  inactive:\t6.00e-03 +- 4.55e-02\n",
      "[dimension 14/145]  inactive:\t-1.72e-03 +- 2.56e-02\n",
      "[dimension 15/145]  inactive:\t6.03e-04 +- 3.93e-02\n",
      "[dimension 16/145]  inactive:\t6.24e-04 +- 2.07e-02\n",
      "[dimension 17/145]  inactive:\t-4.81e-04 +- 3.39e-02\n",
      "[dimension 18/145]  inactive:\t3.70e-04 +- 3.28e-02\n",
      "[dimension 19/145]  inactive:\t-2.09e-03 +- 2.06e-02\n",
      "[dimension 20/145]  inactive:\t-1.65e-03 +- 2.95e-02\n",
      "[dimension 21/145]  inactive:\t-1.75e-03 +- 2.59e-02\n",
      "[dimension 22/145]  inactive:\t-5.21e-05 +- 2.33e-02\n",
      "[dimension 23/145]  inactive:\t-9.26e-04 +- 3.90e-02\n",
      "[dimension 24/145]  inactive:\t2.05e-03 +- 3.15e-02\n",
      "[dimension 25/145]  inactive:\t3.64e-03 +- 2.52e-02\n",
      "[dimension 26/145]  inactive:\t-9.25e-04 +- 2.89e-02\n",
      "[dimension 27/145]  inactive:\t9.51e-04 +- 2.88e-02\n",
      "[dimension 28/145]  inactive:\t7.41e-04 +- 2.13e-02\n",
      "[dimension 29/145]  inactive:\t-3.68e-04 +- 2.78e-02\n",
      "[dimension 30/145]  inactive:\t9.98e-04 +- 2.99e-02\n",
      "[dimension 31/145]  inactive:\t5.66e-03 +- 4.16e-02\n",
      "[dimension 32/145]  inactive:\t-2.51e-03 +- 3.38e-02\n",
      "[dimension 33/145]  inactive:\t2.90e-03 +- 4.25e-02\n",
      "[dimension 34/145]  inactive:\t1.09e-03 +- 2.16e-02\n",
      "[dimension 35/145]  inactive:\t3.58e-04 +- 2.73e-02\n",
      "[dimension 36/145]  inactive:\t5.74e-04 +- 2.45e-02\n",
      "[dimension 37/145]  inactive:\t3.91e-03 +- 2.76e-02\n",
      "[dimension 38/145]  inactive:\t-1.89e-03 +- 3.58e-02\n",
      "[dimension 39/145]  inactive:\t2.65e-03 +- 3.73e-02\n",
      "[dimension 40/145]  inactive:\t6.07e-03 +- 4.30e-02\n",
      "[dimension 41/145]  inactive:\t-1.58e-03 +- 4.18e-02\n",
      "[dimension 42/145]  inactive:\t1.78e-02 +- 1.10e-01\n",
      "[dimension 43/145]  inactive:\t-5.88e-04 +- 2.16e-02\n",
      "[dimension 44/145]  inactive:\t-3.46e-04 +- 2.73e-02\n",
      "[dimension 45/145]  inactive:\t-3.84e-04 +- 2.53e-02\n",
      "[dimension 46/145]  inactive:\t1.25e-03 +- 1.82e-02\n",
      "[dimension 47/145]  inactive:\t-1.68e-03 +- 2.57e-02\n",
      "[dimension 48/145]  inactive:\t1.82e-03 +- 2.83e-02\n",
      "[dimension 49/145]  inactive:\t3.13e-03 +- 2.56e-02\n",
      "[dimension 50/145]  inactive:\t-1.78e-03 +- 2.84e-02\n",
      "[dimension 51/145]  inactive:\t2.35e-03 +- 2.63e-02\n",
      "[dimension 52/145]  inactive:\t6.51e-03 +- 2.80e-02\n",
      "[dimension 53/145]  inactive:\t-1.72e-03 +- 3.35e-02\n",
      "[dimension 54/145]  inactive:\t-9.34e-05 +- 2.14e-02\n",
      "[dimension 55/145]  inactive:\t7.34e-04 +- 1.74e-02\n",
      "[dimension 56/145]  inactive:\t-2.40e-03 +- 2.40e-02\n",
      "[dimension 57/145]  inactive:\t1.15e-03 +- 3.32e-02\n",
      "[dimension 58/145]  inactive:\t1.20e-02 +- 6.68e-02\n",
      "[dimension 59/145]  inactive:\t-8.47e-04 +- 1.91e-02\n",
      "[dimension 60/145]  inactive:\t4.41e-04 +- 3.24e-02\n",
      "[dimension 61/145]  inactive:\t3.14e-03 +- 2.82e-02\n",
      "[dimension 62/145]  inactive:\t-9.49e-04 +- 2.50e-02\n",
      "[dimension 63/145]  active:\t6.91e-01 +- 4.28e-01\n",
      "[dimension 64/145]  inactive:\t-2.94e-03 +- 2.55e-02\n",
      "[dimension 65/145]  inactive:\t-6.14e-04 +- 2.93e-02\n",
      "[dimension 66/145]  inactive:\t4.23e-04 +- 3.18e-02\n",
      "[dimension 67/145]  inactive:\t1.44e-03 +- 2.76e-02\n",
      "[dimension 68/145]  inactive:\t-6.40e-04 +- 2.34e-02\n",
      "[dimension 69/145]  inactive:\t4.38e-03 +- 4.57e-02\n",
      "[dimension 70/145]  inactive:\t3.77e-03 +- 2.64e-02\n",
      "[dimension 71/145]  inactive:\t1.25e-04 +- 2.30e-02\n",
      "[dimension 72/145]  inactive:\t2.68e-04 +- 2.10e-02\n",
      "[dimension 73/145]  inactive:\t-9.28e-05 +- 1.98e-02\n",
      "[dimension 74/145]  inactive:\t-1.50e-03 +- 3.73e-02\n",
      "[dimension 75/145]  inactive:\t2.59e-04 +- 2.72e-02\n",
      "[dimension 76/145]  inactive:\t5.85e-03 +- 4.13e-02\n",
      "[dimension 77/145]  inactive:\t-1.93e-03 +- 4.31e-02\n",
      "[dimension 78/145]  inactive:\t1.36e-02 +- 9.28e-02\n",
      "[dimension 79/145]  inactive:\t6.50e-03 +- 3.62e-02\n",
      "[dimension 80/145]  inactive:\t-5.20e-04 +- 3.50e-02\n",
      "[dimension 81/145]  inactive:\t1.75e-03 +- 3.37e-02\n",
      "[dimension 82/145]  inactive:\t3.47e-04 +- 1.66e-02\n",
      "[dimension 83/145]  inactive:\t-1.55e-03 +- 1.87e-02\n",
      "[dimension 84/145]  inactive:\t-6.47e-04 +- 2.67e-02\n",
      "[dimension 85/145]  inactive:\t2.89e-03 +- 3.24e-02\n",
      "[dimension 86/145]  inactive:\t-4.32e-04 +- 2.21e-02\n",
      "[dimension 87/145]  inactive:\t1.32e-03 +- 2.98e-02\n",
      "[dimension 88/145]  inactive:\t3.72e-03 +- 2.93e-02\n",
      "[dimension 89/145]  inactive:\t-9.12e-04 +- 2.29e-02\n",
      "[dimension 90/145]  inactive:\t1.07e-01 +- 2.88e-01\n",
      "[dimension 91/145]  inactive:\t1.28e-04 +- 2.27e-02\n",
      "[dimension 92/145]  inactive:\t-1.53e-03 +- 2.88e-02\n",
      "[dimension 93/145]  inactive:\t-3.88e-04 +- 2.51e-02\n",
      "[dimension 94/145]  inactive:\t3.12e-03 +- 3.60e-02\n",
      "[dimension 95/145]  inactive:\t-3.43e-04 +- 2.52e-02\n",
      "[dimension 96/145]  inactive:\t2.37e-03 +- 4.39e-02\n",
      "[dimension 97/145]  inactive:\t2.31e-03 +- 2.28e-02\n",
      "[dimension 98/145]  inactive:\t-7.92e-04 +- 2.66e-02\n",
      "[dimension 99/145]  inactive:\t4.52e-03 +- 4.72e-02\n",
      "[dimension 100/145]  inactive:\t-6.29e-04 +- 1.72e-02\n",
      "[dimension 101/145]  inactive:\t-2.77e-03 +- 2.28e-02\n",
      "[dimension 102/145]  inactive:\t-4.03e-04 +- 2.54e-02\n",
      "[dimension 103/145]  inactive:\t9.68e-04 +- 2.38e-02\n",
      "[dimension 104/145]  inactive:\t-7.00e-04 +- 1.81e-02\n",
      "[dimension 105/145]  inactive:\t4.37e-04 +- 2.87e-02\n",
      "[dimension 106/145]  inactive:\t7.69e-03 +- 4.35e-02\n",
      "[dimension 107/145]  inactive:\t-1.05e-03 +- 2.13e-02\n",
      "[dimension 108/145]  inactive:\t9.66e-03 +- 8.02e-02\n",
      "[dimension 109/145]  inactive:\t-4.31e-04 +- 2.03e-02\n",
      "[dimension 110/145]  inactive:\t-1.08e-03 +- 3.58e-02\n",
      "[dimension 111/145]  inactive:\t2.48e-03 +- 3.97e-02\n",
      "[dimension 112/145]  inactive:\t7.32e-03 +- 6.00e-02\n",
      "[dimension 113/145]  inactive:\t-1.68e-03 +- 2.47e-02\n",
      "[dimension 114/145]  inactive:\t8.68e-04 +- 3.62e-02\n",
      "[dimension 115/145]  inactive:\t2.27e-03 +- 2.51e-02\n",
      "[dimension 116/145]  inactive:\t1.88e-03 +- 6.21e-02\n",
      "[dimension 117/145]  inactive:\t4.89e-03 +- 5.11e-02\n",
      "[dimension 118/145]  inactive:\t3.19e-03 +- 2.68e-02\n",
      "[dimension 119/145]  inactive:\t-2.79e-03 +- 3.59e-02\n",
      "[dimension 120/145]  inactive:\t-2.63e-04 +- 2.55e-02\n",
      "[dimension 121/145]  inactive:\t5.27e-03 +- 4.14e-02\n",
      "[dimension 122/145]  inactive:\t-3.36e-03 +- 4.01e-02\n",
      "[dimension 123/145]  inactive:\t4.26e-03 +- 5.56e-02\n",
      "[dimension 124/145]  inactive:\t-1.47e-03 +- 2.02e-02\n",
      "[dimension 125/145]  inactive:\t-1.66e-03 +- 3.03e-02\n",
      "[dimension 126/145]  inactive:\t-1.22e-03 +- 2.75e-02\n",
      "[dimension 127/145]  inactive:\t1.08e-05 +- 1.75e-02\n",
      "[dimension 128/145]  inactive:\t-1.52e-03 +- 3.52e-02\n",
      "[dimension 129/145]  inactive:\t7.06e-04 +- 3.05e-02\n",
      "[dimension 130/145]  inactive:\t3.88e-03 +- 2.90e-02\n",
      "[dimension 131/145]  inactive:\t-1.49e-03 +- 3.66e-02\n",
      "[dimension 132/145]  inactive:\t6.18e-03 +- 5.31e-02\n",
      "[dimension 133/145]  inactive:\t2.92e-03 +- 2.33e-02\n",
      "[dimension 134/145]  inactive:\t-1.06e-03 +- 2.91e-02\n",
      "[dimension 135/145]  inactive:\t8.13e-04 +- 2.99e-02\n",
      "[dimension 136/145]  inactive:\t1.34e-03 +- 2.26e-02\n",
      "[dimension 137/145]  inactive:\t-4.46e-04 +- 3.39e-02\n",
      "[dimension 138/145]  inactive:\t2.52e-04 +- 2.22e-02\n",
      "[dimension 139/145]  inactive:\t3.96e-04 +- 2.55e-02\n",
      "[dimension 140/145]  inactive:\t-1.52e-03 +- 3.15e-02\n",
      "[dimension 141/145]  inactive:\t1.34e-03 +- 2.97e-02\n",
      "[dimension 142/145]  inactive:\t1.42e-03 +- 1.93e-02\n",
      "[dimension 143/145]  inactive:\t1.49e-03 +- 3.82e-02\n",
      "[dimension 144/145]  inactive:\t1.10e-04 +- 2.15e-02\n",
      "[dimension 145/145]  inactive:\t-3.16e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9230962]\n",
      "cov_act[[0.04066816]]\n",
      "Active_dimensions: [62]\n",
      "33, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 51.50it/s, 31 steps of size 1.81e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    679.29      1.00\n",
      "  lambda[0]      2.58      8.96      0.93      0.00      4.72    865.82      1.00\n",
      "  lambda[1]      2.62      6.51      1.02      0.00      5.76    625.71      1.00\n",
      "  lambda[2]      2.61      6.12      0.98      0.00      5.55    653.39      1.00\n",
      "  lambda[3]      4.29     20.41      1.04      0.00      6.60    559.89      1.00\n",
      "  lambda[4]      3.58     15.84      1.00      0.00      6.02    561.88      1.00\n",
      "  lambda[5]      3.86     14.83      1.01      0.00      6.62    649.64      1.00\n",
      "  lambda[6]      3.79     12.22      1.05      0.00      6.51    673.32      1.00\n",
      "  lambda[7]      3.41     13.51      0.97      0.00      5.41    497.72      1.01\n",
      "  lambda[8]      2.53      6.12      1.01      0.00      5.33    707.22      1.00\n",
      "  lambda[9]      2.32      4.97      0.97      0.00      4.42    763.62      1.00\n",
      " lambda[10]      3.27     13.67      1.04      0.00      5.48    729.88      1.00\n",
      " lambda[11]      2.48      5.92      1.00      0.00      5.20    930.83      1.00\n",
      " lambda[12]      4.80     16.89      1.02      0.00      8.45    650.45      1.00\n",
      " lambda[13]      2.72      7.39      1.00      0.00      5.55    588.54      1.00\n",
      " lambda[14]      3.34     13.05      1.04      0.00      5.58    508.77      1.00\n",
      " lambda[15]      2.87      7.94      1.04      0.00      5.10    627.87      1.00\n",
      " lambda[16]      3.65     14.66      0.98      0.00      7.41    632.22      1.00\n",
      " lambda[17]      3.96     22.88      0.98      0.00      6.03    572.11      1.00\n",
      " lambda[18]      2.78      6.33      0.93      0.00      6.63    630.04      1.00\n",
      " lambda[19]      2.82      7.01      0.95      0.00      6.00    355.71      1.01\n",
      " lambda[20]      2.62      6.53      0.94      0.00      5.31    703.74      1.00\n",
      " lambda[21]      2.75     10.42      1.02      0.01      5.62    658.15      1.00\n",
      " lambda[22]      2.40      5.08      0.96      0.00      5.13    802.97      1.00\n",
      " lambda[23]      3.06     10.64      0.99      0.00      5.86    829.38      1.00\n",
      " lambda[24]      3.70     20.91      1.01      0.00      5.21    869.23      1.00\n",
      " lambda[25]      2.80      6.69      1.06      0.01      5.91    660.13      1.00\n",
      " lambda[26]      2.85     10.17      1.03      0.00      5.22    668.73      1.00\n",
      " lambda[27]      2.54      6.23      0.97      0.00      5.04    794.90      1.00\n",
      " lambda[28]      3.04     10.15      1.02      0.00      5.59    538.58      1.00\n",
      " lambda[29]      2.79      8.23      1.02      0.00      4.98    741.49      1.00\n",
      " lambda[30]      3.44     10.05      1.02      0.01      7.33    666.20      1.00\n",
      " lambda[31]      3.52     12.80      0.93      0.00      5.99    663.17      1.00\n",
      " lambda[32]      3.57     11.35      0.97      0.00      5.84    598.99      1.00\n",
      " lambda[33]      3.09      8.87      0.97      0.00      6.56    732.18      1.00\n",
      " lambda[34]      2.87      7.81      0.92      0.00      5.74    646.82      1.00\n",
      " lambda[35]      2.38      5.22      1.03      0.01      5.23    682.87      1.00\n",
      " lambda[36]      3.00      9.49      0.95      0.00      5.75    615.51      1.00\n",
      " lambda[37]      3.72     16.34      1.00      0.00      7.05    948.35      1.00\n",
      " lambda[38]      2.96      7.79      1.00      0.00      5.43    780.82      1.00\n",
      " lambda[39]      3.30     10.81      0.94      0.00      6.13    627.17      1.00\n",
      " lambda[40]      3.96     21.80      0.94      0.00      5.74    951.76      1.00\n",
      " lambda[41]    100.85   1507.12      0.92      0.00     14.47    546.25      1.00\n",
      " lambda[42]      2.54      6.08      0.96      0.00      5.28    695.99      1.01\n",
      " lambda[43]      4.12     35.39      0.98      0.00      6.79    934.66      1.00\n",
      " lambda[44]      2.86      6.85      1.03      0.00      6.37    659.75      1.00\n",
      " lambda[45]      2.32      5.27      0.98      0.00      4.43    691.11      1.00\n",
      " lambda[46]      2.75      9.08      1.01      0.00      4.63    592.20      1.00\n",
      " lambda[47]      2.68      6.29      0.98      0.00      5.88    635.32      1.00\n",
      " lambda[48]      2.51      6.97      1.05      0.00      5.45    855.33      1.00\n",
      " lambda[49]      3.25     10.91      0.97      0.00      6.07    769.30      1.00\n",
      " lambda[50]      3.48     10.69      1.01      0.00      6.80    513.32      1.00\n",
      " lambda[51]      6.58     71.24      1.06      0.00      6.39    882.06      1.00\n",
      " lambda[52]      2.48      5.16      1.00      0.00      5.53    866.81      1.00\n",
      " lambda[53]      2.76      8.48      0.97      0.00      5.11    775.57      1.00\n",
      " lambda[54]      2.18      4.74      0.97      0.00      4.47    462.69      1.00\n",
      " lambda[55]      2.30      4.57      1.00      0.00      4.83    777.22      1.00\n",
      " lambda[56]      3.25      8.83      1.00      0.00      6.00    499.67      1.00\n",
      " lambda[57]      6.58     32.65      1.04      0.00      9.87    383.36      1.00\n",
      " lambda[58]      2.51      6.36      0.94      0.00      5.14    582.23      1.00\n",
      " lambda[59]      3.21     11.89      0.98      0.00      5.75    804.29      1.00\n",
      " lambda[60]      3.26     13.66      1.00      0.00      5.74    965.09      1.00\n",
      " lambda[61]      2.53      5.71      0.95      0.00      5.38    681.81      1.00\n",
      " lambda[62]   2909.95  44647.82    183.50      0.00   2011.75    535.21      1.00\n",
      " lambda[63]      2.69      6.81      0.97      0.00      5.04    766.77      1.00\n",
      " lambda[64]      3.00      8.86      1.02      0.00      5.81    583.35      1.00\n",
      " lambda[65]      2.90      9.29      0.92      0.00      5.74    819.69      1.00\n",
      " lambda[66]      8.84    116.43      1.07      0.00      7.39    446.57      1.00\n",
      " lambda[67]      2.25      5.21      0.90      0.00      4.76    819.39      1.00\n",
      " lambda[68]      4.59     43.52      0.97      0.00      5.77    739.68      1.00\n",
      " lambda[69]      4.49     32.33      0.92      0.00      5.72    700.21      1.00\n",
      " lambda[70]      2.70      6.17      1.01      0.00      5.98    442.92      1.01\n",
      " lambda[71]      3.30     11.10      0.95      0.00      5.28    441.40      1.00\n",
      " lambda[72]      2.52      6.44      1.03      0.01      5.09    665.31      1.00\n",
      " lambda[73]      3.67     21.59      1.02      0.00      5.30    707.68      1.00\n",
      " lambda[74]      2.68      7.87      1.01      0.01      6.07    903.24      1.00\n",
      " lambda[75]      3.91     13.09      1.01      0.00      7.49    807.03      1.00\n",
      " lambda[76]      2.77      7.61      0.95      0.00      5.21    704.90      1.00\n",
      " lambda[77]      9.00     66.48      1.07      0.00      8.05    480.99      1.01\n",
      " lambda[78]      3.59     16.72      0.98      0.00      6.43    594.95      1.00\n",
      " lambda[79]      3.16     11.48      0.96      0.00      5.49    748.18      1.00\n",
      " lambda[80]      3.26     10.74      1.00      0.01      5.83    442.79      1.00\n",
      " lambda[81]      2.76      6.98      0.93      0.00      5.47    833.03      1.00\n",
      " lambda[82]      2.50      8.07      0.90      0.00      4.77    837.34      1.00\n",
      " lambda[83]      2.77      7.68      0.96      0.00      5.37    837.43      1.00\n",
      " lambda[84]      3.18      9.60      0.99      0.00      6.26    556.12      1.00\n",
      " lambda[85]      2.49      5.63      0.96      0.00      5.63    992.56      1.00\n",
      " lambda[86]      2.98     10.77      0.97      0.00      5.79   1031.16      1.00\n",
      " lambda[87]      3.48     22.57      0.99      0.00      6.43    855.09      1.00\n",
      " lambda[88]      2.87      7.78      0.95      0.00      6.18    730.95      1.00\n",
      " lambda[89]    149.60   1873.93      1.24      0.00     73.59    723.87      1.00\n",
      " lambda[90]      2.88      7.80      1.00      0.00      6.08    725.63      1.00\n",
      " lambda[91]      2.63      6.13      1.04      0.00      5.49    631.94      1.00\n",
      " lambda[92]      2.66      7.01      1.00      0.00      4.80    597.17      1.00\n",
      " lambda[93]      2.54      5.99      1.04      0.00      5.46    712.59      1.00\n",
      " lambda[94]      2.83      7.78      0.91      0.00      5.59    594.07      1.00\n",
      " lambda[95]      3.26     13.39      0.92      0.00      5.46    561.03      1.00\n",
      " lambda[96]      2.35      5.15      1.00      0.00      4.86    527.23      1.00\n",
      " lambda[97]      2.87      9.71      1.01      0.00      5.42    765.08      1.00\n",
      " lambda[98]      4.06     19.18      1.06      0.00      6.29    680.53      1.00\n",
      " lambda[99]      2.74      7.70      1.01      0.00      5.31    788.11      1.00\n",
      "lambda[100]      2.91      9.45      0.90      0.00      6.04    585.95      1.00\n",
      "lambda[101]      2.81      6.34      0.91      0.01      6.43    686.98      1.00\n",
      "lambda[102]      2.85      8.08      0.95      0.00      5.31    747.13      1.00\n",
      "lambda[103]      2.61      6.25      0.99      0.00      5.98    457.74      1.00\n",
      "lambda[104]      2.75      6.71      0.94      0.00      5.89    772.58      1.00\n",
      "lambda[105]      3.37      9.52      1.04      0.01      6.27    530.43      1.00\n",
      "lambda[106]      2.61      6.54      1.01      0.00      5.41    849.99      1.00\n",
      "lambda[107]      4.06     26.25      0.96      0.00      5.78    898.38      1.00\n",
      "lambda[108]      2.30      4.95      0.96      0.00      4.81    640.86      1.00\n",
      "lambda[109]      5.20     43.78      1.01      0.00      5.90    811.41      1.00\n",
      "lambda[110]      3.95     13.15      0.98      0.00      6.55    514.35      1.00\n",
      "lambda[111]      3.41     12.30      0.95      0.00      6.63    519.23      1.00\n",
      "lambda[112]      2.74      7.54      0.95      0.00      5.80    884.10      1.00\n",
      "lambda[113]      4.28     18.44      1.02      0.00      6.74    677.66      1.00\n",
      "lambda[114]      3.55     11.61      0.98      0.00      6.55    818.44      1.00\n",
      "lambda[115]      3.72     16.79      0.97      0.00      5.66    937.98      1.00\n",
      "lambda[116]      5.17     39.19      1.02      0.00      6.17    591.68      1.00\n",
      "lambda[117]      3.32     11.72      0.98      0.00      6.35    566.01      1.00\n",
      "lambda[118]      3.32     12.51      1.00      0.00      5.83    823.02      1.00\n",
      "lambda[119]      2.33      4.66      1.04      0.00      5.17    717.89      1.00\n",
      "lambda[120]      4.49     16.73      1.03      0.00      6.75    552.31      1.00\n",
      "lambda[121]      2.84      8.38      0.93      0.00      5.98    630.80      1.00\n",
      "lambda[122]      2.89      8.67      0.96      0.00      6.03    942.55      1.00\n",
      "lambda[123]      2.72      7.93      0.92      0.00      6.13    828.01      1.00\n",
      "lambda[124]      2.69      5.95      1.08      0.00      6.15    945.93      1.00\n",
      "lambda[125]      2.69      7.05      0.97      0.00      5.25    655.75      1.00\n",
      "lambda[126]      2.55      6.70      0.96      0.00      5.18    698.01      1.00\n",
      "lambda[127]      3.98     16.34      0.98      0.00      7.28    855.25      1.00\n",
      "lambda[128]      2.61      8.14      0.96      0.00      4.92    539.72      1.00\n",
      "lambda[129]      3.44     12.20      1.07      0.00      6.25    736.19      1.00\n",
      "lambda[130]      3.02      7.79      0.91      0.00      5.48    664.46      1.00\n",
      "lambda[131]      3.13     14.26      1.00      0.01      5.61    846.00      1.00\n",
      "lambda[132]      3.41     12.90      1.00      0.00      6.44    510.29      1.00\n",
      "lambda[133]      2.88      9.89      0.96      0.00      5.48    849.36      1.00\n",
      "lambda[134]      3.63     10.18      0.93      0.00      7.63    613.71      1.01\n",
      "lambda[135]      3.21     20.49      0.95      0.00      5.50    823.82      1.00\n",
      "lambda[136]      3.20     10.57      0.97      0.00      6.21    798.09      1.00\n",
      "lambda[137]      2.39      6.41      0.98      0.00      4.58    826.69      1.00\n",
      "lambda[138]      3.22     11.99      1.03      0.00      5.06    775.01      1.00\n",
      "lambda[139]      3.06      8.61      1.06      0.00      5.80    643.34      1.00\n",
      "lambda[140]      2.83     12.15      0.95      0.00      5.25    937.33      1.00\n",
      "lambda[141]      2.64      6.32      0.86      0.00      5.97    562.08      1.00\n",
      "lambda[142]      4.56     25.22      0.99      0.01      6.59    696.07      1.00\n",
      "lambda[143]      2.23      4.36      0.96      0.00      4.98    507.50      1.00\n",
      "        msq      1.46      0.82      1.25      0.44      2.50   1071.94      1.00\n",
      "      sigma      5.51      8.20      2.07      0.00     15.76   1416.55      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    603.93      1.00\n",
      "       xisq      3.61     24.53      0.86      0.09      5.49    467.10      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 32.81721591949463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.18e-04 +- 1.64e-02\n",
      "[dimension 02/145]  inactive:\t5.96e-04 +- 2.06e-02\n",
      "[dimension 03/145]  inactive:\t3.31e-04 +- 1.98e-02\n",
      "[dimension 04/145]  inactive:\t4.57e-03 +- 3.66e-02\n",
      "[dimension 05/145]  inactive:\t-3.23e-04 +- 2.17e-02\n",
      "[dimension 06/145]  inactive:\t2.34e-03 +- 3.12e-02\n",
      "[dimension 07/145]  inactive:\t9.73e-04 +- 1.93e-02\n",
      "[dimension 08/145]  inactive:\t8.07e-04 +- 2.56e-02\n",
      "[dimension 09/145]  inactive:\t7.92e-04 +- 2.30e-02\n",
      "[dimension 10/145]  inactive:\t4.23e-04 +- 1.41e-02\n",
      "[dimension 11/145]  inactive:\t7.12e-05 +- 2.22e-02\n",
      "[dimension 12/145]  inactive:\t2.50e-04 +- 1.83e-02\n",
      "[dimension 13/145]  inactive:\t5.52e-03 +- 4.43e-02\n",
      "[dimension 14/145]  inactive:\t-5.47e-04 +- 2.20e-02\n",
      "[dimension 15/145]  inactive:\t2.28e-03 +- 3.56e-02\n",
      "[dimension 16/145]  inactive:\t1.04e-03 +- 1.90e-02\n",
      "[dimension 17/145]  inactive:\t6.43e-04 +- 2.71e-02\n",
      "[dimension 18/145]  inactive:\t6.19e-04 +- 2.61e-02\n",
      "[dimension 19/145]  inactive:\t-1.48e-03 +- 1.74e-02\n",
      "[dimension 20/145]  inactive:\t-1.95e-04 +- 2.47e-02\n",
      "[dimension 21/145]  inactive:\t-1.03e-03 +- 1.99e-02\n",
      "[dimension 22/145]  inactive:\t9.20e-05 +- 1.63e-02\n",
      "[dimension 23/145]  inactive:\t5.73e-05 +- 2.28e-02\n",
      "[dimension 24/145]  inactive:\t1.59e-03 +- 2.60e-02\n",
      "[dimension 25/145]  inactive:\t2.48e-03 +- 2.03e-02\n",
      "[dimension 26/145]  inactive:\t-6.61e-05 +- 2.53e-02\n",
      "[dimension 27/145]  inactive:\t7.96e-04 +- 2.00e-02\n",
      "[dimension 28/145]  inactive:\t6.46e-04 +- 1.73e-02\n",
      "[dimension 29/145]  inactive:\t1.91e-04 +- 2.34e-02\n",
      "[dimension 30/145]  inactive:\t1.37e-03 +- 2.37e-02\n",
      "[dimension 31/145]  inactive:\t5.15e-03 +- 4.27e-02\n",
      "[dimension 32/145]  inactive:\t-5.98e-04 +- 2.56e-02\n",
      "[dimension 33/145]  inactive:\t4.77e-03 +- 4.86e-02\n",
      "[dimension 34/145]  inactive:\t8.30e-04 +- 1.86e-02\n",
      "[dimension 35/145]  inactive:\t1.06e-03 +- 2.35e-02\n",
      "[dimension 36/145]  inactive:\t6.06e-04 +- 1.69e-02\n",
      "[dimension 37/145]  inactive:\t2.88e-03 +- 2.23e-02\n",
      "[dimension 38/145]  inactive:\t-7.73e-04 +- 2.77e-02\n",
      "[dimension 39/145]  inactive:\t1.29e-03 +- 2.99e-02\n",
      "[dimension 40/145]  inactive:\t3.60e-03 +- 3.16e-02\n",
      "[dimension 41/145]  inactive:\t1.55e-04 +- 3.43e-02\n",
      "[dimension 42/145]  inactive:\t3.95e-02 +- 1.73e-01\n",
      "[dimension 43/145]  inactive:\t2.28e-04 +- 1.54e-02\n",
      "[dimension 44/145]  inactive:\t1.62e-04 +- 2.79e-02\n",
      "[dimension 45/145]  inactive:\t1.16e-04 +- 2.03e-02\n",
      "[dimension 46/145]  inactive:\t5.56e-04 +- 1.33e-02\n",
      "[dimension 47/145]  inactive:\t-8.51e-04 +- 1.94e-02\n",
      "[dimension 48/145]  inactive:\t1.62e-03 +- 2.52e-02\n",
      "[dimension 49/145]  inactive:\t1.47e-03 +- 1.91e-02\n",
      "[dimension 50/145]  inactive:\t-9.64e-04 +- 2.28e-02\n",
      "[dimension 51/145]  inactive:\t3.48e-03 +- 3.36e-02\n",
      "[dimension 52/145]  inactive:\t5.38e-03 +- 2.54e-02\n",
      "[dimension 53/145]  inactive:\t-3.36e-04 +- 1.75e-02\n",
      "[dimension 54/145]  inactive:\t4.73e-05 +- 1.81e-02\n",
      "[dimension 55/145]  inactive:\t4.38e-04 +- 1.29e-02\n",
      "[dimension 56/145]  inactive:\t-1.06e-03 +- 1.80e-02\n",
      "[dimension 57/145]  inactive:\t2.08e-03 +- 2.93e-02\n",
      "[dimension 58/145]  inactive:\t1.62e-02 +- 7.84e-02\n",
      "[dimension 59/145]  inactive:\t-4.53e-04 +- 1.61e-02\n",
      "[dimension 60/145]  inactive:\t1.47e-03 +- 2.93e-02\n",
      "[dimension 61/145]  inactive:\t2.57e-03 +- 2.43e-02\n",
      "[dimension 62/145]  inactive:\t2.50e-05 +- 2.05e-02\n",
      "[dimension 63/145]  active:\t6.52e-01 +- 4.36e-01\n",
      "[dimension 64/145]  inactive:\t-1.87e-03 +- 2.04e-02\n",
      "[dimension 65/145]  inactive:\t-2.29e-04 +- 2.11e-02\n",
      "[dimension 66/145]  inactive:\t6.06e-04 +- 2.09e-02\n",
      "[dimension 67/145]  inactive:\t1.49e-03 +- 2.67e-02\n",
      "[dimension 68/145]  inactive:\t-5.17e-05 +- 1.77e-02\n",
      "[dimension 69/145]  inactive:\t4.67e-03 +- 4.90e-02\n",
      "[dimension 70/145]  inactive:\t3.16e-03 +- 2.23e-02\n",
      "[dimension 71/145]  inactive:\t7.23e-04 +- 2.51e-02\n",
      "[dimension 72/145]  inactive:\t1.14e-03 +- 2.27e-02\n",
      "[dimension 73/145]  inactive:\t5.29e-04 +- 1.61e-02\n",
      "[dimension 74/145]  inactive:\t-9.09e-04 +- 3.00e-02\n",
      "[dimension 75/145]  inactive:\t9.86e-04 +- 2.40e-02\n",
      "[dimension 76/145]  inactive:\t5.19e-03 +- 3.84e-02\n",
      "[dimension 77/145]  inactive:\t-4.96e-04 +- 2.29e-02\n",
      "[dimension 78/145]  inactive:\t1.46e-02 +- 9.81e-02\n",
      "[dimension 79/145]  inactive:\t5.17e-03 +- 3.35e-02\n",
      "[dimension 80/145]  inactive:\t3.23e-04 +- 2.56e-02\n",
      "[dimension 81/145]  inactive:\t4.15e-03 +- 4.43e-02\n",
      "[dimension 82/145]  inactive:\t2.94e-04 +- 1.44e-02\n",
      "[dimension 83/145]  inactive:\t-8.37e-04 +- 1.42e-02\n",
      "[dimension 84/145]  inactive:\t-6.33e-04 +- 2.03e-02\n",
      "[dimension 85/145]  inactive:\t2.51e-03 +- 2.80e-02\n",
      "[dimension 86/145]  inactive:\t-3.25e-04 +- 1.66e-02\n",
      "[dimension 87/145]  inactive:\t2.17e-03 +- 3.71e-02\n",
      "[dimension 88/145]  inactive:\t2.59e-03 +- 2.28e-02\n",
      "[dimension 89/145]  inactive:\t-7.98e-05 +- 2.08e-02\n",
      "[dimension 90/145]  inactive:\t9.22e-02 +- 2.59e-01\n",
      "[dimension 91/145]  inactive:\t4.23e-05 +- 1.76e-02\n",
      "[dimension 92/145]  inactive:\t-7.34e-04 +- 2.27e-02\n",
      "[dimension 93/145]  inactive:\t-7.47e-05 +- 2.23e-02\n",
      "[dimension 94/145]  inactive:\t1.33e-03 +- 2.18e-02\n",
      "[dimension 95/145]  inactive:\t9.83e-05 +- 2.02e-02\n",
      "[dimension 96/145]  inactive:\t4.02e-04 +- 2.78e-02\n",
      "[dimension 97/145]  inactive:\t1.45e-03 +- 1.83e-02\n",
      "[dimension 98/145]  inactive:\t-2.31e-04 +- 1.91e-02\n",
      "[dimension 99/145]  inactive:\t6.77e-03 +- 5.69e-02\n",
      "[dimension 100/145]  inactive:\t-2.26e-04 +- 1.50e-02\n",
      "[dimension 101/145]  inactive:\t-2.14e-03 +- 2.18e-02\n",
      "[dimension 102/145]  inactive:\t-2.58e-04 +- 2.41e-02\n",
      "[dimension 103/145]  inactive:\t1.34e-03 +- 2.51e-02\n",
      "[dimension 104/145]  inactive:\t-5.36e-04 +- 1.62e-02\n",
      "[dimension 105/145]  inactive:\t8.53e-04 +- 2.84e-02\n",
      "[dimension 106/145]  inactive:\t5.87e-03 +- 3.98e-02\n",
      "[dimension 107/145]  inactive:\t-7.05e-04 +- 1.79e-02\n",
      "[dimension 108/145]  inactive:\t6.19e-03 +- 6.00e-02\n",
      "[dimension 109/145]  inactive:\t-2.56e-04 +- 1.55e-02\n",
      "[dimension 110/145]  inactive:\t-2.94e-05 +- 3.09e-02\n",
      "[dimension 111/145]  inactive:\t1.48e-03 +- 2.75e-02\n",
      "[dimension 112/145]  inactive:\t2.68e-03 +- 2.78e-02\n",
      "[dimension 113/145]  inactive:\t-6.68e-04 +- 2.19e-02\n",
      "[dimension 114/145]  inactive:\t2.47e-03 +- 4.19e-02\n",
      "[dimension 115/145]  inactive:\t1.75e-03 +- 2.10e-02\n",
      "[dimension 116/145]  inactive:\t1.65e-03 +- 4.23e-02\n",
      "[dimension 117/145]  inactive:\t5.73e-03 +- 5.65e-02\n",
      "[dimension 118/145]  inactive:\t2.06e-03 +- 1.98e-02\n",
      "[dimension 119/145]  inactive:\t-1.02e-03 +- 2.36e-02\n",
      "[dimension 120/145]  inactive:\t2.30e-04 +- 1.80e-02\n",
      "[dimension 121/145]  inactive:\t5.34e-03 +- 4.20e-02\n",
      "[dimension 122/145]  inactive:\t-1.16e-03 +- 2.27e-02\n",
      "[dimension 123/145]  inactive:\t1.62e-03 +- 3.07e-02\n",
      "[dimension 124/145]  inactive:\t-7.92e-04 +- 1.91e-02\n",
      "[dimension 125/145]  inactive:\t-9.43e-04 +- 2.53e-02\n",
      "[dimension 126/145]  inactive:\t-2.67e-04 +- 1.90e-02\n",
      "[dimension 127/145]  inactive:\t3.89e-04 +- 1.64e-02\n",
      "[dimension 128/145]  inactive:\t-5.73e-04 +- 2.70e-02\n",
      "[dimension 129/145]  inactive:\t1.49e-04 +- 2.45e-02\n",
      "[dimension 130/145]  inactive:\t2.63e-03 +- 2.44e-02\n",
      "[dimension 131/145]  inactive:\t-2.94e-05 +- 2.59e-02\n",
      "[dimension 132/145]  inactive:\t3.18e-03 +- 3.58e-02\n",
      "[dimension 133/145]  inactive:\t2.52e-03 +- 2.07e-02\n",
      "[dimension 134/145]  inactive:\t-1.83e-04 +- 2.13e-02\n",
      "[dimension 135/145]  inactive:\t1.32e-03 +- 2.72e-02\n",
      "[dimension 136/145]  inactive:\t1.07e-03 +- 1.72e-02\n",
      "[dimension 137/145]  inactive:\t8.06e-05 +- 2.68e-02\n",
      "[dimension 138/145]  inactive:\t2.00e-04 +- 1.87e-02\n",
      "[dimension 139/145]  inactive:\t5.54e-04 +- 1.92e-02\n",
      "[dimension 140/145]  inactive:\t-4.06e-04 +- 2.60e-02\n",
      "[dimension 141/145]  inactive:\t1.08e-03 +- 2.22e-02\n",
      "[dimension 142/145]  inactive:\t1.75e-03 +- 1.86e-02\n",
      "[dimension 143/145]  inactive:\t3.18e-03 +- 4.18e-02\n",
      "[dimension 144/145]  inactive:\t2.29e-04 +- 1.60e-02\n",
      "[dimension 145/145]  inactive:\t3.25e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.016963]\n",
      "cov_act[[0.01229392]]\n",
      "Active_dimensions: [62]\n",
      "34, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.51it/s, 31 steps of size 1.61e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    554.27      1.00\n",
      "  lambda[0]      2.34      6.42      0.96      0.00      4.62    664.71      1.00\n",
      "  lambda[1]      2.57      6.10      0.98      0.00      5.55    563.66      1.00\n",
      "  lambda[2]      3.27     13.60      1.02      0.00      5.27    575.02      1.00\n",
      "  lambda[3]      3.85     15.36      1.09      0.00      6.84    662.37      1.00\n",
      "  lambda[4]      2.90      9.48      1.03      0.00      5.62    642.27      1.00\n",
      "  lambda[5]      3.11     12.65      0.93      0.00      5.23    582.33      1.00\n",
      "  lambda[6]      2.73      7.42      0.96      0.00      5.69    698.15      1.00\n",
      "  lambda[7]      3.11      9.71      1.00      0.00      6.19    567.80      1.00\n",
      "  lambda[8]      2.34      5.05      0.99      0.00      4.65    801.76      1.00\n",
      "  lambda[9]      2.50      6.99      0.95      0.00      5.07    603.83      1.00\n",
      " lambda[10]      3.62     11.91      1.10      0.00      6.29    657.09      1.00\n",
      " lambda[11]      2.85      7.43      1.01      0.01      5.64    847.02      1.00\n",
      " lambda[12]      4.25     14.26      1.06      0.00      7.53    767.33      1.00\n",
      " lambda[13]      2.56      7.84      0.95      0.00      5.60    861.69      1.00\n",
      " lambda[14]      4.85     30.15      0.96      0.00      4.95    607.79      1.00\n",
      " lambda[15]      2.74      9.56      0.98      0.00      4.88    565.18      1.00\n",
      " lambda[16]      3.76     11.20      0.98      0.00      7.85    709.45      1.00\n",
      " lambda[17]      2.58      6.61      0.98      0.01      5.03    874.77      1.00\n",
      " lambda[18]      2.93      7.52      0.93      0.00      6.00    917.41      1.00\n",
      " lambda[19]      3.60     20.56      0.97      0.01      5.35    812.62      1.00\n",
      " lambda[20]      2.78      6.47      0.98      0.01      6.06    747.93      1.00\n",
      " lambda[21]      2.71      7.47      1.00      0.01      5.88    706.74      1.00\n",
      " lambda[22]      2.70      6.73      1.05      0.00      5.13    690.07      1.00\n",
      " lambda[23]      2.94      9.24      0.99      0.00      5.54    829.60      1.00\n",
      " lambda[24]      3.14      9.72      1.03      0.00      5.65    602.03      1.00\n",
      " lambda[25]      3.46     10.90      1.01      0.00      6.21    444.04      1.00\n",
      " lambda[26]      3.48     15.54      1.06      0.00      4.98    704.34      1.00\n",
      " lambda[27]      2.89      8.28      0.99      0.00      5.69    585.39      1.00\n",
      " lambda[28]      2.79      8.13      0.99      0.00      5.93    864.67      1.00\n",
      " lambda[29]      2.99      8.11      0.95      0.00      6.46    596.04      1.00\n",
      " lambda[30]      3.87     14.63      0.98      0.01      6.69    689.14      1.01\n",
      " lambda[31]      4.12     18.51      1.01      0.00      6.74    735.52      1.00\n",
      " lambda[32]      3.68     15.95      0.95      0.00      6.67    611.65      1.00\n",
      " lambda[33]      3.04     11.64      0.96      0.01      6.42    938.85      1.00\n",
      " lambda[34]      2.69      8.52      0.95      0.00      5.00    707.26      1.00\n",
      " lambda[35]      2.47      6.05      1.01      0.00      5.07    800.16      1.00\n",
      " lambda[36]      3.66     17.54      1.01      0.00      6.08    734.50      1.00\n",
      " lambda[37]      2.98      8.06      1.00      0.00      6.17    724.55      1.00\n",
      " lambda[38]      2.90      8.04      0.98      0.00      5.65    886.96      1.00\n",
      " lambda[39]      3.34     12.25      1.03      0.00      5.82    544.32      1.00\n",
      " lambda[40]      3.99     17.96      0.93      0.00      5.76    674.60      1.00\n",
      " lambda[41]     15.21    131.23      0.99      0.00     11.44    333.55      1.00\n",
      " lambda[42]      3.31     15.54      0.99      0.00      5.19    653.49      1.00\n",
      " lambda[43]      3.26     19.55      1.03      0.00      5.75    982.57      1.00\n",
      " lambda[44]      2.31      4.79      0.95      0.00      4.99    893.52      1.00\n",
      " lambda[45]      2.61      6.59      0.97      0.00      5.50    697.23      1.00\n",
      " lambda[46]      2.54      6.28      1.03      0.01      4.99    784.21      1.00\n",
      " lambda[47]      2.57      5.21      0.97      0.00      5.57    758.87      1.00\n",
      " lambda[48]      2.88      9.76      0.95      0.01      5.81    732.98      1.00\n",
      " lambda[49]      3.15      8.95      0.98      0.00      6.20    850.43      1.00\n",
      " lambda[50]      4.04     20.35      1.00      0.00      6.38    588.29      1.00\n",
      " lambda[51]      4.98     26.57      1.02      0.00      7.68    988.60      1.00\n",
      " lambda[52]      2.67      8.06      0.96      0.00      5.50    772.06      1.00\n",
      " lambda[53]      3.16     11.73      0.96      0.00      5.38    605.67      1.01\n",
      " lambda[54]      2.81     12.96      0.94      0.00      4.84    533.25      1.00\n",
      " lambda[55]      3.25     14.35      0.95      0.00      5.42    865.55      1.00\n",
      " lambda[56]      2.49      5.53      1.01      0.00      4.73    850.86      1.00\n",
      " lambda[57]      5.34     19.76      1.05      0.00      7.90    483.65      1.00\n",
      " lambda[58]      2.39      5.79      0.93      0.00      4.97    630.84      1.00\n",
      " lambda[59]      3.45     10.04      0.96      0.00      6.92    457.71      1.00\n",
      " lambda[60]      2.49      5.90      0.94      0.00      5.40    612.63      1.00\n",
      " lambda[61]      2.74      6.13      0.99      0.00      6.10    760.99      1.00\n",
      " lambda[62]    796.74   8477.44    142.46      0.00   1006.46    753.71      1.00\n",
      " lambda[63]      2.37      5.15      0.97      0.00      5.40    826.37      1.00\n",
      " lambda[64]      3.43     13.67      0.98      0.00      5.54    629.44      1.00\n",
      " lambda[65]      3.41     12.40      0.94      0.00      6.12    733.17      1.00\n",
      " lambda[66]      3.13      9.56      1.01      0.00      6.64    656.74      1.00\n",
      " lambda[67]      2.38      6.40      0.93      0.00      5.04    776.04      1.00\n",
      " lambda[68]      5.11     47.39      0.94      0.00      6.39    487.98      1.00\n",
      " lambda[69]      3.60     17.57      0.94      0.00      5.81    714.97      1.00\n",
      " lambda[70]      2.45      5.38      1.00      0.00      5.13    678.77      1.01\n",
      " lambda[71]      4.62     33.16      0.97      0.00      5.21    349.31      1.00\n",
      " lambda[72]      2.64      6.92      1.00      0.01      5.26    658.27      1.00\n",
      " lambda[73]      2.49      5.26      1.10      0.00      5.14    693.06      1.00\n",
      " lambda[74]      2.45      4.50      1.06      0.00      5.35    964.29      1.00\n",
      " lambda[75]      5.15     23.30      0.96      0.00      7.81    833.79      1.00\n",
      " lambda[76]      2.86      7.05      0.99      0.00      5.80    789.82      1.00\n",
      " lambda[77]      4.86     24.35      1.08      0.00      7.41    559.07      1.00\n",
      " lambda[78]      4.43     22.29      1.06      0.00      7.22    582.78      1.00\n",
      " lambda[79]      3.26     11.77      1.02      0.00      5.58    554.64      1.00\n",
      " lambda[80]      4.91     28.52      1.02      0.00      6.36    615.71      1.00\n",
      " lambda[81]      2.56      8.24      1.00      0.00      4.77   1033.64      1.00\n",
      " lambda[82]      2.61      7.26      0.92      0.00      5.04    517.24      1.00\n",
      " lambda[83]      3.16     10.21      0.97      0.00      6.08    598.28      1.00\n",
      " lambda[84]      5.01     57.22      1.00      0.00      6.41    941.09      1.00\n",
      " lambda[85]      2.82      9.00      0.97      0.00      6.01    471.69      1.00\n",
      " lambda[86]      3.61     12.43      0.98      0.00      5.63    843.83      1.00\n",
      " lambda[87]      3.85     21.65      0.99      0.01      6.35    724.15      1.00\n",
      " lambda[88]      2.75      8.09      0.95      0.00      6.03    985.71      1.00\n",
      " lambda[89]     68.28    707.21      1.27      0.00     87.98    623.00      1.00\n",
      " lambda[90]      2.46      5.37      0.99      0.00      5.16    658.03      1.00\n",
      " lambda[91]      2.76      7.63      0.96      0.00      5.62    808.32      1.00\n",
      " lambda[92]      2.68      6.30      1.06      0.00      5.29    591.92      1.00\n",
      " lambda[93]      2.49      5.51      1.00      0.00      5.32    497.99      1.00\n",
      " lambda[94]      2.61      7.29      0.96      0.00      5.58    926.01      1.00\n",
      " lambda[95]      2.72      7.22      0.97      0.00      5.47    981.40      1.00\n",
      " lambda[96]      2.91     11.37      0.97      0.00      5.41    574.90      1.00\n",
      " lambda[97]      3.59     18.69      1.00      0.00      5.51    639.12      1.00\n",
      " lambda[98]      5.10     42.46      0.96      0.00      6.53    450.89      1.00\n",
      " lambda[99]      2.58      6.93      0.98      0.00      4.86    789.86      1.00\n",
      "lambda[100]      3.98     21.80      0.92      0.01      6.41    864.21      1.00\n",
      "lambda[101]      2.98      8.91      1.00      0.00      6.06    633.10      1.00\n",
      "lambda[102]      2.74      7.98      0.94      0.00      5.31    836.75      1.00\n",
      "lambda[103]      2.45      4.98      0.98      0.00      5.26    672.09      1.00\n",
      "lambda[104]      4.06     24.32      0.97      0.00      6.87    701.65      1.00\n",
      "lambda[105]      3.55     12.85      1.04      0.00      6.99    813.97      1.00\n",
      "lambda[106]      2.96      7.85      0.97      0.00      5.59    547.10      1.00\n",
      "lambda[107]      7.82     57.32      0.99      0.00      6.69    740.34      1.00\n",
      "lambda[108]      2.47      5.21      0.93      0.00      5.32    560.83      1.01\n",
      "lambda[109]      5.05     55.73      0.97      0.00      6.39    995.57      1.00\n",
      "lambda[110]      3.08      9.10      1.03      0.01      5.96    913.42      1.00\n",
      "lambda[111]      3.37     12.38      0.87      0.00      6.44    654.08      1.00\n",
      "lambda[112]      2.99     13.80      0.95      0.00      5.77    946.71      1.00\n",
      "lambda[113]      4.16     15.23      1.01      0.00      7.43    671.25      1.00\n",
      "lambda[114]      3.12     14.69      1.05      0.00      5.64    925.78      1.00\n",
      "lambda[115]      4.07     22.16      0.93      0.00      5.57    592.08      1.00\n",
      "lambda[116]      5.12     31.28      1.05      0.00      5.53    435.84      1.00\n",
      "lambda[117]      3.24     12.98      0.98      0.00      6.10    842.66      1.00\n",
      "lambda[118]      3.56     15.64      0.99      0.00      5.82    809.82      1.00\n",
      "lambda[119]      2.78     10.68      1.01      0.00      5.36    921.13      1.00\n",
      "lambda[120]      3.97     19.34      0.97      0.00      5.76    757.08      1.00\n",
      "lambda[121]      3.75     24.52      0.92      0.00      5.71    922.55      1.00\n",
      "lambda[122]      3.98     17.96      1.02      0.00      6.95    554.48      1.00\n",
      "lambda[123]      3.35     14.79      0.93      0.00      5.54    487.18      1.00\n",
      "lambda[124]      2.71      6.66      1.01      0.00      5.96    692.79      1.00\n",
      "lambda[125]      2.79      8.00      0.93      0.01      5.74    687.38      1.00\n",
      "lambda[126]      2.31      5.29      0.95      0.00      4.81    916.76      1.00\n",
      "lambda[127]      4.28     20.80      0.98      0.00      6.13    758.73      1.00\n",
      "lambda[128]      3.33     15.82      0.95      0.00      5.07    426.27      1.00\n",
      "lambda[129]      3.87     25.00      0.98      0.00      5.83    992.79      1.00\n",
      "lambda[130]      3.42      8.73      0.95      0.00      7.44    674.60      1.00\n",
      "lambda[131]      3.63     15.75      0.96      0.00      6.11    606.60      1.00\n",
      "lambda[132]      2.37      4.75      0.93      0.00      5.25   1067.11      1.00\n",
      "lambda[133]      2.60      7.09      1.01      0.00      5.32    770.02      1.00\n",
      "lambda[134]      3.56      8.99      0.87      0.00      7.71    769.23      1.00\n",
      "lambda[135]      2.67     11.41      0.93      0.00      4.58    823.36      1.00\n",
      "lambda[136]      3.13      7.66      0.99      0.00      6.79    616.68      1.00\n",
      "lambda[137]      2.59      7.32      1.00      0.00      5.34    725.04      1.01\n",
      "lambda[138]      3.35     13.54      1.00      0.00      5.61    735.26      1.00\n",
      "lambda[139]      3.34     10.41      0.98      0.00      6.17    804.98      1.01\n",
      "lambda[140]      3.17      9.50      0.97      0.00      5.66    746.81      1.00\n",
      "lambda[141]      2.38      6.54      0.86      0.00      4.92    560.76      1.00\n",
      "lambda[142]      3.78     16.07      0.98      0.01      5.66    734.71      1.00\n",
      "lambda[143]      2.15      5.16      0.93      0.00      4.81    895.56      1.00\n",
      "        msq    904.18   7482.46     23.22      0.97    449.59    767.97      1.00\n",
      "      sigma      6.10      8.57      2.61      0.02     16.94   1146.16      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    577.37      1.00\n",
      "       xisq      0.12      0.07      0.11      0.04      0.21   1329.04      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 34.40540385246277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.29e-04 +- 2.07e-02\n",
      "[dimension 02/145]  inactive:\t-3.01e-04 +- 2.75e-02\n",
      "[dimension 03/145]  inactive:\t5.97e-04 +- 3.19e-02\n",
      "[dimension 04/145]  inactive:\t7.04e-03 +- 4.54e-02\n",
      "[dimension 05/145]  inactive:\t-1.04e-03 +- 2.78e-02\n",
      "[dimension 06/145]  inactive:\t3.13e-03 +- 4.09e-02\n",
      "[dimension 07/145]  inactive:\t5.43e-04 +- 2.13e-02\n",
      "[dimension 08/145]  inactive:\t7.52e-04 +- 3.21e-02\n",
      "[dimension 09/145]  inactive:\t3.75e-04 +- 2.38e-02\n",
      "[dimension 10/145]  inactive:\t5.25e-04 +- 2.19e-02\n",
      "[dimension 11/145]  inactive:\t-7.03e-04 +- 2.99e-02\n",
      "[dimension 12/145]  inactive:\t-1.83e-04 +- 3.47e-02\n",
      "[dimension 13/145]  inactive:\t6.58e-03 +- 4.89e-02\n",
      "[dimension 14/145]  inactive:\t-1.69e-03 +- 2.80e-02\n",
      "[dimension 15/145]  inactive:\t8.32e-04 +- 3.91e-02\n",
      "[dimension 16/145]  inactive:\t1.23e-03 +- 2.21e-02\n",
      "[dimension 17/145]  inactive:\t-3.70e-05 +- 3.81e-02\n",
      "[dimension 18/145]  inactive:\t-5.43e-05 +- 2.83e-02\n",
      "[dimension 19/145]  inactive:\t-3.27e-03 +- 2.73e-02\n",
      "[dimension 20/145]  inactive:\t-1.50e-03 +- 3.28e-02\n",
      "[dimension 21/145]  inactive:\t-2.78e-03 +- 3.12e-02\n",
      "[dimension 22/145]  inactive:\t-3.99e-04 +- 2.67e-02\n",
      "[dimension 23/145]  inactive:\t-8.25e-04 +- 2.76e-02\n",
      "[dimension 24/145]  inactive:\t2.11e-03 +- 3.28e-02\n",
      "[dimension 25/145]  inactive:\t3.16e-03 +- 2.29e-02\n",
      "[dimension 26/145]  inactive:\t-9.69e-04 +- 3.74e-02\n",
      "[dimension 27/145]  inactive:\t9.67e-04 +- 2.59e-02\n",
      "[dimension 28/145]  inactive:\t1.06e-03 +- 2.32e-02\n",
      "[dimension 29/145]  inactive:\t-1.07e-04 +- 3.22e-02\n",
      "[dimension 30/145]  inactive:\t1.08e-03 +- 3.32e-02\n",
      "[dimension 31/145]  inactive:\t7.95e-03 +- 5.37e-02\n",
      "[dimension 32/145]  inactive:\t-2.70e-03 +- 3.32e-02\n",
      "[dimension 33/145]  inactive:\t3.16e-03 +- 4.58e-02\n",
      "[dimension 34/145]  inactive:\t1.10e-03 +- 2.30e-02\n",
      "[dimension 35/145]  inactive:\t3.22e-04 +- 2.69e-02\n",
      "[dimension 36/145]  inactive:\t1.51e-03 +- 3.07e-02\n",
      "[dimension 37/145]  inactive:\t5.92e-03 +- 3.59e-02\n",
      "[dimension 38/145]  inactive:\t-1.73e-03 +- 3.97e-02\n",
      "[dimension 39/145]  inactive:\t1.31e-03 +- 3.43e-02\n",
      "[dimension 40/145]  inactive:\t5.28e-03 +- 3.96e-02\n",
      "[dimension 41/145]  inactive:\t-3.00e-03 +- 3.95e-02\n",
      "[dimension 42/145]  inactive:\t2.73e-02 +- 1.37e-01\n",
      "[dimension 43/145]  inactive:\t-6.92e-04 +- 2.31e-02\n",
      "[dimension 44/145]  inactive:\t-4.14e-04 +- 3.18e-02\n",
      "[dimension 45/145]  inactive:\t-9.20e-05 +- 2.60e-02\n",
      "[dimension 46/145]  inactive:\t1.33e-03 +- 1.96e-02\n",
      "[dimension 47/145]  inactive:\t-2.32e-03 +- 3.27e-02\n",
      "[dimension 48/145]  inactive:\t1.93e-03 +- 2.86e-02\n",
      "[dimension 49/145]  inactive:\t3.44e-03 +- 2.68e-02\n",
      "[dimension 50/145]  inactive:\t-2.04e-03 +- 3.25e-02\n",
      "[dimension 51/145]  inactive:\t4.69e-03 +- 3.95e-02\n",
      "[dimension 52/145]  inactive:\t8.04e-03 +- 3.25e-02\n",
      "[dimension 53/145]  inactive:\t-1.05e-03 +- 2.65e-02\n",
      "[dimension 54/145]  inactive:\t5.71e-04 +- 2.39e-02\n",
      "[dimension 55/145]  inactive:\t7.45e-04 +- 1.99e-02\n",
      "[dimension 56/145]  inactive:\t-2.16e-03 +- 2.49e-02\n",
      "[dimension 57/145]  inactive:\t9.31e-04 +- 2.86e-02\n",
      "[dimension 58/145]  inactive:\t1.83e-02 +- 8.76e-02\n",
      "[dimension 59/145]  inactive:\t-5.62e-04 +- 1.95e-02\n",
      "[dimension 60/145]  inactive:\t2.20e-03 +- 4.07e-02\n",
      "[dimension 61/145]  inactive:\t2.71e-03 +- 2.59e-02\n",
      "[dimension 62/145]  inactive:\t-8.69e-04 +- 2.92e-02\n",
      "[dimension 63/145]  active:\t6.51e-01 +- 4.51e-01\n",
      "[dimension 64/145]  inactive:\t-3.40e-03 +- 3.01e-02\n",
      "[dimension 65/145]  inactive:\t-1.02e-03 +- 2.86e-02\n",
      "[dimension 66/145]  inactive:\t9.98e-04 +- 3.19e-02\n",
      "[dimension 67/145]  inactive:\t1.37e-03 +- 3.28e-02\n",
      "[dimension 68/145]  inactive:\t-7.53e-04 +- 2.91e-02\n",
      "[dimension 69/145]  inactive:\t4.51e-03 +- 4.56e-02\n",
      "[dimension 70/145]  inactive:\t3.42e-03 +- 2.34e-02\n",
      "[dimension 71/145]  inactive:\t9.99e-05 +- 2.47e-02\n",
      "[dimension 72/145]  inactive:\t1.37e-04 +- 2.57e-02\n",
      "[dimension 73/145]  inactive:\t-7.01e-05 +- 2.16e-02\n",
      "[dimension 74/145]  inactive:\t-1.37e-03 +- 3.84e-02\n",
      "[dimension 75/145]  inactive:\t5.02e-04 +- 2.69e-02\n",
      "[dimension 76/145]  inactive:\t8.08e-03 +- 4.94e-02\n",
      "[dimension 77/145]  inactive:\t-1.61e-03 +- 3.64e-02\n",
      "[dimension 78/145]  inactive:\t1.11e-02 +- 7.82e-02\n",
      "[dimension 79/145]  inactive:\t7.45e-03 +- 3.81e-02\n",
      "[dimension 80/145]  inactive:\t-4.85e-04 +- 3.66e-02\n",
      "[dimension 81/145]  inactive:\t2.24e-03 +- 3.92e-02\n",
      "[dimension 82/145]  inactive:\t3.11e-04 +- 1.76e-02\n",
      "[dimension 83/145]  inactive:\t-1.80e-03 +- 1.95e-02\n",
      "[dimension 84/145]  inactive:\t-1.19e-03 +- 2.96e-02\n",
      "[dimension 85/145]  inactive:\t3.68e-03 +- 3.50e-02\n",
      "[dimension 86/145]  inactive:\t-1.14e-03 +- 2.32e-02\n",
      "[dimension 87/145]  inactive:\t4.31e-03 +- 5.10e-02\n",
      "[dimension 88/145]  inactive:\t3.38e-03 +- 2.93e-02\n",
      "[dimension 89/145]  inactive:\t-9.13e-04 +- 2.67e-02\n",
      "[dimension 90/145]  inactive:\t1.14e-01 +- 2.97e-01\n",
      "[dimension 91/145]  inactive:\t-1.88e-04 +- 2.02e-02\n",
      "[dimension 92/145]  inactive:\t-1.45e-03 +- 3.01e-02\n",
      "[dimension 93/145]  inactive:\t-1.01e-04 +- 2.54e-02\n",
      "[dimension 94/145]  inactive:\t2.43e-03 +- 3.02e-02\n",
      "[dimension 95/145]  inactive:\t-3.51e-04 +- 2.44e-02\n",
      "[dimension 96/145]  inactive:\t-1.81e-04 +- 3.42e-02\n",
      "[dimension 97/145]  inactive:\t2.60e-03 +- 2.62e-02\n",
      "[dimension 98/145]  inactive:\t-1.13e-03 +- 2.91e-02\n",
      "[dimension 99/145]  inactive:\t4.99e-03 +- 5.08e-02\n",
      "[dimension 100/145]  inactive:\t-6.94e-04 +- 1.89e-02\n",
      "[dimension 101/145]  inactive:\t-2.83e-03 +- 2.41e-02\n",
      "[dimension 102/145]  inactive:\t-4.86e-04 +- 3.29e-02\n",
      "[dimension 103/145]  inactive:\t1.20e-03 +- 2.51e-02\n",
      "[dimension 104/145]  inactive:\t-1.17e-03 +- 2.04e-02\n",
      "[dimension 105/145]  inactive:\t1.43e-05 +- 3.29e-02\n",
      "[dimension 106/145]  inactive:\t6.25e-03 +- 3.80e-02\n",
      "[dimension 107/145]  inactive:\t-1.59e-03 +- 2.59e-02\n",
      "[dimension 108/145]  inactive:\t1.78e-02 +- 1.11e-01\n",
      "[dimension 109/145]  inactive:\t-7.47e-04 +- 2.26e-02\n",
      "[dimension 110/145]  inactive:\t-1.70e-03 +- 3.25e-02\n",
      "[dimension 111/145]  inactive:\t1.86e-03 +- 3.54e-02\n",
      "[dimension 112/145]  inactive:\t5.48e-03 +- 4.34e-02\n",
      "[dimension 113/145]  inactive:\t-2.03e-03 +- 2.65e-02\n",
      "[dimension 114/145]  inactive:\t1.90e-03 +- 4.62e-02\n",
      "[dimension 115/145]  inactive:\t1.90e-03 +- 2.26e-02\n",
      "[dimension 116/145]  inactive:\t1.28e-03 +- 4.76e-02\n",
      "[dimension 117/145]  inactive:\t9.10e-03 +- 7.51e-02\n",
      "[dimension 118/145]  inactive:\t3.54e-03 +- 2.77e-02\n",
      "[dimension 119/145]  inactive:\t-3.17e-03 +- 3.74e-02\n",
      "[dimension 120/145]  inactive:\t-6.16e-05 +- 3.08e-02\n",
      "[dimension 121/145]  inactive:\t5.11e-03 +- 4.11e-02\n",
      "[dimension 122/145]  inactive:\t-3.44e-03 +- 4.22e-02\n",
      "[dimension 123/145]  inactive:\t4.48e-03 +- 6.00e-02\n",
      "[dimension 124/145]  inactive:\t-1.38e-03 +- 2.15e-02\n",
      "[dimension 125/145]  inactive:\t-1.90e-03 +- 3.06e-02\n",
      "[dimension 126/145]  inactive:\t-1.01e-03 +- 2.62e-02\n",
      "[dimension 127/145]  inactive:\t-2.36e-04 +- 2.05e-02\n",
      "[dimension 128/145]  inactive:\t-1.79e-03 +- 3.78e-02\n",
      "[dimension 129/145]  inactive:\t3.52e-05 +- 2.80e-02\n",
      "[dimension 130/145]  inactive:\t3.81e-03 +- 2.94e-02\n",
      "[dimension 131/145]  inactive:\t-1.39e-03 +- 3.52e-02\n",
      "[dimension 132/145]  inactive:\t5.82e-03 +- 5.29e-02\n",
      "[dimension 133/145]  inactive:\t2.43e-03 +- 2.21e-02\n",
      "[dimension 134/145]  inactive:\t-7.21e-04 +- 2.98e-02\n",
      "[dimension 135/145]  inactive:\t4.61e-04 +- 3.68e-02\n",
      "[dimension 136/145]  inactive:\t9.44e-04 +- 2.11e-02\n",
      "[dimension 137/145]  inactive:\t-2.59e-04 +- 4.34e-02\n",
      "[dimension 138/145]  inactive:\t1.16e-03 +- 2.83e-02\n",
      "[dimension 139/145]  inactive:\t6.24e-04 +- 2.45e-02\n",
      "[dimension 140/145]  inactive:\t-1.12e-03 +- 3.42e-02\n",
      "[dimension 141/145]  inactive:\t2.34e-03 +- 3.68e-02\n",
      "[dimension 142/145]  inactive:\t1.36e-03 +- 1.85e-02\n",
      "[dimension 143/145]  inactive:\t1.22e-03 +- 3.93e-02\n",
      "[dimension 144/145]  inactive:\t2.12e-05 +- 1.96e-02\n",
      "[dimension 145/145]  inactive:\t-2.74e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.5151948]\n",
      "cov_act[[0.02645403]]\n",
      "Active_dimensions: [62]\n",
      "35, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.87it/s, 31 steps of size 1.79e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    775.13      1.00\n",
      "  lambda[0]      2.18      4.64      0.97      0.00      4.30    908.43      1.00\n",
      "  lambda[1]      2.76      7.55      1.01      0.00      5.82    605.08      1.00\n",
      "  lambda[2]      3.06     10.37      0.95      0.00      5.50    484.98      1.00\n",
      "  lambda[3]      5.83     43.35      0.95      0.00      6.91    659.65      1.00\n",
      "  lambda[4]      2.72      6.93      1.04      0.00      5.64    786.09      1.00\n",
      "  lambda[5]      3.07      8.33      0.96      0.00      6.16    724.09      1.00\n",
      "  lambda[6]      2.61      6.81      0.96      0.00      5.23    873.93      1.00\n",
      "  lambda[7]      3.19     11.09      0.93      0.00      6.31    358.11      1.01\n",
      "  lambda[8]      2.39      4.63      0.97      0.00      5.03    650.68      1.00\n",
      "  lambda[9]      2.49      6.99      0.98      0.00      4.79    633.72      1.00\n",
      " lambda[10]      2.96      7.54      1.08      0.00      6.40    649.96      1.00\n",
      " lambda[11]      2.63      5.55      1.02      0.00      6.09    626.14      1.00\n",
      " lambda[12]      3.74     11.81      0.98      0.00      7.27    674.07      1.01\n",
      " lambda[13]      2.57      7.47      0.97      0.00      4.71    622.11      1.00\n",
      " lambda[14]      4.24     26.26      0.99      0.00      5.70    481.40      1.00\n",
      " lambda[15]      3.15     10.68      0.95      0.00      5.56    820.68      1.00\n",
      " lambda[16]      3.41     10.83      0.96      0.00      6.77    659.57      1.00\n",
      " lambda[17]      2.51      7.83      0.97      0.00      4.99    599.91      1.00\n",
      " lambda[18]      2.97      6.55      0.96      0.00      6.24    623.05      1.00\n",
      " lambda[19]      3.95     16.80      0.97      0.01      6.33    739.81      1.00\n",
      " lambda[20]      2.95     11.22      0.97      0.00      6.24    702.79      1.00\n",
      " lambda[21]      2.73      5.98      0.99      0.00      6.68    757.07      1.00\n",
      " lambda[22]      2.88      7.55      1.01      0.00      5.64    659.89      1.00\n",
      " lambda[23]      2.78      7.21      0.93      0.00      5.62    778.71      1.00\n",
      " lambda[24]      3.42     10.42      1.03      0.00      6.63    708.08      1.00\n",
      " lambda[25]      3.25     11.07      1.02      0.00      5.77    389.43      1.00\n",
      " lambda[26]      3.19     12.93      0.96      0.00      5.15    501.80      1.00\n",
      " lambda[27]      2.71      6.22      0.98      0.00      5.50    574.28      1.00\n",
      " lambda[28]      3.34     12.60      1.03      0.00      6.02    504.58      1.00\n",
      " lambda[29]      3.02      9.42      0.96      0.00      5.24    595.98      1.00\n",
      " lambda[30]      3.69     14.01      0.99      0.01      6.22    811.79      1.00\n",
      " lambda[31]      3.50     13.93      0.95      0.00      5.91    783.27      1.00\n",
      " lambda[32]     62.35   1321.91      0.97      0.00      6.51    525.01      1.00\n",
      " lambda[33]      3.01     11.03      1.02      0.00      5.98    926.53      1.00\n",
      " lambda[34]      2.64      6.33      0.94      0.00      5.72    659.70      1.00\n",
      " lambda[35]      2.78      8.17      0.97      0.00      4.58    655.22      1.00\n",
      " lambda[36]      4.28     25.66      1.00      0.00      6.01    725.02      1.00\n",
      " lambda[37]      4.85     44.80      1.10      0.00      5.80    818.60      1.00\n",
      " lambda[38]      3.37      9.66      0.91      0.00      6.54    810.21      1.00\n",
      " lambda[39]      3.42     10.49      1.03      0.00      6.21    785.41      1.00\n",
      " lambda[40]      3.60     14.25      0.97      0.00      5.62    976.36      1.00\n",
      " lambda[41]    100.55   1401.08      0.99      0.00     13.26    578.37      1.00\n",
      " lambda[42]      2.49      6.16      0.96      0.00      5.12    781.44      1.00\n",
      " lambda[43]      8.68    158.34      0.99      0.00      5.65   1005.48      1.00\n",
      " lambda[44]      2.96      7.36      0.93      0.00      6.35    574.79      1.00\n",
      " lambda[45]      2.24      4.59      0.98      0.00      4.62    748.41      1.00\n",
      " lambda[46]      2.94     10.52      0.91      0.00      5.05    766.00      1.00\n",
      " lambda[47]      2.95      9.20      0.98      0.00      5.47    697.86      1.00\n",
      " lambda[48]      2.67      7.82      1.00      0.01      5.40    820.35      1.00\n",
      " lambda[49]      3.61     14.02      0.93      0.00      6.39    871.99      1.00\n",
      " lambda[50]      3.35     12.09      1.03      0.00      5.63    578.69      1.00\n",
      " lambda[51]     12.89    296.46      1.06      0.00      6.56    996.85      1.00\n",
      " lambda[52]      3.01      8.80      0.96      0.00      5.99    480.34      1.00\n",
      " lambda[53]      3.17     11.52      0.95      0.01      5.38    636.99      1.01\n",
      " lambda[54]      2.74     11.01      0.92      0.00      4.79    769.71      1.00\n",
      " lambda[55]      3.16     13.38      1.01      0.00      5.49   1021.49      1.00\n",
      " lambda[56]      2.63      6.14      1.00      0.00      5.44    651.87      1.00\n",
      " lambda[57]      6.78     32.51      1.01      0.00      8.65    455.48      1.00\n",
      " lambda[58]      2.71      6.26      0.98      0.00      5.89    597.30      1.00\n",
      " lambda[59]      3.62     15.75      0.99      0.00      5.84    718.95      1.00\n",
      " lambda[60]      4.37     39.02      0.97      0.00      5.34    815.61      1.00\n",
      " lambda[61]      2.56      6.33      0.98      0.01      5.26    797.55      1.00\n",
      " lambda[62]  61757.98 1849715.25    146.56      0.00   1535.36   1001.68      1.00\n",
      " lambda[63]      2.67      6.92      0.99      0.00      5.01    852.38      1.00\n",
      " lambda[64]      3.13      9.07      0.92      0.00      6.03    588.92      1.00\n",
      " lambda[65]      3.05     10.67      0.97      0.00      5.23    637.54      1.00\n",
      " lambda[66]      3.03      9.63      1.03      0.00      6.59    695.76      1.00\n",
      " lambda[67]      3.64     21.98      0.99      0.00      5.95    458.21      1.00\n",
      " lambda[68]      3.78     27.11      0.99      0.00      5.60    818.09      1.00\n",
      " lambda[69]      4.77     33.80      0.93      0.00      6.71    740.06      1.00\n",
      " lambda[70]      2.31      5.14      0.86      0.00      5.36    701.49      1.00\n",
      " lambda[71]      3.92     23.43      1.03      0.00      5.92    608.61      1.00\n",
      " lambda[72]      2.82      7.30      0.97      0.01      5.44    346.22      1.00\n",
      " lambda[73]      3.00      8.02      1.03      0.00      6.22    813.24      1.00\n",
      " lambda[74]      2.54      5.77      1.05      0.01      5.16    806.51      1.00\n",
      " lambda[75]      7.36     38.19      1.07      0.00      8.45    609.61      1.00\n",
      " lambda[76]      3.22     11.18      0.96      0.00      5.87    592.79      1.00\n",
      " lambda[77]     10.75    203.05      1.04      0.00      7.54    947.43      1.00\n",
      " lambda[78]      4.45     37.11      1.07      0.01      6.39    867.64      1.00\n",
      " lambda[79]      3.22     12.76      1.04      0.00      5.60    787.90      1.00\n",
      " lambda[80]      3.12      8.58      1.02      0.00      7.21    666.26      1.00\n",
      " lambda[81]      2.91     12.88      0.94      0.00      5.76    739.63      1.00\n",
      " lambda[82]      2.84      7.16      1.04      0.00      5.16    621.59      1.00\n",
      " lambda[83]      2.91     11.43      0.89      0.00      5.56   1034.71      1.00\n",
      " lambda[84]      3.15      8.95      1.03      0.00      6.16    645.27      1.00\n",
      " lambda[85]      2.43      5.33      0.92      0.00      5.63    702.21      1.00\n",
      " lambda[86]      3.26      9.95      1.00      0.00      6.33    653.02      1.00\n",
      " lambda[87]      3.38      9.96      0.96      0.00      6.35    936.31      1.00\n",
      " lambda[88]      2.79      8.70      0.97      0.00      5.80    718.29      1.00\n",
      " lambda[89]     82.14    603.36      1.29      0.00    118.15    670.03      1.00\n",
      " lambda[90]      3.10     12.42      0.97      0.00      4.99    528.49      1.00\n",
      " lambda[91]      2.80      7.37      1.03      0.01      5.63    779.30      1.00\n",
      " lambda[92]      3.55     11.42      1.04      0.00      6.16    421.04      1.00\n",
      " lambda[93]      2.75      8.10      1.00      0.00      6.26    584.46      1.00\n",
      " lambda[94]      3.29     17.71      0.97      0.00      5.54    922.32      1.00\n",
      " lambda[95]      3.64     16.55      0.99      0.00      5.65    404.36      1.00\n",
      " lambda[96]      2.42      5.51      0.94      0.00      4.91    774.69      1.00\n",
      " lambda[97]      3.59     15.57      1.03      0.00      6.01    650.10      1.00\n",
      " lambda[98]      4.56     33.05      1.02      0.00      5.99    759.83      1.00\n",
      " lambda[99]      2.74      7.43      0.98      0.00      5.25    621.52      1.00\n",
      "lambda[100]      2.84     10.16      0.94      0.00      5.69    745.24      1.00\n",
      "lambda[101]      2.98      6.88      0.90      0.00      6.11    586.38      1.00\n",
      "lambda[102]      3.47     13.04      0.98      0.00      5.46    432.37      1.00\n",
      "lambda[103]      2.47      5.62      0.97      0.00      5.54    700.24      1.00\n",
      "lambda[104]      2.80      6.13      0.99      0.00      6.26    648.29      1.00\n",
      "lambda[105]      3.19      9.28      1.03      0.00      6.35    618.35      1.00\n",
      "lambda[106]      2.62      7.31      0.98      0.00      5.70    640.13      1.00\n",
      "lambda[107]     18.67    306.24      0.98      0.00      7.52    502.08      1.00\n",
      "lambda[108]      2.27      4.52      0.94      0.01      4.83    612.80      1.01\n",
      "lambda[109]      4.33     31.25      0.96      0.00      6.60    889.61      1.00\n",
      "lambda[110]      4.21     21.24      0.94      0.00      6.27    840.97      1.00\n",
      "lambda[111]      3.37     10.83      0.91      0.00      5.93    651.24      1.00\n",
      "lambda[112]      3.15     19.30      0.92      0.00      5.95    799.68      1.00\n",
      "lambda[113]      3.58     14.19      0.97      0.00      6.09    483.69      1.00\n",
      "lambda[114]      3.89     17.18      0.95      0.00      6.29    703.21      1.00\n",
      "lambda[115]      4.63     26.89      0.97      0.00      5.93    593.89      1.00\n",
      "lambda[116]      6.67     84.09      1.03      0.01      5.58    502.35      1.00\n",
      "lambda[117]      3.52     16.05      1.00      0.00      5.65    832.60      1.00\n",
      "lambda[118]      3.38     11.67      1.00      0.00      6.25    932.99      1.00\n",
      "lambda[119]      2.97     13.15      1.01      0.00      5.91    971.36      1.00\n",
      "lambda[120]      3.93     17.68      0.96      0.00      6.46    865.93      1.00\n",
      "lambda[121]      3.35     12.26      0.89      0.00      5.94    693.81      1.00\n",
      "lambda[122]      3.53     12.13      1.00      0.00      7.13    596.03      1.00\n",
      "lambda[123]      3.08      9.28      0.93      0.00      6.53    687.35      1.00\n",
      "lambda[124]      2.78      7.05      1.03      0.00      6.10    661.22      1.00\n",
      "lambda[125]      3.03      9.84      0.98      0.00      5.45    520.99      1.00\n",
      "lambda[126]      2.78      8.77      0.97      0.00      5.14    843.60      1.00\n",
      "lambda[127]      3.21      9.67      0.99      0.00      5.13    408.18      1.00\n",
      "lambda[128]      3.30     14.02      0.94      0.00      5.08    445.36      1.00\n",
      "lambda[129]      3.87     17.55      0.96      0.00      6.43    893.13      1.00\n",
      "lambda[130]      3.13      8.31      0.92      0.00      6.21    824.58      1.00\n",
      "lambda[131]      2.88      8.80      0.94      0.01      5.48    703.49      1.00\n",
      "lambda[132]      3.08     11.35      0.95      0.00      6.08    529.06      1.00\n",
      "lambda[133]      2.98     10.56      1.02      0.00      5.53    595.69      1.00\n",
      "lambda[134]      3.33      8.64      0.91      0.00      7.82    816.29      1.00\n",
      "lambda[135]      2.82     14.40      0.89      0.00      4.46    902.53      1.00\n",
      "lambda[136]      2.81      7.30      0.99      0.00      5.69    737.23      1.01\n",
      "lambda[137]      2.71      7.79      0.97      0.00      4.87    747.36      1.00\n",
      "lambda[138]      3.49     20.68      1.06      0.00      5.38    756.09      1.00\n",
      "lambda[139]      3.38     11.50      1.02      0.00      6.03    841.92      1.01\n",
      "lambda[140]      3.11     10.16      0.97      0.00      5.52    866.37      1.00\n",
      "lambda[141]      2.51      5.57      0.90      0.00      5.38    934.13      1.00\n",
      "lambda[142]      4.40     22.25      0.98      0.01      5.94    730.08      1.00\n",
      "lambda[143]      2.37      4.79      0.96      0.00      5.42    468.16      1.00\n",
      "        msq      1.34      0.76      1.15      0.49      2.27    947.75      1.00\n",
      "      sigma      5.58      7.71      2.47      0.01     15.73   1124.11      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    958.30      1.00\n",
      "       xisq      0.12      0.06      0.10      0.04      0.20   1133.10      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 33.87581396102905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.70e-04 +- 1.73e-02\n",
      "[dimension 02/145]  inactive:\t-4.56e-04 +- 2.44e-02\n",
      "[dimension 03/145]  inactive:\t2.81e-04 +- 2.54e-02\n",
      "[dimension 04/145]  inactive:\t6.08e-03 +- 4.30e-02\n",
      "[dimension 05/145]  inactive:\t-3.96e-04 +- 2.68e-02\n",
      "[dimension 06/145]  inactive:\t2.83e-03 +- 3.99e-02\n",
      "[dimension 07/145]  inactive:\t5.63e-04 +- 1.88e-02\n",
      "[dimension 08/145]  inactive:\t9.58e-04 +- 2.85e-02\n",
      "[dimension 09/145]  inactive:\t4.33e-04 +- 2.01e-02\n",
      "[dimension 10/145]  inactive:\t4.72e-04 +- 1.68e-02\n",
      "[dimension 11/145]  inactive:\t-5.95e-04 +- 2.62e-02\n",
      "[dimension 12/145]  inactive:\t3.58e-04 +- 2.73e-02\n",
      "[dimension 13/145]  inactive:\t6.45e-03 +- 4.95e-02\n",
      "[dimension 14/145]  inactive:\t-9.46e-04 +- 2.54e-02\n",
      "[dimension 15/145]  inactive:\t1.63e-03 +- 3.73e-02\n",
      "[dimension 16/145]  inactive:\t1.16e-03 +- 2.20e-02\n",
      "[dimension 17/145]  inactive:\t6.39e-04 +- 3.36e-02\n",
      "[dimension 18/145]  inactive:\t5.75e-04 +- 2.64e-02\n",
      "[dimension 19/145]  inactive:\t-2.07e-03 +- 2.12e-02\n",
      "[dimension 20/145]  inactive:\t-1.26e-03 +- 2.84e-02\n",
      "[dimension 21/145]  inactive:\t-1.78e-03 +- 2.55e-02\n",
      "[dimension 22/145]  inactive:\t-8.24e-05 +- 2.19e-02\n",
      "[dimension 23/145]  inactive:\t-5.82e-05 +- 2.96e-02\n",
      "[dimension 24/145]  inactive:\t1.75e-03 +- 2.83e-02\n",
      "[dimension 25/145]  inactive:\t3.26e-03 +- 2.32e-02\n",
      "[dimension 26/145]  inactive:\t-5.98e-04 +- 2.71e-02\n",
      "[dimension 27/145]  inactive:\t1.53e-03 +- 2.86e-02\n",
      "[dimension 28/145]  inactive:\t1.07e-03 +- 2.07e-02\n",
      "[dimension 29/145]  inactive:\t-1.05e-04 +- 2.77e-02\n",
      "[dimension 30/145]  inactive:\t1.62e-03 +- 2.89e-02\n",
      "[dimension 31/145]  inactive:\t5.21e-03 +- 3.87e-02\n",
      "[dimension 32/145]  inactive:\t-9.17e-04 +- 2.91e-02\n",
      "[dimension 33/145]  inactive:\t6.72e-03 +- 6.04e-02\n",
      "[dimension 34/145]  inactive:\t1.07e-03 +- 2.04e-02\n",
      "[dimension 35/145]  inactive:\t6.28e-04 +- 2.58e-02\n",
      "[dimension 36/145]  inactive:\t1.83e-03 +- 3.00e-02\n",
      "[dimension 37/145]  inactive:\t4.65e-03 +- 2.90e-02\n",
      "[dimension 38/145]  inactive:\t-1.40e-03 +- 3.21e-02\n",
      "[dimension 39/145]  inactive:\t2.13e-03 +- 3.34e-02\n",
      "[dimension 40/145]  inactive:\t6.32e-03 +- 4.67e-02\n",
      "[dimension 41/145]  inactive:\t-1.53e-03 +- 3.44e-02\n",
      "[dimension 42/145]  inactive:\t3.50e-02 +- 1.58e-01\n",
      "[dimension 43/145]  inactive:\t-1.62e-04 +- 1.89e-02\n",
      "[dimension 44/145]  inactive:\t-6.53e-04 +- 3.42e-02\n",
      "[dimension 45/145]  inactive:\t-5.45e-05 +- 2.66e-02\n",
      "[dimension 46/145]  inactive:\t8.49e-04 +- 1.59e-02\n",
      "[dimension 47/145]  inactive:\t-1.96e-03 +- 3.00e-02\n",
      "[dimension 48/145]  inactive:\t1.85e-03 +- 2.70e-02\n",
      "[dimension 49/145]  inactive:\t2.65e-03 +- 2.48e-02\n",
      "[dimension 50/145]  inactive:\t-1.82e-03 +- 2.96e-02\n",
      "[dimension 51/145]  inactive:\t4.69e-03 +- 3.85e-02\n",
      "[dimension 52/145]  inactive:\t5.32e-03 +- 2.47e-02\n",
      "[dimension 53/145]  inactive:\t-1.30e-03 +- 2.98e-02\n",
      "[dimension 54/145]  inactive:\t6.39e-04 +- 2.18e-02\n",
      "[dimension 55/145]  inactive:\t9.18e-04 +- 1.82e-02\n",
      "[dimension 56/145]  inactive:\t-2.08e-03 +- 2.14e-02\n",
      "[dimension 57/145]  inactive:\t1.53e-03 +- 2.87e-02\n",
      "[dimension 58/145]  inactive:\t1.80e-02 +- 8.49e-02\n",
      "[dimension 59/145]  inactive:\t-6.40e-04 +- 1.99e-02\n",
      "[dimension 60/145]  inactive:\t3.20e-03 +- 4.18e-02\n",
      "[dimension 61/145]  inactive:\t3.92e-03 +- 3.31e-02\n",
      "[dimension 62/145]  inactive:\t-3.63e-04 +- 2.25e-02\n",
      "[dimension 63/145]  active:\t6.21e-01 +- 4.46e-01\n",
      "[dimension 64/145]  inactive:\t-2.92e-03 +- 2.78e-02\n",
      "[dimension 65/145]  inactive:\t-3.23e-04 +- 3.45e-02\n",
      "[dimension 66/145]  inactive:\t4.85e-04 +- 2.26e-02\n",
      "[dimension 67/145]  inactive:\t1.27e-03 +- 2.57e-02\n",
      "[dimension 68/145]  inactive:\t-6.10e-04 +- 2.49e-02\n",
      "[dimension 69/145]  inactive:\t3.39e-03 +- 3.83e-02\n",
      "[dimension 70/145]  inactive:\t4.09e-03 +- 2.56e-02\n",
      "[dimension 71/145]  inactive:\t3.05e-04 +- 2.26e-02\n",
      "[dimension 72/145]  inactive:\t8.13e-04 +- 2.72e-02\n",
      "[dimension 73/145]  inactive:\t4.40e-04 +- 1.81e-02\n",
      "[dimension 74/145]  inactive:\t-9.05e-04 +- 3.06e-02\n",
      "[dimension 75/145]  inactive:\t6.40e-04 +- 2.21e-02\n",
      "[dimension 76/145]  inactive:\t1.01e-02 +- 5.92e-02\n",
      "[dimension 77/145]  inactive:\t-1.14e-03 +- 3.29e-02\n",
      "[dimension 78/145]  inactive:\t1.17e-02 +- 8.29e-02\n",
      "[dimension 79/145]  inactive:\t6.41e-03 +- 3.59e-02\n",
      "[dimension 80/145]  inactive:\t2.02e-05 +- 3.19e-02\n",
      "[dimension 81/145]  inactive:\t1.89e-03 +- 3.20e-02\n",
      "[dimension 82/145]  inactive:\t3.31e-04 +- 1.77e-02\n",
      "[dimension 83/145]  inactive:\t-2.00e-03 +- 2.08e-02\n",
      "[dimension 84/145]  inactive:\t-1.16e-03 +- 2.63e-02\n",
      "[dimension 85/145]  inactive:\t3.08e-03 +- 3.18e-02\n",
      "[dimension 86/145]  inactive:\t-2.82e-04 +- 2.21e-02\n",
      "[dimension 87/145]  inactive:\t4.67e-03 +- 4.74e-02\n",
      "[dimension 88/145]  inactive:\t3.65e-03 +- 2.89e-02\n",
      "[dimension 89/145]  inactive:\t-8.47e-04 +- 2.51e-02\n",
      "[dimension 90/145]  inactive:\t1.16e-01 +- 2.94e-01\n",
      "[dimension 91/145]  inactive:\t6.63e-05 +- 1.90e-02\n",
      "[dimension 92/145]  inactive:\t-1.48e-03 +- 2.69e-02\n",
      "[dimension 93/145]  inactive:\t-1.27e-03 +- 3.52e-02\n",
      "[dimension 94/145]  inactive:\t1.91e-03 +- 2.82e-02\n",
      "[dimension 95/145]  inactive:\t-2.29e-04 +- 2.21e-02\n",
      "[dimension 96/145]  inactive:\t1.89e-03 +- 4.73e-02\n",
      "[dimension 97/145]  inactive:\t1.87e-03 +- 2.07e-02\n",
      "[dimension 98/145]  inactive:\t-8.63e-04 +- 2.48e-02\n",
      "[dimension 99/145]  inactive:\t6.32e-03 +- 5.77e-02\n",
      "[dimension 100/145]  inactive:\t-5.89e-04 +- 1.78e-02\n",
      "[dimension 101/145]  inactive:\t-1.64e-03 +- 2.02e-02\n",
      "[dimension 102/145]  inactive:\t-1.39e-05 +- 3.13e-02\n",
      "[dimension 103/145]  inactive:\t9.17e-04 +- 2.53e-02\n",
      "[dimension 104/145]  inactive:\t-9.18e-04 +- 1.83e-02\n",
      "[dimension 105/145]  inactive:\t-1.70e-04 +- 2.50e-02\n",
      "[dimension 106/145]  inactive:\t5.61e-03 +- 3.85e-02\n",
      "[dimension 107/145]  inactive:\t-9.00e-04 +- 2.12e-02\n",
      "[dimension 108/145]  inactive:\t1.42e-02 +- 9.64e-02\n",
      "[dimension 109/145]  inactive:\t-4.04e-04 +- 1.75e-02\n",
      "[dimension 110/145]  inactive:\t-4.86e-04 +- 3.30e-02\n",
      "[dimension 111/145]  inactive:\t1.69e-03 +- 3.18e-02\n",
      "[dimension 112/145]  inactive:\t4.38e-03 +- 3.90e-02\n",
      "[dimension 113/145]  inactive:\t-1.70e-03 +- 2.56e-02\n",
      "[dimension 114/145]  inactive:\t2.43e-03 +- 4.17e-02\n",
      "[dimension 115/145]  inactive:\t2.46e-03 +- 2.39e-02\n",
      "[dimension 116/145]  inactive:\t2.49e-03 +- 6.12e-02\n",
      "[dimension 117/145]  inactive:\t5.29e-03 +- 5.34e-02\n",
      "[dimension 118/145]  inactive:\t3.50e-03 +- 2.73e-02\n",
      "[dimension 119/145]  inactive:\t-1.98e-03 +- 2.96e-02\n",
      "[dimension 120/145]  inactive:\t3.14e-04 +- 2.90e-02\n",
      "[dimension 121/145]  inactive:\t4.01e-03 +- 3.47e-02\n",
      "[dimension 122/145]  inactive:\t-3.05e-03 +- 4.15e-02\n",
      "[dimension 123/145]  inactive:\t3.02e-03 +- 4.38e-02\n",
      "[dimension 124/145]  inactive:\t-1.43e-03 +- 2.11e-02\n",
      "[dimension 125/145]  inactive:\t-1.16e-03 +- 2.46e-02\n",
      "[dimension 126/145]  inactive:\t-5.86e-04 +- 2.39e-02\n",
      "[dimension 127/145]  inactive:\t2.11e-04 +- 1.88e-02\n",
      "[dimension 128/145]  inactive:\t-8.42e-04 +- 3.10e-02\n",
      "[dimension 129/145]  inactive:\t5.57e-04 +- 2.93e-02\n",
      "[dimension 130/145]  inactive:\t3.83e-03 +- 3.03e-02\n",
      "[dimension 131/145]  inactive:\t-9.79e-04 +- 2.65e-02\n",
      "[dimension 132/145]  inactive:\t3.90e-03 +- 4.03e-02\n",
      "[dimension 133/145]  inactive:\t2.86e-03 +- 2.35e-02\n",
      "[dimension 134/145]  inactive:\t3.39e-05 +- 3.06e-02\n",
      "[dimension 135/145]  inactive:\t8.22e-04 +- 3.01e-02\n",
      "[dimension 136/145]  inactive:\t8.96e-04 +- 1.95e-02\n",
      "[dimension 137/145]  inactive:\t9.00e-05 +- 3.17e-02\n",
      "[dimension 138/145]  inactive:\t8.91e-04 +- 2.62e-02\n",
      "[dimension 139/145]  inactive:\t8.37e-04 +- 2.52e-02\n",
      "[dimension 140/145]  inactive:\t-1.19e-03 +- 3.06e-02\n",
      "[dimension 141/145]  inactive:\t1.33e-03 +- 2.97e-02\n",
      "[dimension 142/145]  inactive:\t1.55e-03 +- 1.91e-02\n",
      "[dimension 143/145]  inactive:\t2.59e-03 +- 4.15e-02\n",
      "[dimension 144/145]  inactive:\t3.27e-04 +- 1.92e-02\n",
      "[dimension 145/145]  inactive:\t-5.87e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.82791644]\n",
      "cov_act[[0.03356841]]\n",
      "Active_dimensions: [62]\n",
      "36, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 51.01it/s, 31 steps of size 1.65e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    620.56      1.00\n",
      "  lambda[0]      2.22      4.92      0.93      0.00      4.84    749.37      1.00\n",
      "  lambda[1]      2.85      8.76      1.06      0.00      5.80    717.47      1.01\n",
      "  lambda[2]      3.19     11.55      0.98      0.00      5.73    655.65      1.00\n",
      "  lambda[3]      4.14     19.53      0.98      0.00      6.74    559.66      1.00\n",
      "  lambda[4]      2.85      9.36      1.04      0.00      5.69    729.69      1.00\n",
      "  lambda[5]      2.82      7.26      1.03      0.00      5.51    717.89      1.00\n",
      "  lambda[6]      2.91     10.46      1.01      0.00      5.42    899.15      1.00\n",
      "  lambda[7]      3.36     11.88      0.94      0.00      6.40    461.77      1.00\n",
      "  lambda[8]      2.29      4.59      1.04      0.00      4.91    844.71      1.00\n",
      "  lambda[9]      2.59      6.48      0.99      0.00      5.36    828.26      1.00\n",
      " lambda[10]      3.99     22.28      1.03      0.00      5.69    507.82      1.00\n",
      " lambda[11]      2.91      8.18      1.00      0.00      5.48    793.00      1.00\n",
      " lambda[12]      3.75      9.80      1.01      0.00      7.49    573.82      1.00\n",
      " lambda[13]      3.68     15.17      1.01      0.00      5.48    287.58      1.01\n",
      " lambda[14]      4.18     20.43      0.94      0.00      6.41    657.15      1.00\n",
      " lambda[15]      2.91      9.80      1.00      0.00      5.26    686.93      1.00\n",
      " lambda[16]      3.63     10.16      0.94      0.00      8.02    646.01      1.00\n",
      " lambda[17]      3.14     14.72      1.00      0.00      5.84    774.03      1.00\n",
      " lambda[18]      2.71      5.97      0.92      0.00      6.23    655.32      1.00\n",
      " lambda[19]      3.82     21.27      0.99      0.01      6.22    853.25      1.00\n",
      " lambda[20]      2.87      6.99      0.98      0.01      6.11    730.71      1.00\n",
      " lambda[21]      2.74      7.45      0.95      0.00      5.97    676.72      1.00\n",
      " lambda[22]      2.60      7.11      0.99      0.00      4.90    816.25      1.00\n",
      " lambda[23]      3.30      8.80      1.00      0.00      6.38    679.86      1.00\n",
      " lambda[24]      3.23     13.77      1.04      0.00      5.75    890.12      1.00\n",
      " lambda[25]      3.33      9.44      0.97      0.00      6.70    769.57      1.00\n",
      " lambda[26]      2.19      3.92      1.05      0.01      4.73    930.62      1.00\n",
      " lambda[27]      3.13      8.23      0.99      0.00      6.07    514.79      1.01\n",
      " lambda[28]      2.82      9.52      0.99      0.00      5.13    676.12      1.00\n",
      " lambda[29]      2.92      8.72      0.95      0.00      6.20    748.88      1.00\n",
      " lambda[30]      3.45     10.32      1.05      0.01      6.89    785.78      1.00\n",
      " lambda[31]      3.94     18.63      0.98      0.00      6.59    686.88      1.00\n",
      " lambda[32]      3.71     18.29      0.95      0.00      6.90    635.18      1.00\n",
      " lambda[33]      2.67      9.54      0.97      0.01      5.21    851.37      1.00\n",
      " lambda[34]      2.98      9.84      0.94      0.00      5.50    566.94      1.00\n",
      " lambda[35]      2.57      6.83      1.05      0.00      5.16    800.49      1.00\n",
      " lambda[36]      3.75     16.67      0.99      0.00      6.30    868.16      1.00\n",
      " lambda[37]      3.20      8.82      0.99      0.00      5.98    700.67      1.00\n",
      " lambda[38]      2.79      6.62      0.92      0.00      5.71    831.78      1.00\n",
      " lambda[39]      2.97      7.15      0.97      0.00      6.81    652.14      1.00\n",
      " lambda[40]      3.34     11.58      0.90      0.00      5.66    648.18      1.00\n",
      " lambda[41]      9.65     73.68      0.97      0.00      9.35    375.26      1.01\n",
      " lambda[42]      3.38     23.67      0.98      0.00      5.03    966.70      1.00\n",
      " lambda[43]      4.37     37.32      0.98      0.00      6.29    897.02      1.00\n",
      " lambda[44]      2.84      7.03      0.97      0.00      5.50    639.56      1.00\n",
      " lambda[45]      2.52      5.76      0.99      0.00      5.61    702.59      1.00\n",
      " lambda[46]      2.73      7.15      1.07      0.01      5.41    723.64      1.00\n",
      " lambda[47]      2.62      5.78      0.95      0.00      5.57    580.96      1.00\n",
      " lambda[48]      3.07     12.07      1.02      0.00      5.05    893.95      1.00\n",
      " lambda[49]      2.99      8.21      1.01      0.00      5.68    798.80      1.00\n",
      " lambda[50]      2.70      7.11      0.98      0.00      5.82    535.15      1.00\n",
      " lambda[51]      3.63     14.25      1.03      0.00      6.79    657.41      1.00\n",
      " lambda[52]      2.89      8.84      0.91      0.00      5.19    595.54      1.00\n",
      " lambda[53]      3.04     10.82      0.96      0.00      5.31    723.44      1.00\n",
      " lambda[54]      2.31      5.05      0.97      0.01      4.76    597.69      1.00\n",
      " lambda[55]      3.13     12.49      1.00      0.00      5.59    606.38      1.00\n",
      " lambda[56]      2.77      6.59      1.03      0.00      5.78    803.30      1.00\n",
      " lambda[57]      4.47     17.65      0.98      0.00      7.46    552.39      1.01\n",
      " lambda[58]      2.36      5.17      0.94      0.00      5.54    612.19      1.00\n",
      " lambda[59]      3.06      7.69      1.02      0.00      6.83    438.16      1.00\n",
      " lambda[60]      3.49     15.96      0.97      0.00      5.50    709.77      1.00\n",
      " lambda[61]      2.79      6.40      1.03      0.01      6.13    643.48      1.00\n",
      " lambda[62]    974.39   9872.09    211.82      0.01   1161.59    892.15      1.00\n",
      " lambda[63]      2.71      7.39      1.03      0.00      5.22    836.27      1.00\n",
      " lambda[64]      3.40     15.14      0.96      0.00      5.49    430.49      1.00\n",
      " lambda[65]      2.53      5.54      0.99      0.00      5.38    971.37      1.00\n",
      " lambda[66]      2.98      8.36      1.02      0.00      6.33    694.88      1.00\n",
      " lambda[67]      2.41      5.27      0.92      0.00      5.24    737.71      1.00\n",
      " lambda[68]      3.88     34.78      0.95      0.00      6.63    914.65      1.00\n",
      " lambda[69]      3.55     15.34      0.94      0.00      5.24    768.31      1.00\n",
      " lambda[70]      3.18      9.11      0.97      0.00      5.89    630.90      1.00\n",
      " lambda[71]      5.62     79.58      0.96      0.00      5.02    929.76      1.00\n",
      " lambda[72]      2.32      4.94      0.97      0.01      5.27    910.45      1.00\n",
      " lambda[73]      3.47     16.09      1.03      0.00      5.88    817.68      1.00\n",
      " lambda[74]      2.22      4.10      1.00      0.01      4.85    950.67      1.00\n",
      " lambda[75]      4.20     14.69      1.01      0.00      7.96    623.29      1.00\n",
      " lambda[76]      2.84      7.53      0.95      0.00      5.59    807.71      1.00\n",
      " lambda[77]      3.07      8.16      1.05      0.00      6.22    795.51      1.00\n",
      " lambda[78]      3.34     11.50      1.05      0.00      6.69    644.22      1.00\n",
      " lambda[79]      3.48     15.15      1.06      0.00      5.52    717.47      1.00\n",
      " lambda[80]      4.29     31.99      1.05      0.00      6.40    953.22      1.00\n",
      " lambda[81]      2.79      6.85      0.87      0.00      5.59    329.52      1.00\n",
      " lambda[82]      2.19      4.75      0.94      0.00      4.62    744.93      1.00\n",
      " lambda[83]      2.99     10.06      0.93      0.00      5.24    733.59      1.00\n",
      " lambda[84]      3.14      8.53      1.00      0.00      7.58    781.58      1.00\n",
      " lambda[85]      2.60      8.20      0.93      0.00      5.48    682.21      1.00\n",
      " lambda[86]      3.06      8.70      0.99      0.01      5.14    706.07      1.00\n",
      " lambda[87]      2.97      6.24      1.01      0.00      6.89    583.66      1.00\n",
      " lambda[88]      2.77      7.04      0.94      0.00      5.75    738.99      1.00\n",
      " lambda[89]     34.89    289.23      1.15      0.00     28.38    474.68      1.00\n",
      " lambda[90]      2.99      8.01      1.02      0.00      5.86    666.80      1.00\n",
      " lambda[91]      2.41      5.64      0.96      0.00      5.07    703.62      1.00\n",
      " lambda[92]      3.76     23.38      0.96      0.00      5.31    513.04      1.00\n",
      " lambda[93]      2.61      6.79      1.00      0.00      5.08    589.30      1.00\n",
      " lambda[94]      2.40      5.87      0.99      0.00      5.00   1035.46      1.00\n",
      " lambda[95]      2.79      6.35      1.02      0.00      6.28    850.80      1.00\n",
      " lambda[96]      3.81     22.33      0.96      0.00      5.39    575.98      1.00\n",
      " lambda[97]      3.16     10.18      0.97      0.00      5.61    598.13      1.00\n",
      " lambda[98]      4.07     33.63      1.05      0.00      5.75    845.51      1.00\n",
      " lambda[99]      2.43      6.81      0.98      0.00      4.37    847.06      1.00\n",
      "lambda[100]      3.55     18.25      0.91      0.00      5.97    749.05      1.00\n",
      "lambda[101]      3.07      8.44      0.94      0.00      6.51    676.94      1.00\n",
      "lambda[102]      3.15     10.62      0.93      0.00      5.12    573.37      1.00\n",
      "lambda[103]      2.14      3.70      0.98      0.00      5.02    738.64      1.00\n",
      "lambda[104]      3.30     13.85      0.95      0.00      5.77    498.12      1.00\n",
      "lambda[105]      3.80     15.75      0.95      0.00      6.55    633.10      1.00\n",
      "lambda[106]      3.25     11.47      0.97      0.00      6.60    725.76      1.00\n",
      "lambda[107]      3.03      9.13      1.02      0.00      5.04    547.35      1.00\n",
      "lambda[108]      2.36      4.50      0.99      0.00      5.32    540.79      1.00\n",
      "lambda[109]      5.70     79.90      0.92      0.00      6.76    998.00      1.00\n",
      "lambda[110]      3.28      9.26      0.98      0.00      6.93    636.91      1.00\n",
      "lambda[111]      6.95     73.93      0.91      0.00      6.31    624.39      1.00\n",
      "lambda[112]      2.87      7.81      0.90      0.01      6.13    732.56      1.00\n",
      "lambda[113]      3.63     12.14      0.99      0.00      5.96    757.85      1.00\n",
      "lambda[114]      3.23      9.28      0.99      0.00      5.82    784.24      1.00\n",
      "lambda[115]      4.42     22.16      0.99      0.00      5.73    567.63      1.00\n",
      "lambda[116]      4.28     27.40      1.01      0.00      5.07    537.04      1.00\n",
      "lambda[117]      3.05      8.64      0.99      0.00      6.32    892.54      1.00\n",
      "lambda[118]      3.47     10.03      0.99      0.00      5.89    434.82      1.00\n",
      "lambda[119]      3.22     13.28      1.02      0.00      6.09    543.72      1.00\n",
      "lambda[120]      4.61     24.41      0.99      0.00      6.76    812.64      1.00\n",
      "lambda[121]      3.12     13.27      0.90      0.00      5.40    888.72      1.00\n",
      "lambda[122]      3.02      7.75      0.97      0.00      6.57    717.82      1.00\n",
      "lambda[123]      2.73      7.44      0.93      0.00      5.30    726.78      1.00\n",
      "lambda[124]      2.60      5.65      0.96      0.00      6.02    727.17      1.00\n",
      "lambda[125]      2.84      7.26      0.94      0.00      5.94    672.30      1.00\n",
      "lambda[126]      2.54      6.89      0.95      0.00      5.05    749.96      1.00\n",
      "lambda[127]      4.41     16.75      1.00      0.00      7.17    488.66      1.00\n",
      "lambda[128]      2.95      8.61      0.99      0.00      5.65    589.65      1.00\n",
      "lambda[129]      4.00     14.57      1.00      0.00      6.01    759.05      1.00\n",
      "lambda[130]      3.19      9.21      1.00      0.00      6.65    781.54      1.00\n",
      "lambda[131]      3.18     10.50      0.94      0.00      6.28    657.61      1.00\n",
      "lambda[132]      3.24      8.07      0.98      0.00      7.33    524.63      1.00\n",
      "lambda[133]      2.76      7.12      0.99      0.00      5.73    747.22      1.00\n",
      "lambda[134]      3.29      7.68      0.90      0.00      7.40    685.80      1.00\n",
      "lambda[135]      2.82     10.36      0.88      0.00      5.18    768.58      1.00\n",
      "lambda[136]      2.74      6.54      0.96      0.00      5.76    959.97      1.00\n",
      "lambda[137]      2.78      7.85      0.97      0.00      5.69    761.19      1.00\n",
      "lambda[138]      2.99     10.08      1.04      0.00      5.35    704.35      1.00\n",
      "lambda[139]      3.14      8.71      1.04      0.00      6.20    754.72      1.00\n",
      "lambda[140]      3.36     14.87      1.00      0.00      5.99    786.14      1.00\n",
      "lambda[141]      2.60      7.77      0.96      0.00      4.84    549.24      1.00\n",
      "lambda[142]      4.18     19.37      0.93      0.01      7.18    700.94      1.00\n",
      "lambda[143]      2.30      4.95      1.00      0.00      4.96    489.38      1.01\n",
      "        msq   1114.72   9175.69     31.16      1.14    837.18    703.50      1.00\n",
      "      sigma      3.43      4.51      1.61      0.01      9.56   1230.60      1.00\n",
      "    var_obs      0.09      0.01      0.08      0.06      0.11    957.23      1.00\n",
      "       xisq     43.52    537.62      1.74      0.10     20.19    833.33      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 33.354538917541504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.18e-04 +- 1.63e-02\n",
      "[dimension 02/145]  inactive:\t-2.48e-04 +- 2.64e-02\n",
      "[dimension 03/145]  inactive:\t1.33e-04 +- 2.69e-02\n",
      "[dimension 04/145]  inactive:\t5.76e-03 +- 3.89e-02\n",
      "[dimension 05/145]  inactive:\t-1.43e-03 +- 2.92e-02\n",
      "[dimension 06/145]  inactive:\t1.38e-03 +- 3.00e-02\n",
      "[dimension 07/145]  inactive:\t5.82e-04 +- 1.91e-02\n",
      "[dimension 08/145]  inactive:\t1.38e-04 +- 2.78e-02\n",
      "[dimension 09/145]  inactive:\t8.17e-06 +- 2.12e-02\n",
      "[dimension 10/145]  inactive:\t3.97e-04 +- 1.82e-02\n",
      "[dimension 11/145]  inactive:\t-1.54e-03 +- 2.64e-02\n",
      "[dimension 12/145]  inactive:\t-3.71e-04 +- 2.86e-02\n",
      "[dimension 13/145]  inactive:\t4.88e-03 +- 4.12e-02\n",
      "[dimension 14/145]  inactive:\t-2.00e-03 +- 2.75e-02\n",
      "[dimension 15/145]  inactive:\t4.04e-05 +- 3.11e-02\n",
      "[dimension 16/145]  inactive:\t9.58e-04 +- 1.98e-02\n",
      "[dimension 17/145]  inactive:\t-3.77e-04 +- 3.37e-02\n",
      "[dimension 18/145]  inactive:\t-5.03e-04 +- 2.83e-02\n",
      "[dimension 19/145]  inactive:\t-3.59e-03 +- 2.64e-02\n",
      "[dimension 20/145]  inactive:\t-1.73e-03 +- 2.96e-02\n",
      "[dimension 21/145]  inactive:\t-1.86e-03 +- 2.55e-02\n",
      "[dimension 22/145]  inactive:\t3.06e-05 +- 2.18e-02\n",
      "[dimension 23/145]  inactive:\t-1.06e-03 +- 2.78e-02\n",
      "[dimension 24/145]  inactive:\t2.15e-03 +- 2.96e-02\n",
      "[dimension 25/145]  inactive:\t3.02e-03 +- 2.17e-02\n",
      "[dimension 26/145]  inactive:\t-1.59e-03 +- 2.74e-02\n",
      "[dimension 27/145]  inactive:\t3.17e-04 +- 2.22e-02\n",
      "[dimension 28/145]  inactive:\t9.38e-04 +- 2.15e-02\n",
      "[dimension 29/145]  inactive:\t-4.18e-04 +- 2.78e-02\n",
      "[dimension 30/145]  inactive:\t7.07e-04 +- 2.72e-02\n",
      "[dimension 31/145]  inactive:\t5.40e-03 +- 3.86e-02\n",
      "[dimension 32/145]  inactive:\t-2.48e-03 +- 3.09e-02\n",
      "[dimension 33/145]  inactive:\t3.16e-03 +- 4.18e-02\n",
      "[dimension 34/145]  inactive:\t6.55e-04 +- 1.71e-02\n",
      "[dimension 35/145]  inactive:\t-1.36e-04 +- 2.39e-02\n",
      "[dimension 36/145]  inactive:\t2.87e-04 +- 2.27e-02\n",
      "[dimension 37/145]  inactive:\t5.11e-03 +- 3.07e-02\n",
      "[dimension 38/145]  inactive:\t-2.28e-03 +- 3.23e-02\n",
      "[dimension 39/145]  inactive:\t6.58e-04 +- 2.64e-02\n",
      "[dimension 40/145]  inactive:\t4.78e-03 +- 3.44e-02\n",
      "[dimension 41/145]  inactive:\t-1.62e-03 +- 2.93e-02\n",
      "[dimension 42/145]  inactive:\t1.40e-02 +- 9.24e-02\n",
      "[dimension 43/145]  inactive:\t-6.40e-04 +- 1.93e-02\n",
      "[dimension 44/145]  inactive:\t-1.11e-03 +- 3.01e-02\n",
      "[dimension 45/145]  inactive:\t-1.09e-03 +- 2.65e-02\n",
      "[dimension 46/145]  inactive:\t1.44e-03 +- 1.73e-02\n",
      "[dimension 47/145]  inactive:\t-2.04e-03 +- 2.73e-02\n",
      "[dimension 48/145]  inactive:\t1.62e-03 +- 2.74e-02\n",
      "[dimension 49/145]  inactive:\t3.49e-03 +- 2.61e-02\n",
      "[dimension 50/145]  inactive:\t-2.26e-03 +- 2.93e-02\n",
      "[dimension 51/145]  inactive:\t2.76e-03 +- 2.91e-02\n",
      "[dimension 52/145]  inactive:\t5.60e-03 +- 2.38e-02\n",
      "[dimension 53/145]  inactive:\t-9.95e-04 +- 2.47e-02\n",
      "[dimension 54/145]  inactive:\t1.75e-04 +- 1.97e-02\n",
      "[dimension 55/145]  inactive:\t6.32e-04 +- 1.66e-02\n",
      "[dimension 56/145]  inactive:\t-2.51e-03 +- 2.39e-02\n",
      "[dimension 57/145]  inactive:\t5.41e-05 +- 2.65e-02\n",
      "[dimension 58/145]  inactive:\t1.10e-02 +- 6.31e-02\n",
      "[dimension 59/145]  inactive:\t-6.22e-04 +- 1.77e-02\n",
      "[dimension 60/145]  inactive:\t5.53e-04 +- 3.14e-02\n",
      "[dimension 61/145]  inactive:\t2.45e-03 +- 2.46e-02\n",
      "[dimension 62/145]  inactive:\t-1.11e-03 +- 2.46e-02\n",
      "[dimension 63/145]  active:\t7.89e-01 +- 3.77e-01\n",
      "[dimension 64/145]  inactive:\t-2.98e-03 +- 2.54e-02\n",
      "[dimension 65/145]  inactive:\t-8.73e-04 +- 2.39e-02\n",
      "[dimension 66/145]  inactive:\t6.50e-04 +- 2.19e-02\n",
      "[dimension 67/145]  inactive:\t1.60e-03 +- 2.39e-02\n",
      "[dimension 68/145]  inactive:\t-6.81e-04 +- 2.12e-02\n",
      "[dimension 69/145]  inactive:\t2.16e-03 +- 2.84e-02\n",
      "[dimension 70/145]  inactive:\t3.24e-03 +- 2.23e-02\n",
      "[dimension 71/145]  inactive:\t-2.66e-04 +- 3.05e-02\n",
      "[dimension 72/145]  inactive:\t2.77e-04 +- 2.29e-02\n",
      "[dimension 73/145]  inactive:\t-1.34e-05 +- 1.77e-02\n",
      "[dimension 74/145]  inactive:\t-2.39e-03 +- 3.79e-02\n",
      "[dimension 75/145]  inactive:\t-2.11e-04 +- 2.08e-02\n",
      "[dimension 76/145]  inactive:\t5.71e-03 +- 3.73e-02\n",
      "[dimension 77/145]  inactive:\t-1.75e-03 +- 2.68e-02\n",
      "[dimension 78/145]  inactive:\t3.14e-03 +- 4.26e-02\n",
      "[dimension 79/145]  inactive:\t5.99e-03 +- 3.32e-02\n",
      "[dimension 80/145]  inactive:\t-4.60e-04 +- 3.73e-02\n",
      "[dimension 81/145]  inactive:\t4.08e-04 +- 2.98e-02\n",
      "[dimension 82/145]  inactive:\t2.47e-04 +- 1.70e-02\n",
      "[dimension 83/145]  inactive:\t-1.45e-03 +- 1.73e-02\n",
      "[dimension 84/145]  inactive:\t-1.73e-03 +- 2.83e-02\n",
      "[dimension 85/145]  inactive:\t3.48e-03 +- 3.51e-02\n",
      "[dimension 86/145]  inactive:\t-3.01e-04 +- 1.99e-02\n",
      "[dimension 87/145]  inactive:\t1.33e-03 +- 3.01e-02\n",
      "[dimension 88/145]  inactive:\t3.01e-03 +- 2.42e-02\n",
      "[dimension 89/145]  inactive:\t-1.50e-03 +- 2.41e-02\n",
      "[dimension 90/145]  inactive:\t7.81e-02 +- 2.52e-01\n",
      "[dimension 91/145]  inactive:\t1.08e-04 +- 1.90e-02\n",
      "[dimension 92/145]  inactive:\t-1.41e-03 +- 2.28e-02\n",
      "[dimension 93/145]  inactive:\t-2.05e-04 +- 2.93e-02\n",
      "[dimension 94/145]  inactive:\t1.84e-03 +- 2.73e-02\n",
      "[dimension 95/145]  inactive:\t-4.55e-04 +- 2.15e-02\n",
      "[dimension 96/145]  inactive:\t-2.89e-06 +- 2.55e-02\n",
      "[dimension 97/145]  inactive:\t2.24e-03 +- 2.42e-02\n",
      "[dimension 98/145]  inactive:\t-1.15e-03 +- 2.48e-02\n",
      "[dimension 99/145]  inactive:\t2.72e-03 +- 3.90e-02\n",
      "[dimension 100/145]  inactive:\t-5.08e-04 +- 1.45e-02\n",
      "[dimension 101/145]  inactive:\t-2.54e-03 +- 2.05e-02\n",
      "[dimension 102/145]  inactive:\t-1.77e-03 +- 2.67e-02\n",
      "[dimension 103/145]  inactive:\t9.39e-04 +- 2.52e-02\n",
      "[dimension 104/145]  inactive:\t-7.76e-04 +- 1.66e-02\n",
      "[dimension 105/145]  inactive:\t-6.29e-04 +- 2.75e-02\n",
      "[dimension 106/145]  inactive:\t5.34e-03 +- 3.62e-02\n",
      "[dimension 107/145]  inactive:\t-1.61e-03 +- 2.15e-02\n",
      "[dimension 108/145]  inactive:\t2.55e-03 +- 4.55e-02\n",
      "[dimension 109/145]  inactive:\t-4.06e-04 +- 1.86e-02\n",
      "[dimension 110/145]  inactive:\t-1.97e-03 +- 2.92e-02\n",
      "[dimension 111/145]  inactive:\t1.34e-03 +- 2.99e-02\n",
      "[dimension 112/145]  inactive:\t6.90e-03 +- 5.49e-02\n",
      "[dimension 113/145]  inactive:\t-1.94e-03 +- 2.28e-02\n",
      "[dimension 114/145]  inactive:\t1.80e-03 +- 4.67e-02\n",
      "[dimension 115/145]  inactive:\t2.07e-03 +- 2.26e-02\n",
      "[dimension 116/145]  inactive:\t6.75e-04 +- 4.98e-02\n",
      "[dimension 117/145]  inactive:\t4.10e-03 +- 4.79e-02\n",
      "[dimension 118/145]  inactive:\t3.30e-03 +- 2.56e-02\n",
      "[dimension 119/145]  inactive:\t-3.54e-03 +- 3.46e-02\n",
      "[dimension 120/145]  inactive:\t-3.52e-04 +- 2.73e-02\n",
      "[dimension 121/145]  inactive:\t5.16e-03 +- 3.93e-02\n",
      "[dimension 122/145]  inactive:\t-2.60e-03 +- 3.09e-02\n",
      "[dimension 123/145]  inactive:\t1.32e-03 +- 3.43e-02\n",
      "[dimension 124/145]  inactive:\t-1.34e-03 +- 1.78e-02\n",
      "[dimension 125/145]  inactive:\t-1.77e-03 +- 2.64e-02\n",
      "[dimension 126/145]  inactive:\t-1.55e-03 +- 2.51e-02\n",
      "[dimension 127/145]  inactive:\t1.36e-04 +- 1.77e-02\n",
      "[dimension 128/145]  inactive:\t-3.01e-03 +- 3.80e-02\n",
      "[dimension 129/145]  inactive:\t-2.97e-04 +- 2.33e-02\n",
      "[dimension 130/145]  inactive:\t4.34e-03 +- 3.11e-02\n",
      "[dimension 131/145]  inactive:\t-1.25e-03 +- 3.44e-02\n",
      "[dimension 132/145]  inactive:\t3.64e-03 +- 3.65e-02\n",
      "[dimension 133/145]  inactive:\t3.08e-03 +- 2.35e-02\n",
      "[dimension 134/145]  inactive:\t-2.49e-04 +- 2.61e-02\n",
      "[dimension 135/145]  inactive:\t9.00e-05 +- 2.93e-02\n",
      "[dimension 136/145]  inactive:\t1.21e-03 +- 2.05e-02\n",
      "[dimension 137/145]  inactive:\t-7.87e-04 +- 3.17e-02\n",
      "[dimension 138/145]  inactive:\t6.99e-04 +- 2.39e-02\n",
      "[dimension 139/145]  inactive:\t8.75e-04 +- 2.13e-02\n",
      "[dimension 140/145]  inactive:\t-1.48e-03 +- 2.82e-02\n",
      "[dimension 141/145]  inactive:\t1.71e-03 +- 2.84e-02\n",
      "[dimension 142/145]  inactive:\t1.11e-03 +- 1.69e-02\n",
      "[dimension 143/145]  inactive:\t3.36e-04 +- 3.48e-02\n",
      "[dimension 144/145]  inactive:\t1.30e-04 +- 1.84e-02\n",
      "[dimension 145/145]  inactive:\t-1.46e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.89674854]\n",
      "cov_act[[0.02778569]]\n",
      "Active_dimensions: [62]\n",
      "37, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.41it/s, 15 steps of size 1.96e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    753.68      1.01\n",
      "  lambda[0]      2.36      7.66      0.91      0.00      4.46   1045.18      1.00\n",
      "  lambda[1]      2.96      8.43      0.96      0.00      5.97    406.24      1.01\n",
      "  lambda[2]      3.12      7.64      1.02      0.00      6.81    505.78      1.00\n",
      "  lambda[3]      3.05      9.04      0.93      0.01      6.12    679.05      1.00\n",
      "  lambda[4]      3.12      8.98      1.01      0.00      5.77    592.14      1.00\n",
      "  lambda[5]      3.55     16.73      0.96      0.00      6.02    635.02      1.00\n",
      "  lambda[6]      3.23      9.70      0.95      0.00      5.87    749.48      1.00\n",
      "  lambda[7]      2.64      6.50      0.94      0.00      6.24    914.44      1.00\n",
      "  lambda[8]      2.96      6.71      1.05      0.01      6.44    628.73      1.00\n",
      "  lambda[9]      2.75      8.55      0.99      0.00      4.88    840.41      1.00\n",
      " lambda[10]      3.12      8.97      1.01      0.00      6.33    668.86      1.00\n",
      " lambda[11]      3.03      8.06      0.98      0.00      6.28    412.02      1.00\n",
      " lambda[12]      4.42     16.53      0.98      0.01      8.56    684.98      1.00\n",
      " lambda[13]      3.21     14.34      0.97      0.00      5.36    446.65      1.00\n",
      " lambda[14]      4.08     18.18      0.98      0.00      5.76    688.91      1.00\n",
      " lambda[15]      2.97     17.71      0.98      0.00      5.59    980.63      1.00\n",
      " lambda[16]      2.88      7.42      0.92      0.00      5.95    752.53      1.00\n",
      " lambda[17]      4.37     46.09      0.95      0.00      5.27    714.35      1.00\n",
      " lambda[18]      2.89      7.31      0.99      0.00      6.13    666.80      1.00\n",
      " lambda[19]      2.74      6.41      1.05      0.00      5.51    887.20      1.00\n",
      " lambda[20]      2.74      6.78      0.95      0.00      6.38    685.16      1.00\n",
      " lambda[21]      2.37      4.60      0.96      0.00      5.61    846.10      1.00\n",
      " lambda[22]      2.72      7.66      1.01      0.00      5.72    626.16      1.00\n",
      " lambda[23]      3.30     15.80      1.01      0.00      5.76    959.05      1.00\n",
      " lambda[24]      3.21      8.89      0.97      0.00      6.37    758.40      1.00\n",
      " lambda[25]      2.85      9.47      0.97      0.00      5.03    684.30      1.00\n",
      " lambda[26]      4.27     18.68      0.97      0.00      7.06    551.49      1.00\n",
      " lambda[27]      2.70      7.26      0.99      0.00      5.57    608.01      1.00\n",
      " lambda[28]      2.76      8.32      0.95      0.00      5.68    681.26      1.00\n",
      " lambda[29]      2.84      6.85      1.00      0.00      6.69    799.27      1.00\n",
      " lambda[30]      3.46     12.75      1.07      0.01      6.71    775.17      1.00\n",
      " lambda[31]      3.33     14.10      1.00      0.00      5.78   1046.36      1.00\n",
      " lambda[32]      2.85      8.16      1.00      0.00      5.51    914.78      1.00\n",
      " lambda[33]      2.70      5.94      0.94      0.00      5.94    588.59      1.00\n",
      " lambda[34]      3.44     15.12      1.00      0.00      5.86    658.15      1.00\n",
      " lambda[35]      3.33     14.58      1.01      0.00      5.57    368.52      1.00\n",
      " lambda[36]      2.98      8.63      0.93      0.00      5.69    684.65      1.00\n",
      " lambda[37]      4.08     20.19      1.04      0.00      6.37    364.05      1.00\n",
      " lambda[38]      3.05      9.72      0.98      0.00      6.79    938.68      1.00\n",
      " lambda[39]      3.09     10.61      0.96      0.00      4.94    768.27      1.00\n",
      " lambda[40]      3.99     27.94      0.91      0.00      6.35    952.48      1.00\n",
      " lambda[41]     25.13    377.65      0.90      0.00      8.29    627.32      1.00\n",
      " lambda[42]      2.53      5.82      1.00      0.00      5.01    882.49      1.00\n",
      " lambda[43]      3.40     16.50      0.99      0.00      5.52    976.56      1.00\n",
      " lambda[44]      2.77      8.06      0.98      0.00      5.81    983.93      1.00\n",
      " lambda[45]      2.55      7.11      0.92      0.00      4.86    641.66      1.00\n",
      " lambda[46]      2.51      6.92      1.02      0.00      4.58    619.35      1.00\n",
      " lambda[47]      2.22      4.36      1.02      0.00      4.64    872.50      1.00\n",
      " lambda[48]      2.67      8.03      0.93      0.01      5.77    838.65      1.00\n",
      " lambda[49]      2.92      8.56      1.01      0.00      5.56    724.30      1.00\n",
      " lambda[50]      3.84     17.03      1.00      0.00      6.75    567.13      1.00\n",
      " lambda[51]      4.76     28.15      1.05      0.00      6.81    729.15      1.00\n",
      " lambda[52]      2.87      7.53      1.01      0.00      6.22    935.92      1.00\n",
      " lambda[53]      2.74      7.20      0.94      0.00      4.94    964.16      1.00\n",
      " lambda[54]      2.19      5.10      0.97      0.00      4.30    632.73      1.00\n",
      " lambda[55]      2.89     10.16      0.90      0.00      4.72    421.67      1.00\n",
      " lambda[56]      3.15      9.54      0.97      0.00      5.50    444.90      1.00\n",
      " lambda[57]      3.04      7.21      0.92      0.00      7.03    561.31      1.00\n",
      " lambda[58]      2.40      5.88      0.92      0.00      5.05    741.14      1.00\n",
      " lambda[59]      3.79     24.41      0.96      0.00      5.55    939.88      1.00\n",
      " lambda[60]      3.85     21.48      0.97      0.00      5.85    631.10      1.00\n",
      " lambda[61]      2.88      8.72      1.02      0.00      5.61    758.62      1.00\n",
      " lambda[62]   4591.42  40905.66    314.43      0.00   3101.69    878.60      1.00\n",
      " lambda[63]      2.38      5.56      0.98      0.00      5.45    675.58      1.00\n",
      " lambda[64]      2.63      6.66      0.86      0.00      5.38    631.00      1.00\n",
      " lambda[65]      2.72      6.88      0.99      0.00      5.58    888.70      1.00\n",
      " lambda[66]      2.89      8.27      0.97      0.00      6.04    868.72      1.00\n",
      " lambda[67]      3.05      7.99      0.93      0.00      6.31    771.36      1.00\n",
      " lambda[68]      2.96      7.27      1.01      0.00      5.62    672.49      1.00\n",
      " lambda[69]      3.74     14.10      0.96      0.00      5.84    743.84      1.00\n",
      " lambda[70]      2.65      6.34      0.99      0.00      5.77    662.58      1.00\n",
      " lambda[71]      3.09     11.81      1.04      0.00      5.02    624.04      1.00\n",
      " lambda[72]      2.61      7.25      0.93      0.00      4.94    687.37      1.00\n",
      " lambda[73]      3.66     22.11      1.03      0.00      5.42    831.84      1.00\n",
      " lambda[74]      2.88     10.34      0.97      0.00      5.13    525.75      1.00\n",
      " lambda[75]      4.12     16.20      1.07      0.00      7.18    692.74      1.00\n",
      " lambda[76]      2.89      7.74      0.96      0.00      6.31    635.71      1.00\n",
      " lambda[77]      4.28     29.43      1.09      0.00      6.86    674.98      1.00\n",
      " lambda[78]      3.06      9.92      1.00      0.00      6.30    798.92      1.00\n",
      " lambda[79]      2.99     10.41      0.92      0.00      4.81    763.89      1.00\n",
      " lambda[80]      3.14      9.44      1.02      0.00      6.06    536.69      1.00\n",
      " lambda[81]      2.69      7.29      0.99      0.00      5.33    900.81      1.00\n",
      " lambda[82]      2.74      8.05      0.95      0.00      5.23    912.33      1.00\n",
      " lambda[83]      3.09      8.01      1.01      0.00      6.47    781.19      1.00\n",
      " lambda[84]      3.19      9.30      1.08      0.00      6.53    744.65      1.00\n",
      " lambda[85]      3.19      8.98      1.01      0.00      6.85    635.42      1.00\n",
      " lambda[86]      3.64     13.82      0.95      0.00      6.67    516.08      1.00\n",
      " lambda[87]      3.33      9.13      1.03      0.00      6.60    690.29      1.00\n",
      " lambda[88]      2.99     10.06      0.97      0.00      5.90    807.18      1.00\n",
      " lambda[89]     48.45    277.56      1.25      0.00     40.30    140.70      1.02\n",
      " lambda[90]      2.56      6.20      0.94      0.00      5.09    463.48      1.00\n",
      " lambda[91]      2.72      6.46      1.05      0.00      5.84    790.68      1.00\n",
      " lambda[92]      3.33     15.04      0.97      0.00      6.01    702.99      1.00\n",
      " lambda[93]      2.70      8.59      1.04      0.00      5.11    672.13      1.00\n",
      " lambda[94]      2.61      6.96      0.96      0.00      4.93    840.54      1.00\n",
      " lambda[95]      3.36      9.27      0.96      0.00      6.30    661.75      1.00\n",
      " lambda[96]      3.32     10.60      0.98      0.00      6.85    537.49      1.00\n",
      " lambda[97]      2.92      6.62      1.10      0.00      5.95    715.29      1.00\n",
      " lambda[98]      3.49     16.50      0.95      0.00      5.68    747.28      1.00\n",
      " lambda[99]      2.80      7.24      1.03      0.00      5.35    810.63      1.00\n",
      "lambda[100]      3.17     10.18      0.92      0.00      6.04    658.23      1.00\n",
      "lambda[101]      3.03      8.09      0.94      0.00      5.87    633.63      1.00\n",
      "lambda[102]      2.82      7.69      0.97      0.00      5.93    594.36      1.00\n",
      "lambda[103]      2.33      5.23      0.89      0.00      5.16    863.98      1.00\n",
      "lambda[104]      2.70      8.24      0.91      0.00      4.90    869.18      1.00\n",
      "lambda[105]      3.45     11.63      0.95      0.00      6.45    492.22      1.00\n",
      "lambda[106]      3.20     12.58      0.96      0.00      6.39    354.68      1.01\n",
      "lambda[107]      3.32     16.69      0.97      0.00      4.84    529.05      1.00\n",
      "lambda[108]      2.38      5.32      0.97      0.01      5.37    817.81      1.00\n",
      "lambda[109]      9.55    143.22      0.96      0.00      5.75   1006.97      1.00\n",
      "lambda[110]      3.30      8.57      1.01      0.00      7.31    764.66      1.00\n",
      "lambda[111]      4.19     16.37      0.98      0.00      7.08    554.12      1.00\n",
      "lambda[112]      2.50      6.69      0.99      0.01      5.30    891.00      1.00\n",
      "lambda[113]      4.18     23.89      0.98      0.00      6.13    642.13      1.00\n",
      "lambda[114]      2.94     11.23      0.96      0.00      5.79    941.75      1.00\n",
      "lambda[115]      3.02     10.34      1.04      0.00      5.96    989.37      1.00\n",
      "lambda[116]      3.20     11.09      1.03      0.00      5.39    490.16      1.00\n",
      "lambda[117]      3.23     11.22      0.94      0.00      6.14    949.02      1.00\n",
      "lambda[118]      2.86      7.38      0.93      0.00      6.10   1063.20      1.00\n",
      "lambda[119]      2.93      8.88      0.97      0.00      5.87    785.15      1.00\n",
      "lambda[120]      3.34     11.14      1.00      0.00      5.97    904.71      1.00\n",
      "lambda[121]      3.58     14.32      1.03      0.00      6.17    776.86      1.00\n",
      "lambda[122]      3.30     12.04      1.02      0.00      5.00    661.80      1.00\n",
      "lambda[123]      2.68      6.63      0.97      0.01      5.73    815.23      1.00\n",
      "lambda[124]      2.80      6.92      1.02      0.00      5.54    912.70      1.00\n",
      "lambda[125]      2.65      6.22      0.97      0.00      5.93    698.91      1.00\n",
      "lambda[126]      2.81     10.15      0.97      0.00      5.33    864.54      1.00\n",
      "lambda[127]      3.63     17.30      1.01      0.00      5.98    918.76      1.00\n",
      "lambda[128]      2.61      6.21      0.96      0.01      5.40    780.85      1.00\n",
      "lambda[129]      3.48     14.66      0.95      0.00      5.63    962.73      1.00\n",
      "lambda[130]      2.96     10.89      0.97      0.00      5.46    924.82      1.00\n",
      "lambda[131]      3.71     24.72      0.99      0.00      5.94    886.37      1.00\n",
      "lambda[132]      2.92      6.24      1.06      0.00      6.76    907.90      1.00\n",
      "lambda[133]      2.81      7.60      1.00      0.00      5.39    835.20      1.00\n",
      "lambda[134]      3.10      7.93      0.97      0.00      7.10    793.22      1.00\n",
      "lambda[135]      2.29      5.63      0.92      0.00      4.69    881.33      1.00\n",
      "lambda[136]      3.04      9.93      0.93      0.00      5.94    856.39      1.00\n",
      "lambda[137]      2.65      7.78      0.99      0.01      5.46    926.18      1.00\n",
      "lambda[138]      2.68      6.87      0.96      0.00      5.52    899.92      1.00\n",
      "lambda[139]      3.11      9.32      1.06      0.00      6.44    647.31      1.00\n",
      "lambda[140]      3.15     12.78      0.94      0.00      5.86    816.51      1.00\n",
      "lambda[141]      3.92     41.51      0.96      0.00      5.49    960.81      1.00\n",
      "lambda[142]      5.55     34.21      0.94      0.00      6.41    561.19      1.00\n",
      "lambda[143]      2.18      3.85      0.94      0.00      4.95    670.31      1.00\n",
      "        msq      1.48      0.96      1.24      0.43      2.51    727.22      1.00\n",
      "      sigma      3.02      4.04      1.38      0.00      8.23   1046.18      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    959.05      1.00\n",
      "       xisq      5.74     27.95      0.92      0.07      7.66    334.96      1.01\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.07555103302002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.17e-04 +- 1.38e-02\n",
      "[dimension 02/145]  inactive:\t-2.11e-04 +- 1.91e-02\n",
      "[dimension 03/145]  inactive:\t-3.82e-05 +- 1.76e-02\n",
      "[dimension 04/145]  inactive:\t3.65e-03 +- 3.07e-02\n",
      "[dimension 05/145]  inactive:\t-5.10e-04 +- 1.95e-02\n",
      "[dimension 06/145]  inactive:\t1.39e-03 +- 2.89e-02\n",
      "[dimension 07/145]  inactive:\t3.81e-04 +- 1.62e-02\n",
      "[dimension 08/145]  inactive:\t3.66e-04 +- 1.68e-02\n",
      "[dimension 09/145]  inactive:\t3.43e-04 +- 1.73e-02\n",
      "[dimension 10/145]  inactive:\t5.27e-04 +- 1.57e-02\n",
      "[dimension 11/145]  inactive:\t-5.33e-04 +- 1.81e-02\n",
      "[dimension 12/145]  inactive:\t-5.61e-04 +- 2.19e-02\n",
      "[dimension 13/145]  inactive:\t3.48e-03 +- 3.17e-02\n",
      "[dimension 14/145]  inactive:\t-8.70e-04 +- 1.90e-02\n",
      "[dimension 15/145]  inactive:\t9.30e-04 +- 2.68e-02\n",
      "[dimension 16/145]  inactive:\t4.42e-04 +- 1.51e-02\n",
      "[dimension 17/145]  inactive:\t3.83e-04 +- 2.66e-02\n",
      "[dimension 18/145]  inactive:\t-5.86e-04 +- 2.41e-02\n",
      "[dimension 19/145]  inactive:\t-1.53e-03 +- 1.83e-02\n",
      "[dimension 20/145]  inactive:\t-4.00e-04 +- 1.63e-02\n",
      "[dimension 21/145]  inactive:\t-1.03e-03 +- 1.90e-02\n",
      "[dimension 22/145]  inactive:\t1.91e-04 +- 1.32e-02\n",
      "[dimension 23/145]  inactive:\t-3.06e-04 +- 1.92e-02\n",
      "[dimension 24/145]  inactive:\t1.14e-03 +- 2.17e-02\n",
      "[dimension 25/145]  inactive:\t2.66e-03 +- 2.01e-02\n",
      "[dimension 26/145]  inactive:\t-4.02e-04 +- 2.25e-02\n",
      "[dimension 27/145]  inactive:\t7.14e-04 +- 1.89e-02\n",
      "[dimension 28/145]  inactive:\t6.34e-04 +- 1.55e-02\n",
      "[dimension 29/145]  inactive:\t4.75e-04 +- 2.18e-02\n",
      "[dimension 30/145]  inactive:\t6.31e-04 +- 1.82e-02\n",
      "[dimension 31/145]  inactive:\t2.96e-03 +- 2.65e-02\n",
      "[dimension 32/145]  inactive:\t-8.26e-04 +- 1.94e-02\n",
      "[dimension 33/145]  inactive:\t1.06e-03 +- 2.34e-02\n",
      "[dimension 34/145]  inactive:\t5.77e-04 +- 1.47e-02\n",
      "[dimension 35/145]  inactive:\t4.73e-04 +- 2.03e-02\n",
      "[dimension 36/145]  inactive:\t5.29e-04 +- 1.82e-02\n",
      "[dimension 37/145]  inactive:\t2.83e-03 +- 2.09e-02\n",
      "[dimension 38/145]  inactive:\t-1.40e-03 +- 2.68e-02\n",
      "[dimension 39/145]  inactive:\t1.07e-03 +- 2.59e-02\n",
      "[dimension 40/145]  inactive:\t2.72e-03 +- 2.53e-02\n",
      "[dimension 41/145]  inactive:\t-9.25e-04 +- 2.64e-02\n",
      "[dimension 42/145]  inactive:\t8.62e-03 +- 7.29e-02\n",
      "[dimension 43/145]  inactive:\t-8.75e-05 +- 1.52e-02\n",
      "[dimension 44/145]  inactive:\t-4.54e-04 +- 2.22e-02\n",
      "[dimension 45/145]  inactive:\t-2.09e-04 +- 1.92e-02\n",
      "[dimension 46/145]  inactive:\t7.46e-04 +- 1.12e-02\n",
      "[dimension 47/145]  inactive:\t-9.73e-04 +- 2.03e-02\n",
      "[dimension 48/145]  inactive:\t4.70e-04 +- 1.44e-02\n",
      "[dimension 49/145]  inactive:\t1.79e-03 +- 1.80e-02\n",
      "[dimension 50/145]  inactive:\t-1.12e-03 +- 2.27e-02\n",
      "[dimension 51/145]  inactive:\t1.67e-03 +- 2.30e-02\n",
      "[dimension 52/145]  inactive:\t4.27e-03 +- 2.16e-02\n",
      "[dimension 53/145]  inactive:\t-9.06e-04 +- 1.98e-02\n",
      "[dimension 54/145]  inactive:\t2.04e-04 +- 1.64e-02\n",
      "[dimension 55/145]  inactive:\t3.47e-04 +- 1.18e-02\n",
      "[dimension 56/145]  inactive:\t-1.61e-03 +- 1.71e-02\n",
      "[dimension 57/145]  inactive:\t8.38e-04 +- 2.45e-02\n",
      "[dimension 58/145]  inactive:\t3.95e-03 +- 3.10e-02\n",
      "[dimension 59/145]  inactive:\t-4.98e-04 +- 1.41e-02\n",
      "[dimension 60/145]  inactive:\t3.36e-04 +- 1.90e-02\n",
      "[dimension 61/145]  inactive:\t1.71e-03 +- 2.09e-02\n",
      "[dimension 62/145]  inactive:\t-6.37e-04 +- 1.49e-02\n",
      "[dimension 63/145]  active:\t8.10e-01 +- 3.42e-01\n",
      "[dimension 64/145]  inactive:\t-1.17e-03 +- 1.49e-02\n",
      "[dimension 65/145]  inactive:\t-3.04e-04 +- 1.63e-02\n",
      "[dimension 66/145]  inactive:\t5.85e-04 +- 1.64e-02\n",
      "[dimension 67/145]  inactive:\t9.99e-04 +- 1.99e-02\n",
      "[dimension 68/145]  inactive:\t-7.69e-05 +- 2.54e-02\n",
      "[dimension 69/145]  inactive:\t1.37e-03 +- 2.06e-02\n",
      "[dimension 70/145]  inactive:\t3.21e-03 +- 2.16e-02\n",
      "[dimension 71/145]  inactive:\t1.45e-04 +- 1.90e-02\n",
      "[dimension 72/145]  inactive:\t7.52e-04 +- 1.90e-02\n",
      "[dimension 73/145]  inactive:\t3.74e-04 +- 1.44e-02\n",
      "[dimension 74/145]  inactive:\t-1.24e-03 +- 2.42e-02\n",
      "[dimension 75/145]  inactive:\t1.70e-04 +- 1.75e-02\n",
      "[dimension 76/145]  inactive:\t4.25e-03 +- 3.38e-02\n",
      "[dimension 77/145]  inactive:\t-1.02e-03 +- 2.61e-02\n",
      "[dimension 78/145]  inactive:\t4.41e-03 +- 4.78e-02\n",
      "[dimension 79/145]  inactive:\t3.24e-03 +- 2.33e-02\n",
      "[dimension 80/145]  inactive:\t-1.68e-04 +- 2.17e-02\n",
      "[dimension 81/145]  inactive:\t6.00e-04 +- 2.13e-02\n",
      "[dimension 82/145]  inactive:\t3.19e-04 +- 1.41e-02\n",
      "[dimension 83/145]  inactive:\t-1.31e-03 +- 1.51e-02\n",
      "[dimension 84/145]  inactive:\t-6.19e-04 +- 1.89e-02\n",
      "[dimension 85/145]  inactive:\t1.61e-03 +- 2.08e-02\n",
      "[dimension 86/145]  inactive:\t-6.36e-04 +- 1.60e-02\n",
      "[dimension 87/145]  inactive:\t1.03e-03 +- 2.58e-02\n",
      "[dimension 88/145]  inactive:\t2.17e-03 +- 2.08e-02\n",
      "[dimension 89/145]  inactive:\t-6.45e-04 +- 1.80e-02\n",
      "[dimension 90/145]  inactive:\t7.46e-02 +- 2.39e-01\n",
      "[dimension 91/145]  inactive:\t2.55e-04 +- 1.38e-02\n",
      "[dimension 92/145]  inactive:\t-6.41e-04 +- 1.63e-02\n",
      "[dimension 93/145]  inactive:\t-2.56e-04 +- 1.96e-02\n",
      "[dimension 94/145]  inactive:\t1.10e-03 +- 2.10e-02\n",
      "[dimension 95/145]  inactive:\t-8.44e-05 +- 1.88e-02\n",
      "[dimension 96/145]  inactive:\t3.87e-04 +- 2.72e-02\n",
      "[dimension 97/145]  inactive:\t2.24e-03 +- 2.23e-02\n",
      "[dimension 98/145]  inactive:\t-5.56e-04 +- 1.67e-02\n",
      "[dimension 99/145]  inactive:\t1.34e-03 +- 2.57e-02\n",
      "[dimension 100/145]  inactive:\t-3.99e-04 +- 1.43e-02\n",
      "[dimension 101/145]  inactive:\t-1.57e-03 +- 1.56e-02\n",
      "[dimension 102/145]  inactive:\t-8.60e-04 +- 1.99e-02\n",
      "[dimension 103/145]  inactive:\t7.85e-04 +- 1.88e-02\n",
      "[dimension 104/145]  inactive:\t-6.13e-04 +- 1.40e-02\n",
      "[dimension 105/145]  inactive:\t-3.64e-04 +- 1.76e-02\n",
      "[dimension 106/145]  inactive:\t3.68e-03 +- 2.90e-02\n",
      "[dimension 107/145]  inactive:\t-9.37e-04 +- 1.54e-02\n",
      "[dimension 108/145]  inactive:\t1.65e-03 +- 3.72e-02\n",
      "[dimension 109/145]  inactive:\t-1.56e-04 +- 1.38e-02\n",
      "[dimension 110/145]  inactive:\t-4.19e-04 +- 2.42e-02\n",
      "[dimension 111/145]  inactive:\t7.27e-04 +- 1.94e-02\n",
      "[dimension 112/145]  inactive:\t4.74e-03 +- 3.91e-02\n",
      "[dimension 113/145]  inactive:\t-1.06e-03 +- 1.95e-02\n",
      "[dimension 114/145]  inactive:\t1.03e-03 +- 3.05e-02\n",
      "[dimension 115/145]  inactive:\t1.35e-03 +- 1.64e-02\n",
      "[dimension 116/145]  inactive:\t1.20e-04 +- 1.89e-02\n",
      "[dimension 117/145]  inactive:\t2.90e-03 +- 3.63e-02\n",
      "[dimension 118/145]  inactive:\t2.14e-03 +- 2.02e-02\n",
      "[dimension 119/145]  inactive:\t-1.32e-03 +- 2.45e-02\n",
      "[dimension 120/145]  inactive:\t-1.42e-06 +- 2.03e-02\n",
      "[dimension 121/145]  inactive:\t2.89e-03 +- 2.72e-02\n",
      "[dimension 122/145]  inactive:\t-1.53e-03 +- 2.37e-02\n",
      "[dimension 123/145]  inactive:\t1.01e-03 +- 2.40e-02\n",
      "[dimension 124/145]  inactive:\t-1.16e-03 +- 1.63e-02\n",
      "[dimension 125/145]  inactive:\t-8.94e-04 +- 2.11e-02\n",
      "[dimension 126/145]  inactive:\t-8.36e-04 +- 1.79e-02\n",
      "[dimension 127/145]  inactive:\t3.25e-04 +- 1.28e-02\n",
      "[dimension 128/145]  inactive:\t-3.25e-04 +- 2.68e-02\n",
      "[dimension 129/145]  inactive:\t-7.07e-05 +- 1.79e-02\n",
      "[dimension 130/145]  inactive:\t2.78e-03 +- 2.50e-02\n",
      "[dimension 131/145]  inactive:\t-6.33e-04 +- 2.04e-02\n",
      "[dimension 132/145]  inactive:\t1.77e-03 +- 2.37e-02\n",
      "[dimension 133/145]  inactive:\t1.80e-03 +- 1.64e-02\n",
      "[dimension 134/145]  inactive:\t-3.95e-04 +- 2.04e-02\n",
      "[dimension 135/145]  inactive:\t9.27e-05 +- 1.82e-02\n",
      "[dimension 136/145]  inactive:\t5.93e-04 +- 1.30e-02\n",
      "[dimension 137/145]  inactive:\t-2.08e-04 +- 2.17e-02\n",
      "[dimension 138/145]  inactive:\t2.01e-04 +- 1.60e-02\n",
      "[dimension 139/145]  inactive:\t2.93e-04 +- 1.83e-02\n",
      "[dimension 140/145]  inactive:\t-6.36e-04 +- 2.52e-02\n",
      "[dimension 141/145]  inactive:\t8.97e-04 +- 2.07e-02\n",
      "[dimension 142/145]  inactive:\t1.22e-03 +- 1.55e-02\n",
      "[dimension 143/145]  inactive:\t1.21e-03 +- 2.85e-02\n",
      "[dimension 144/145]  inactive:\t2.11e-04 +- 1.50e-02\n",
      "[dimension 145/145]  inactive:\t1.04e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8906353]\n",
      "cov_act[[0.02196816]]\n",
      "Active_dimensions: [62]\n",
      "38, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.81it/s, 31 steps of size 1.72e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    650.16      1.00\n",
      "  lambda[0]      2.34      5.72      0.94      0.00      4.98    750.68      1.00\n",
      "  lambda[1]      3.35     12.47      1.01      0.00      5.75    738.61      1.00\n",
      "  lambda[2]      2.90      9.35      0.97      0.00      5.45    720.20      1.00\n",
      "  lambda[3]      4.98     30.10      1.02      0.00      7.39    513.48      1.00\n",
      "  lambda[4]      2.90      8.71      1.03      0.00      5.57    755.33      1.00\n",
      "  lambda[5]      7.36    119.78      0.99      0.00      6.39    855.88      1.00\n",
      "  lambda[6]      2.97      8.69      0.96      0.00      5.87    796.33      1.00\n",
      "  lambda[7]      3.16      8.56      0.98      0.00      6.01    615.95      1.01\n",
      "  lambda[8]      2.47      5.15      1.00      0.00      5.93    614.87      1.00\n",
      "  lambda[9]      2.78      8.99      0.92      0.00      5.03    557.81      1.00\n",
      " lambda[10]      3.54     13.33      1.07      0.00      5.86    624.66      1.00\n",
      " lambda[11]      2.83      8.04      1.02      0.00      5.52    648.06      1.00\n",
      " lambda[12]      4.34     13.29      1.04      0.00      7.77    473.42      1.00\n",
      " lambda[13]      3.12     12.37      1.01      0.00      6.10    730.73      1.00\n",
      " lambda[14]      3.78     23.75      0.98      0.00      4.86    489.92      1.00\n",
      " lambda[15]      3.42     13.19      1.01      0.00      5.84    643.09      1.00\n",
      " lambda[16]      3.93     14.61      1.00      0.00      8.15    731.71      1.00\n",
      " lambda[17]      3.06     17.58      0.96      0.00      5.15    662.23      1.00\n",
      " lambda[18]      2.78      6.65      0.94      0.00      6.95    530.21      1.00\n",
      " lambda[19]      3.40     20.29      0.94      0.01      5.99    963.37      1.00\n",
      " lambda[20]      3.35     12.56      0.94      0.00      6.80    530.50      1.00\n",
      " lambda[21]      3.05      9.40      1.00      0.00      6.14    913.63      1.00\n",
      " lambda[22]      2.87      7.13      1.06      0.00      6.04    894.52      1.00\n",
      " lambda[23]      3.10      9.96      0.98      0.00      5.76    849.79      1.00\n",
      " lambda[24]      3.20     11.18      1.01      0.00      6.25    831.75      1.00\n",
      " lambda[25]      3.13      8.45      0.98      0.01      5.97    417.53      1.00\n",
      " lambda[26]      3.31     12.79      0.97      0.00      5.74    770.11      1.00\n",
      " lambda[27]      2.57      6.00      0.97      0.00      5.44    660.77      1.00\n",
      " lambda[28]      3.00      9.52      1.02      0.00      5.31    468.35      1.00\n",
      " lambda[29]      3.08      8.83      0.91      0.00      6.79    610.35      1.00\n",
      " lambda[30]      4.81     24.13      1.05      0.01      7.31    479.84      1.00\n",
      " lambda[31]      4.18     23.95      1.01      0.00      5.59    527.59      1.00\n",
      " lambda[32]      3.32     10.72      0.98      0.00      6.05    534.92      1.00\n",
      " lambda[33]      2.93     10.48      0.95      0.01      6.14    876.38      1.00\n",
      " lambda[34]      2.95      8.03      0.98      0.00      5.95    622.94      1.00\n",
      " lambda[35]      2.56      6.89      0.98      0.00      5.25    831.84      1.00\n",
      " lambda[36]      4.21     22.13      0.97      0.00      6.73    568.96      1.00\n",
      " lambda[37]      3.58     16.01      1.06      0.00      6.18    925.17      1.00\n",
      " lambda[38]      2.96      7.98      0.96      0.00      5.71    679.29      1.00\n",
      " lambda[39]      3.25     10.10      0.94      0.00      6.08    734.14      1.00\n",
      " lambda[40]      4.34     23.67      0.97      0.00      6.00   1035.85      1.00\n",
      " lambda[41]      7.88     54.08      0.91      0.00      8.60    723.29      1.00\n",
      " lambda[42]      2.91     10.28      0.97      0.00      5.72    607.58      1.00\n",
      " lambda[43]      4.99     55.23      0.96      0.00      5.90    979.47      1.00\n",
      " lambda[44]      2.97      8.33      0.98      0.00      6.20    469.06      1.00\n",
      " lambda[45]      3.03      9.83      0.93      0.00      4.96    678.70      1.00\n",
      " lambda[46]      3.02      8.85      0.99      0.00      5.05    733.08      1.00\n",
      " lambda[47]      2.44      5.44      0.98      0.00      5.13    564.18      1.00\n",
      " lambda[48]      3.34     12.24      1.02      0.00      6.83    737.31      1.00\n",
      " lambda[49]      3.48     11.52      0.97      0.00      6.58    810.74      1.00\n",
      " lambda[50]      2.65      7.47      0.97      0.00      4.98   1048.26      1.00\n",
      " lambda[51]      5.82     45.33      1.04      0.00      7.87    944.80      1.00\n",
      " lambda[52]      3.19     12.82      0.98      0.00      5.07    480.45      1.00\n",
      " lambda[53]      3.03     15.59      0.93      0.00      4.92    612.08      1.00\n",
      " lambda[54]      2.23      5.14      0.96      0.01      4.71    502.72      1.00\n",
      " lambda[55]      3.03     13.43      1.03      0.00      5.41    815.97      1.00\n",
      " lambda[56]      2.72      7.63      0.99      0.00      5.15    758.39      1.00\n",
      " lambda[57]      4.88     26.59      0.95      0.00      7.13    891.47      1.01\n",
      " lambda[58]      2.37      5.65      0.93      0.00      5.00    617.02      1.00\n",
      " lambda[59]      3.20      9.69      1.01      0.00      6.69    698.78      1.00\n",
      " lambda[60]      3.40     13.92      0.99      0.00      5.36    453.81      1.00\n",
      " lambda[61]      2.62      6.77      1.00      0.00      5.17    698.92      1.00\n",
      " lambda[62]   1153.59  13231.66    195.46      0.01   1178.74    787.24      1.00\n",
      " lambda[63]      2.37      5.74      1.01      0.00      4.60    970.32      1.00\n",
      " lambda[64]      3.95     18.75      1.01      0.00      5.96    586.06      1.00\n",
      " lambda[65]      2.98     10.49      0.98      0.00      6.24    871.34      1.00\n",
      " lambda[66]      3.13      7.57      1.01      0.00      7.34    671.15      1.00\n",
      " lambda[67]      2.58      7.29      0.90      0.00      5.16    865.80      1.00\n",
      " lambda[68]      5.11     48.80      0.98      0.00      5.43    514.37      1.00\n",
      " lambda[69]      3.54     13.76      0.91      0.00      5.88    800.16      1.00\n",
      " lambda[70]      2.73      7.91      1.01      0.00      5.30    723.96      1.00\n",
      " lambda[71]      3.38     10.74      0.94      0.00      6.08    453.85      1.00\n",
      " lambda[72]      3.10     10.59      0.98      0.00      5.72    450.51      1.00\n",
      " lambda[73]      2.78      6.78      1.00      0.00      5.91    739.22      1.00\n",
      " lambda[74]      2.41      4.76      0.99      0.01      5.90    802.08      1.00\n",
      " lambda[75]      4.97     29.02      1.04      0.00      6.50    767.86      1.00\n",
      " lambda[76]      3.18      9.31      1.00      0.00      6.15    812.08      1.00\n",
      " lambda[77]      6.05     51.14      1.07      0.00      6.46    295.04      1.00\n",
      " lambda[78]      3.77     12.95      1.05      0.00      6.92    417.78      1.00\n",
      " lambda[79]      3.27     11.64      1.04      0.00      5.37    593.63      1.00\n",
      " lambda[80]      3.93     21.01      1.04      0.00      6.24    694.28      1.00\n",
      " lambda[81]      2.81     15.23      0.97      0.00      5.24   1024.68      1.00\n",
      " lambda[82]      2.12      4.67      0.95      0.00      4.30    950.12      1.00\n",
      " lambda[83]      3.11     10.56      0.96      0.00      5.27    719.46      1.00\n",
      " lambda[84]      4.48     27.52      1.06      0.00      7.40    777.73      1.00\n",
      " lambda[85]      2.73      6.57      0.95      0.00      6.36    635.20      1.00\n",
      " lambda[86]      3.17     14.59      0.99      0.00      6.26    687.92      1.00\n",
      " lambda[87]      3.18      8.79      0.95      0.00      6.09    798.92      1.00\n",
      " lambda[88]      2.76      7.88      0.94      0.00      5.62    976.77      1.00\n",
      " lambda[89]     64.37    966.18      1.28      0.00     59.51    815.46      1.00\n",
      " lambda[90]      2.78      8.40      0.97      0.00      5.15    690.33      1.00\n",
      " lambda[91]      2.88      9.87      1.03      0.00      5.47    684.35      1.00\n",
      " lambda[92]      2.62      6.34      1.03      0.01      5.14    767.26      1.00\n",
      " lambda[93]      2.87      7.51      1.05      0.00      5.75    439.35      1.00\n",
      " lambda[94]      2.63      7.71      0.95      0.00      5.04    780.50      1.00\n",
      " lambda[95]      2.99     10.04      0.98      0.00      5.99    836.94      1.00\n",
      " lambda[96]      2.53      6.99      0.97      0.00      4.91    541.22      1.00\n",
      " lambda[97]      3.61     20.79      0.97      0.00      5.39    931.47      1.00\n",
      " lambda[98]      4.30     41.43      0.98      0.00      5.83    998.11      1.00\n",
      " lambda[99]      2.61      7.55      0.97      0.00      4.69    844.15      1.00\n",
      "lambda[100]      3.11      9.98      0.90      0.00      6.11    648.98      1.00\n",
      "lambda[101]      2.82      7.13      0.88      0.01      5.97    631.95      1.00\n",
      "lambda[102]      2.81      7.12      0.94      0.00      5.67    732.12      1.00\n",
      "lambda[103]      2.54      5.65      0.99      0.00      5.49    620.59      1.00\n",
      "lambda[104]      3.00      9.35      0.98      0.00      6.34    452.90      1.00\n",
      "lambda[105]      3.36      9.18      1.06      0.00      7.44    531.17      1.00\n",
      "lambda[106]      2.52      4.86      1.00      0.01      6.14   1068.94      1.00\n",
      "lambda[107]      4.43     23.07      1.00      0.00      5.96    361.25      1.00\n",
      "lambda[108]      2.33      6.87      0.93      0.00      4.71    657.83      1.00\n",
      "lambda[109]      6.72    104.01      0.98      0.00      6.70    999.11      1.00\n",
      "lambda[110]      3.72     13.53      1.00      0.00      7.00    748.86      1.00\n",
      "lambda[111]      4.58     21.07      0.95      0.00      6.18    728.74      1.00\n",
      "lambda[112]      2.60      5.34      0.93      0.01      5.80    854.92      1.00\n",
      "lambda[113]      4.09     16.21      1.05      0.00      6.70    720.85      1.00\n",
      "lambda[114]      3.23     10.12      0.96      0.00      5.67    880.04      1.00\n",
      "lambda[115]      3.36      9.51      0.99      0.00      6.52    689.96      1.00\n",
      "lambda[116]      5.01     38.56      1.06      0.00      6.13    469.49      1.00\n",
      "lambda[117]      3.62     14.56      0.96      0.00      6.04    609.13      1.00\n",
      "lambda[118]      3.46     10.89      0.99      0.00      6.94    877.98      1.00\n",
      "lambda[119]      2.93     14.29      1.02      0.00      4.99   1011.88      1.00\n",
      "lambda[120]      5.38     30.80      0.95      0.00      6.82    798.46      1.00\n",
      "lambda[121]      4.22     22.66      0.91      0.00      6.09    689.15      1.00\n",
      "lambda[122]      2.76      7.33      1.00      0.00      5.90    825.66      1.00\n",
      "lambda[123]      2.83      7.89      0.96      0.00      5.46    696.25      1.00\n",
      "lambda[124]      2.86      6.73      1.05      0.00      6.24    796.01      1.00\n",
      "lambda[125]      3.38     10.75      0.92      0.00      5.57    468.74      1.00\n",
      "lambda[126]      2.54      6.49      0.92      0.00      5.61    859.37      1.00\n",
      "lambda[127]      4.30     18.96      0.97      0.00      6.63    765.06      1.00\n",
      "lambda[128]      2.45      6.08      0.95      0.00      4.60    427.76      1.00\n",
      "lambda[129]      4.18     24.75      1.00      0.00      6.51   1005.64      1.00\n",
      "lambda[130]      3.40     13.39      0.94      0.00      6.20    815.36      1.00\n",
      "lambda[131]      2.94      7.83      0.97      0.01      5.54    661.59      1.00\n",
      "lambda[132]      2.64      6.63      0.95      0.00      5.28    794.30      1.00\n",
      "lambda[133]      2.80      9.09      0.99      0.00      5.46    615.86      1.00\n",
      "lambda[134]      3.53     10.84      0.91      0.00      7.79    972.41      1.00\n",
      "lambda[135]      3.07     16.49      0.90      0.00      5.09    842.55      1.00\n",
      "lambda[136]      2.93      7.32      1.00      0.01      6.32    572.19      1.00\n",
      "lambda[137]      2.99     10.37      0.95      0.00      5.83    452.33      1.00\n",
      "lambda[138]      3.42     14.94      1.01      0.00      5.80    737.46      1.00\n",
      "lambda[139]      3.58     11.68      1.00      0.00      6.48    737.41      1.01\n",
      "lambda[140]      3.10      9.04      0.99      0.00      5.80    706.95      1.00\n",
      "lambda[141]      2.58      7.54      0.88      0.00      5.25    614.22      1.00\n",
      "lambda[142]      4.07     20.95      0.97      0.01      5.63    702.24      1.00\n",
      "lambda[143]      2.26      4.40      0.95      0.00      4.86    667.34      1.00\n",
      "        msq   1088.06  16436.32     22.88      1.13    425.84    989.07      1.00\n",
      "      sigma      3.46      4.48      1.76      0.01      9.13   1226.78      1.00\n",
      "    var_obs      0.09      0.01      0.09      0.06      0.11   1195.38      1.00\n",
      "       xisq      0.12      0.07      0.11      0.04      0.21   1266.86      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.48352384567261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.12e-04 +- 1.75e-02\n",
      "[dimension 02/145]  inactive:\t-1.06e-03 +- 3.03e-02\n",
      "[dimension 03/145]  inactive:\t1.05e-04 +- 2.50e-02\n",
      "[dimension 04/145]  inactive:\t8.07e-03 +- 4.99e-02\n",
      "[dimension 05/145]  inactive:\t-1.47e-03 +- 4.17e-02\n",
      "[dimension 06/145]  inactive:\t2.80e-03 +- 4.15e-02\n",
      "[dimension 07/145]  inactive:\t2.51e-04 +- 2.35e-02\n",
      "[dimension 08/145]  inactive:\t4.88e-04 +- 2.99e-02\n",
      "[dimension 09/145]  inactive:\t-7.32e-05 +- 2.07e-02\n",
      "[dimension 10/145]  inactive:\t4.55e-04 +- 1.95e-02\n",
      "[dimension 11/145]  inactive:\t-1.95e-03 +- 2.55e-02\n",
      "[dimension 12/145]  inactive:\t-6.31e-04 +- 2.63e-02\n",
      "[dimension 13/145]  inactive:\t5.22e-03 +- 3.94e-02\n",
      "[dimension 14/145]  inactive:\t-2.35e-03 +- 3.87e-02\n",
      "[dimension 15/145]  inactive:\t-1.14e-04 +- 2.73e-02\n",
      "[dimension 16/145]  inactive:\t9.91e-04 +- 2.24e-02\n",
      "[dimension 17/145]  inactive:\t-5.47e-04 +- 3.30e-02\n",
      "[dimension 18/145]  inactive:\t-2.68e-04 +- 2.62e-02\n",
      "[dimension 19/145]  inactive:\t-2.95e-03 +- 2.28e-02\n",
      "[dimension 20/145]  inactive:\t-1.68e-03 +- 3.01e-02\n",
      "[dimension 21/145]  inactive:\t-1.88e-03 +- 2.61e-02\n",
      "[dimension 22/145]  inactive:\t-7.43e-04 +- 2.81e-02\n",
      "[dimension 23/145]  inactive:\t-1.04e-03 +- 2.87e-02\n",
      "[dimension 24/145]  inactive:\t1.95e-03 +- 2.87e-02\n",
      "[dimension 25/145]  inactive:\t3.36e-03 +- 2.36e-02\n",
      "[dimension 26/145]  inactive:\t-1.60e-03 +- 3.20e-02\n",
      "[dimension 27/145]  inactive:\t8.12e-04 +- 2.57e-02\n",
      "[dimension 28/145]  inactive:\t6.55e-04 +- 1.91e-02\n",
      "[dimension 29/145]  inactive:\t-6.20e-04 +- 3.11e-02\n",
      "[dimension 30/145]  inactive:\t4.99e-04 +- 2.77e-02\n",
      "[dimension 31/145]  inactive:\t8.31e-03 +- 5.51e-02\n",
      "[dimension 32/145]  inactive:\t-2.45e-03 +- 2.69e-02\n",
      "[dimension 33/145]  inactive:\t2.27e-03 +- 4.03e-02\n",
      "[dimension 34/145]  inactive:\t6.28e-04 +- 2.01e-02\n",
      "[dimension 35/145]  inactive:\t2.09e-04 +- 2.98e-02\n",
      "[dimension 36/145]  inactive:\t4.76e-04 +- 2.59e-02\n",
      "[dimension 37/145]  inactive:\t5.55e-03 +- 3.10e-02\n",
      "[dimension 38/145]  inactive:\t-3.06e-03 +- 3.91e-02\n",
      "[dimension 39/145]  inactive:\t9.27e-04 +- 2.98e-02\n",
      "[dimension 40/145]  inactive:\t5.10e-03 +- 3.79e-02\n",
      "[dimension 41/145]  inactive:\t-2.34e-03 +- 3.46e-02\n",
      "[dimension 42/145]  inactive:\t1.16e-02 +- 7.96e-02\n",
      "[dimension 43/145]  inactive:\t-9.92e-04 +- 2.19e-02\n",
      "[dimension 44/145]  inactive:\t-1.22e-03 +- 3.45e-02\n",
      "[dimension 45/145]  inactive:\t-2.19e-04 +- 2.68e-02\n",
      "[dimension 46/145]  inactive:\t1.42e-03 +- 1.68e-02\n",
      "[dimension 47/145]  inactive:\t-2.97e-03 +- 3.27e-02\n",
      "[dimension 48/145]  inactive:\t1.20e-03 +- 2.36e-02\n",
      "[dimension 49/145]  inactive:\t3.96e-03 +- 2.82e-02\n",
      "[dimension 50/145]  inactive:\t-2.23e-03 +- 3.06e-02\n",
      "[dimension 51/145]  inactive:\t2.56e-03 +- 2.79e-02\n",
      "[dimension 52/145]  inactive:\t6.86e-03 +- 2.72e-02\n",
      "[dimension 53/145]  inactive:\t-1.27e-03 +- 2.76e-02\n",
      "[dimension 54/145]  inactive:\t1.80e-04 +- 1.95e-02\n",
      "[dimension 55/145]  inactive:\t3.53e-04 +- 1.69e-02\n",
      "[dimension 56/145]  inactive:\t-1.81e-03 +- 2.13e-02\n",
      "[dimension 57/145]  inactive:\t5.44e-04 +- 2.81e-02\n",
      "[dimension 58/145]  inactive:\t1.17e-02 +- 6.62e-02\n",
      "[dimension 59/145]  inactive:\t-5.49e-04 +- 1.80e-02\n",
      "[dimension 60/145]  inactive:\t1.38e-03 +- 3.67e-02\n",
      "[dimension 61/145]  inactive:\t2.91e-03 +- 2.98e-02\n",
      "[dimension 62/145]  inactive:\t-9.13e-04 +- 2.23e-02\n",
      "[dimension 63/145]  active:\t7.62e-01 +- 3.98e-01\n",
      "[dimension 64/145]  inactive:\t-3.00e-03 +- 2.70e-02\n",
      "[dimension 65/145]  inactive:\t-6.42e-04 +- 2.90e-02\n",
      "[dimension 66/145]  inactive:\t5.91e-04 +- 2.31e-02\n",
      "[dimension 67/145]  inactive:\t1.57e-03 +- 2.65e-02\n",
      "[dimension 68/145]  inactive:\t-9.59e-04 +- 2.29e-02\n",
      "[dimension 69/145]  inactive:\t5.32e-03 +- 5.08e-02\n",
      "[dimension 70/145]  inactive:\t3.61e-03 +- 2.44e-02\n",
      "[dimension 71/145]  inactive:\t-2.25e-04 +- 2.59e-02\n",
      "[dimension 72/145]  inactive:\t-2.13e-04 +- 2.62e-02\n",
      "[dimension 73/145]  inactive:\t1.87e-04 +- 2.01e-02\n",
      "[dimension 74/145]  inactive:\t-2.19e-03 +- 3.91e-02\n",
      "[dimension 75/145]  inactive:\t-3.91e-04 +- 2.27e-02\n",
      "[dimension 76/145]  inactive:\t6.51e-03 +- 4.36e-02\n",
      "[dimension 77/145]  inactive:\t-2.27e-03 +- 3.48e-02\n",
      "[dimension 78/145]  inactive:\t5.90e-03 +- 6.13e-02\n",
      "[dimension 79/145]  inactive:\t6.48e-03 +- 3.48e-02\n",
      "[dimension 80/145]  inactive:\t-1.20e-03 +- 3.23e-02\n",
      "[dimension 81/145]  inactive:\t7.09e-04 +- 3.12e-02\n",
      "[dimension 82/145]  inactive:\t2.75e-04 +- 1.73e-02\n",
      "[dimension 83/145]  inactive:\t-1.57e-03 +- 2.06e-02\n",
      "[dimension 84/145]  inactive:\t-1.53e-03 +- 2.88e-02\n",
      "[dimension 85/145]  inactive:\t3.66e-03 +- 3.60e-02\n",
      "[dimension 86/145]  inactive:\t-2.32e-04 +- 2.60e-02\n",
      "[dimension 87/145]  inactive:\t3.29e-03 +- 4.33e-02\n",
      "[dimension 88/145]  inactive:\t3.67e-03 +- 2.95e-02\n",
      "[dimension 89/145]  inactive:\t-1.26e-03 +- 2.37e-02\n",
      "[dimension 90/145]  inactive:\t8.95e-02 +- 2.66e-01\n",
      "[dimension 91/145]  inactive:\t-8.49e-05 +- 1.92e-02\n",
      "[dimension 92/145]  inactive:\t-1.71e-03 +- 3.17e-02\n",
      "[dimension 93/145]  inactive:\t-5.61e-04 +- 2.65e-02\n",
      "[dimension 94/145]  inactive:\t2.70e-03 +- 3.20e-02\n",
      "[dimension 95/145]  inactive:\t-7.88e-04 +- 2.15e-02\n",
      "[dimension 96/145]  inactive:\t1.76e-03 +- 4.70e-02\n",
      "[dimension 97/145]  inactive:\t2.14e-03 +- 2.37e-02\n",
      "[dimension 98/145]  inactive:\t-1.19e-03 +- 2.65e-02\n",
      "[dimension 99/145]  inactive:\t1.58e-03 +- 2.99e-02\n",
      "[dimension 100/145]  inactive:\t-7.14e-04 +- 1.63e-02\n",
      "[dimension 101/145]  inactive:\t-3.50e-03 +- 2.56e-02\n",
      "[dimension 102/145]  inactive:\t-1.52e-04 +- 3.04e-02\n",
      "[dimension 103/145]  inactive:\t8.73e-04 +- 2.26e-02\n",
      "[dimension 104/145]  inactive:\t-9.87e-04 +- 2.03e-02\n",
      "[dimension 105/145]  inactive:\t-8.14e-04 +- 2.48e-02\n",
      "[dimension 106/145]  inactive:\t5.17e-03 +- 3.24e-02\n",
      "[dimension 107/145]  inactive:\t-1.10e-03 +- 2.07e-02\n",
      "[dimension 108/145]  inactive:\t5.63e-03 +- 6.80e-02\n",
      "[dimension 109/145]  inactive:\t-7.24e-04 +- 2.00e-02\n",
      "[dimension 110/145]  inactive:\t-2.16e-03 +- 3.12e-02\n",
      "[dimension 111/145]  inactive:\t2.45e-03 +- 3.89e-02\n",
      "[dimension 112/145]  inactive:\t6.67e-03 +- 4.85e-02\n",
      "[dimension 113/145]  inactive:\t-2.00e-03 +- 2.35e-02\n",
      "[dimension 114/145]  inactive:\t-3.75e-04 +- 3.27e-02\n",
      "[dimension 115/145]  inactive:\t2.47e-03 +- 2.45e-02\n",
      "[dimension 116/145]  inactive:\t2.35e-03 +- 7.97e-02\n",
      "[dimension 117/145]  inactive:\t4.50e-03 +- 5.42e-02\n",
      "[dimension 118/145]  inactive:\t3.95e-03 +- 2.84e-02\n",
      "[dimension 119/145]  inactive:\t-3.63e-03 +- 3.90e-02\n",
      "[dimension 120/145]  inactive:\t1.64e-05 +- 2.79e-02\n",
      "[dimension 121/145]  inactive:\t6.13e-03 +- 4.46e-02\n",
      "[dimension 122/145]  inactive:\t-3.03e-03 +- 3.23e-02\n",
      "[dimension 123/145]  inactive:\t1.40e-03 +- 3.27e-02\n",
      "[dimension 124/145]  inactive:\t-2.08e-03 +- 2.09e-02\n",
      "[dimension 125/145]  inactive:\t-2.24e-03 +- 3.00e-02\n",
      "[dimension 126/145]  inactive:\t-1.79e-03 +- 2.78e-02\n",
      "[dimension 127/145]  inactive:\t5.38e-05 +- 1.90e-02\n",
      "[dimension 128/145]  inactive:\t-2.52e-03 +- 4.28e-02\n",
      "[dimension 129/145]  inactive:\t-3.77e-04 +- 2.49e-02\n",
      "[dimension 130/145]  inactive:\t3.96e-03 +- 2.91e-02\n",
      "[dimension 131/145]  inactive:\t-1.85e-03 +- 3.59e-02\n",
      "[dimension 132/145]  inactive:\t2.79e-03 +- 3.31e-02\n",
      "[dimension 133/145]  inactive:\t2.72e-03 +- 2.25e-02\n",
      "[dimension 134/145]  inactive:\t-1.10e-03 +- 2.99e-02\n",
      "[dimension 135/145]  inactive:\t1.85e-04 +- 3.28e-02\n",
      "[dimension 136/145]  inactive:\t1.13e-03 +- 2.22e-02\n",
      "[dimension 137/145]  inactive:\t-5.95e-04 +- 3.20e-02\n",
      "[dimension 138/145]  inactive:\t6.37e-04 +- 2.44e-02\n",
      "[dimension 139/145]  inactive:\t4.38e-04 +- 2.30e-02\n",
      "[dimension 140/145]  inactive:\t-2.44e-03 +- 3.65e-02\n",
      "[dimension 141/145]  inactive:\t1.27e-03 +- 2.76e-02\n",
      "[dimension 142/145]  inactive:\t1.20e-03 +- 1.80e-02\n",
      "[dimension 143/145]  inactive:\t3.36e-04 +- 3.32e-02\n",
      "[dimension 144/145]  inactive:\t1.51e-04 +- 1.86e-02\n",
      "[dimension 145/145]  inactive:\t1.79e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8917923]\n",
      "cov_act[[0.02339333]]\n",
      "Active_dimensions: [62]\n",
      "39, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.50it/s, 15 steps of size 2.02e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    384.99      1.00\n",
      "  lambda[0]      2.14      3.96      0.96      0.00      4.97    808.90      1.00\n",
      "  lambda[1]      7.15    119.94      0.92      0.00      6.07    725.64      1.00\n",
      "  lambda[2]      2.91      6.83      1.01      0.01      5.47    514.04      1.00\n",
      "  lambda[3]      4.35     32.72      0.96      0.00      6.80    965.48      1.00\n",
      "  lambda[4]      2.30      5.12      0.93      0.00      4.80    898.73      1.00\n",
      "  lambda[5]      5.09     40.00      1.05      0.00      7.00    807.01      1.00\n",
      "  lambda[6]      3.36     11.78      0.97      0.00      6.59    742.43      1.00\n",
      "  lambda[7]      2.92      7.63      0.88      0.00      6.04    701.94      1.00\n",
      "  lambda[8]      2.53      5.75      0.95      0.00      5.75    891.60      1.00\n",
      "  lambda[9]      2.58      6.26      1.05      0.00      4.93   1032.57      1.00\n",
      " lambda[10]      3.33      9.72      1.08      0.00      6.45    742.04      1.00\n",
      " lambda[11]      2.65      7.70      0.90      0.00      5.50    771.88      1.00\n",
      " lambda[12]      4.83     31.56      0.92      0.00      7.01    867.82      1.00\n",
      " lambda[13]      2.88      9.28      0.98      0.00      5.16    529.61      1.00\n",
      " lambda[14]      3.81     11.28      1.04      0.00      6.74    768.07      1.00\n",
      " lambda[15]      4.28     48.16      0.97      0.00      5.45    936.19      1.00\n",
      " lambda[16]      3.07      8.28      0.98      0.00      6.16    601.69      1.00\n",
      " lambda[17]      4.03     36.28      0.94      0.00      5.21    850.06      1.00\n",
      " lambda[18]      3.77     24.12      0.96      0.00      6.36    702.84      1.00\n",
      " lambda[19]      3.65     18.28      1.07      0.00      5.95    651.95      1.00\n",
      " lambda[20]      2.94      9.07      0.98      0.00      6.40    782.58      1.00\n",
      " lambda[21]      3.00      7.66      0.98      0.00      6.80    388.58      1.00\n",
      " lambda[22]      2.48      5.58      0.99      0.00      5.78    520.71      1.00\n",
      " lambda[23]      3.05      9.37      0.91      0.00      5.09    794.53      1.00\n",
      " lambda[24]      3.96     16.22      1.00      0.00      7.05    664.28      1.00\n",
      " lambda[25]      2.37      6.32      0.96      0.01      5.12    653.57      1.00\n",
      " lambda[26]      3.56     20.85      1.02      0.00      6.30   1013.73      1.00\n",
      " lambda[27]      2.92      8.30      0.96      0.00      6.09    627.43      1.00\n",
      " lambda[28]      2.47      6.33      0.97      0.00      5.30    743.07      1.00\n",
      " lambda[29]      3.12      8.41      0.91      0.00      6.39    582.92      1.00\n",
      " lambda[30]      3.46     11.11      0.98      0.00      7.14    621.74      1.00\n",
      " lambda[31]      3.38     13.03      0.95      0.00      5.14    922.46      1.00\n",
      " lambda[32]      3.31     11.11      1.01      0.00      6.15    553.99      1.00\n",
      " lambda[33]      2.31      5.03      0.94      0.00      4.72    684.22      1.00\n",
      " lambda[34]      2.68     11.60      0.91      0.00      5.08   1034.45      1.00\n",
      " lambda[35]      2.78      7.83      0.95      0.00      5.79    941.54      1.00\n",
      " lambda[36]      3.17     10.51      1.01      0.00      6.13    698.69      1.00\n",
      " lambda[37]      2.84      8.00      1.05      0.01      5.74    921.17      1.00\n",
      " lambda[38]      3.16      9.20      0.99      0.00      6.07    667.18      1.00\n",
      " lambda[39]      3.17     12.76      0.96      0.00      5.91    848.28      1.00\n",
      " lambda[40]      2.99      8.88      0.94      0.00      5.32    842.87      1.00\n",
      " lambda[41]    113.41   2209.67      1.02      0.00     11.48    764.31      1.00\n",
      " lambda[42]      2.40      4.88      0.92      0.00      5.28    718.96      1.00\n",
      " lambda[43]      2.81      7.33      0.95      0.00      5.81    639.71      1.00\n",
      " lambda[44]      2.81      7.03      1.01      0.00      5.69    671.80      1.00\n",
      " lambda[45]      2.68     10.08      0.98      0.00      5.06    801.99      1.00\n",
      " lambda[46]      2.54      8.37      0.93      0.00      4.61    901.25      1.00\n",
      " lambda[47]      2.60      7.27      1.00      0.01      5.69    933.87      1.00\n",
      " lambda[48]      2.78      6.82      0.97      0.01      5.93    616.33      1.00\n",
      " lambda[49]      3.01      8.10      0.94      0.00      6.48    775.86      1.00\n",
      " lambda[50]      3.30     10.18      1.00      0.00      5.83    563.47      1.00\n",
      " lambda[51]      3.52     10.03      1.05      0.00      8.43    899.79      1.00\n",
      " lambda[52]      2.94     12.73      0.95      0.00      4.51    963.97      1.00\n",
      " lambda[53]      2.96      8.63      0.94      0.00      5.71    837.39      1.00\n",
      " lambda[54]      2.34      6.37      0.93      0.01      4.63    923.44      1.00\n",
      " lambda[55]      3.22     16.53      0.89      0.00      5.49   1003.35      1.00\n",
      " lambda[56]      3.71     15.01      0.98      0.00      5.32    417.37      1.00\n",
      " lambda[57]      6.18     26.21      0.97      0.00      8.02    413.17      1.00\n",
      " lambda[58]      2.53      6.80      0.93      0.00      5.78    710.37      1.00\n",
      " lambda[59]      5.02     63.96      1.08      0.00      6.05    951.30      1.00\n",
      " lambda[60]      3.23     10.12      1.04      0.00      6.02    835.93      1.00\n",
      " lambda[61]      2.54      5.25      0.94      0.00      5.89    856.35      1.00\n",
      " lambda[62]   3273.42  47846.41    191.89      0.01   1645.11    473.53      1.00\n",
      " lambda[63]      2.72      6.80      1.00      0.01      5.63    932.80      1.00\n",
      " lambda[64]      2.55      6.21      1.02      0.00      5.06    620.47      1.00\n",
      " lambda[65]      2.73      6.99      0.94      0.00      5.65    789.34      1.00\n",
      " lambda[66]      2.76      6.73      1.01      0.00      6.09    723.82      1.00\n",
      " lambda[67]      3.53     14.88      1.02      0.00      6.04    590.22      1.00\n",
      " lambda[68]      4.20     12.66      1.02      0.00      8.12    268.43      1.00\n",
      " lambda[69]      3.27     15.04      0.95      0.00      5.91    632.20      1.00\n",
      " lambda[70]      3.15      8.89      1.01      0.01      5.94    653.43      1.00\n",
      " lambda[71]      6.30     92.21      0.98      0.00      5.03    605.72      1.00\n",
      " lambda[72]      2.48      7.25      0.95      0.01      4.75    841.85      1.00\n",
      " lambda[73]      3.47     14.74      0.96      0.00      5.98    867.13      1.00\n",
      " lambda[74]      2.59      6.27      0.95      0.00      5.53    783.67      1.00\n",
      " lambda[75]      5.00     21.67      1.08      0.00      7.83    619.70      1.00\n",
      " lambda[76]      4.11     23.99      1.03      0.00      6.57    464.21      1.00\n",
      " lambda[77]     15.56    140.71      1.06      0.00      7.70    238.82      1.00\n",
      " lambda[78]      3.51     13.30      1.01      0.00      5.92    664.66      1.00\n",
      " lambda[79]      3.24     12.40      0.95      0.00      5.49    628.87      1.00\n",
      " lambda[80]      3.60     13.00      1.03      0.00      6.93    486.45      1.00\n",
      " lambda[81]      3.03      9.40      0.99      0.00      6.28    638.12      1.00\n",
      " lambda[82]      2.65     11.13      0.93      0.00      4.42    531.28      1.00\n",
      " lambda[83]      3.21      9.47      0.97      0.00      6.29    702.39      1.00\n",
      " lambda[84]      4.29     24.37      1.01      0.00      6.20    745.36      1.00\n",
      " lambda[85]      2.54      6.20      0.92      0.00      5.16    510.39      1.00\n",
      " lambda[86]      4.54     26.54      0.96      0.00      6.99    585.81      1.00\n",
      " lambda[87]      3.24      8.82      1.02      0.00      6.64    813.46      1.00\n",
      " lambda[88]      2.61      7.59      0.97      0.00      5.15    758.78      1.00\n",
      " lambda[89]     50.00    458.65      1.16      0.00     18.04    727.66      1.00\n",
      " lambda[90]      2.39      7.38      0.96      0.01      4.68    977.93      1.00\n",
      " lambda[91]      2.62      7.08      1.01      0.01      5.45    771.24      1.00\n",
      " lambda[92]      2.91      8.19      0.98      0.00      5.36    543.64      1.00\n",
      " lambda[93]      2.49      7.35      1.02      0.00      4.64    593.89      1.00\n",
      " lambda[94]      3.13      9.26      1.00      0.01      6.34    721.63      1.00\n",
      " lambda[95]      3.21     11.07      0.94      0.00      5.41    929.84      1.00\n",
      " lambda[96]      4.45     31.56      0.98      0.00      6.19    363.02      1.00\n",
      " lambda[97]      2.72      7.22      0.99      0.00      5.19    820.49      1.00\n",
      " lambda[98]      4.20     31.98      1.04      0.00      5.96    944.63      1.00\n",
      " lambda[99]      2.60      5.67      0.96      0.00      5.68    798.95      1.00\n",
      "lambda[100]      3.09     10.78      0.98      0.00      6.12    945.35      1.00\n",
      "lambda[101]      3.57     10.84      1.05      0.00      6.26    621.55      1.00\n",
      "lambda[102]      3.13     11.24      1.01      0.00      5.74    596.50      1.00\n",
      "lambda[103]      2.21      3.83      0.98      0.00      5.11    965.91      1.00\n",
      "lambda[104]      2.67      7.40      0.89      0.00      4.80    749.69      1.00\n",
      "lambda[105]      3.64     11.57      1.05      0.00      7.23    498.64      1.00\n",
      "lambda[106]      2.70      5.83      1.00      0.00      6.74    637.35      1.00\n",
      "lambda[107]      4.62     27.51      0.98      0.00      5.72    783.89      1.00\n",
      "lambda[108]      2.35      6.01      0.93      0.00      5.15    927.08      1.00\n",
      "lambda[109]     28.99    652.38      0.98      0.00      5.99    873.29      1.00\n",
      "lambda[110]      3.58     12.63      1.00      0.00      5.90    547.48      1.01\n",
      "lambda[111]      4.28     18.51      1.08      0.00      7.68   1001.50      1.00\n",
      "lambda[112]      2.04      3.81      0.96      0.01      4.61    804.08      1.00\n",
      "lambda[113]      9.24    110.68      1.02      0.00      7.99    871.21      1.00\n",
      "lambda[114]      3.56     32.87      0.95      0.00      5.24   1006.37      1.00\n",
      "lambda[115]      4.78     45.27      0.95      0.00      6.08    551.89      1.00\n",
      "lambda[116]      3.89     26.47      1.01      0.01      6.27    973.45      1.00\n",
      "lambda[117]      3.56     24.60      0.87      0.00      5.33    942.51      1.00\n",
      "lambda[118]      3.17      9.85      0.92      0.00      6.36    559.67      1.00\n",
      "lambda[119]      3.02      8.48      0.97      0.00      5.79    936.81      1.00\n",
      "lambda[120]      4.12     17.29      1.01      0.00      6.76    996.59      1.00\n",
      "lambda[121]      3.25     12.47      1.01      0.00      5.91    898.11      1.00\n",
      "lambda[122]      4.72     28.37      1.01      0.00      5.53    492.72      1.00\n",
      "lambda[123]      2.69      6.89      0.95      0.00      5.37    680.94      1.00\n",
      "lambda[124]      3.01      9.83      0.98      0.00      6.07    498.10      1.00\n",
      "lambda[125]      2.49      5.10      0.99      0.01      5.52    715.36      1.00\n",
      "lambda[126]      2.33      8.75      1.00      0.00      4.53    789.20      1.00\n",
      "lambda[127]      4.10     22.85      0.96      0.00      5.68    451.92      1.00\n",
      "lambda[128]      2.46      5.33      0.96      0.00      5.07    648.35      1.00\n",
      "lambda[129]      2.67      7.15      0.94      0.00      5.25    816.36      1.00\n",
      "lambda[130]      4.84     28.73      0.95      0.00      6.66    632.01      1.00\n",
      "lambda[131]      4.09     24.39      0.97      0.00      5.76    778.76      1.00\n",
      "lambda[132]      2.70      7.06      1.01      0.00      5.38    906.68      1.00\n",
      "lambda[133]      2.44      5.80      0.95      0.00      5.20    990.78      1.00\n",
      "lambda[134]      2.73      7.36      0.93      0.01      5.68    961.13      1.00\n",
      "lambda[135]      2.65     14.84      0.91      0.00      4.73    797.21      1.00\n",
      "lambda[136]      2.88      7.84      0.92      0.00      5.90    572.52      1.00\n",
      "lambda[137]      3.41     17.28      1.08      0.01      6.21    905.85      1.00\n",
      "lambda[138]      2.98      8.05      0.97      0.00      6.72    584.33      1.00\n",
      "lambda[139]      2.33      5.86      0.94      0.00      4.97    783.76      1.00\n",
      "lambda[140]      3.47     12.27      1.04      0.00      6.12    737.17      1.00\n",
      "lambda[141]      2.71      8.16      0.88      0.00      5.62    878.68      1.00\n",
      "lambda[142]      4.03     19.85      0.97      0.00      6.55    944.84      1.00\n",
      "lambda[143]      2.27      5.64      0.93      0.00      4.41    688.88      1.00\n",
      "        msq      1.39      0.87      1.17      0.45      2.32    629.02      1.00\n",
      "      sigma      3.24      4.22      1.48      0.00      8.48   1042.12      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.12    677.95      1.00\n",
      "       xisq      0.12      0.07      0.11      0.04      0.21    658.13      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 32.394256830215454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.85e-04 +- 1.81e-02\n",
      "[dimension 02/145]  inactive:\t-7.67e-04 +- 2.68e-02\n",
      "[dimension 03/145]  inactive:\t1.26e-04 +- 2.66e-02\n",
      "[dimension 04/145]  inactive:\t6.42e-03 +- 4.48e-02\n",
      "[dimension 05/145]  inactive:\t-7.42e-04 +- 2.06e-02\n",
      "[dimension 06/145]  inactive:\t4.14e-03 +- 4.82e-02\n",
      "[dimension 07/145]  inactive:\t6.14e-04 +- 2.13e-02\n",
      "[dimension 08/145]  inactive:\t9.35e-04 +- 3.03e-02\n",
      "[dimension 09/145]  inactive:\t3.80e-04 +- 2.44e-02\n",
      "[dimension 10/145]  inactive:\t4.02e-04 +- 1.90e-02\n",
      "[dimension 11/145]  inactive:\t-4.96e-04 +- 3.32e-02\n",
      "[dimension 12/145]  inactive:\t8.30e-05 +- 2.52e-02\n",
      "[dimension 13/145]  inactive:\t4.71e-03 +- 3.96e-02\n",
      "[dimension 14/145]  inactive:\t-1.86e-03 +- 2.61e-02\n",
      "[dimension 15/145]  inactive:\t1.37e-03 +- 4.16e-02\n",
      "[dimension 16/145]  inactive:\t1.05e-03 +- 2.11e-02\n",
      "[dimension 17/145]  inactive:\t1.37e-04 +- 3.29e-02\n",
      "[dimension 18/145]  inactive:\t-4.59e-04 +- 2.71e-02\n",
      "[dimension 19/145]  inactive:\t-2.55e-03 +- 2.21e-02\n",
      "[dimension 20/145]  inactive:\t-1.61e-03 +- 3.11e-02\n",
      "[dimension 21/145]  inactive:\t-1.60e-03 +- 2.28e-02\n",
      "[dimension 22/145]  inactive:\t-5.05e-04 +- 2.27e-02\n",
      "[dimension 23/145]  inactive:\t-5.24e-04 +- 2.38e-02\n",
      "[dimension 24/145]  inactive:\t1.59e-03 +- 2.76e-02\n",
      "[dimension 25/145]  inactive:\t4.57e-03 +- 2.80e-02\n",
      "[dimension 26/145]  inactive:\t-5.59e-04 +- 2.50e-02\n",
      "[dimension 27/145]  inactive:\t1.16e-03 +- 2.56e-02\n",
      "[dimension 28/145]  inactive:\t9.49e-04 +- 2.04e-02\n",
      "[dimension 29/145]  inactive:\t-3.36e-04 +- 2.17e-02\n",
      "[dimension 30/145]  inactive:\t1.72e-03 +- 3.29e-02\n",
      "[dimension 31/145]  inactive:\t5.53e-03 +- 4.10e-02\n",
      "[dimension 32/145]  inactive:\t-8.23e-04 +- 2.91e-02\n",
      "[dimension 33/145]  inactive:\t5.47e-03 +- 5.49e-02\n",
      "[dimension 34/145]  inactive:\t8.11e-04 +- 1.93e-02\n",
      "[dimension 35/145]  inactive:\t4.65e-04 +- 2.67e-02\n",
      "[dimension 36/145]  inactive:\t1.47e-03 +- 2.79e-02\n",
      "[dimension 37/145]  inactive:\t4.98e-03 +- 3.10e-02\n",
      "[dimension 38/145]  inactive:\t-1.45e-03 +- 2.99e-02\n",
      "[dimension 39/145]  inactive:\t1.74e-03 +- 3.40e-02\n",
      "[dimension 40/145]  inactive:\t4.18e-03 +- 3.53e-02\n",
      "[dimension 41/145]  inactive:\t-1.50e-03 +- 2.74e-02\n",
      "[dimension 42/145]  inactive:\t3.17e-02 +- 1.54e-01\n",
      "[dimension 43/145]  inactive:\t-4.64e-04 +- 1.97e-02\n",
      "[dimension 44/145]  inactive:\t-4.52e-04 +- 2.67e-02\n",
      "[dimension 45/145]  inactive:\t-3.28e-04 +- 2.55e-02\n",
      "[dimension 46/145]  inactive:\t9.33e-04 +- 1.53e-02\n",
      "[dimension 47/145]  inactive:\t-1.32e-03 +- 3.17e-02\n",
      "[dimension 48/145]  inactive:\t1.67e-03 +- 2.50e-02\n",
      "[dimension 49/145]  inactive:\t3.32e-03 +- 2.55e-02\n",
      "[dimension 50/145]  inactive:\t-1.49e-03 +- 2.54e-02\n",
      "[dimension 51/145]  inactive:\t4.34e-03 +- 3.87e-02\n",
      "[dimension 52/145]  inactive:\t6.92e-03 +- 2.75e-02\n",
      "[dimension 53/145]  inactive:\t-4.83e-04 +- 2.44e-02\n",
      "[dimension 54/145]  inactive:\t7.98e-04 +- 2.31e-02\n",
      "[dimension 55/145]  inactive:\t5.67e-04 +- 1.72e-02\n",
      "[dimension 56/145]  inactive:\t-2.08e-03 +- 2.18e-02\n",
      "[dimension 57/145]  inactive:\t2.75e-03 +- 4.04e-02\n",
      "[dimension 58/145]  inactive:\t1.70e-02 +- 8.39e-02\n",
      "[dimension 59/145]  inactive:\t-4.74e-04 +- 1.99e-02\n",
      "[dimension 60/145]  inactive:\t3.12e-03 +- 3.74e-02\n",
      "[dimension 61/145]  inactive:\t2.82e-03 +- 2.46e-02\n",
      "[dimension 62/145]  inactive:\t-3.86e-04 +- 2.37e-02\n",
      "[dimension 63/145]  active:\t6.90e-01 +- 4.26e-01\n",
      "[dimension 64/145]  inactive:\t-3.68e-03 +- 2.99e-02\n",
      "[dimension 65/145]  inactive:\t-5.45e-04 +- 2.22e-02\n",
      "[dimension 66/145]  inactive:\t1.92e-05 +- 2.43e-02\n",
      "[dimension 67/145]  inactive:\t1.08e-03 +- 2.47e-02\n",
      "[dimension 68/145]  inactive:\t-1.07e-03 +- 3.29e-02\n",
      "[dimension 69/145]  inactive:\t8.05e-03 +- 6.37e-02\n",
      "[dimension 70/145]  inactive:\t3.46e-03 +- 2.37e-02\n",
      "[dimension 71/145]  inactive:\t1.56e-04 +- 3.26e-02\n",
      "[dimension 72/145]  inactive:\t1.21e-03 +- 2.68e-02\n",
      "[dimension 73/145]  inactive:\t3.11e-04 +- 1.76e-02\n",
      "[dimension 74/145]  inactive:\t-1.49e-03 +- 2.55e-02\n",
      "[dimension 75/145]  inactive:\t6.24e-04 +- 2.54e-02\n",
      "[dimension 76/145]  inactive:\t7.56e-03 +- 4.74e-02\n",
      "[dimension 77/145]  inactive:\t-1.88e-03 +- 3.66e-02\n",
      "[dimension 78/145]  inactive:\t1.98e-02 +- 1.13e-01\n",
      "[dimension 79/145]  inactive:\t6.26e-03 +- 3.33e-02\n",
      "[dimension 80/145]  inactive:\t-3.13e-04 +- 2.89e-02\n",
      "[dimension 81/145]  inactive:\t1.13e-03 +- 3.88e-02\n",
      "[dimension 82/145]  inactive:\t6.08e-04 +- 1.89e-02\n",
      "[dimension 83/145]  inactive:\t-1.31e-03 +- 1.77e-02\n",
      "[dimension 84/145]  inactive:\t-1.25e-03 +- 2.69e-02\n",
      "[dimension 85/145]  inactive:\t4.92e-03 +- 3.93e-02\n",
      "[dimension 86/145]  inactive:\t-4.07e-04 +- 1.76e-02\n",
      "[dimension 87/145]  inactive:\t3.47e-03 +- 4.80e-02\n",
      "[dimension 88/145]  inactive:\t3.22e-03 +- 2.56e-02\n",
      "[dimension 89/145]  inactive:\t-5.84e-04 +- 2.00e-02\n",
      "[dimension 90/145]  inactive:\t5.77e-02 +- 2.12e-01\n",
      "[dimension 91/145]  inactive:\t1.49e-04 +- 1.81e-02\n",
      "[dimension 92/145]  inactive:\t-9.65e-04 +- 2.20e-02\n",
      "[dimension 93/145]  inactive:\t-7.34e-04 +- 2.91e-02\n",
      "[dimension 94/145]  inactive:\t1.34e-03 +- 2.34e-02\n",
      "[dimension 95/145]  inactive:\t-3.80e-04 +- 2.49e-02\n",
      "[dimension 96/145]  inactive:\t1.39e-03 +- 4.04e-02\n",
      "[dimension 97/145]  inactive:\t3.10e-03 +- 2.61e-02\n",
      "[dimension 98/145]  inactive:\t-1.50e-04 +- 2.21e-02\n",
      "[dimension 99/145]  inactive:\t3.88e-03 +- 4.40e-02\n",
      "[dimension 100/145]  inactive:\t-5.65e-04 +- 1.74e-02\n",
      "[dimension 101/145]  inactive:\t-2.19e-03 +- 1.99e-02\n",
      "[dimension 102/145]  inactive:\t-1.40e-04 +- 3.14e-02\n",
      "[dimension 103/145]  inactive:\t2.35e-03 +- 3.44e-02\n",
      "[dimension 104/145]  inactive:\t-7.90e-04 +- 1.77e-02\n",
      "[dimension 105/145]  inactive:\t-2.60e-04 +- 2.15e-02\n",
      "[dimension 106/145]  inactive:\t6.27e-03 +- 3.61e-02\n",
      "[dimension 107/145]  inactive:\t-9.69e-04 +- 2.16e-02\n",
      "[dimension 108/145]  inactive:\t6.84e-03 +- 6.32e-02\n",
      "[dimension 109/145]  inactive:\t-4.73e-04 +- 1.70e-02\n",
      "[dimension 110/145]  inactive:\t-1.05e-03 +- 4.10e-02\n",
      "[dimension 111/145]  inactive:\t3.58e-03 +- 4.20e-02\n",
      "[dimension 112/145]  inactive:\t7.45e-03 +- 5.42e-02\n",
      "[dimension 113/145]  inactive:\t-1.08e-03 +- 2.08e-02\n",
      "[dimension 114/145]  inactive:\t4.64e-03 +- 6.05e-02\n",
      "[dimension 115/145]  inactive:\t1.68e-03 +- 2.12e-02\n",
      "[dimension 116/145]  inactive:\t1.41e-03 +- 3.89e-02\n",
      "[dimension 117/145]  inactive:\t3.94e-03 +- 4.27e-02\n",
      "[dimension 118/145]  inactive:\t2.72e-03 +- 2.29e-02\n",
      "[dimension 119/145]  inactive:\t-2.57e-03 +- 3.21e-02\n",
      "[dimension 120/145]  inactive:\t3.82e-04 +- 3.28e-02\n",
      "[dimension 121/145]  inactive:\t4.34e-03 +- 3.62e-02\n",
      "[dimension 122/145]  inactive:\t-2.63e-03 +- 3.35e-02\n",
      "[dimension 123/145]  inactive:\t5.81e-03 +- 5.87e-02\n",
      "[dimension 124/145]  inactive:\t-1.63e-03 +- 1.90e-02\n",
      "[dimension 125/145]  inactive:\t-1.62e-03 +- 2.69e-02\n",
      "[dimension 126/145]  inactive:\t-6.32e-04 +- 2.28e-02\n",
      "[dimension 127/145]  inactive:\t5.09e-05 +- 1.52e-02\n",
      "[dimension 128/145]  inactive:\t-5.93e-04 +- 3.39e-02\n",
      "[dimension 129/145]  inactive:\t-4.30e-04 +- 2.42e-02\n",
      "[dimension 130/145]  inactive:\t3.12e-03 +- 2.82e-02\n",
      "[dimension 131/145]  inactive:\t-1.38e-03 +- 3.62e-02\n",
      "[dimension 132/145]  inactive:\t3.79e-03 +- 3.85e-02\n",
      "[dimension 133/145]  inactive:\t2.33e-03 +- 1.91e-02\n",
      "[dimension 134/145]  inactive:\t-4.07e-04 +- 2.33e-02\n",
      "[dimension 135/145]  inactive:\t2.71e-04 +- 2.25e-02\n",
      "[dimension 136/145]  inactive:\t1.05e-03 +- 1.94e-02\n",
      "[dimension 137/145]  inactive:\t-1.86e-04 +- 2.65e-02\n",
      "[dimension 138/145]  inactive:\t8.91e-04 +- 2.58e-02\n",
      "[dimension 139/145]  inactive:\t3.03e-04 +- 2.64e-02\n",
      "[dimension 140/145]  inactive:\t-7.32e-04 +- 2.44e-02\n",
      "[dimension 141/145]  inactive:\t1.86e-03 +- 3.24e-02\n",
      "[dimension 142/145]  inactive:\t1.65e-03 +- 1.97e-02\n",
      "[dimension 143/145]  inactive:\t6.54e-04 +- 3.31e-02\n",
      "[dimension 144/145]  inactive:\t3.17e-04 +- 1.93e-02\n",
      "[dimension 145/145]  inactive:\t-1.46e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[3.4451485e-05]\n",
      "cov_act[[3.8444996e-06]]\n",
      "Active_dimensions: [62]\n",
      "40, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:30<00:00, 49.07it/s, 31 steps of size 1.85e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    786.03      1.00\n",
      "  lambda[0]      2.55     12.18      0.93      0.00      4.91    924.48      1.00\n",
      "  lambda[1]      3.15     10.76      0.96      0.00      5.67    493.92      1.00\n",
      "  lambda[2]      2.84      7.78      0.97      0.00      6.05    578.44      1.00\n",
      "  lambda[3]      5.76     37.38      1.01      0.00      6.18    633.94      1.00\n",
      "  lambda[4]      2.65      6.02      1.04      0.00      5.80    774.31      1.00\n",
      "  lambda[5]      3.29     13.94      0.98      0.00      5.92    812.77      1.00\n",
      "  lambda[6]      2.72      7.93      0.97      0.00      5.14    933.60      1.00\n",
      "  lambda[7]      3.09      9.28      0.99      0.00      6.13    387.75      1.00\n",
      "  lambda[8]      2.50      5.83      1.00      0.00      5.12    682.27      1.00\n",
      "  lambda[9]      2.54      6.64      0.97      0.00      4.95    649.07      1.00\n",
      " lambda[10]      3.42     13.90      1.08      0.00      5.80    779.45      1.00\n",
      " lambda[11]      2.98     10.30      0.94      0.00      6.14    663.15      1.00\n",
      " lambda[12]      4.60     19.30      1.09      0.00      6.67    759.93      1.00\n",
      " lambda[13]      3.03     11.61      1.00      0.00      5.47    723.66      1.00\n",
      " lambda[14]      3.66     19.44      0.97      0.00      4.80    955.36      1.00\n",
      " lambda[15]      2.70      7.59      0.98      0.00      5.46    996.76      1.00\n",
      " lambda[16]      4.05     14.64      0.97      0.00      8.00    635.85      1.01\n",
      " lambda[17]      3.26     18.13      0.96      0.00      5.16    454.82      1.00\n",
      " lambda[18]      2.58      6.25      0.95      0.00      5.64    964.08      1.00\n",
      " lambda[19]      3.56     12.89      0.97      0.00      6.11    789.11      1.00\n",
      " lambda[20]      2.37      5.08      0.93      0.00      5.56    865.33      1.00\n",
      " lambda[21]      2.47      5.05      1.01      0.00      5.54    962.29      1.00\n",
      " lambda[22]      2.71      6.97      1.00      0.00      5.19    853.63      1.00\n",
      " lambda[23]      3.44     10.00      0.97      0.00      7.30    754.44      1.00\n",
      " lambda[24]      3.16      9.32      0.98      0.00      5.80    676.25      1.00\n",
      " lambda[25]      2.96      7.78      1.04      0.01      5.25    491.40      1.00\n",
      " lambda[26]      3.22      9.69      1.03      0.00      5.35    284.68      1.00\n",
      " lambda[27]      2.43      5.27      0.97      0.00      5.18    636.92      1.00\n",
      " lambda[28]      2.61      6.46      0.99      0.00      5.96    869.42      1.00\n",
      " lambda[29]      2.76      8.20      0.93      0.00      5.19    520.82      1.00\n",
      " lambda[30]      3.78     14.79      1.01      0.01      7.61    898.64      1.00\n",
      " lambda[31]      4.10     22.26      0.92      0.00      5.97    619.89      1.00\n",
      " lambda[32]      3.67     15.64      0.99      0.00      6.81    585.34      1.00\n",
      " lambda[33]      2.55     10.01      0.98      0.02      5.34    997.99      1.00\n",
      " lambda[34]      3.60     12.36      0.96      0.00      6.18    532.48      1.00\n",
      " lambda[35]      2.58      7.47      1.04      0.00      5.61    913.33      1.00\n",
      " lambda[36]      3.79     17.42      0.98      0.00      5.97    700.92      1.00\n",
      " lambda[37]      5.51     53.62      1.11      0.00      6.29    568.41      1.00\n",
      " lambda[38]      2.85      7.88      0.95      0.00      5.99    806.34      1.01\n",
      " lambda[39]      3.19      8.21      1.03      0.00      6.33    671.88      1.00\n",
      " lambda[40]      4.44     20.47      0.91      0.00      6.40    422.45      1.01\n",
      " lambda[41]      8.86     81.95      0.92      0.00      9.56    760.20      1.00\n",
      " lambda[42]      2.57      6.68      0.98      0.00      5.58    739.04      1.00\n",
      " lambda[43]      4.15     29.14      0.97      0.00      6.58   1024.15      1.00\n",
      " lambda[44]      3.35     11.97      1.00      0.00      6.09    620.45      1.00\n",
      " lambda[45]      2.62      6.07      0.99      0.00      5.30    655.80      1.00\n",
      " lambda[46]      2.98      7.87      1.07      0.00      5.75    898.20      1.00\n",
      " lambda[47]      2.59      6.47      0.93      0.00      5.03    606.09      1.00\n",
      " lambda[48]      3.08     11.24      1.06      0.00      5.26    845.94      1.00\n",
      " lambda[49]      3.08      8.90      0.94      0.00      5.99    757.96      1.00\n",
      " lambda[50]      2.55      8.31      0.94      0.00      4.75    433.81      1.00\n",
      " lambda[51]      3.94     15.99      1.00      0.00      6.89    666.32      1.00\n",
      " lambda[52]      2.82      7.66      0.98      0.00      5.95    943.76      1.00\n",
      " lambda[53]      2.58      6.61      0.95      0.00      5.28    825.10      1.00\n",
      " lambda[54]      2.59      7.52      0.99      0.00      4.91    611.56      1.00\n",
      " lambda[55]      3.10     13.43      0.98      0.00      5.46    960.96      1.00\n",
      " lambda[56]      2.67      6.45      0.91      0.00      5.35    818.20      1.00\n",
      " lambda[57]      4.08     14.37      1.05      0.00      7.30    825.39      1.00\n",
      " lambda[58]      2.25      4.81      0.98      0.00      4.66    675.23      1.00\n",
      " lambda[59]      3.38     17.47      0.94      0.00      5.78    894.69      1.00\n",
      " lambda[60]      2.94      8.80      0.94      0.00      5.40    716.77      1.00\n",
      " lambda[61]      2.78      8.62      1.00      0.00      5.22    694.01      1.00\n",
      " lambda[62]   1918.31  26235.25    213.46      0.00   1167.12    919.51      1.00\n",
      " lambda[63]      2.30      5.96      1.02      0.00      4.73   1058.47      1.00\n",
      " lambda[64]      3.36     12.14      0.97      0.00      5.93    621.31      1.00\n",
      " lambda[65]      3.14     11.27      0.95      0.00      5.59    679.57      1.00\n",
      " lambda[66]      5.69     68.42      0.99      0.00      6.19    643.53      1.00\n",
      " lambda[67]      2.77      7.84      0.87      0.00      5.11    744.58      1.00\n",
      " lambda[68]      5.09     59.27      0.98      0.00      5.32    856.11      1.00\n",
      " lambda[69]      2.50      6.49      0.93      0.00      5.44    823.73      1.00\n",
      " lambda[70]      2.68      6.41      1.01      0.01      5.35    587.65      1.00\n",
      " lambda[71]      2.87      8.20      0.94      0.00      5.98    480.88      1.00\n",
      " lambda[72]      2.44      6.68      0.99      0.01      5.25    798.57      1.00\n",
      " lambda[73]      2.92      6.71      1.07      0.00      6.46    784.16      1.00\n",
      " lambda[74]      2.45      4.75      1.00      0.00      5.52    979.87      1.00\n",
      " lambda[75]      4.99     30.60      1.02      0.00      7.47    964.43      1.00\n",
      " lambda[76]      3.22      9.08      1.03      0.00      6.08    747.34      1.00\n",
      " lambda[77]      3.37     10.75      1.04      0.00      6.94    612.64      1.00\n",
      " lambda[78]      3.02      7.57      1.01      0.01      6.35    779.73      1.00\n",
      " lambda[79]      3.45     16.71      1.03      0.00      5.62    717.69      1.00\n",
      " lambda[80]      2.76      7.42      1.04      0.01      5.65    898.97      1.00\n",
      " lambda[81]      2.52      5.83      0.92      0.00      5.20   1098.38      1.00\n",
      " lambda[82]      2.81      7.09      1.00      0.00      4.98    606.98      1.00\n",
      " lambda[83]      3.26     14.65      0.95      0.00      5.31    776.08      1.00\n",
      " lambda[84]      3.44     12.92      1.03      0.00      6.29    702.45      1.00\n",
      " lambda[85]      2.76      8.46      0.90      0.00      5.72    713.51      1.00\n",
      " lambda[86]      2.57      6.07      0.99      0.00      5.40    765.98      1.00\n",
      " lambda[87]      3.28     12.91      0.96      0.00      6.43    607.89      1.00\n",
      " lambda[88]      3.08      7.32      0.97      0.00      7.16    664.34      1.00\n",
      " lambda[89]     21.47    118.61      1.07      0.00     13.33    272.11      1.00\n",
      " lambda[90]      2.97      9.72      1.04      0.00      5.75    712.29      1.00\n",
      " lambda[91]      3.31     12.04      1.01      0.00      5.82    456.50      1.00\n",
      " lambda[92]      2.38      5.20      0.98      0.00      5.16    900.58      1.00\n",
      " lambda[93]      2.84      7.79      1.03      0.00      5.37    537.08      1.00\n",
      " lambda[94]      2.61      7.57      0.92      0.00      5.02    917.35      1.00\n",
      " lambda[95]      2.87      7.31      1.02      0.00      6.16    875.49      1.00\n",
      " lambda[96]      2.58      6.47      0.96      0.00      4.93    533.48      1.00\n",
      " lambda[97]      3.20     12.47      1.00      0.00      5.83    598.86      1.00\n",
      " lambda[98]      4.01     45.20      1.05      0.00      5.41    936.60      1.00\n",
      " lambda[99]      2.65      8.07      0.93      0.00      4.69    806.76      1.00\n",
      "lambda[100]      2.93      9.23      0.93      0.00      5.90    763.88      1.00\n",
      "lambda[101]      2.90      7.15      0.93      0.00      6.35    685.80      1.00\n",
      "lambda[102]      3.24      9.64      0.94      0.00      5.86    594.21      1.00\n",
      "lambda[103]      2.24      4.16      0.98      0.00      5.42    858.53      1.00\n",
      "lambda[104]      2.68      6.13      0.95      0.00      5.57    755.06      1.00\n",
      "lambda[105]      3.97     19.85      1.12      0.00      7.03    924.51      1.00\n",
      "lambda[106]      2.77      7.17      1.00      0.00      6.24    627.77      1.00\n",
      "lambda[107]      2.87     10.18      1.01      0.00      4.85    824.32      1.00\n",
      "lambda[108]      2.25      4.55      0.94      0.00      4.80    832.06      1.00\n",
      "lambda[109]      5.32     53.78      0.94      0.00      5.32    968.93      1.00\n",
      "lambda[110]      3.79     15.06      1.00      0.00      6.59    760.64      1.00\n",
      "lambda[111]      4.83     23.60      0.92      0.00      8.16    691.94      1.00\n",
      "lambda[112]      2.59      7.05      0.97      0.00      5.67    918.20      1.00\n",
      "lambda[113]      3.21     10.91      1.00      0.00      6.60    679.28      1.00\n",
      "lambda[114]      3.68     16.00      1.00      0.00      6.76    851.41      1.00\n",
      "lambda[115]      3.47     14.02      0.97      0.00      6.28    949.25      1.00\n",
      "lambda[116]      3.42     20.25      0.99      0.00      5.43    444.37      1.00\n",
      "lambda[117]      3.61     11.39      1.02      0.00      6.95    646.47      1.00\n",
      "lambda[118]      3.21      9.56      0.97      0.00      5.46    815.43      1.00\n",
      "lambda[119]      2.88     13.75      1.00      0.00      5.57   1023.17      1.00\n",
      "lambda[120]      3.64     11.47      0.95      0.00      7.11    740.52      1.00\n",
      "lambda[121]      3.08     11.48      1.02      0.00      6.56    806.66      1.00\n",
      "lambda[122]      3.13      9.68      0.98      0.00      5.89    501.59      1.00\n",
      "lambda[123]      3.08      9.20      0.89      0.00      5.98    740.64      1.00\n",
      "lambda[124]      2.66      5.99      1.04      0.00      5.84    948.19      1.00\n",
      "lambda[125]      3.00     10.50      1.02      0.01      5.94    503.17      1.00\n",
      "lambda[126]      2.92      9.04      0.95      0.00      5.61    653.66      1.00\n",
      "lambda[127]      3.05     10.05      0.99      0.00      5.28    807.82      1.00\n",
      "lambda[128]      2.74      9.51      0.91      0.01      5.59    556.80      1.00\n",
      "lambda[129]      3.63     15.90      1.03      0.00      6.19    958.74      1.00\n",
      "lambda[130]      4.44     42.18      0.95      0.00      6.47    990.19      1.00\n",
      "lambda[131]      3.22     18.73      0.96      0.00      5.26    539.99      1.00\n",
      "lambda[132]      3.36     14.07      0.98      0.00      6.35    397.08      1.00\n",
      "lambda[133]      3.11      9.74      0.97      0.00      5.77    425.97      1.00\n",
      "lambda[134]      3.58     13.38      0.88      0.00      6.41    740.62      1.00\n",
      "lambda[135]      2.80      9.45      0.87      0.00      4.88    824.75      1.00\n",
      "lambda[136]      2.74      6.90      0.95      0.00      5.47    637.79      1.01\n",
      "lambda[137]      3.33     11.24      0.93      0.00      5.60    580.05      1.00\n",
      "lambda[138]      3.05     13.11      0.96      0.00      4.76    863.97      1.00\n",
      "lambda[139]      2.69      7.38      1.09      0.00      5.30    911.13      1.00\n",
      "lambda[140]      3.27     11.09      0.95      0.00      5.73    708.00      1.00\n",
      "lambda[141]      2.24      4.78      0.85      0.00      5.08    991.15      1.00\n",
      "lambda[142]      3.82     16.42      0.97      0.01      6.14    571.86      1.00\n",
      "lambda[143]      2.47      6.17      0.93      0.00      4.96    517.11      1.00\n",
      "        msq  19254.90 214749.61     29.02      0.86    805.46    742.70      1.00\n",
      "      sigma      4.52      6.00      2.03      0.02     12.10   1259.99      1.00\n",
      "    var_obs      0.09      0.01      0.09      0.06      0.11   1571.42      1.00\n",
      "       xisq     30.36    266.60      1.68      0.10     22.16    773.64      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.34775924682617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.35e-04 +- 1.75e-02\n",
      "[dimension 02/145]  inactive:\t-1.36e-03 +- 2.95e-02\n",
      "[dimension 03/145]  inactive:\t-3.73e-04 +- 2.69e-02\n",
      "[dimension 04/145]  inactive:\t7.58e-03 +- 5.14e-02\n",
      "[dimension 05/145]  inactive:\t-1.37e-03 +- 2.46e-02\n",
      "[dimension 06/145]  inactive:\t2.56e-03 +- 3.92e-02\n",
      "[dimension 07/145]  inactive:\t3.68e-04 +- 1.91e-02\n",
      "[dimension 08/145]  inactive:\t3.70e-04 +- 3.21e-02\n",
      "[dimension 09/145]  inactive:\t4.78e-05 +- 2.03e-02\n",
      "[dimension 10/145]  inactive:\t5.35e-04 +- 1.87e-02\n",
      "[dimension 11/145]  inactive:\t-1.73e-03 +- 2.63e-02\n",
      "[dimension 12/145]  inactive:\t-1.23e-03 +- 2.74e-02\n",
      "[dimension 13/145]  inactive:\t5.51e-03 +- 4.42e-02\n",
      "[dimension 14/145]  inactive:\t-1.89e-03 +- 2.62e-02\n",
      "[dimension 15/145]  inactive:\t2.76e-04 +- 3.61e-02\n",
      "[dimension 16/145]  inactive:\t7.57e-04 +- 2.05e-02\n",
      "[dimension 17/145]  inactive:\t-7.42e-04 +- 3.71e-02\n",
      "[dimension 18/145]  inactive:\t-1.28e-03 +- 2.83e-02\n",
      "[dimension 19/145]  inactive:\t-2.74e-03 +- 2.36e-02\n",
      "[dimension 20/145]  inactive:\t-2.13e-03 +- 2.98e-02\n",
      "[dimension 21/145]  inactive:\t-1.78e-03 +- 2.53e-02\n",
      "[dimension 22/145]  inactive:\t-3.45e-05 +- 2.01e-02\n",
      "[dimension 23/145]  inactive:\t-1.27e-03 +- 2.58e-02\n",
      "[dimension 24/145]  inactive:\t2.32e-03 +- 3.10e-02\n",
      "[dimension 25/145]  inactive:\t3.54e-03 +- 2.39e-02\n",
      "[dimension 26/145]  inactive:\t-8.32e-04 +- 2.97e-02\n",
      "[dimension 27/145]  inactive:\t2.76e-04 +- 2.41e-02\n",
      "[dimension 28/145]  inactive:\t6.21e-04 +- 1.97e-02\n",
      "[dimension 29/145]  inactive:\t-3.76e-04 +- 2.78e-02\n",
      "[dimension 30/145]  inactive:\t3.56e-04 +- 2.78e-02\n",
      "[dimension 31/145]  inactive:\t7.48e-03 +- 5.14e-02\n",
      "[dimension 32/145]  inactive:\t-2.63e-03 +- 3.20e-02\n",
      "[dimension 33/145]  inactive:\t1.45e-03 +- 3.58e-02\n",
      "[dimension 34/145]  inactive:\t6.39e-04 +- 1.88e-02\n",
      "[dimension 35/145]  inactive:\t-2.44e-04 +- 2.86e-02\n",
      "[dimension 36/145]  inactive:\t4.39e-04 +- 2.08e-02\n",
      "[dimension 37/145]  inactive:\t4.90e-03 +- 3.13e-02\n",
      "[dimension 38/145]  inactive:\t-2.75e-03 +- 3.66e-02\n",
      "[dimension 39/145]  inactive:\t2.51e-04 +- 2.79e-02\n",
      "[dimension 40/145]  inactive:\t4.52e-03 +- 3.51e-02\n",
      "[dimension 41/145]  inactive:\t-3.50e-03 +- 3.88e-02\n",
      "[dimension 42/145]  inactive:\t8.77e-03 +- 6.42e-02\n",
      "[dimension 43/145]  inactive:\t-6.06e-04 +- 1.95e-02\n",
      "[dimension 44/145]  inactive:\t-1.32e-03 +- 3.22e-02\n",
      "[dimension 45/145]  inactive:\t-1.11e-03 +- 2.57e-02\n",
      "[dimension 46/145]  inactive:\t1.39e-03 +- 1.73e-02\n",
      "[dimension 47/145]  inactive:\t-2.96e-03 +- 3.42e-02\n",
      "[dimension 48/145]  inactive:\t8.73e-04 +- 2.23e-02\n",
      "[dimension 49/145]  inactive:\t3.52e-03 +- 2.70e-02\n",
      "[dimension 50/145]  inactive:\t-1.91e-03 +- 2.45e-02\n",
      "[dimension 51/145]  inactive:\t3.22e-03 +- 3.37e-02\n",
      "[dimension 52/145]  inactive:\t6.02e-03 +- 2.53e-02\n",
      "[dimension 53/145]  inactive:\t-1.68e-03 +- 2.71e-02\n",
      "[dimension 54/145]  inactive:\t5.26e-05 +- 1.74e-02\n",
      "[dimension 55/145]  inactive:\t5.87e-04 +- 1.75e-02\n",
      "[dimension 56/145]  inactive:\t-2.38e-03 +- 2.31e-02\n",
      "[dimension 57/145]  inactive:\t1.16e-04 +- 2.65e-02\n",
      "[dimension 58/145]  inactive:\t9.35e-03 +- 5.49e-02\n",
      "[dimension 59/145]  inactive:\t-5.10e-04 +- 1.90e-02\n",
      "[dimension 60/145]  inactive:\t7.21e-04 +- 3.24e-02\n",
      "[dimension 61/145]  inactive:\t2.07e-03 +- 2.28e-02\n",
      "[dimension 62/145]  inactive:\t-6.56e-04 +- 2.39e-02\n",
      "[dimension 63/145]  active:\t8.29e-01 +- 3.33e-01\n",
      "[dimension 64/145]  inactive:\t-2.11e-03 +- 2.08e-02\n",
      "[dimension 65/145]  inactive:\t-1.42e-03 +- 2.77e-02\n",
      "[dimension 66/145]  inactive:\t3.44e-04 +- 2.33e-02\n",
      "[dimension 67/145]  inactive:\t1.87e-03 +- 2.82e-02\n",
      "[dimension 68/145]  inactive:\t-1.09e-03 +- 2.42e-02\n",
      "[dimension 69/145]  inactive:\t4.94e-03 +- 4.98e-02\n",
      "[dimension 70/145]  inactive:\t2.89e-03 +- 2.11e-02\n",
      "[dimension 71/145]  inactive:\t-4.34e-05 +- 2.51e-02\n",
      "[dimension 72/145]  inactive:\t-2.03e-05 +- 2.20e-02\n",
      "[dimension 73/145]  inactive:\t1.30e-04 +- 1.82e-02\n",
      "[dimension 74/145]  inactive:\t-2.37e-03 +- 3.57e-02\n",
      "[dimension 75/145]  inactive:\t-5.72e-05 +- 2.09e-02\n",
      "[dimension 76/145]  inactive:\t5.78e-03 +- 3.93e-02\n",
      "[dimension 77/145]  inactive:\t-1.86e-03 +- 3.31e-02\n",
      "[dimension 78/145]  inactive:\t1.77e-03 +- 3.01e-02\n",
      "[dimension 79/145]  inactive:\t5.71e-03 +- 3.23e-02\n",
      "[dimension 80/145]  inactive:\t-9.85e-04 +- 3.06e-02\n",
      "[dimension 81/145]  inactive:\t-7.02e-05 +- 2.32e-02\n",
      "[dimension 82/145]  inactive:\t3.05e-04 +- 1.68e-02\n",
      "[dimension 83/145]  inactive:\t-1.82e-03 +- 2.16e-02\n",
      "[dimension 84/145]  inactive:\t-1.47e-03 +- 2.41e-02\n",
      "[dimension 85/145]  inactive:\t2.42e-03 +- 2.56e-02\n",
      "[dimension 86/145]  inactive:\t-2.02e-04 +- 2.09e-02\n",
      "[dimension 87/145]  inactive:\t1.12e-03 +- 3.01e-02\n",
      "[dimension 88/145]  inactive:\t3.33e-03 +- 2.63e-02\n",
      "[dimension 89/145]  inactive:\t-7.29e-04 +- 2.48e-02\n",
      "[dimension 90/145]  inactive:\t5.32e-02 +- 2.09e-01\n",
      "[dimension 91/145]  inactive:\t2.82e-06 +- 1.99e-02\n",
      "[dimension 92/145]  inactive:\t-2.38e-03 +- 2.92e-02\n",
      "[dimension 93/145]  inactive:\t-2.54e-04 +- 2.47e-02\n",
      "[dimension 94/145]  inactive:\t2.02e-03 +- 2.63e-02\n",
      "[dimension 95/145]  inactive:\t-4.54e-04 +- 2.25e-02\n",
      "[dimension 96/145]  inactive:\t4.57e-04 +- 3.87e-02\n",
      "[dimension 97/145]  inactive:\t2.03e-03 +- 2.21e-02\n",
      "[dimension 98/145]  inactive:\t-8.03e-04 +- 2.42e-02\n",
      "[dimension 99/145]  inactive:\t1.23e-03 +- 2.63e-02\n",
      "[dimension 100/145]  inactive:\t-6.87e-04 +- 1.63e-02\n",
      "[dimension 101/145]  inactive:\t-2.27e-03 +- 2.07e-02\n",
      "[dimension 102/145]  inactive:\t-5.55e-04 +- 3.31e-02\n",
      "[dimension 103/145]  inactive:\t9.97e-04 +- 2.58e-02\n",
      "[dimension 104/145]  inactive:\t-7.56e-04 +- 1.98e-02\n",
      "[dimension 105/145]  inactive:\t-8.18e-04 +- 2.16e-02\n",
      "[dimension 106/145]  inactive:\t5.99e-03 +- 3.66e-02\n",
      "[dimension 107/145]  inactive:\t-1.20e-03 +- 2.28e-02\n",
      "[dimension 108/145]  inactive:\t3.15e-03 +- 5.04e-02\n",
      "[dimension 109/145]  inactive:\t-5.15e-04 +- 1.90e-02\n",
      "[dimension 110/145]  inactive:\t-2.19e-03 +- 3.34e-02\n",
      "[dimension 111/145]  inactive:\t1.34e-03 +- 2.98e-02\n",
      "[dimension 112/145]  inactive:\t6.54e-03 +- 4.50e-02\n",
      "[dimension 113/145]  inactive:\t-2.02e-03 +- 2.37e-02\n",
      "[dimension 114/145]  inactive:\t4.74e-04 +- 3.19e-02\n",
      "[dimension 115/145]  inactive:\t2.26e-03 +- 2.22e-02\n",
      "[dimension 116/145]  inactive:\t-1.60e-04 +- 3.47e-02\n",
      "[dimension 117/145]  inactive:\t2.42e-03 +- 3.59e-02\n",
      "[dimension 118/145]  inactive:\t3.73e-03 +- 2.83e-02\n",
      "[dimension 119/145]  inactive:\t-3.20e-03 +- 3.21e-02\n",
      "[dimension 120/145]  inactive:\t-9.21e-05 +- 2.86e-02\n",
      "[dimension 121/145]  inactive:\t4.81e-03 +- 3.84e-02\n",
      "[dimension 122/145]  inactive:\t-2.52e-03 +- 2.90e-02\n",
      "[dimension 123/145]  inactive:\t1.99e-03 +- 3.95e-02\n",
      "[dimension 124/145]  inactive:\t-2.42e-03 +- 2.31e-02\n",
      "[dimension 125/145]  inactive:\t-1.84e-03 +- 2.70e-02\n",
      "[dimension 126/145]  inactive:\t-1.12e-03 +- 2.59e-02\n",
      "[dimension 127/145]  inactive:\t-1.38e-04 +- 2.13e-02\n",
      "[dimension 128/145]  inactive:\t-1.29e-03 +- 3.02e-02\n",
      "[dimension 129/145]  inactive:\t-4.64e-04 +- 2.64e-02\n",
      "[dimension 130/145]  inactive:\t3.79e-03 +- 2.83e-02\n",
      "[dimension 131/145]  inactive:\t-1.74e-03 +- 3.05e-02\n",
      "[dimension 132/145]  inactive:\t3.25e-03 +- 3.68e-02\n",
      "[dimension 133/145]  inactive:\t2.79e-03 +- 2.16e-02\n",
      "[dimension 134/145]  inactive:\t-1.30e-03 +- 3.06e-02\n",
      "[dimension 135/145]  inactive:\t-4.65e-05 +- 2.90e-02\n",
      "[dimension 136/145]  inactive:\t1.16e-03 +- 1.96e-02\n",
      "[dimension 137/145]  inactive:\t-7.29e-04 +- 2.93e-02\n",
      "[dimension 138/145]  inactive:\t1.10e-03 +- 2.82e-02\n",
      "[dimension 139/145]  inactive:\t-4.07e-06 +- 2.31e-02\n",
      "[dimension 140/145]  inactive:\t-1.41e-03 +- 2.95e-02\n",
      "[dimension 141/145]  inactive:\t1.55e-03 +- 2.92e-02\n",
      "[dimension 142/145]  inactive:\t1.19e-03 +- 1.81e-02\n",
      "[dimension 143/145]  inactive:\t3.64e-04 +- 3.08e-02\n",
      "[dimension 144/145]  inactive:\t1.54e-04 +- 1.80e-02\n",
      "[dimension 145/145]  inactive:\t-1.34e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.0084915]\n",
      "cov_act[[0.02272606]]\n",
      "Active_dimensions: [62]\n",
      "41, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:23<00:00, 62.90it/s, 15 steps of size 2.69e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    349.27      1.01\n",
      "  lambda[0]      2.28      4.80      1.00      0.00      4.97    851.31      1.00\n",
      "  lambda[1]      3.12     17.08      0.95      0.00      4.87    666.46      1.00\n",
      "  lambda[2]      2.64      6.10      0.98      0.00      6.07    918.44      1.00\n",
      "  lambda[3]      4.25     28.96      1.04      0.00      6.65    981.46      1.00\n",
      "  lambda[4]      3.05      8.40      1.00      0.00      5.99    420.85      1.00\n",
      "  lambda[5]      4.02     22.56      1.00      0.00      6.16    538.18      1.00\n",
      "  lambda[6]      3.42     11.24      1.01      0.00      5.70    791.46      1.00\n",
      "  lambda[7]      3.15     10.69      0.93      0.00      6.16    760.89      1.00\n",
      "  lambda[8]      2.86      6.19      0.95      0.01      6.69    725.19      1.00\n",
      "  lambda[9]      3.07      8.40      1.02      0.00      6.36    883.78      1.00\n",
      " lambda[10]      3.00      7.89      1.00      0.00      6.25    585.97      1.00\n",
      " lambda[11]      2.85      7.28      0.96      0.00      5.97    930.38      1.00\n",
      " lambda[12]      4.21     23.19      0.98      0.00      6.61    514.13      1.00\n",
      " lambda[13]      2.65      6.50      0.95      0.00      5.36    645.14      1.00\n",
      " lambda[14]      5.98     46.71      1.08      0.00      7.06    669.57      1.00\n",
      " lambda[15]      3.28     11.15      1.04      0.00      5.65    873.98      1.00\n",
      " lambda[16]      2.58      6.64      0.95      0.00      5.59    994.74      1.00\n",
      " lambda[17]      2.78      6.36      1.01      0.00      5.72    784.06      1.00\n",
      " lambda[18]      2.97      8.71      0.96      0.00      5.62    691.84      1.00\n",
      " lambda[19]      3.20      9.76      1.02      0.00      6.93    480.24      1.00\n",
      " lambda[20]      2.49      5.56      0.97      0.00      5.12    626.01      1.00\n",
      " lambda[21]      2.78      5.76      1.02      0.00      6.17    559.84      1.00\n",
      " lambda[22]      3.32     26.41      0.94      0.00      5.61   1013.74      1.00\n",
      " lambda[23]      2.81      7.63      1.01      0.01      5.33    852.44      1.00\n",
      " lambda[24]      3.43     11.24      1.03      0.00      6.34    890.39      1.00\n",
      " lambda[25]      2.84      6.33      1.01      0.00      6.94    558.18      1.00\n",
      " lambda[26]      2.53      6.30      0.99      0.00      4.99    919.11      1.00\n",
      " lambda[27]      2.63      5.87      0.95      0.00      6.02    870.45      1.00\n",
      " lambda[28]      2.32      4.41      0.96      0.01      5.69    841.90      1.00\n",
      " lambda[29]      3.03     13.86      0.92      0.00      5.47    860.07      1.01\n",
      " lambda[30]      2.62      6.69      0.98      0.01      6.10    774.23      1.00\n",
      " lambda[31]      3.07      9.09      0.97      0.00      5.99    716.37      1.00\n",
      " lambda[32]      2.82      6.07      0.99      0.00      6.48    717.82      1.00\n",
      " lambda[33]      2.67      7.18      0.98      0.00      5.64    853.80      1.00\n",
      " lambda[34]      2.66      7.10      1.06      0.00      5.44    592.32      1.00\n",
      " lambda[35]      2.63      5.95      0.98      0.00      5.34    530.84      1.00\n",
      " lambda[36]      2.94      8.85      1.01      0.00      6.25    880.83      1.00\n",
      " lambda[37]      3.20     14.12      0.99      0.00      5.84    977.99      1.00\n",
      " lambda[38]      5.32     71.54      0.99      0.00      6.22    958.08      1.00\n",
      " lambda[39]      3.27     13.90      0.99      0.00      6.47    859.64      1.00\n",
      " lambda[40]      2.69      6.11      1.01      0.00      5.58    847.22      1.00\n",
      " lambda[41]      5.73     30.39      1.02      0.00      7.76    452.09      1.00\n",
      " lambda[42]      2.39      5.66      0.94      0.00      5.18    920.79      1.00\n",
      " lambda[43]      3.34     13.19      0.97      0.00      5.64    605.68      1.00\n",
      " lambda[44]      2.34      4.96      0.97      0.01      5.03    818.78      1.00\n",
      " lambda[45]      2.74      8.14      0.97      0.01      5.32    958.38      1.00\n",
      " lambda[46]      3.01     10.33      0.98      0.00      4.95    671.81      1.00\n",
      " lambda[47]      2.35      4.53      1.00      0.00      5.36    863.91      1.00\n",
      " lambda[48]      3.08      8.05      1.05      0.00      6.50    615.77      1.00\n",
      " lambda[49]      3.19      7.74      1.02      0.00      6.78    693.62      1.00\n",
      " lambda[50]      3.15      9.67      0.98      0.00      5.79    700.37      1.00\n",
      " lambda[51]      4.78     18.63      1.04      0.00      8.62    515.74      1.00\n",
      " lambda[52]      2.54      6.39      0.95      0.00      5.27    842.30      1.00\n",
      " lambda[53]      3.06      8.44      1.01      0.00      5.81    682.04      1.00\n",
      " lambda[54]      2.53      5.71      0.94      0.00      5.23    606.46      1.00\n",
      " lambda[55]      2.98     10.59      0.87      0.00      5.75   1017.21      1.00\n",
      " lambda[56]      2.67      7.04      0.94      0.01      5.16    881.83      1.00\n",
      " lambda[57]      5.15     24.74      1.03      0.01      7.46    657.45      1.00\n",
      " lambda[58]      2.41      5.91      0.91      0.00      5.07    845.54      1.00\n",
      " lambda[59]      3.09      8.37      1.03      0.00      5.96    401.61      1.00\n",
      " lambda[60]      3.48     15.23      0.98      0.00      5.52    499.40      1.00\n",
      " lambda[61]      2.75      6.82      1.00      0.00      5.92    722.04      1.00\n",
      " lambda[62]   2050.21  21459.87    269.14      0.01   2397.15    838.39      1.00\n",
      " lambda[63]      2.46      4.98      0.98      0.00      5.38    690.31      1.00\n",
      " lambda[64]      2.47      5.82      0.97      0.00      5.23    942.02      1.00\n",
      " lambda[65]      3.14     12.68      0.96      0.00      4.85    916.59      1.00\n",
      " lambda[66]      3.41     12.93      0.95      0.00      6.15    906.04      1.00\n",
      " lambda[67]      2.98     10.67      1.01      0.00      5.88   1035.05      1.00\n",
      " lambda[68]      3.00      8.74      1.02      0.00      5.33   1031.92      1.00\n",
      " lambda[69]      3.93     12.19      0.98      0.00      6.73    896.86      1.00\n",
      " lambda[70]      3.03     13.92      0.97      0.00      5.75    820.16      1.00\n",
      " lambda[71]      3.13     10.52      1.09      0.00      5.53    583.37      1.00\n",
      " lambda[72]      2.44      6.56      0.99      0.00      5.02    877.71      1.00\n",
      " lambda[73]      2.56      6.27      0.95      0.00      5.48    820.27      1.01\n",
      " lambda[74]      2.83      6.96      1.02      0.00      5.81    712.65      1.00\n",
      " lambda[75]      4.73     22.64      1.04      0.00      7.44    781.47      1.00\n",
      " lambda[76]      2.65      5.92      1.01      0.00      5.63    593.84      1.00\n",
      " lambda[77]      5.19     55.66      0.98      0.00      5.15    664.08      1.00\n",
      " lambda[78]      2.99      8.94      0.98      0.01      5.68    851.58      1.00\n",
      " lambda[79]      2.52      7.15      0.93      0.00      5.05    717.37      1.00\n",
      " lambda[80]      3.16      8.54      0.99      0.00      6.14    611.74      1.00\n",
      " lambda[81]      2.85      7.39      1.00      0.00      5.40    551.30      1.00\n",
      " lambda[82]      2.54      6.10      1.02      0.00      5.11    624.49      1.00\n",
      " lambda[83]      3.15     10.04      0.99      0.00      6.16    801.33      1.00\n",
      " lambda[84]      2.62      7.59      0.99      0.00      4.60    807.41      1.00\n",
      " lambda[85]      2.85      8.92      0.94      0.00      5.77    674.58      1.00\n",
      " lambda[86]      3.93     21.67      1.01      0.00      6.06    728.58      1.00\n",
      " lambda[87]      2.53      5.24      0.98      0.00      5.71    842.19      1.00\n",
      " lambda[88]      3.42     12.00      1.04      0.00      7.08    587.61      1.00\n",
      " lambda[89]   5814.29 141959.20      1.28      0.00    125.36    618.42      1.00\n",
      " lambda[90]      2.85      7.86      0.95      0.00      5.67    900.15      1.00\n",
      " lambda[91]      2.89     10.06      1.02      0.00      4.97    500.28      1.00\n",
      " lambda[92]      3.10      8.22      0.94      0.00      5.82    712.27      1.00\n",
      " lambda[93]      2.70     10.74      1.00      0.00      4.90    630.93      1.00\n",
      " lambda[94]      3.43      9.43      0.96      0.00      6.90    683.63      1.00\n",
      " lambda[95]      4.20     22.85      1.00      0.00      6.38    483.00      1.00\n",
      " lambda[96]      2.96      7.98      0.95      0.00      6.47    649.73      1.00\n",
      " lambda[97]      2.58      6.77      1.00      0.01      5.21    936.05      1.00\n",
      " lambda[98]      3.61     15.32      0.99      0.00      5.02    500.38      1.00\n",
      " lambda[99]      3.17      9.33      0.90      0.00      6.11    573.52      1.00\n",
      "lambda[100]      3.05      9.60      0.94      0.00      6.37    558.91      1.00\n",
      "lambda[101]      2.91      9.38      0.97      0.00      5.39    613.30      1.00\n",
      "lambda[102]      2.87      8.14      0.97      0.00      5.79    761.12      1.00\n",
      "lambda[103]      4.82     46.11      0.90      0.00      5.10    356.46      1.00\n",
      "lambda[104]      2.98     10.17      1.00      0.00      4.61    560.36      1.00\n",
      "lambda[105]      3.11      8.89      0.97      0.00      6.29    787.89      1.00\n",
      "lambda[106]      3.25     17.58      0.97      0.00      5.29    598.93      1.00\n",
      "lambda[107]      4.80     61.51      0.97      0.00      5.21    970.98      1.00\n",
      "lambda[108]      2.30      6.10      0.90      0.00      4.95   1010.81      1.00\n",
      "lambda[109]      4.25     17.31      0.97      0.00      7.13    776.09      1.00\n",
      "lambda[110]      3.35     15.12      1.03      0.00      6.45    877.52      1.00\n",
      "lambda[111]      4.35     17.39      1.01      0.00      6.79    470.24      1.00\n",
      "lambda[112]      2.42      6.39      0.97      0.01      4.90    457.47      1.00\n",
      "lambda[113]      3.15      8.82      0.93      0.00      6.23    604.88      1.00\n",
      "lambda[114]      2.84      7.18      1.00      0.01      6.29    673.64      1.00\n",
      "lambda[115]      3.36     16.60      0.96      0.00      6.00    997.51      1.00\n",
      "lambda[116]      2.97     12.64      1.04      0.00      5.64    887.54      1.00\n",
      "lambda[117]      3.59     13.92      0.99      0.00      6.44    735.27      1.00\n",
      "lambda[118]      3.48     32.12      0.96      0.00      5.04    970.10      1.00\n",
      "lambda[119]      4.40     17.01      0.98      0.00      7.39    758.04      1.00\n",
      "lambda[120]      3.21      8.46      0.97      0.00      6.63    780.59      1.00\n",
      "lambda[121]      3.19      8.59      1.05      0.00      6.17    657.59      1.00\n",
      "lambda[122]      2.88     10.58      1.00      0.00      5.34    852.03      1.00\n",
      "lambda[123]      2.46      5.50      0.91      0.00      5.39    887.15      1.00\n",
      "lambda[124]      2.83      7.34      0.99      0.00      6.19    934.53      1.00\n",
      "lambda[125]      2.63      6.52      0.95      0.01      5.44    515.61      1.00\n",
      "lambda[126]      2.27      4.89      0.95      0.00      5.17    894.13      1.00\n",
      "lambda[127]      5.73     35.60      1.00      0.00      6.29    207.75      1.00\n",
      "lambda[128]      4.67     38.07      0.94      0.00      5.45    379.89      1.00\n",
      "lambda[129]      3.10     12.88      0.92      0.00      5.53    918.79      1.00\n",
      "lambda[130]      2.81      6.25      1.00      0.00      6.47    845.08      1.00\n",
      "lambda[131]      2.94     12.14      1.00      0.00      5.07    757.31      1.00\n",
      "lambda[132]      3.09     10.47      1.05      0.00      5.71    783.50      1.00\n",
      "lambda[133]      2.66      7.72      0.91      0.00      5.00    873.35      1.00\n",
      "lambda[134]      3.58      9.63      0.97      0.00      6.93    749.35      1.00\n",
      "lambda[135]      2.19      4.70      0.93      0.00      4.50    902.85      1.00\n",
      "lambda[136]      2.84      7.34      0.94      0.00      6.34    776.26      1.00\n",
      "lambda[137]      2.83      8.10      1.05      0.00      5.56    984.98      1.00\n",
      "lambda[138]      3.30     10.47      0.97      0.00      6.02    686.34      1.00\n",
      "lambda[139]      2.69      6.07      0.98      0.00      5.95    806.30      1.00\n",
      "lambda[140]      3.38     18.16      0.96      0.00      6.03    930.98      1.00\n",
      "lambda[141]      2.93      6.69      0.98      0.00      6.70    594.16      1.00\n",
      "lambda[142]      4.83     34.01      0.96      0.01      6.50    533.38      1.00\n",
      "lambda[143]      2.40      5.61      0.98      0.00      5.46    734.31      1.00\n",
      "        msq      1.50      0.94      1.27      0.46      2.58    835.53      1.00\n",
      "      sigma      4.23      5.79      1.86      0.00     11.71   1171.52      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    995.06      1.00\n",
      "       xisq      3.11     10.84      0.98      0.09      5.89    601.74      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 27.81949281692505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.11e-04 +- 1.47e-02\n",
      "[dimension 02/145]  inactive:\t3.23e-04 +- 2.55e-02\n",
      "[dimension 03/145]  inactive:\t6.03e-05 +- 1.60e-02\n",
      "[dimension 04/145]  inactive:\t4.65e-03 +- 3.95e-02\n",
      "[dimension 05/145]  inactive:\t-5.56e-04 +- 2.30e-02\n",
      "[dimension 06/145]  inactive:\t3.08e-03 +- 3.79e-02\n",
      "[dimension 07/145]  inactive:\t8.82e-04 +- 1.75e-02\n",
      "[dimension 08/145]  inactive:\t1.25e-03 +- 2.56e-02\n",
      "[dimension 09/145]  inactive:\t4.16e-04 +- 1.91e-02\n",
      "[dimension 10/145]  inactive:\t3.97e-04 +- 1.89e-02\n",
      "[dimension 11/145]  inactive:\t3.40e-04 +- 2.48e-02\n",
      "[dimension 12/145]  inactive:\t1.35e-04 +- 2.01e-02\n",
      "[dimension 13/145]  inactive:\t3.34e-03 +- 3.45e-02\n",
      "[dimension 14/145]  inactive:\t-8.66e-04 +- 1.82e-02\n",
      "[dimension 15/145]  inactive:\t7.49e-04 +- 3.22e-02\n",
      "[dimension 16/145]  inactive:\t3.20e-04 +- 1.96e-02\n",
      "[dimension 17/145]  inactive:\t4.82e-04 +- 2.52e-02\n",
      "[dimension 18/145]  inactive:\t-2.05e-04 +- 2.57e-02\n",
      "[dimension 19/145]  inactive:\t-1.02e-03 +- 1.47e-02\n",
      "[dimension 20/145]  inactive:\t-1.00e-03 +- 2.50e-02\n",
      "[dimension 21/145]  inactive:\t-1.21e-03 +- 1.82e-02\n",
      "[dimension 22/145]  inactive:\t3.74e-04 +- 1.97e-02\n",
      "[dimension 23/145]  inactive:\t-1.30e-04 +- 2.05e-02\n",
      "[dimension 24/145]  inactive:\t9.84e-04 +- 2.21e-02\n",
      "[dimension 25/145]  inactive:\t2.55e-03 +- 1.93e-02\n",
      "[dimension 26/145]  inactive:\t-5.05e-04 +- 2.52e-02\n",
      "[dimension 27/145]  inactive:\t3.23e-04 +- 1.83e-02\n",
      "[dimension 28/145]  inactive:\t5.80e-04 +- 1.53e-02\n",
      "[dimension 29/145]  inactive:\t4.33e-04 +- 2.07e-02\n",
      "[dimension 30/145]  inactive:\t1.88e-03 +- 2.78e-02\n",
      "[dimension 31/145]  inactive:\t2.57e-03 +- 2.64e-02\n",
      "[dimension 32/145]  inactive:\t-4.08e-04 +- 2.42e-02\n",
      "[dimension 33/145]  inactive:\t1.35e-03 +- 2.62e-02\n",
      "[dimension 34/145]  inactive:\t6.80e-04 +- 1.54e-02\n",
      "[dimension 35/145]  inactive:\t3.37e-04 +- 2.05e-02\n",
      "[dimension 36/145]  inactive:\t7.32e-04 +- 2.26e-02\n",
      "[dimension 37/145]  inactive:\t3.52e-03 +- 2.48e-02\n",
      "[dimension 38/145]  inactive:\t-8.40e-04 +- 2.24e-02\n",
      "[dimension 39/145]  inactive:\t1.70e-03 +- 3.60e-02\n",
      "[dimension 40/145]  inactive:\t2.63e-03 +- 2.50e-02\n",
      "[dimension 41/145]  inactive:\t-6.41e-04 +- 1.94e-02\n",
      "[dimension 42/145]  inactive:\t2.91e-03 +- 3.25e-02\n",
      "[dimension 43/145]  inactive:\t-1.30e-04 +- 1.61e-02\n",
      "[dimension 44/145]  inactive:\t-2.84e-04 +- 2.38e-02\n",
      "[dimension 45/145]  inactive:\t-2.91e-04 +- 1.89e-02\n",
      "[dimension 46/145]  inactive:\t8.25e-04 +- 1.39e-02\n",
      "[dimension 47/145]  inactive:\t-1.44e-03 +- 2.90e-02\n",
      "[dimension 48/145]  inactive:\t4.36e-04 +- 1.88e-02\n",
      "[dimension 49/145]  inactive:\t2.10e-03 +- 2.26e-02\n",
      "[dimension 50/145]  inactive:\t-1.14e-03 +- 1.97e-02\n",
      "[dimension 51/145]  inactive:\t1.80e-03 +- 2.41e-02\n",
      "[dimension 52/145]  inactive:\t5.86e-03 +- 2.50e-02\n",
      "[dimension 53/145]  inactive:\t-6.45e-04 +- 1.95e-02\n",
      "[dimension 54/145]  inactive:\t8.20e-06 +- 1.93e-02\n",
      "[dimension 55/145]  inactive:\t3.96e-04 +- 1.41e-02\n",
      "[dimension 56/145]  inactive:\t-1.81e-03 +- 1.84e-02\n",
      "[dimension 57/145]  inactive:\t9.88e-04 +- 2.70e-02\n",
      "[dimension 58/145]  inactive:\t8.95e-03 +- 5.85e-02\n",
      "[dimension 59/145]  inactive:\t-9.76e-04 +- 1.91e-02\n",
      "[dimension 60/145]  inactive:\t4.07e-04 +- 2.47e-02\n",
      "[dimension 61/145]  inactive:\t2.14e-03 +- 2.11e-02\n",
      "[dimension 62/145]  inactive:\t-5.46e-04 +- 1.81e-02\n",
      "[dimension 63/145]  active:\t7.51e-01 +- 3.90e-01\n",
      "[dimension 64/145]  inactive:\t-1.55e-03 +- 1.75e-02\n",
      "[dimension 65/145]  inactive:\t-1.01e-04 +- 1.86e-02\n",
      "[dimension 66/145]  inactive:\t1.81e-04 +- 1.99e-02\n",
      "[dimension 67/145]  inactive:\t1.18e-03 +- 2.02e-02\n",
      "[dimension 68/145]  inactive:\t-6.26e-04 +- 2.49e-02\n",
      "[dimension 69/145]  inactive:\t2.46e-03 +- 3.29e-02\n",
      "[dimension 70/145]  inactive:\t3.64e-03 +- 2.31e-02\n",
      "[dimension 71/145]  inactive:\t6.11e-05 +- 1.99e-02\n",
      "[dimension 72/145]  inactive:\t5.31e-04 +- 1.79e-02\n",
      "[dimension 73/145]  inactive:\t2.15e-04 +- 1.35e-02\n",
      "[dimension 74/145]  inactive:\t-1.00e-03 +- 2.13e-02\n",
      "[dimension 75/145]  inactive:\t8.40e-04 +- 2.47e-02\n",
      "[dimension 76/145]  inactive:\t4.70e-03 +- 3.50e-02\n",
      "[dimension 77/145]  inactive:\t-1.03e-03 +- 2.52e-02\n",
      "[dimension 78/145]  inactive:\t4.36e-03 +- 4.67e-02\n",
      "[dimension 79/145]  inactive:\t4.75e-03 +- 3.01e-02\n",
      "[dimension 80/145]  inactive:\t-3.62e-04 +- 2.09e-02\n",
      "[dimension 81/145]  inactive:\t6.06e-04 +- 2.46e-02\n",
      "[dimension 82/145]  inactive:\t2.35e-04 +- 1.56e-02\n",
      "[dimension 83/145]  inactive:\t-1.11e-03 +- 1.38e-02\n",
      "[dimension 84/145]  inactive:\t-1.79e-03 +- 2.47e-02\n",
      "[dimension 85/145]  inactive:\t1.75e-03 +- 2.36e-02\n",
      "[dimension 86/145]  inactive:\t-5.78e-04 +- 1.46e-02\n",
      "[dimension 87/145]  inactive:\t2.40e-03 +- 3.86e-02\n",
      "[dimension 88/145]  inactive:\t1.54e-03 +- 1.64e-02\n",
      "[dimension 89/145]  inactive:\t-9.61e-04 +- 1.77e-02\n",
      "[dimension 90/145]  inactive:\t1.15e-01 +- 2.97e-01\n",
      "[dimension 91/145]  inactive:\t8.43e-05 +- 1.66e-02\n",
      "[dimension 92/145]  inactive:\t-1.07e-03 +- 1.95e-02\n",
      "[dimension 93/145]  inactive:\t-5.93e-04 +- 2.33e-02\n",
      "[dimension 94/145]  inactive:\t7.68e-04 +- 1.63e-02\n",
      "[dimension 95/145]  inactive:\t-1.76e-05 +- 2.56e-02\n",
      "[dimension 96/145]  inactive:\t1.56e-03 +- 4.21e-02\n",
      "[dimension 97/145]  inactive:\t1.82e-03 +- 1.95e-02\n",
      "[dimension 98/145]  inactive:\t7.06e-05 +- 2.17e-02\n",
      "[dimension 99/145]  inactive:\t1.95e-03 +- 3.46e-02\n",
      "[dimension 100/145]  inactive:\t-4.63e-04 +- 1.50e-02\n",
      "[dimension 101/145]  inactive:\t-1.58e-03 +- 1.53e-02\n",
      "[dimension 102/145]  inactive:\t-7.12e-04 +- 2.22e-02\n",
      "[dimension 103/145]  inactive:\t4.05e-04 +- 2.09e-02\n",
      "[dimension 104/145]  inactive:\t-6.86e-04 +- 1.42e-02\n",
      "[dimension 105/145]  inactive:\t-3.82e-04 +- 1.74e-02\n",
      "[dimension 106/145]  inactive:\t2.91e-03 +- 2.32e-02\n",
      "[dimension 107/145]  inactive:\t-1.23e-03 +- 1.76e-02\n",
      "[dimension 108/145]  inactive:\t2.28e-03 +- 3.70e-02\n",
      "[dimension 109/145]  inactive:\t-1.34e-04 +- 1.35e-02\n",
      "[dimension 110/145]  inactive:\t-7.33e-04 +- 2.80e-02\n",
      "[dimension 111/145]  inactive:\t1.73e-03 +- 3.07e-02\n",
      "[dimension 112/145]  inactive:\t5.61e-03 +- 4.50e-02\n",
      "[dimension 113/145]  inactive:\t-6.93e-04 +- 1.46e-02\n",
      "[dimension 114/145]  inactive:\t4.45e-04 +- 2.70e-02\n",
      "[dimension 115/145]  inactive:\t1.69e-03 +- 1.86e-02\n",
      "[dimension 116/145]  inactive:\t9.84e-04 +- 3.26e-02\n",
      "[dimension 117/145]  inactive:\t2.26e-03 +- 3.04e-02\n",
      "[dimension 118/145]  inactive:\t2.51e-03 +- 2.22e-02\n",
      "[dimension 119/145]  inactive:\t-1.02e-03 +- 2.17e-02\n",
      "[dimension 120/145]  inactive:\t-2.29e-05 +- 3.20e-02\n",
      "[dimension 121/145]  inactive:\t3.13e-03 +- 3.01e-02\n",
      "[dimension 122/145]  inactive:\t-1.34e-03 +- 2.37e-02\n",
      "[dimension 123/145]  inactive:\t7.79e-04 +- 2.50e-02\n",
      "[dimension 124/145]  inactive:\t-9.73e-04 +- 1.41e-02\n",
      "[dimension 125/145]  inactive:\t-9.88e-04 +- 1.92e-02\n",
      "[dimension 126/145]  inactive:\t-7.51e-04 +- 2.06e-02\n",
      "[dimension 127/145]  inactive:\t1.20e-04 +- 1.30e-02\n",
      "[dimension 128/145]  inactive:\t-5.71e-04 +- 2.45e-02\n",
      "[dimension 129/145]  inactive:\t-1.95e-04 +- 2.36e-02\n",
      "[dimension 130/145]  inactive:\t2.79e-03 +- 2.44e-02\n",
      "[dimension 131/145]  inactive:\t-3.41e-04 +- 2.28e-02\n",
      "[dimension 132/145]  inactive:\t1.71e-03 +- 2.56e-02\n",
      "[dimension 133/145]  inactive:\t2.15e-03 +- 1.87e-02\n",
      "[dimension 134/145]  inactive:\t-3.34e-04 +- 1.91e-02\n",
      "[dimension 135/145]  inactive:\t3.70e-04 +- 2.40e-02\n",
      "[dimension 136/145]  inactive:\t5.50e-04 +- 1.52e-02\n",
      "[dimension 137/145]  inactive:\t-1.87e-05 +- 2.44e-02\n",
      "[dimension 138/145]  inactive:\t3.47e-05 +- 1.82e-02\n",
      "[dimension 139/145]  inactive:\t3.47e-05 +- 2.37e-02\n",
      "[dimension 140/145]  inactive:\t-4.01e-04 +- 2.65e-02\n",
      "[dimension 141/145]  inactive:\t1.20e-03 +- 2.52e-02\n",
      "[dimension 142/145]  inactive:\t1.70e-03 +- 1.81e-02\n",
      "[dimension 143/145]  inactive:\t1.46e-03 +- 3.37e-02\n",
      "[dimension 144/145]  inactive:\t2.22e-04 +- 1.60e-02\n",
      "[dimension 145/145]  inactive:\t2.50e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[5.632639e-05]\n",
      "cov_act[[4.2691827e-06]]\n",
      "Active_dimensions: [62]\n",
      "42, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:24<00:00, 62.19it/s, 15 steps of size 2.19e-01. acc. prob=0.87] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    367.20      1.00\n",
      "  lambda[0]      2.87      9.88      0.98      0.01      5.48    867.07      1.00\n",
      "  lambda[1]      3.85     19.18      0.97      0.01      5.97    372.18      1.00\n",
      "  lambda[2]      2.65      6.63      1.00      0.01      5.40    564.14      1.00\n",
      "  lambda[3]      4.22     23.61      1.09      0.00      7.33    971.66      1.00\n",
      "  lambda[4]      3.15      9.97      1.01      0.00      6.72    770.85      1.00\n",
      "  lambda[5]      4.02     26.09      0.94      0.00      5.44    548.24      1.00\n",
      "  lambda[6]      2.59      6.53      0.97      0.00      4.87    669.01      1.00\n",
      "  lambda[7]      2.90      9.43      0.93      0.00      6.05    853.22      1.00\n",
      "  lambda[8]      2.75      6.63      0.96      0.00      6.42    783.75      1.01\n",
      "  lambda[9]      2.75      7.79      1.09      0.00      4.65    555.15      1.00\n",
      " lambda[10]      3.50     11.62      1.05      0.00      6.30    731.81      1.00\n",
      " lambda[11]      2.97     12.36      0.93      0.01      4.97    523.82      1.01\n",
      " lambda[12]      4.85     28.81      0.97      0.01      7.43    495.32      1.00\n",
      " lambda[13]      2.62      7.49      0.92      0.00      5.12    725.59      1.00\n",
      " lambda[14]      4.01     17.46      0.98      0.00      6.29    799.22      1.00\n",
      " lambda[15]      2.59      6.04      1.04      0.00      5.61    915.11      1.00\n",
      " lambda[16]      2.98      7.53      0.96      0.00      5.82    651.94      1.00\n",
      " lambda[17]      3.09     14.54      1.04      0.00      5.39    716.42      1.00\n",
      " lambda[18]      3.37     13.85      0.99      0.00      5.96    640.28      1.00\n",
      " lambda[19]      2.67      6.01      1.06      0.00      6.06    953.20      1.00\n",
      " lambda[20]      3.49     10.91      1.03      0.00      7.26    556.44      1.00\n",
      " lambda[21]      2.66      6.81      0.99      0.00      5.59    339.29      1.00\n",
      " lambda[22]      2.99     11.19      0.93      0.00      4.97    643.25      1.00\n",
      " lambda[23]      3.33     13.18      1.03      0.00      5.46    913.45      1.00\n",
      " lambda[24]      3.49     12.57      1.07      0.00      6.63    685.59      1.00\n",
      " lambda[25]      2.63      6.71      0.95      0.01      5.84    399.44      1.00\n",
      " lambda[26]      3.33     14.73      0.98      0.00      5.90    738.44      1.00\n",
      " lambda[27]      2.94     10.34      0.92      0.00      5.65    756.14      1.00\n",
      " lambda[28]      2.45      5.46      0.97      0.01      5.70    920.56      1.00\n",
      " lambda[29]      3.40     14.98      0.95      0.00      5.85    763.57      1.00\n",
      " lambda[30]      3.12      9.16      0.94      0.00      6.58    809.57      1.00\n",
      " lambda[31]      3.44     18.08      0.98      0.00      5.06    956.76      1.00\n",
      " lambda[32]      3.26     12.42      1.02      0.00      6.61    879.44      1.00\n",
      " lambda[33]      2.37      5.12      0.93      0.00      5.06    661.99      1.00\n",
      " lambda[34]      2.83      8.08      0.96      0.00      5.77    672.84      1.00\n",
      " lambda[35]      2.89      6.88      1.01      0.00      6.12    716.99      1.00\n",
      " lambda[36]      3.14      9.19      1.01      0.00      6.06    681.00      1.00\n",
      " lambda[37]      3.40     12.69      1.00      0.00      6.51    898.14      1.00\n",
      " lambda[38]      3.66     20.35      0.92      0.00      6.04    918.12      1.00\n",
      " lambda[39]      3.12     12.86      0.96      0.00      5.55    914.86      1.00\n",
      " lambda[40]      3.11     11.87      0.97      0.00      5.51    639.98      1.00\n",
      " lambda[41]     10.15     59.47      1.01      0.00      9.71    406.45      1.00\n",
      " lambda[42]      2.30      5.84      0.94      0.00      4.88    979.04      1.00\n",
      " lambda[43]      9.66    162.47      1.02      0.00      6.38    650.28      1.00\n",
      " lambda[44]      2.82      6.89      0.94      0.00      6.14    750.91      1.00\n",
      " lambda[45]      2.57      9.35      0.98      0.00      5.10    810.64      1.00\n",
      " lambda[46]      2.97     10.88      0.94      0.00      4.56    983.58      1.00\n",
      " lambda[47]      2.41      4.55      1.00      0.00      5.42    749.37      1.00\n",
      " lambda[48]      3.31     11.17      1.02      0.00      6.22    734.82      1.00\n",
      " lambda[49]      2.82      7.32      1.01      0.00      5.59    539.36      1.00\n",
      " lambda[50]      4.60     30.46      0.97      0.01      6.91    731.68      1.00\n",
      " lambda[51]      3.35     11.01      0.99      0.00      6.50    657.02      1.00\n",
      " lambda[52]      2.76      8.77      0.94      0.00      5.21    799.38      1.00\n",
      " lambda[53]      3.09     10.29      0.95      0.00      5.90    544.56      1.00\n",
      " lambda[54]      2.22      5.55      0.89      0.00      4.13    789.20      1.00\n",
      " lambda[55]      3.45     21.41      0.92      0.01      5.53    976.66      1.00\n",
      " lambda[56]      2.50      7.22      0.99      0.00      4.95    936.67      1.00\n",
      " lambda[57]      7.81     42.30      1.04      0.01      9.84    571.80      1.00\n",
      " lambda[58]      2.63      6.88      1.01      0.00      5.67    632.77      1.00\n",
      " lambda[59]      3.18      7.76      1.05      0.00      7.02    737.10      1.00\n",
      " lambda[60]      3.23     14.81      0.99      0.00      5.28    861.00      1.00\n",
      " lambda[61]      2.63      6.20      1.00      0.00      5.56    558.53      1.00\n",
      " lambda[62]    443.30   1442.21    145.58      0.01    980.28    387.48      1.00\n",
      " lambda[63]      2.79      7.73      0.96      0.00      6.03    805.82      1.00\n",
      " lambda[64]      2.97     12.06      0.98      0.00      5.32    732.99      1.00\n",
      " lambda[65]      3.15     12.76      0.95      0.00      5.37    846.74      1.00\n",
      " lambda[66]      3.00      8.62      0.97      0.00      5.57    737.13      1.00\n",
      " lambda[67]      2.99      8.94      1.09      0.00      6.17    785.93      1.00\n",
      " lambda[68]      3.63     11.27      1.02      0.01      6.65    659.89      1.00\n",
      " lambda[69]      3.58     11.73      0.98      0.00      6.70    608.24      1.00\n",
      " lambda[70]      3.02     14.46      0.94      0.00      4.74    800.79      1.00\n",
      " lambda[71]      2.94      9.26      1.02      0.00      5.18    565.92      1.00\n",
      " lambda[72]      2.45      6.14      0.96      0.01      4.86    594.85      1.00\n",
      " lambda[73]      3.26     11.99      0.98      0.00      5.69    835.65      1.00\n",
      " lambda[74]      2.39      5.28      0.94      0.00      5.47    695.00      1.00\n",
      " lambda[75]      4.43     18.94      1.03      0.00      7.28    590.71      1.00\n",
      " lambda[76]      2.89      8.80      1.01      0.00      6.08    821.72      1.00\n",
      " lambda[77]      3.74     14.33      1.01      0.00      6.34    562.54      1.00\n",
      " lambda[78]      2.76      6.62      1.03      0.01      5.91    625.93      1.00\n",
      " lambda[79]      3.79     28.90      0.91      0.00      4.92    538.97      1.00\n",
      " lambda[80]      3.71     18.10      0.96      0.00      6.68    761.66      1.00\n",
      " lambda[81]      2.78      6.66      1.00      0.00      6.01    522.71      1.00\n",
      " lambda[82]      2.55      5.80      1.00      0.00      5.52    709.02      1.00\n",
      " lambda[83]      3.28      9.70      0.97      0.00      6.42    740.37      1.00\n",
      " lambda[84]      7.08    120.98      1.02      0.00      6.12    902.06      1.00\n",
      " lambda[85]      2.98     12.68      0.99      0.00      5.96    719.33      1.00\n",
      " lambda[86]      4.90     42.48      1.01      0.00      5.94    987.76      1.00\n",
      " lambda[87]      3.58     19.54      0.89      0.00      5.48    734.74      1.00\n",
      " lambda[88]      2.50      5.43      0.98      0.01      5.76    653.50      1.00\n",
      " lambda[89]   1328.87  32893.21      1.32      0.00    138.09    686.35      1.00\n",
      " lambda[90]      2.31      5.07      0.93      0.00      5.12    810.86      1.00\n",
      " lambda[91]      2.79      7.71      1.00      0.00      5.48    510.89      1.00\n",
      " lambda[92]      2.82      7.27      0.98      0.00      5.58    750.78      1.00\n",
      " lambda[93]      2.60      9.55      0.97      0.00      5.19    613.34      1.00\n",
      " lambda[94]      3.01      8.81      0.97      0.00      5.98    706.39      1.00\n",
      " lambda[95]      3.67     14.30      0.96      0.00      6.61    587.04      1.00\n",
      " lambda[96]      3.33      9.09      1.01      0.00      6.81    449.96      1.00\n",
      " lambda[97]      2.69      6.62      0.99      0.01      5.48    589.05      1.00\n",
      " lambda[98]      3.76     20.59      0.99      0.00      5.31    863.50      1.00\n",
      " lambda[99]      2.45      5.96      0.92      0.00      5.21    709.56      1.00\n",
      "lambda[100]      3.30     10.82      1.00      0.00      6.55    777.48      1.00\n",
      "lambda[101]      3.38     11.66      1.02      0.00      5.57    557.09      1.00\n",
      "lambda[102]      2.60      6.67      0.95      0.00      5.09    988.85      1.00\n",
      "lambda[103]      3.41     18.40      0.95      0.00      6.13    288.28      1.00\n",
      "lambda[104]      4.26     28.66      1.00      0.00      4.80    318.50      1.00\n",
      "lambda[105]      2.98      9.54      0.96      0.00      5.69    844.09      1.00\n",
      "lambda[106]      3.25     12.59      0.98      0.00      6.01    701.57      1.00\n",
      "lambda[107]      3.60     10.97      1.02      0.01      5.87    350.16      1.00\n",
      "lambda[108]      2.19      4.57      0.94      0.01      5.14    897.18      1.00\n",
      "lambda[109]      5.94     33.55      0.99      0.00      6.79    504.21      1.00\n",
      "lambda[110]      3.36     11.04      1.01      0.00      6.17    795.92      1.00\n",
      "lambda[111]      4.09     15.76      0.99      0.00      5.99    677.03      1.00\n",
      "lambda[112]      2.24      5.19      0.96      0.01      4.74    321.91      1.00\n",
      "lambda[113]      3.16      9.99      1.00      0.00      6.01    765.65      1.00\n",
      "lambda[114]      2.48      5.55      0.93      0.00      5.60    735.39      1.00\n",
      "lambda[115]      3.56     21.34      0.97      0.00      6.12    984.55      1.00\n",
      "lambda[116]      2.88     13.59      1.01      0.01      5.51    902.75      1.00\n",
      "lambda[117]      3.70     18.55      0.95      0.00      5.76    790.42      1.00\n",
      "lambda[118]      3.30     17.79      0.98      0.00      5.88    857.84      1.00\n",
      "lambda[119]      3.92     15.26      0.99      0.01      6.80    840.02      1.00\n",
      "lambda[120]      4.97     26.05      1.02      0.00      7.12    821.01      1.00\n",
      "lambda[121]      3.34      9.49      0.97      0.00      6.96    638.46      1.00\n",
      "lambda[122]      3.46     14.09      0.96      0.00      5.70    631.21      1.00\n",
      "lambda[123]      2.50      4.97      0.87      0.00      5.93    694.32      1.00\n",
      "lambda[124]      3.27     12.91      1.00      0.01      6.53    872.72      1.00\n",
      "lambda[125]      2.53      7.60      0.95      0.00      4.87    499.61      1.00\n",
      "lambda[126]      2.65     11.17      0.94      0.00      5.03   1000.33      1.00\n",
      "lambda[127]      2.89      8.44      0.98      0.00      5.32    880.25      1.00\n",
      "lambda[128]      3.41     16.37      0.94      0.00      5.90    565.30      1.00\n",
      "lambda[129]      4.12     40.28      0.90      0.00      5.41    884.63      1.00\n",
      "lambda[130]      3.05     10.40      0.96      0.00      6.14    815.07      1.01\n",
      "lambda[131]      4.04     22.99      1.03      0.00      5.49    583.43      1.00\n",
      "lambda[132]      2.77      7.17      0.97      0.00      5.29    706.06      1.00\n",
      "lambda[133]      2.67      7.36      0.88      0.00      5.23    684.09      1.00\n",
      "lambda[134]      2.81      6.76      0.98      0.00      6.74    850.34      1.00\n",
      "lambda[135]      2.12      5.15      0.94      0.00      4.29   1071.71      1.00\n",
      "lambda[136]      2.74      7.19      0.96      0.00      5.79    734.91      1.00\n",
      "lambda[137]      2.95     10.59      1.02      0.00      5.50    725.22      1.00\n",
      "lambda[138]      3.14     10.91      0.94      0.00      6.22    726.03      1.00\n",
      "lambda[139]      2.62      6.11      0.96      0.00      5.67    709.69      1.00\n",
      "lambda[140]      3.08     10.26      0.98      0.00      6.06    830.46      1.00\n",
      "lambda[141]      2.96      7.49      0.99      0.00      6.79    638.84      1.00\n",
      "lambda[142]      3.71     11.56      0.96      0.00      7.24    681.36      1.00\n",
      "lambda[143]      2.59      9.16      0.94      0.00      5.11   1013.09      1.00\n",
      "        msq  14108.05 310806.66     26.63      1.03    687.11    762.22      1.00\n",
      "      sigma      4.87      6.20      2.19      0.00     13.39   1054.82      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    537.15      1.00\n",
      "       xisq      0.13      0.07      0.12      0.05      0.22    766.11      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 27.781490802764893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.31e-04 +- 2.18e-02\n",
      "[dimension 02/145]  inactive:\t-2.19e-04 +- 3.84e-02\n",
      "[dimension 03/145]  inactive:\t-3.20e-05 +- 2.83e-02\n",
      "[dimension 04/145]  inactive:\t7.86e-03 +- 4.93e-02\n",
      "[dimension 05/145]  inactive:\t-8.84e-04 +- 3.05e-02\n",
      "[dimension 06/145]  inactive:\t3.66e-03 +- 5.03e-02\n",
      "[dimension 07/145]  inactive:\t3.70e-04 +- 1.96e-02\n",
      "[dimension 08/145]  inactive:\t1.30e-03 +- 2.98e-02\n",
      "[dimension 09/145]  inactive:\t5.32e-04 +- 2.73e-02\n",
      "[dimension 10/145]  inactive:\t1.61e-04 +- 2.09e-02\n",
      "[dimension 11/145]  inactive:\t-1.58e-03 +- 2.93e-02\n",
      "[dimension 12/145]  inactive:\t-3.79e-04 +- 2.55e-02\n",
      "[dimension 13/145]  inactive:\t5.29e-03 +- 4.13e-02\n",
      "[dimension 14/145]  inactive:\t-1.82e-03 +- 2.58e-02\n",
      "[dimension 15/145]  inactive:\t7.59e-04 +- 3.56e-02\n",
      "[dimension 16/145]  inactive:\t8.54e-04 +- 2.17e-02\n",
      "[dimension 17/145]  inactive:\t-8.13e-05 +- 3.12e-02\n",
      "[dimension 18/145]  inactive:\t-5.82e-04 +- 2.87e-02\n",
      "[dimension 19/145]  inactive:\t-3.00e-03 +- 2.39e-02\n",
      "[dimension 20/145]  inactive:\t-1.75e-03 +- 3.10e-02\n",
      "[dimension 21/145]  inactive:\t-2.50e-03 +- 2.89e-02\n",
      "[dimension 22/145]  inactive:\t-4.44e-04 +- 2.54e-02\n",
      "[dimension 23/145]  inactive:\t-7.17e-04 +- 3.08e-02\n",
      "[dimension 24/145]  inactive:\t1.69e-03 +- 2.92e-02\n",
      "[dimension 25/145]  inactive:\t3.98e-03 +- 2.57e-02\n",
      "[dimension 26/145]  inactive:\t-7.39e-04 +- 2.69e-02\n",
      "[dimension 27/145]  inactive:\t6.30e-04 +- 2.68e-02\n",
      "[dimension 28/145]  inactive:\t1.05e-03 +- 2.20e-02\n",
      "[dimension 29/145]  inactive:\t-7.31e-05 +- 2.82e-02\n",
      "[dimension 30/145]  inactive:\t2.18e-03 +- 3.95e-02\n",
      "[dimension 31/145]  inactive:\t7.62e-03 +- 5.00e-02\n",
      "[dimension 32/145]  inactive:\t-1.90e-03 +- 2.95e-02\n",
      "[dimension 33/145]  inactive:\t2.54e-03 +- 3.71e-02\n",
      "[dimension 34/145]  inactive:\t8.24e-04 +- 1.89e-02\n",
      "[dimension 35/145]  inactive:\t4.75e-04 +- 3.11e-02\n",
      "[dimension 36/145]  inactive:\t8.03e-04 +- 2.56e-02\n",
      "[dimension 37/145]  inactive:\t5.99e-03 +- 3.39e-02\n",
      "[dimension 38/145]  inactive:\t-2.11e-03 +- 3.33e-02\n",
      "[dimension 39/145]  inactive:\t1.39e-03 +- 3.75e-02\n",
      "[dimension 40/145]  inactive:\t4.42e-03 +- 3.35e-02\n",
      "[dimension 41/145]  inactive:\t-1.96e-03 +- 2.67e-02\n",
      "[dimension 42/145]  inactive:\t1.84e-02 +- 1.11e-01\n",
      "[dimension 43/145]  inactive:\t-3.35e-04 +- 1.98e-02\n",
      "[dimension 44/145]  inactive:\t-1.42e-03 +- 3.62e-02\n",
      "[dimension 45/145]  inactive:\t-8.85e-04 +- 2.83e-02\n",
      "[dimension 46/145]  inactive:\t1.03e-03 +- 1.59e-02\n",
      "[dimension 47/145]  inactive:\t-2.59e-03 +- 3.87e-02\n",
      "[dimension 48/145]  inactive:\t1.28e-03 +- 2.48e-02\n",
      "[dimension 49/145]  inactive:\t4.37e-03 +- 3.05e-02\n",
      "[dimension 50/145]  inactive:\t-1.57e-03 +- 2.39e-02\n",
      "[dimension 51/145]  inactive:\t5.51e-03 +- 4.50e-02\n",
      "[dimension 52/145]  inactive:\t6.16e-03 +- 2.55e-02\n",
      "[dimension 53/145]  inactive:\t-1.20e-03 +- 2.45e-02\n",
      "[dimension 54/145]  inactive:\t7.29e-05 +- 2.22e-02\n",
      "[dimension 55/145]  inactive:\t5.55e-04 +- 1.77e-02\n",
      "[dimension 56/145]  inactive:\t-2.23e-03 +- 2.20e-02\n",
      "[dimension 57/145]  inactive:\t1.22e-03 +- 3.32e-02\n",
      "[dimension 58/145]  inactive:\t2.06e-02 +- 9.19e-02\n",
      "[dimension 59/145]  inactive:\t-1.11e-03 +- 2.11e-02\n",
      "[dimension 60/145]  inactive:\t1.46e-03 +- 3.56e-02\n",
      "[dimension 61/145]  inactive:\t2.42e-03 +- 2.34e-02\n",
      "[dimension 62/145]  inactive:\t-5.88e-04 +- 2.43e-02\n",
      "[dimension 63/145]  active:\t6.75e-01 +- 4.44e-01\n",
      "[dimension 64/145]  inactive:\t-4.28e-03 +- 3.71e-02\n",
      "[dimension 65/145]  inactive:\t-1.15e-03 +- 2.69e-02\n",
      "[dimension 66/145]  inactive:\t3.62e-04 +- 2.63e-02\n",
      "[dimension 67/145]  inactive:\t1.37e-03 +- 2.82e-02\n",
      "[dimension 68/145]  inactive:\t-1.68e-03 +- 4.20e-02\n",
      "[dimension 69/145]  inactive:\t5.37e-03 +- 4.87e-02\n",
      "[dimension 70/145]  inactive:\t4.57e-03 +- 2.66e-02\n",
      "[dimension 71/145]  inactive:\t2.80e-04 +- 2.91e-02\n",
      "[dimension 72/145]  inactive:\t2.98e-04 +- 2.45e-02\n",
      "[dimension 73/145]  inactive:\t1.68e-04 +- 1.74e-02\n",
      "[dimension 74/145]  inactive:\t-2.15e-03 +- 3.26e-02\n",
      "[dimension 75/145]  inactive:\t4.64e-04 +- 2.35e-02\n",
      "[dimension 76/145]  inactive:\t6.46e-03 +- 4.06e-02\n",
      "[dimension 77/145]  inactive:\t-2.11e-03 +- 3.00e-02\n",
      "[dimension 78/145]  inactive:\t4.84e-03 +- 5.09e-02\n",
      "[dimension 79/145]  inactive:\t5.68e-03 +- 3.16e-02\n",
      "[dimension 80/145]  inactive:\t-8.37e-04 +- 3.72e-02\n",
      "[dimension 81/145]  inactive:\t4.01e-04 +- 3.77e-02\n",
      "[dimension 82/145]  inactive:\t3.69e-04 +- 1.96e-02\n",
      "[dimension 83/145]  inactive:\t-2.58e-03 +- 2.30e-02\n",
      "[dimension 84/145]  inactive:\t-2.55e-03 +- 3.31e-02\n",
      "[dimension 85/145]  inactive:\t4.21e-03 +- 4.00e-02\n",
      "[dimension 86/145]  inactive:\t-1.14e-03 +- 2.22e-02\n",
      "[dimension 87/145]  inactive:\t4.66e-03 +- 5.71e-02\n",
      "[dimension 88/145]  inactive:\t2.99e-03 +- 2.52e-02\n",
      "[dimension 89/145]  inactive:\t-9.58e-04 +- 2.08e-02\n",
      "[dimension 90/145]  inactive:\t1.48e-01 +- 3.32e-01\n",
      "[dimension 91/145]  inactive:\t-8.77e-05 +- 2.12e-02\n",
      "[dimension 92/145]  inactive:\t-2.15e-03 +- 2.69e-02\n",
      "[dimension 93/145]  inactive:\t-9.14e-04 +- 2.49e-02\n",
      "[dimension 94/145]  inactive:\t1.44e-03 +- 2.57e-02\n",
      "[dimension 95/145]  inactive:\t-9.01e-04 +- 2.80e-02\n",
      "[dimension 96/145]  inactive:\t8.44e-04 +- 4.47e-02\n",
      "[dimension 97/145]  inactive:\t3.55e-03 +- 2.80e-02\n",
      "[dimension 98/145]  inactive:\t-3.19e-04 +- 2.86e-02\n",
      "[dimension 99/145]  inactive:\t3.31e-03 +- 4.25e-02\n",
      "[dimension 100/145]  inactive:\t-8.42e-04 +- 1.83e-02\n",
      "[dimension 101/145]  inactive:\t-3.27e-03 +- 2.41e-02\n",
      "[dimension 102/145]  inactive:\t-9.43e-04 +- 3.07e-02\n",
      "[dimension 103/145]  inactive:\t9.05e-04 +- 2.51e-02\n",
      "[dimension 104/145]  inactive:\t-1.28e-03 +- 1.88e-02\n",
      "[dimension 105/145]  inactive:\t-1.64e-03 +- 2.98e-02\n",
      "[dimension 106/145]  inactive:\t4.10e-03 +- 3.04e-02\n",
      "[dimension 107/145]  inactive:\t-1.76e-03 +- 2.42e-02\n",
      "[dimension 108/145]  inactive:\t5.39e-03 +- 6.42e-02\n",
      "[dimension 109/145]  inactive:\t-5.93e-04 +- 1.81e-02\n",
      "[dimension 110/145]  inactive:\t-2.14e-03 +- 3.97e-02\n",
      "[dimension 111/145]  inactive:\t3.23e-03 +- 4.27e-02\n",
      "[dimension 112/145]  inactive:\t8.28e-03 +- 5.82e-02\n",
      "[dimension 113/145]  inactive:\t-1.29e-03 +- 2.00e-02\n",
      "[dimension 114/145]  inactive:\t2.70e-04 +- 3.35e-02\n",
      "[dimension 115/145]  inactive:\t2.07e-03 +- 2.16e-02\n",
      "[dimension 116/145]  inactive:\t-7.87e-06 +- 3.27e-02\n",
      "[dimension 117/145]  inactive:\t2.77e-03 +- 3.90e-02\n",
      "[dimension 118/145]  inactive:\t4.06e-03 +- 3.12e-02\n",
      "[dimension 119/145]  inactive:\t-2.91e-03 +- 3.59e-02\n",
      "[dimension 120/145]  inactive:\t-1.01e-03 +- 4.21e-02\n",
      "[dimension 121/145]  inactive:\t6.17e-03 +- 4.56e-02\n",
      "[dimension 122/145]  inactive:\t-3.44e-03 +- 3.48e-02\n",
      "[dimension 123/145]  inactive:\t1.75e-03 +- 3.73e-02\n",
      "[dimension 124/145]  inactive:\t-2.22e-03 +- 2.18e-02\n",
      "[dimension 125/145]  inactive:\t-2.75e-03 +- 3.36e-02\n",
      "[dimension 126/145]  inactive:\t-1.54e-03 +- 2.51e-02\n",
      "[dimension 127/145]  inactive:\t4.56e-06 +- 1.71e-02\n",
      "[dimension 128/145]  inactive:\t-1.48e-03 +- 2.80e-02\n",
      "[dimension 129/145]  inactive:\t-3.68e-04 +- 2.80e-02\n",
      "[dimension 130/145]  inactive:\t3.87e-03 +- 3.14e-02\n",
      "[dimension 131/145]  inactive:\t-1.58e-03 +- 3.13e-02\n",
      "[dimension 132/145]  inactive:\t5.25e-03 +- 4.80e-02\n",
      "[dimension 133/145]  inactive:\t2.38e-03 +- 1.98e-02\n",
      "[dimension 134/145]  inactive:\t-7.58e-04 +- 2.87e-02\n",
      "[dimension 135/145]  inactive:\t4.08e-04 +- 2.80e-02\n",
      "[dimension 136/145]  inactive:\t9.37e-04 +- 1.93e-02\n",
      "[dimension 137/145]  inactive:\t-6.80e-04 +- 3.18e-02\n",
      "[dimension 138/145]  inactive:\t-8.46e-05 +- 2.80e-02\n",
      "[dimension 139/145]  inactive:\t-1.69e-04 +- 2.81e-02\n",
      "[dimension 140/145]  inactive:\t-1.19e-03 +- 3.21e-02\n",
      "[dimension 141/145]  inactive:\t1.61e-03 +- 3.02e-02\n",
      "[dimension 142/145]  inactive:\t1.58e-03 +- 1.98e-02\n",
      "[dimension 143/145]  inactive:\t1.48e-03 +- 3.91e-02\n",
      "[dimension 144/145]  inactive:\t1.88e-04 +- 2.20e-02\n",
      "[dimension 145/145]  inactive:\t9.83e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00380547]\n",
      "cov_act[[0.00036419]]\n",
      "Active_dimensions: [62]\n",
      "43, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:27<00:00, 54.50it/s, 31 steps of size 1.90e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    493.44      1.00\n",
      "  lambda[0]      2.63     11.11      0.99      0.00      4.87    928.13      1.00\n",
      "  lambda[1]      2.73      8.50      1.01      0.00      4.71    725.16      1.00\n",
      "  lambda[2]      3.29     12.79      0.95      0.00      5.52    358.80      1.00\n",
      "  lambda[3]      5.89     33.85      1.08      0.00      6.76    468.85      1.00\n",
      "  lambda[4]      3.22     11.20      1.05      0.00      5.34    697.49      1.00\n",
      "  lambda[5]      3.57     26.65      0.92      0.00      4.95   1018.78      1.00\n",
      "  lambda[6]      2.82      9.27      1.01      0.00      4.64    497.67      1.00\n",
      "  lambda[7]      2.74      7.34      0.90      0.00      5.89    599.68      1.00\n",
      "  lambda[8]      2.37      4.60      0.99      0.01      4.65    890.07      1.00\n",
      "  lambda[9]      2.81      8.53      0.90      0.00      5.21    671.85      1.00\n",
      " lambda[10]      2.82      7.10      0.93      0.01      6.36    669.29      1.00\n",
      " lambda[11]      2.69      7.71      0.98      0.00      5.38    550.48      1.00\n",
      " lambda[12]      3.90     12.88      1.01      0.00      7.10    895.68      1.00\n",
      " lambda[13]      3.57     11.36      1.02      0.00      6.69    482.15      1.00\n",
      " lambda[14]      4.15     26.69      0.97      0.00      4.92    526.42      1.00\n",
      " lambda[15]      3.10     17.89      0.90      0.00      4.56    991.50      1.00\n",
      " lambda[16]      3.59     11.02      1.03      0.00      6.42    522.78      1.00\n",
      " lambda[17]      6.89    110.84      1.01      0.00      4.97    774.59      1.00\n",
      " lambda[18]      3.06      9.31      0.96      0.00      6.38    945.84      1.00\n",
      " lambda[19]      3.25     12.43      0.98      0.00      5.88    666.06      1.00\n",
      " lambda[20]      2.92      9.59      0.94      0.00      5.90    941.87      1.00\n",
      " lambda[21]      2.90      7.34      0.97      0.00      6.24    896.10      1.00\n",
      " lambda[22]      2.39      6.29      0.98      0.00      4.69    914.78      1.00\n",
      " lambda[23]      3.63     22.09      0.98      0.00      5.58    931.74      1.00\n",
      " lambda[24]      3.76     15.28      1.02      0.00      6.93    787.51      1.00\n",
      " lambda[25]      2.91     11.19      0.98      0.00      5.08    533.20      1.00\n",
      " lambda[26]      3.76     16.56      1.00      0.00      5.42    453.04      1.00\n",
      " lambda[27]      2.37      4.78      0.95      0.00      5.45    429.81      1.00\n",
      " lambda[28]      2.65      9.06      1.00      0.01      5.10    694.47      1.00\n",
      " lambda[29]      2.58      6.24      1.06      0.00      5.24    656.76      1.00\n",
      " lambda[30]      3.63     15.12      1.04      0.01      6.58    919.76      1.00\n",
      " lambda[31]      3.92     17.75      0.94      0.00      6.15    557.97      1.00\n",
      " lambda[32]      3.18     11.33      0.99      0.00      6.01    903.92      1.00\n",
      " lambda[33]      2.78      7.11      0.95      0.00      5.59    740.54      1.00\n",
      " lambda[34]      3.32     13.13      1.01      0.00      6.05    787.99      1.00\n",
      " lambda[35]      2.70      7.76      1.03      0.00      5.17    905.89      1.00\n",
      " lambda[36]      3.45     10.82      1.01      0.00      6.88    763.09      1.00\n",
      " lambda[37]      4.55     20.71      1.05      0.00      6.51    657.69      1.00\n",
      " lambda[38]      2.91      6.47      0.95      0.00      6.45    813.89      1.00\n",
      " lambda[39]      3.25      8.87      1.00      0.00      5.62    714.16      1.00\n",
      " lambda[40]      3.31     12.64      0.95      0.00      6.48    986.07      1.00\n",
      " lambda[41]     14.38    182.82      0.93      0.00      7.49    520.13      1.00\n",
      " lambda[42]      2.97      6.61      1.06      0.00      7.04    599.57      1.00\n",
      " lambda[43]      4.31     24.50      1.01      0.00      7.25    666.11      1.00\n",
      " lambda[44]      3.02      7.11      1.03      0.00      6.28    711.16      1.00\n",
      " lambda[45]      2.51      7.49      0.97      0.00      4.34    664.13      1.00\n",
      " lambda[46]      2.90     10.88      1.00      0.00      4.92    783.69      1.00\n",
      " lambda[47]      2.28      5.06      0.95      0.00      4.45    714.89      1.00\n",
      " lambda[48]      2.88      8.48      0.97      0.01      6.04    664.59      1.00\n",
      " lambda[49]      3.34     10.08      0.94      0.00      6.21    853.71      1.00\n",
      " lambda[50]      2.54      5.76      0.96      0.00      5.63    805.30      1.00\n",
      " lambda[51]      3.93     15.45      0.99      0.00      6.15    694.73      1.00\n",
      " lambda[52]      2.51      7.11      0.95      0.00      4.68    944.47      1.00\n",
      " lambda[53]      2.50      5.30      0.95      0.00      5.57    811.69      1.00\n",
      " lambda[54]      2.13      4.67      0.92      0.00      4.52    516.07      1.00\n",
      " lambda[55]      2.36      5.39      0.91      0.00      4.97    754.71      1.00\n",
      " lambda[56]      2.57      6.59      0.99      0.00      5.18    737.49      1.00\n",
      " lambda[57]      6.12     25.90      0.96      0.00      8.54    349.21      1.01\n",
      " lambda[58]      2.50      5.37      1.03      0.00      5.79    607.91      1.00\n",
      " lambda[59]      4.91     37.04      0.91      0.00      6.43    909.93      1.00\n",
      " lambda[60]      3.48     13.07      0.96      0.00      5.39    780.63      1.00\n",
      " lambda[61]      3.27     15.82      0.99      0.00      5.33    829.86      1.00\n",
      " lambda[62]   6103.65 112399.03    207.25      0.01   1907.98    517.58      1.00\n",
      " lambda[63]      2.46      7.16      0.96      0.00      5.07    883.60      1.00\n",
      " lambda[64]      3.10      9.27      0.99      0.00      5.72    635.07      1.00\n",
      " lambda[65]      3.05     11.15      1.11      0.00      5.40    742.54      1.00\n",
      " lambda[66]      3.60     12.16      0.98      0.00      8.10    729.66      1.00\n",
      " lambda[67]      2.93      8.32      0.95      0.00      6.29    610.44      1.00\n",
      " lambda[68]      3.38     10.51      0.90      0.01      5.94    571.21      1.01\n",
      " lambda[69]      4.24     29.02      0.94      0.00      5.66    986.94      1.00\n",
      " lambda[70]      2.63      7.09      0.97      0.00      5.86    768.73      1.01\n",
      " lambda[71]      5.36     80.96      1.01      0.00      4.77    763.20      1.00\n",
      " lambda[72]      2.17      4.56      0.98      0.00      4.72    813.27      1.00\n",
      " lambda[73]      5.10     33.80      1.00      0.00      6.44    721.28      1.00\n",
      " lambda[74]      2.48      4.83      1.03      0.00      5.86    718.52      1.00\n",
      " lambda[75]      4.91     22.42      1.02      0.00      7.87    825.63      1.00\n",
      " lambda[76]      3.02      9.76      0.95      0.00      5.95    778.59      1.00\n",
      " lambda[77]      4.38     18.97      1.02      0.00      7.49    678.74      1.00\n",
      " lambda[78]      4.15     24.24      1.00      0.00      5.85    620.21      1.00\n",
      " lambda[79]      3.00     12.04      0.98      0.00      5.03    916.49      1.00\n",
      " lambda[80]      3.56     22.87      1.02      0.00      5.44    835.59      1.00\n",
      " lambda[81]      2.44      5.11      0.89      0.00      5.24    772.13      1.00\n",
      " lambda[82]      2.37      5.13      1.01      0.00      5.24    953.83      1.00\n",
      " lambda[83]      3.05      9.62      1.00      0.00      5.44    839.20      1.00\n",
      " lambda[84]      2.62      6.79      1.01      0.00      5.47    604.85      1.00\n",
      " lambda[85]      2.72      7.71      1.02      0.00      5.37    739.55      1.00\n",
      " lambda[86]      2.91      8.84      0.97      0.00      5.82    806.94      1.00\n",
      " lambda[87]      3.67     13.45      0.96      0.00      6.48    630.39      1.00\n",
      " lambda[88]      2.67      5.62      0.98      0.00      5.81    837.96      1.00\n",
      " lambda[89]    188.56   3078.73      1.26      0.00     85.52    877.24      1.00\n",
      " lambda[90]      2.96      8.48      1.02      0.00      5.34    600.59      1.00\n",
      " lambda[91]      2.84      9.93      0.94      0.02      5.31    571.03      1.00\n",
      " lambda[92]      2.70      6.42      0.98      0.00      5.13    952.21      1.00\n",
      " lambda[93]      3.13     10.84      1.05      0.00      5.64    596.12      1.00\n",
      " lambda[94]      3.23      9.77      0.92      0.00      6.62    781.66      1.00\n",
      " lambda[95]      5.60     52.33      0.99      0.00      6.08    388.99      1.00\n",
      " lambda[96]      3.25     13.14      0.92      0.00      5.78    489.84      1.00\n",
      " lambda[97]      3.00      7.40      1.05      0.00      6.10    727.12      1.00\n",
      " lambda[98]      3.55     13.08      0.96      0.00      6.07    843.59      1.00\n",
      " lambda[99]      2.69      7.16      0.97      0.00      5.39    729.49      1.00\n",
      "lambda[100]      3.11      9.90      0.97      0.00      6.03    797.43      1.00\n",
      "lambda[101]      2.77      7.41      0.93      0.00      5.88    669.73      1.00\n",
      "lambda[102]      3.06      9.37      0.93      0.00      6.14    786.42      1.00\n",
      "lambda[103]      2.30      4.73      0.98      0.01      5.24    910.40      1.00\n",
      "lambda[104]      2.58      6.19      0.96      0.00      5.72    640.92      1.00\n",
      "lambda[105]      3.22     12.42      0.93      0.00      6.33    812.81      1.00\n",
      "lambda[106]      2.44      6.05      0.95      0.00      4.86   1120.82      1.00\n",
      "lambda[107]     32.97    611.33      1.06      0.00      6.94    504.07      1.00\n",
      "lambda[108]      2.53      5.35      0.91      0.00      5.65    512.08      1.00\n",
      "lambda[109]      4.79     54.60      0.95      0.00      6.15   1008.49      1.00\n",
      "lambda[110]      3.02     10.88      1.00      0.00      6.35    723.40      1.00\n",
      "lambda[111]      3.01      8.70      1.01      0.00      5.33    688.81      1.00\n",
      "lambda[112]      2.79     12.20      0.97      0.00      5.42    440.77      1.00\n",
      "lambda[113]      3.26      9.09      1.00      0.00      6.56    573.25      1.00\n",
      "lambda[114]      3.40     19.59      0.97      0.00      4.97    909.82      1.00\n",
      "lambda[115]      4.02     18.94      1.03      0.00      5.82    622.80      1.00\n",
      "lambda[116]      7.46     83.99      1.00      0.00      5.96    377.62      1.00\n",
      "lambda[117]      3.81     12.90      0.97      0.00      6.99    627.93      1.00\n",
      "lambda[118]      3.16      9.23      1.02      0.00      6.27    869.02      1.00\n",
      "lambda[119]      2.67      6.54      1.05      0.00      5.08    354.44      1.00\n",
      "lambda[120]      6.09     43.17      0.95      0.00      8.15    802.60      1.00\n",
      "lambda[121]      2.94      8.99      1.02      0.00      6.00    748.06      1.00\n",
      "lambda[122]      3.40     11.11      1.04      0.00      5.64    750.22      1.00\n",
      "lambda[123]      2.65      6.49      0.93      0.00      5.26    809.60      1.00\n",
      "lambda[124]      2.84      6.62      0.97      0.00      6.18    759.19      1.00\n",
      "lambda[125]      2.78      7.51      0.98      0.00      5.24    524.66      1.00\n",
      "lambda[126]      2.47      6.86      0.96      0.00      4.92    746.96      1.00\n",
      "lambda[127]      3.54     10.70      0.97      0.00      6.36    472.78      1.00\n",
      "lambda[128]      2.63      7.29      1.00      0.01      6.13    625.18      1.00\n",
      "lambda[129]      4.08     26.70      1.02      0.00      5.83    991.46      1.00\n",
      "lambda[130]      2.97     12.10      0.99      0.00      5.20   1058.73      1.00\n",
      "lambda[131]      4.67     30.42      0.96      0.00      5.94    562.63      1.00\n",
      "lambda[132]      3.32     12.05      1.03      0.00      6.26    428.19      1.00\n",
      "lambda[133]      2.85      7.36      1.01      0.00      5.56    721.94      1.00\n",
      "lambda[134]      3.12      8.70      0.93      0.00      6.75    787.74      1.00\n",
      "lambda[135]      2.65     10.26      0.97      0.00      5.29    878.19      1.00\n",
      "lambda[136]      3.37     10.83      1.00      0.00      5.72    678.44      1.00\n",
      "lambda[137]      3.20     15.11      1.00      0.00      5.90    863.61      1.00\n",
      "lambda[138]      2.81      7.34      0.96      0.00      5.59   1032.69      1.00\n",
      "lambda[139]      3.02      8.07      0.97      0.00      6.18    630.83      1.00\n",
      "lambda[140]      3.11      9.34      0.97      0.00      5.95    720.18      1.00\n",
      "lambda[141]      2.69      7.86      0.89      0.00      5.58    789.44      1.00\n",
      "lambda[142]      4.23     20.36      0.95      0.01      6.58    472.85      1.00\n",
      "lambda[143]      2.04      4.17      0.94      0.01      4.57    825.42      1.00\n",
      "        msq      1.33      0.67      1.18      0.44      2.17   1053.52      1.00\n",
      "      sigma      4.52      5.90      2.06      0.01     12.64   1331.59      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11   1307.51      1.00\n",
      "       xisq      0.12      0.07      0.11      0.05      0.20    782.21      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.25393581390381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.20e-04 +- 1.87e-02\n",
      "[dimension 02/145]  inactive:\t-4.90e-04 +- 2.19e-02\n",
      "[dimension 03/145]  inactive:\t1.52e-04 +- 2.44e-02\n",
      "[dimension 04/145]  inactive:\t7.52e-03 +- 4.90e-02\n",
      "[dimension 05/145]  inactive:\t-1.22e-03 +- 2.78e-02\n",
      "[dimension 06/145]  inactive:\t1.85e-03 +- 3.34e-02\n",
      "[dimension 07/145]  inactive:\t5.34e-04 +- 1.87e-02\n",
      "[dimension 08/145]  inactive:\t1.59e-03 +- 2.93e-02\n",
      "[dimension 09/145]  inactive:\t2.03e-04 +- 2.47e-02\n",
      "[dimension 10/145]  inactive:\t5.34e-04 +- 1.92e-02\n",
      "[dimension 11/145]  inactive:\t-7.80e-04 +- 2.76e-02\n",
      "[dimension 12/145]  inactive:\t-2.06e-04 +- 2.27e-02\n",
      "[dimension 13/145]  inactive:\t5.04e-03 +- 4.09e-02\n",
      "[dimension 14/145]  inactive:\t-1.98e-03 +- 3.14e-02\n",
      "[dimension 15/145]  inactive:\t1.03e-04 +- 2.87e-02\n",
      "[dimension 16/145]  inactive:\t4.57e-04 +- 1.98e-02\n",
      "[dimension 17/145]  inactive:\t1.36e-03 +- 3.85e-02\n",
      "[dimension 18/145]  inactive:\t-4.63e-04 +- 3.50e-02\n",
      "[dimension 19/145]  inactive:\t-2.88e-03 +- 2.33e-02\n",
      "[dimension 20/145]  inactive:\t-1.57e-03 +- 3.05e-02\n",
      "[dimension 21/145]  inactive:\t-2.24e-03 +- 2.79e-02\n",
      "[dimension 22/145]  inactive:\t-2.05e-04 +- 2.47e-02\n",
      "[dimension 23/145]  inactive:\t-4.28e-04 +- 2.19e-02\n",
      "[dimension 24/145]  inactive:\t1.63e-03 +- 3.01e-02\n",
      "[dimension 25/145]  inactive:\t4.00e-03 +- 2.49e-02\n",
      "[dimension 26/145]  inactive:\t-8.25e-04 +- 3.00e-02\n",
      "[dimension 27/145]  inactive:\t8.36e-04 +- 2.79e-02\n",
      "[dimension 28/145]  inactive:\t8.08e-04 +- 1.88e-02\n",
      "[dimension 29/145]  inactive:\t1.80e-04 +- 2.57e-02\n",
      "[dimension 30/145]  inactive:\t6.19e-04 +- 2.55e-02\n",
      "[dimension 31/145]  inactive:\t6.21e-03 +- 4.57e-02\n",
      "[dimension 32/145]  inactive:\t-1.74e-03 +- 2.64e-02\n",
      "[dimension 33/145]  inactive:\t1.95e-03 +- 3.39e-02\n",
      "[dimension 34/145]  inactive:\t7.95e-04 +- 2.00e-02\n",
      "[dimension 35/145]  inactive:\t6.16e-04 +- 3.09e-02\n",
      "[dimension 36/145]  inactive:\t6.36e-04 +- 2.36e-02\n",
      "[dimension 37/145]  inactive:\t5.07e-03 +- 2.98e-02\n",
      "[dimension 38/145]  inactive:\t-2.31e-03 +- 3.53e-02\n",
      "[dimension 39/145]  inactive:\t8.13e-04 +- 2.70e-02\n",
      "[dimension 40/145]  inactive:\t5.33e-03 +- 3.73e-02\n",
      "[dimension 41/145]  inactive:\t-1.91e-03 +- 3.12e-02\n",
      "[dimension 42/145]  inactive:\t1.18e-02 +- 8.37e-02\n",
      "[dimension 43/145]  inactive:\t-3.29e-04 +- 2.16e-02\n",
      "[dimension 44/145]  inactive:\t-1.07e-03 +- 4.14e-02\n",
      "[dimension 45/145]  inactive:\t-8.94e-04 +- 2.70e-02\n",
      "[dimension 46/145]  inactive:\t9.50e-04 +- 1.42e-02\n",
      "[dimension 47/145]  inactive:\t-2.08e-03 +- 3.21e-02\n",
      "[dimension 48/145]  inactive:\t6.07e-04 +- 2.14e-02\n",
      "[dimension 49/145]  inactive:\t3.01e-03 +- 2.59e-02\n",
      "[dimension 50/145]  inactive:\t-1.76e-03 +- 2.93e-02\n",
      "[dimension 51/145]  inactive:\t2.03e-03 +- 2.69e-02\n",
      "[dimension 52/145]  inactive:\t5.60e-03 +- 2.44e-02\n",
      "[dimension 53/145]  inactive:\t-1.04e-03 +- 2.22e-02\n",
      "[dimension 54/145]  inactive:\t-1.85e-04 +- 2.17e-02\n",
      "[dimension 55/145]  inactive:\t5.42e-04 +- 1.57e-02\n",
      "[dimension 56/145]  inactive:\t-1.96e-03 +- 1.88e-02\n",
      "[dimension 57/145]  inactive:\t2.08e-03 +- 3.54e-02\n",
      "[dimension 58/145]  inactive:\t1.68e-02 +- 8.44e-02\n",
      "[dimension 59/145]  inactive:\t-7.73e-04 +- 1.85e-02\n",
      "[dimension 60/145]  inactive:\t1.07e-03 +- 3.06e-02\n",
      "[dimension 61/145]  inactive:\t2.90e-03 +- 2.52e-02\n",
      "[dimension 62/145]  inactive:\t-9.88e-04 +- 2.26e-02\n",
      "[dimension 63/145]  active:\t7.25e-01 +- 4.04e-01\n",
      "[dimension 64/145]  inactive:\t-3.33e-03 +- 2.68e-02\n",
      "[dimension 65/145]  inactive:\t-4.95e-04 +- 2.58e-02\n",
      "[dimension 66/145]  inactive:\t2.56e-04 +- 2.31e-02\n",
      "[dimension 67/145]  inactive:\t1.62e-03 +- 3.09e-02\n",
      "[dimension 68/145]  inactive:\t-7.78e-04 +- 3.02e-02\n",
      "[dimension 69/145]  inactive:\t4.04e-03 +- 4.27e-02\n",
      "[dimension 70/145]  inactive:\t3.83e-03 +- 2.52e-02\n",
      "[dimension 71/145]  inactive:\t6.26e-04 +- 3.40e-02\n",
      "[dimension 72/145]  inactive:\t3.28e-04 +- 2.38e-02\n",
      "[dimension 73/145]  inactive:\t1.75e-04 +- 1.75e-02\n",
      "[dimension 74/145]  inactive:\t-2.56e-03 +- 3.89e-02\n",
      "[dimension 75/145]  inactive:\t2.37e-04 +- 2.26e-02\n",
      "[dimension 76/145]  inactive:\t7.42e-03 +- 4.64e-02\n",
      "[dimension 77/145]  inactive:\t-1.71e-03 +- 3.31e-02\n",
      "[dimension 78/145]  inactive:\t6.35e-03 +- 5.69e-02\n",
      "[dimension 79/145]  inactive:\t6.30e-03 +- 3.47e-02\n",
      "[dimension 80/145]  inactive:\t-5.65e-04 +- 3.20e-02\n",
      "[dimension 81/145]  inactive:\t9.66e-04 +- 2.80e-02\n",
      "[dimension 82/145]  inactive:\t1.70e-04 +- 1.67e-02\n",
      "[dimension 83/145]  inactive:\t-1.74e-03 +- 1.85e-02\n",
      "[dimension 84/145]  inactive:\t-1.51e-03 +- 2.50e-02\n",
      "[dimension 85/145]  inactive:\t1.61e-03 +- 2.40e-02\n",
      "[dimension 86/145]  inactive:\t-4.16e-04 +- 2.07e-02\n",
      "[dimension 87/145]  inactive:\t1.71e-03 +- 3.96e-02\n",
      "[dimension 88/145]  inactive:\t3.46e-03 +- 2.72e-02\n",
      "[dimension 89/145]  inactive:\t-8.46e-04 +- 2.08e-02\n",
      "[dimension 90/145]  inactive:\t1.05e-01 +- 2.83e-01\n",
      "[dimension 91/145]  inactive:\t1.66e-04 +- 1.98e-02\n",
      "[dimension 92/145]  inactive:\t-1.78e-03 +- 2.39e-02\n",
      "[dimension 93/145]  inactive:\t-6.80e-04 +- 2.73e-02\n",
      "[dimension 94/145]  inactive:\t2.32e-03 +- 2.79e-02\n",
      "[dimension 95/145]  inactive:\t-3.92e-04 +- 2.74e-02\n",
      "[dimension 96/145]  inactive:\t3.05e-04 +- 4.12e-02\n",
      "[dimension 97/145]  inactive:\t2.34e-03 +- 2.49e-02\n",
      "[dimension 98/145]  inactive:\t-9.66e-04 +- 2.71e-02\n",
      "[dimension 99/145]  inactive:\t3.58e-03 +- 4.30e-02\n",
      "[dimension 100/145]  inactive:\t-7.00e-04 +- 1.73e-02\n",
      "[dimension 101/145]  inactive:\t-2.93e-03 +- 2.39e-02\n",
      "[dimension 102/145]  inactive:\t-6.58e-04 +- 2.44e-02\n",
      "[dimension 103/145]  inactive:\t1.36e-03 +- 2.78e-02\n",
      "[dimension 104/145]  inactive:\t-1.13e-03 +- 1.78e-02\n",
      "[dimension 105/145]  inactive:\t-3.44e-04 +- 2.31e-02\n",
      "[dimension 106/145]  inactive:\t5.37e-03 +- 3.39e-02\n",
      "[dimension 107/145]  inactive:\t-1.11e-03 +- 2.08e-02\n",
      "[dimension 108/145]  inactive:\t7.83e-03 +- 7.20e-02\n",
      "[dimension 109/145]  inactive:\t-6.13e-04 +- 1.96e-02\n",
      "[dimension 110/145]  inactive:\t-6.48e-04 +- 3.41e-02\n",
      "[dimension 111/145]  inactive:\t1.32e-03 +- 3.01e-02\n",
      "[dimension 112/145]  inactive:\t4.01e-03 +- 3.36e-02\n",
      "[dimension 113/145]  inactive:\t-1.67e-03 +- 2.33e-02\n",
      "[dimension 114/145]  inactive:\t-4.59e-05 +- 3.20e-02\n",
      "[dimension 115/145]  inactive:\t2.04e-03 +- 2.25e-02\n",
      "[dimension 116/145]  inactive:\t-1.46e-04 +- 3.18e-02\n",
      "[dimension 117/145]  inactive:\t4.85e-03 +- 4.68e-02\n",
      "[dimension 118/145]  inactive:\t4.19e-03 +- 2.90e-02\n",
      "[dimension 119/145]  inactive:\t-1.98e-03 +- 2.97e-02\n",
      "[dimension 120/145]  inactive:\t1.55e-04 +- 3.07e-02\n",
      "[dimension 121/145]  inactive:\t6.18e-03 +- 4.35e-02\n",
      "[dimension 122/145]  inactive:\t-2.16e-03 +- 2.77e-02\n",
      "[dimension 123/145]  inactive:\t3.13e-03 +- 4.62e-02\n",
      "[dimension 124/145]  inactive:\t-1.96e-03 +- 2.03e-02\n",
      "[dimension 125/145]  inactive:\t-1.96e-03 +- 3.08e-02\n",
      "[dimension 126/145]  inactive:\t-1.15e-03 +- 2.44e-02\n",
      "[dimension 127/145]  inactive:\t5.34e-05 +- 1.76e-02\n",
      "[dimension 128/145]  inactive:\t-1.29e-03 +- 3.40e-02\n",
      "[dimension 129/145]  inactive:\t-6.30e-05 +- 2.39e-02\n",
      "[dimension 130/145]  inactive:\t3.44e-03 +- 2.81e-02\n",
      "[dimension 131/145]  inactive:\t-6.44e-04 +- 3.24e-02\n",
      "[dimension 132/145]  inactive:\t3.42e-03 +- 3.72e-02\n",
      "[dimension 133/145]  inactive:\t2.67e-03 +- 2.13e-02\n",
      "[dimension 134/145]  inactive:\t-7.89e-04 +- 2.71e-02\n",
      "[dimension 135/145]  inactive:\t8.32e-04 +- 2.98e-02\n",
      "[dimension 136/145]  inactive:\t1.11e-03 +- 1.95e-02\n",
      "[dimension 137/145]  inactive:\t-2.76e-04 +- 3.15e-02\n",
      "[dimension 138/145]  inactive:\t4.55e-04 +- 2.37e-02\n",
      "[dimension 139/145]  inactive:\t-1.65e-04 +- 2.59e-02\n",
      "[dimension 140/145]  inactive:\t-7.55e-04 +- 3.17e-02\n",
      "[dimension 141/145]  inactive:\t1.45e-03 +- 3.34e-02\n",
      "[dimension 142/145]  inactive:\t1.63e-03 +- 1.94e-02\n",
      "[dimension 143/145]  inactive:\t1.35e-03 +- 3.53e-02\n",
      "[dimension 144/145]  inactive:\t2.28e-04 +- 1.77e-02\n",
      "[dimension 145/145]  inactive:\t4.62e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9263853]\n",
      "cov_act[[0.01457995]]\n",
      "Active_dimensions: [62]\n",
      "44, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.21it/s, 31 steps of size 1.70e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    789.15      1.00\n",
      "  lambda[0]      2.31      5.61      0.96      0.00      4.67    740.49      1.00\n",
      "  lambda[1]      3.08      9.20      1.03      0.00      5.87    580.06      1.00\n",
      "  lambda[2]      2.88      8.08      0.99      0.00      5.79    652.46      1.00\n",
      "  lambda[3]      4.94     31.66      0.95      0.00      6.38    640.10      1.00\n",
      "  lambda[4]      2.84     12.13      0.99      0.00      5.47    891.90      1.00\n",
      "  lambda[5]      3.24     15.22      1.00      0.01      5.55    765.34      1.00\n",
      "  lambda[6]      2.83      9.36      1.01      0.00      5.92    864.33      1.00\n",
      "  lambda[7]      3.09     12.29      0.96      0.00      5.39    635.12      1.00\n",
      "  lambda[8]      2.46      5.48      1.00      0.00      5.38    664.25      1.00\n",
      "  lambda[9]      2.43      5.10      1.03      0.00      5.09    889.13      1.00\n",
      " lambda[10]      3.77     15.68      1.07      0.00      6.15    483.17      1.00\n",
      " lambda[11]      2.89      7.15      0.99      0.00      6.18    644.86      1.00\n",
      " lambda[12]      3.51     11.14      1.04      0.00      6.44    680.86      1.00\n",
      " lambda[13]      2.78     10.05      0.92      0.00      5.31    739.32      1.00\n",
      " lambda[14]      4.23     21.04      0.90      0.00      5.39    657.20      1.00\n",
      " lambda[15]      2.85      8.71      0.95      0.00      5.82    775.93      1.00\n",
      " lambda[16]      3.69     10.45      0.93      0.00      8.31    587.30      1.01\n",
      " lambda[17]      2.91     18.85      0.92      0.00      5.37    723.50      1.00\n",
      " lambda[18]      2.98      8.05      0.96      0.00      6.56    487.49      1.00\n",
      " lambda[19]      2.75      7.40      0.94      0.01      5.45    714.49      1.00\n",
      " lambda[20]      2.66      6.21      0.97      0.00      6.06    871.30      1.00\n",
      " lambda[21]      2.87      9.02      0.99      0.00      6.07    633.58      1.00\n",
      " lambda[22]      2.59      6.02      0.96      0.00      5.18    603.52      1.00\n",
      " lambda[23]      3.05      9.19      1.01      0.00      5.71    838.45      1.00\n",
      " lambda[24]      3.51     16.16      1.01      0.00      5.72    806.87      1.00\n",
      " lambda[25]      3.35      9.12      0.99      0.00      6.69    414.99      1.00\n",
      " lambda[26]      3.08      8.91      1.04      0.00      5.64    460.67      1.00\n",
      " lambda[27]      2.72      7.09      0.97      0.00      5.60    653.97      1.00\n",
      " lambda[28]      2.73      9.46      0.95      0.00      5.08    560.05      1.00\n",
      " lambda[29]      3.12      9.50      0.99      0.00      5.68    632.16      1.00\n",
      " lambda[30]      3.36     12.46      1.03      0.00      6.40    952.02      1.00\n",
      " lambda[31]      3.52     15.47      1.01      0.00      5.86    709.30      1.00\n",
      " lambda[32]      2.96      7.59      0.94      0.00      6.57    608.58      1.00\n",
      " lambda[33]      2.57      7.99      0.95      0.01      5.18    871.30      1.00\n",
      " lambda[34]      2.72      8.28      0.98      0.00      5.03    698.18      1.00\n",
      " lambda[35]      2.52      6.25      1.01      0.00      5.24    855.17      1.00\n",
      " lambda[36]      3.70     13.72      0.99      0.00      6.26    545.42      1.00\n",
      " lambda[37]      3.45     10.09      0.98      0.00      6.95    617.35      1.00\n",
      " lambda[38]      3.07      8.21      0.96      0.00      5.93    796.44      1.00\n",
      " lambda[39]      3.13     10.11      0.99      0.00      5.98    686.66      1.00\n",
      " lambda[40]      3.58     13.42      0.91      0.00      6.19    906.87      1.00\n",
      " lambda[41]    201.10   4296.39      0.89      0.00      7.16    500.25      1.00\n",
      " lambda[42]      3.21     18.35      0.97      0.00      5.28    515.39      1.00\n",
      " lambda[43]      3.76     26.32      0.96      0.00      6.49   1014.42      1.00\n",
      " lambda[44]      2.95      8.90      1.00      0.01      5.80    647.22      1.00\n",
      " lambda[45]      2.39      7.84      0.99      0.00      4.50   1021.45      1.00\n",
      " lambda[46]      2.70      7.05      1.07      0.01      5.32    849.32      1.00\n",
      " lambda[47]      2.61      5.51      0.98      0.01      5.58    636.60      1.00\n",
      " lambda[48]      2.47      7.28      0.97      0.01      5.11    973.03      1.00\n",
      " lambda[49]      3.45     12.09      0.98      0.00      5.94    502.73      1.00\n",
      " lambda[50]      3.13      9.06      0.98      0.00      5.85    515.39      1.00\n",
      " lambda[51]      3.78     11.87      1.00      0.00      7.65    565.70      1.00\n",
      " lambda[52]      2.88     10.30      0.94      0.00      5.25    857.55      1.00\n",
      " lambda[53]      2.54      6.43      1.00      0.00      4.47    723.98      1.00\n",
      " lambda[54]      2.06      4.02      1.01      0.00      4.45    921.73      1.00\n",
      " lambda[55]      3.21     14.03      0.99      0.00      5.89   1014.51      1.00\n",
      " lambda[56]      2.70      6.51      0.97      0.00      5.14    706.73      1.00\n",
      " lambda[57]      7.96     49.54      1.00      0.00     10.65    733.59      1.00\n",
      " lambda[58]      2.55      7.01      0.97      0.00      5.20    708.08      1.00\n",
      " lambda[59]      3.11      8.34      1.02      0.00      6.88    627.02      1.00\n",
      " lambda[60]      3.21     11.30      0.91      0.00      5.25    708.83      1.00\n",
      " lambda[61]      2.55      6.73      1.00      0.00      5.70    785.36      1.00\n",
      " lambda[62]   1148.00  21626.09    180.69      0.00   1062.02    994.18      1.00\n",
      " lambda[63]      2.29      5.06      1.02      0.01      5.29    538.77      1.00\n",
      " lambda[64]      3.41     10.41      0.95      0.00      6.13    695.19      1.01\n",
      " lambda[65]      3.24     11.70      0.97      0.00      6.43    798.63      1.00\n",
      " lambda[66]      3.01      7.57      1.03      0.00      6.25    515.52      1.00\n",
      " lambda[67]      2.50      6.68      0.92      0.01      4.88    659.96      1.00\n",
      " lambda[68]      4.46     39.09      1.00      0.00      6.07    877.60      1.00\n",
      " lambda[69]      3.55     13.58      0.95      0.00      6.19    834.93      1.00\n",
      " lambda[70]      2.64      6.08      1.01      0.00      5.24    593.18      1.01\n",
      " lambda[71]      3.01      8.58      0.97      0.00      5.53    496.05      1.00\n",
      " lambda[72]      2.76      8.36      0.98      0.01      5.61    688.71      1.00\n",
      " lambda[73]      2.78      6.56      1.04      0.00      5.62    588.92      1.00\n",
      " lambda[74]      2.58      9.01      1.00      0.01      5.44   1039.92      1.00\n",
      " lambda[75]      3.85     12.38      1.01      0.00      6.96    779.61      1.00\n",
      " lambda[76]      3.01      8.70      0.94      0.00      5.23    752.23      1.00\n",
      " lambda[77]      2.70      5.60      1.04      0.00      6.18    886.90      1.00\n",
      " lambda[78]      3.05      8.66      1.00      0.00      6.45    951.95      1.00\n",
      " lambda[79]      3.16      9.93      1.00      0.00      5.50    582.82      1.00\n",
      " lambda[80]      4.27     21.15      1.06      0.00      6.17    445.71      1.00\n",
      " lambda[81]      2.37      5.22      0.90      0.00      5.26   1098.31      1.00\n",
      " lambda[82]      2.59     14.99      0.97      0.00      4.65   1016.96      1.00\n",
      " lambda[83]      3.33     11.97      0.90      0.00      5.85    848.07      1.00\n",
      " lambda[84]      3.73     22.30      0.92      0.00      5.60    952.32      1.00\n",
      " lambda[85]      2.28      4.67      0.93      0.00      5.19    674.10      1.00\n",
      " lambda[86]      2.80      6.49      0.98      0.00      6.22    680.23      1.00\n",
      " lambda[87]      3.69     16.29      0.97      0.00      6.57    465.85      1.00\n",
      " lambda[88]      2.64      5.97      0.99      0.01      5.98    702.57      1.00\n",
      " lambda[89]     24.57    100.48      1.16      0.00     26.99    192.67      1.00\n",
      " lambda[90]      3.22     10.11      1.04      0.00      6.04    594.26      1.00\n",
      " lambda[91]      2.46      6.65      0.94      0.01      4.58    732.86      1.00\n",
      " lambda[92]      2.79      7.16      1.02      0.01      5.27    714.95      1.00\n",
      " lambda[93]      2.62      6.85      1.01      0.00      4.81    497.21      1.00\n",
      " lambda[94]      2.59      7.81      0.99      0.00      4.89    737.14      1.00\n",
      " lambda[95]      3.15      9.63      0.98      0.00      7.31    655.06      1.00\n",
      " lambda[96]      2.46      5.35      0.94      0.00      5.31    818.17      1.00\n",
      " lambda[97]      3.07      9.44      0.96      0.00      5.93    579.53      1.00\n",
      " lambda[98]      4.38     43.16      1.01      0.00      5.46   1003.45      1.00\n",
      " lambda[99]      2.28      6.11      0.94      0.01      4.67    854.17      1.00\n",
      "lambda[100]      3.04      8.64      0.93      0.00      6.38    703.60      1.00\n",
      "lambda[101]      2.69      6.02      0.90      0.00      6.26    622.49      1.00\n",
      "lambda[102]      2.86     10.97      0.92      0.00      5.33    875.95      1.00\n",
      "lambda[103]      2.49      4.92      0.98      0.00      5.84    641.72      1.00\n",
      "lambda[104]      3.19     12.98      0.96      0.00      6.10    340.74      1.00\n",
      "lambda[105]      2.82      6.52      1.02      0.00      6.51    953.11      1.00\n",
      "lambda[106]      2.56      5.36      0.98      0.00      6.21    850.92      1.00\n",
      "lambda[107]      3.35     10.89      1.00      0.00      5.68    612.38      1.00\n",
      "lambda[108]      2.21      5.26      0.95      0.00      4.91    692.85      1.00\n",
      "lambda[109]      3.33      9.27      0.97      0.00      6.37    749.60      1.00\n",
      "lambda[110]      3.69     12.85      0.99      0.00      7.08    727.74      1.00\n",
      "lambda[111]      3.43     10.40      0.98      0.00      7.03    634.81      1.00\n",
      "lambda[112]      2.70      6.43      0.94      0.00      5.68    886.76      1.00\n",
      "lambda[113]      3.54     10.90      1.08      0.00      6.67    636.09      1.00\n",
      "lambda[114]      2.66      5.91      0.95      0.00      5.88    613.68      1.00\n",
      "lambda[115]      3.97     24.15      0.96      0.00      5.48    587.95      1.00\n",
      "lambda[116]      4.61     30.38      1.00      0.00      6.05    482.68      1.00\n",
      "lambda[117]      3.06      8.92      0.96      0.00      5.99    679.56      1.00\n",
      "lambda[118]      3.48     13.67      0.97      0.00      5.91    962.50      1.00\n",
      "lambda[119]      3.17     12.79      1.03      0.01      6.66    888.17      1.00\n",
      "lambda[120]      4.75     19.71      1.02      0.00      7.39    763.24      1.00\n",
      "lambda[121]      3.04     10.87      0.93      0.00      5.67    629.84      1.00\n",
      "lambda[122]      3.26      9.70      0.99      0.00      6.77    727.39      1.00\n",
      "lambda[123]      2.60      7.15      0.92      0.00      5.53    765.78      1.00\n",
      "lambda[124]      2.63      5.25      1.02      0.00      6.01    727.96      1.00\n",
      "lambda[125]      3.01      9.25      0.98      0.01      5.76    590.67      1.00\n",
      "lambda[126]      2.80      9.20      0.92      0.00      4.83    801.81      1.00\n",
      "lambda[127]      3.72     13.78      1.02      0.00      6.07    462.57      1.00\n",
      "lambda[128]      2.90     10.41      0.97      0.00      4.91    449.90      1.00\n",
      "lambda[129]      3.86     16.33      1.04      0.00      5.61    597.13      1.00\n",
      "lambda[130]      3.22      8.25      0.94      0.00      6.75    515.06      1.00\n",
      "lambda[131]      3.73     14.58      0.96      0.01      6.00    584.57      1.00\n",
      "lambda[132]      2.71      6.89      1.00      0.00      5.86    763.50      1.00\n",
      "lambda[133]      2.42      4.85      0.98      0.00      5.27    758.68      1.00\n",
      "lambda[134]      3.31      9.17      0.90      0.00      7.32    729.56      1.00\n",
      "lambda[135]      2.85     10.35      0.91      0.00      4.99    749.37      1.00\n",
      "lambda[136]      2.95      7.12      0.95      0.00      6.76    696.87      1.00\n",
      "lambda[137]      2.95      9.66      0.94      0.00      5.43    577.40      1.00\n",
      "lambda[138]      2.89      7.77      1.00      0.00      5.56    843.12      1.00\n",
      "lambda[139]      3.39     10.44      0.98      0.01      6.54    573.17      1.01\n",
      "lambda[140]      2.99      7.93      1.00      0.00      5.43    806.45      1.00\n",
      "lambda[141]      2.15      4.18      0.87      0.00      4.85    859.59      1.00\n",
      "lambda[142]      4.47     28.85      0.98      0.00      6.11    560.93      1.00\n",
      "lambda[143]      2.11      3.82      0.97      0.01      4.98    758.69      1.00\n",
      "        msq 164223.30 5022866.00     29.99      1.15    857.14   1000.36      1.00\n",
      "      sigma      5.81      7.93      2.39      0.02     15.59   1311.83      1.00\n",
      "    var_obs      0.09      0.01      0.09      0.07      0.11   1240.31      1.00\n",
      "       xisq     63.28    899.09      1.70      0.09     26.48    675.82      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 32.410491943359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.69e-04 +- 2.04e-02\n",
      "[dimension 02/145]  inactive:\t-1.18e-03 +- 2.76e-02\n",
      "[dimension 03/145]  inactive:\t5.17e-04 +- 2.55e-02\n",
      "[dimension 04/145]  inactive:\t6.59e-03 +- 4.26e-02\n",
      "[dimension 05/145]  inactive:\t-1.25e-03 +- 2.84e-02\n",
      "[dimension 06/145]  inactive:\t3.05e-03 +- 4.22e-02\n",
      "[dimension 07/145]  inactive:\t6.39e-04 +- 1.80e-02\n",
      "[dimension 08/145]  inactive:\t6.17e-04 +- 2.95e-02\n",
      "[dimension 09/145]  inactive:\t7.13e-05 +- 2.22e-02\n",
      "[dimension 10/145]  inactive:\t4.36e-04 +- 2.10e-02\n",
      "[dimension 11/145]  inactive:\t-1.69e-03 +- 2.39e-02\n",
      "[dimension 12/145]  inactive:\t-1.29e-04 +- 3.42e-02\n",
      "[dimension 13/145]  inactive:\t4.41e-03 +- 3.92e-02\n",
      "[dimension 14/145]  inactive:\t-1.81e-03 +- 2.47e-02\n",
      "[dimension 15/145]  inactive:\t4.58e-04 +- 3.64e-02\n",
      "[dimension 16/145]  inactive:\t9.39e-04 +- 2.02e-02\n",
      "[dimension 17/145]  inactive:\t-1.94e-05 +- 3.67e-02\n",
      "[dimension 18/145]  inactive:\t-6.09e-04 +- 2.50e-02\n",
      "[dimension 19/145]  inactive:\t-3.32e-03 +- 2.59e-02\n",
      "[dimension 20/145]  inactive:\t-2.25e-03 +- 3.21e-02\n",
      "[dimension 21/145]  inactive:\t-1.66e-03 +- 2.41e-02\n",
      "[dimension 22/145]  inactive:\t-1.13e-04 +- 2.32e-02\n",
      "[dimension 23/145]  inactive:\t-9.85e-04 +- 2.72e-02\n",
      "[dimension 24/145]  inactive:\t1.98e-03 +- 2.88e-02\n",
      "[dimension 25/145]  inactive:\t2.89e-03 +- 2.17e-02\n",
      "[dimension 26/145]  inactive:\t-1.41e-03 +- 3.08e-02\n",
      "[dimension 27/145]  inactive:\t6.37e-04 +- 2.52e-02\n",
      "[dimension 28/145]  inactive:\t8.03e-04 +- 2.06e-02\n",
      "[dimension 29/145]  inactive:\t-7.30e-04 +- 2.76e-02\n",
      "[dimension 30/145]  inactive:\t1.78e-03 +- 3.64e-02\n",
      "[dimension 31/145]  inactive:\t5.61e-03 +- 4.16e-02\n",
      "[dimension 32/145]  inactive:\t-2.28e-03 +- 2.74e-02\n",
      "[dimension 33/145]  inactive:\t1.44e-03 +- 3.48e-02\n",
      "[dimension 34/145]  inactive:\t6.24e-04 +- 1.79e-02\n",
      "[dimension 35/145]  inactive:\t-1.31e-04 +- 2.68e-02\n",
      "[dimension 36/145]  inactive:\t4.20e-04 +- 2.47e-02\n",
      "[dimension 37/145]  inactive:\t5.03e-03 +- 2.95e-02\n",
      "[dimension 38/145]  inactive:\t-2.68e-03 +- 4.54e-02\n",
      "[dimension 39/145]  inactive:\t1.01e-03 +- 3.27e-02\n",
      "[dimension 40/145]  inactive:\t5.52e-03 +- 4.34e-02\n",
      "[dimension 41/145]  inactive:\t-2.19e-03 +- 3.52e-02\n",
      "[dimension 42/145]  inactive:\t1.29e-02 +- 9.31e-02\n",
      "[dimension 43/145]  inactive:\t-8.76e-04 +- 2.10e-02\n",
      "[dimension 44/145]  inactive:\t-1.07e-03 +- 2.87e-02\n",
      "[dimension 45/145]  inactive:\t-7.58e-04 +- 2.46e-02\n",
      "[dimension 46/145]  inactive:\t1.05e-03 +- 1.52e-02\n",
      "[dimension 47/145]  inactive:\t-1.97e-03 +- 2.97e-02\n",
      "[dimension 48/145]  inactive:\t1.60e-03 +- 2.57e-02\n",
      "[dimension 49/145]  inactive:\t2.81e-03 +- 2.43e-02\n",
      "[dimension 50/145]  inactive:\t-2.89e-03 +- 3.26e-02\n",
      "[dimension 51/145]  inactive:\t3.55e-03 +- 3.41e-02\n",
      "[dimension 52/145]  inactive:\t7.25e-03 +- 2.87e-02\n",
      "[dimension 53/145]  inactive:\t-1.19e-03 +- 2.81e-02\n",
      "[dimension 54/145]  inactive:\t-1.60e-04 +- 1.86e-02\n",
      "[dimension 55/145]  inactive:\t3.83e-04 +- 1.46e-02\n",
      "[dimension 56/145]  inactive:\t-2.34e-03 +- 2.48e-02\n",
      "[dimension 57/145]  inactive:\t4.23e-05 +- 2.53e-02\n",
      "[dimension 58/145]  inactive:\t1.86e-02 +- 8.76e-02\n",
      "[dimension 59/145]  inactive:\t-4.69e-04 +- 1.87e-02\n",
      "[dimension 60/145]  inactive:\t3.36e-04 +- 3.06e-02\n",
      "[dimension 61/145]  inactive:\t2.78e-03 +- 2.77e-02\n",
      "[dimension 62/145]  inactive:\t-8.02e-04 +- 2.34e-02\n",
      "[dimension 63/145]  active:\t7.72e-01 +- 3.86e-01\n",
      "[dimension 64/145]  inactive:\t-3.00e-03 +- 2.48e-02\n",
      "[dimension 65/145]  inactive:\t-1.32e-03 +- 2.98e-02\n",
      "[dimension 66/145]  inactive:\t7.46e-04 +- 2.74e-02\n",
      "[dimension 67/145]  inactive:\t1.86e-03 +- 2.77e-02\n",
      "[dimension 68/145]  inactive:\t-6.86e-04 +- 2.34e-02\n",
      "[dimension 69/145]  inactive:\t3.93e-03 +- 4.06e-02\n",
      "[dimension 70/145]  inactive:\t3.86e-03 +- 2.49e-02\n",
      "[dimension 71/145]  inactive:\t6.53e-05 +- 2.67e-02\n",
      "[dimension 72/145]  inactive:\t1.49e-04 +- 2.68e-02\n",
      "[dimension 73/145]  inactive:\t1.67e-04 +- 1.87e-02\n",
      "[dimension 74/145]  inactive:\t-2.09e-03 +- 3.30e-02\n",
      "[dimension 75/145]  inactive:\t2.94e-04 +- 2.41e-02\n",
      "[dimension 76/145]  inactive:\t5.57e-03 +- 3.86e-02\n",
      "[dimension 77/145]  inactive:\t-2.13e-03 +- 3.20e-02\n",
      "[dimension 78/145]  inactive:\t2.80e-03 +- 3.62e-02\n",
      "[dimension 79/145]  inactive:\t5.37e-03 +- 3.10e-02\n",
      "[dimension 80/145]  inactive:\t-1.34e-03 +- 3.58e-02\n",
      "[dimension 81/145]  inactive:\t5.72e-04 +- 2.92e-02\n",
      "[dimension 82/145]  inactive:\t2.84e-04 +- 1.58e-02\n",
      "[dimension 83/145]  inactive:\t-1.44e-03 +- 1.68e-02\n",
      "[dimension 84/145]  inactive:\t-1.18e-03 +- 2.92e-02\n",
      "[dimension 85/145]  inactive:\t3.13e-03 +- 3.35e-02\n",
      "[dimension 86/145]  inactive:\t-2.17e-04 +- 2.22e-02\n",
      "[dimension 87/145]  inactive:\t3.18e-03 +- 4.26e-02\n",
      "[dimension 88/145]  inactive:\t2.95e-03 +- 2.42e-02\n",
      "[dimension 89/145]  inactive:\t-5.07e-04 +- 2.38e-02\n",
      "[dimension 90/145]  inactive:\t7.76e-02 +- 2.50e-01\n",
      "[dimension 91/145]  inactive:\t2.76e-04 +- 1.83e-02\n",
      "[dimension 92/145]  inactive:\t-1.64e-03 +- 2.64e-02\n",
      "[dimension 93/145]  inactive:\t-2.33e-04 +- 3.13e-02\n",
      "[dimension 94/145]  inactive:\t2.25e-03 +- 2.76e-02\n",
      "[dimension 95/145]  inactive:\t-3.58e-04 +- 2.23e-02\n",
      "[dimension 96/145]  inactive:\t6.12e-04 +- 3.40e-02\n",
      "[dimension 97/145]  inactive:\t1.77e-03 +- 2.03e-02\n",
      "[dimension 98/145]  inactive:\t-8.82e-04 +- 2.52e-02\n",
      "[dimension 99/145]  inactive:\t2.12e-03 +- 3.17e-02\n",
      "[dimension 100/145]  inactive:\t-6.30e-04 +- 1.52e-02\n",
      "[dimension 101/145]  inactive:\t-2.72e-03 +- 2.39e-02\n",
      "[dimension 102/145]  inactive:\t-1.09e-03 +- 2.91e-02\n",
      "[dimension 103/145]  inactive:\t2.09e-04 +- 2.76e-02\n",
      "[dimension 104/145]  inactive:\t-1.51e-03 +- 1.84e-02\n",
      "[dimension 105/145]  inactive:\t-7.85e-04 +- 2.89e-02\n",
      "[dimension 106/145]  inactive:\t4.57e-03 +- 3.11e-02\n",
      "[dimension 107/145]  inactive:\t-1.48e-03 +- 2.10e-02\n",
      "[dimension 108/145]  inactive:\t5.49e-03 +- 6.00e-02\n",
      "[dimension 109/145]  inactive:\t-4.75e-04 +- 1.83e-02\n",
      "[dimension 110/145]  inactive:\t-1.26e-03 +- 3.23e-02\n",
      "[dimension 111/145]  inactive:\t2.45e-03 +- 3.74e-02\n",
      "[dimension 112/145]  inactive:\t5.86e-03 +- 4.72e-02\n",
      "[dimension 113/145]  inactive:\t-1.83e-03 +- 2.21e-02\n",
      "[dimension 114/145]  inactive:\t8.87e-04 +- 3.43e-02\n",
      "[dimension 115/145]  inactive:\t1.79e-03 +- 2.12e-02\n",
      "[dimension 116/145]  inactive:\t2.67e-03 +- 8.07e-02\n",
      "[dimension 117/145]  inactive:\t3.84e-03 +- 4.81e-02\n",
      "[dimension 118/145]  inactive:\t3.53e-03 +- 2.72e-02\n",
      "[dimension 119/145]  inactive:\t-3.17e-03 +- 3.54e-02\n",
      "[dimension 120/145]  inactive:\t-3.99e-04 +- 2.86e-02\n",
      "[dimension 121/145]  inactive:\t6.00e-03 +- 4.40e-02\n",
      "[dimension 122/145]  inactive:\t-3.37e-03 +- 4.89e-02\n",
      "[dimension 123/145]  inactive:\t1.65e-03 +- 3.46e-02\n",
      "[dimension 124/145]  inactive:\t-1.74e-03 +- 1.91e-02\n",
      "[dimension 125/145]  inactive:\t-1.77e-03 +- 2.79e-02\n",
      "[dimension 126/145]  inactive:\t-1.51e-03 +- 2.46e-02\n",
      "[dimension 127/145]  inactive:\t2.25e-04 +- 1.89e-02\n",
      "[dimension 128/145]  inactive:\t-2.16e-03 +- 3.61e-02\n",
      "[dimension 129/145]  inactive:\t-1.60e-04 +- 2.66e-02\n",
      "[dimension 130/145]  inactive:\t3.94e-03 +- 2.76e-02\n",
      "[dimension 131/145]  inactive:\t-1.62e-03 +- 3.01e-02\n",
      "[dimension 132/145]  inactive:\t4.66e-03 +- 4.85e-02\n",
      "[dimension 133/145]  inactive:\t2.67e-03 +- 2.19e-02\n",
      "[dimension 134/145]  inactive:\t-9.07e-04 +- 2.92e-02\n",
      "[dimension 135/145]  inactive:\t-2.43e-05 +- 2.84e-02\n",
      "[dimension 136/145]  inactive:\t1.29e-03 +- 2.01e-02\n",
      "[dimension 137/145]  inactive:\t-9.37e-04 +- 2.97e-02\n",
      "[dimension 138/145]  inactive:\t5.17e-04 +- 2.58e-02\n",
      "[dimension 139/145]  inactive:\t4.39e-04 +- 2.42e-02\n",
      "[dimension 140/145]  inactive:\t-1.34e-03 +- 3.35e-02\n",
      "[dimension 141/145]  inactive:\t1.26e-03 +- 2.81e-02\n",
      "[dimension 142/145]  inactive:\t1.13e-03 +- 1.57e-02\n",
      "[dimension 143/145]  inactive:\t2.01e-03 +- 4.61e-02\n",
      "[dimension 144/145]  inactive:\t-1.29e-04 +- 1.82e-02\n",
      "[dimension 145/145]  inactive:\t7.15e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.77065706]\n",
      "cov_act[[0.02768381]]\n",
      "Active_dimensions: [62]\n",
      "45, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.17it/s, 15 steps of size 1.80e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    681.01      1.00\n",
      "  lambda[0]      2.13      4.17      0.94      0.00      4.51    779.61      1.00\n",
      "  lambda[1]      2.87      8.07      0.96      0.00      5.49    712.64      1.00\n",
      "  lambda[2]      2.54      5.75      0.99      0.00      5.55    812.56      1.00\n",
      "  lambda[3]      6.12     60.43      1.10      0.00      6.37    702.11      1.00\n",
      "  lambda[4]      2.54      5.77      1.02      0.00      5.46   1060.26      1.00\n",
      "  lambda[5]      3.45     10.60      1.03      0.01      6.85    632.00      1.00\n",
      "  lambda[6]      3.28      9.82      0.95      0.00      6.73    754.93      1.00\n",
      "  lambda[7]      3.07      9.37      1.02      0.00      5.80    673.38      1.00\n",
      "  lambda[8]      2.43      5.46      1.02      0.00      5.52    709.74      1.00\n",
      "  lambda[9]      2.63      9.56      0.98      0.00      4.83    638.34      1.00\n",
      " lambda[10]      3.39     13.41      1.11      0.00      5.70    826.60      1.00\n",
      " lambda[11]      2.72      6.48      1.06      0.00      5.63    773.16      1.00\n",
      " lambda[12]      3.53      9.22      0.98      0.00      6.61    717.99      1.00\n",
      " lambda[13]      2.70      8.21      0.95      0.00      5.58    657.52      1.00\n",
      " lambda[14]      2.88      8.38      0.98      0.00      4.78    719.96      1.00\n",
      " lambda[15]      2.99      9.97      0.98      0.00      5.58   1009.28      1.00\n",
      " lambda[16]      3.27      7.79      1.02      0.00      7.57    672.23      1.00\n",
      " lambda[17]      3.07     16.74      0.92      0.00      4.93    789.57      1.00\n",
      " lambda[18]      2.77      7.40      0.94      0.00      6.17    497.48      1.00\n",
      " lambda[19]      3.90     18.87      1.01      0.00      6.31    722.29      1.00\n",
      " lambda[20]      2.55      5.48      0.94      0.00      5.85    901.12      1.00\n",
      " lambda[21]      3.04      8.72      1.01      0.01      6.85    731.34      1.00\n",
      " lambda[22]      2.69      7.01      0.97      0.00      5.13    752.30      1.00\n",
      " lambda[23]      3.15      9.60      0.98      0.00      5.83    777.12      1.00\n",
      " lambda[24]      3.43     15.53      1.01      0.00      6.09    934.16      1.00\n",
      " lambda[25]      2.92      7.76      1.01      0.00      5.69    434.98      1.00\n",
      " lambda[26]      2.60      8.81      1.04      0.00      5.20   1034.88      1.00\n",
      " lambda[27]      2.66      7.44      0.94      0.00      5.35    740.02      1.00\n",
      " lambda[28]      2.74      8.11      0.99      0.00      5.47    749.83      1.00\n",
      " lambda[29]      2.86      8.75      1.01      0.00      5.34    755.20      1.00\n",
      " lambda[30]      2.89      7.65      1.01      0.01      5.96    927.36      1.00\n",
      " lambda[31]      3.16     14.65      0.97      0.00      5.56    656.72      1.00\n",
      " lambda[32]      5.50     77.22      0.97      0.00      6.32    828.91      1.00\n",
      " lambda[33]      3.16      9.61      0.95      0.01      6.52    813.29      1.00\n",
      " lambda[34]      2.91      7.75      0.94      0.00      5.23    521.53      1.00\n",
      " lambda[35]      2.67      6.92      1.01      0.00      5.20    669.79      1.00\n",
      " lambda[36]      3.45     16.06      0.98      0.00      6.26    978.46      1.00\n",
      " lambda[37]      3.27     11.84      0.99      0.00      6.44    935.87      1.00\n",
      " lambda[38]      3.38     12.30      0.89      0.00      5.73    825.17      1.00\n",
      " lambda[39]      3.47     11.07      0.94      0.00      6.04    752.88      1.00\n",
      " lambda[40]      3.40     13.38      0.90      0.00      5.72    954.95      1.00\n",
      " lambda[41]     14.62    142.68      0.93      0.00      8.96    627.80      1.00\n",
      " lambda[42]      2.55      6.02      0.92      0.00      5.73    886.94      1.00\n",
      " lambda[43]      3.44     17.03      0.96      0.00      5.99    840.58      1.00\n",
      " lambda[44]      2.89      7.86      0.96      0.00      6.24    579.75      1.00\n",
      " lambda[45]      2.48      5.44      1.03      0.00      4.85    699.37      1.00\n",
      " lambda[46]      2.81      9.76      0.91      0.00      4.62    715.22      1.00\n",
      " lambda[47]      2.44      5.75      0.95      0.00      4.70    770.72      1.00\n",
      " lambda[48]      2.59      7.57      1.02      0.01      5.41    866.61      1.00\n",
      " lambda[49]      3.35     11.37      0.91      0.00      6.41    790.77      1.00\n",
      " lambda[50]      2.67      7.36      0.97      0.00      4.90    561.76      1.00\n",
      " lambda[51]      3.48     10.61      1.05      0.00      6.86    850.40      1.00\n",
      " lambda[52]      2.96      8.22      0.92      0.00      6.32    819.10      1.00\n",
      " lambda[53]      3.33     12.85      0.95      0.00      5.88    731.02      1.00\n",
      " lambda[54]      2.25      6.00      1.02      0.00      4.52    681.89      1.00\n",
      " lambda[55]      3.52     14.52      0.99      0.00      6.39    385.86      1.00\n",
      " lambda[56]      2.95      7.95      1.03      0.00      6.03    539.74      1.00\n",
      " lambda[57]      8.14     96.32      0.92      0.00      7.73    854.67      1.00\n",
      " lambda[58]      2.33      4.99      0.97      0.00      5.31    662.94      1.00\n",
      " lambda[59]      2.96      8.81      1.00      0.00      6.39    516.48      1.00\n",
      " lambda[60]      3.52     20.83      0.93      0.00      5.30   1030.28      1.00\n",
      " lambda[61]      2.38      4.22      1.00      0.00      5.77    670.59      1.00\n",
      " lambda[62]   2195.36  27264.10    307.75      0.00   2489.25    798.72      1.00\n",
      " lambda[63]      2.38      4.85      0.98      0.00      5.37    821.32      1.00\n",
      " lambda[64]      3.10      9.53      0.96      0.00      5.40    642.53      1.00\n",
      " lambda[65]      3.01      9.98      0.93      0.00      5.70    699.33      1.00\n",
      " lambda[66]      3.14      7.37      1.06      0.00      6.18    605.82      1.00\n",
      " lambda[67]      2.50      5.70      0.89      0.00      5.25    634.98      1.00\n",
      " lambda[68]      2.58      8.59      0.94      0.00      4.29    670.21      1.01\n",
      " lambda[69]      3.79     19.64      0.94      0.00      5.45    793.30      1.00\n",
      " lambda[70]      2.52      6.34      0.98      0.00      4.76    818.46      1.00\n",
      " lambda[71]      3.07      8.95      0.92      0.00      5.73    417.75      1.00\n",
      " lambda[72]      2.41      6.42      0.97      0.00      4.98    593.85      1.00\n",
      " lambda[73]      3.44     21.75      1.02      0.00      5.62    828.20      1.00\n",
      " lambda[74]      2.33      4.23      1.03      0.00      5.11    743.52      1.00\n",
      " lambda[75]      4.05     14.72      0.98      0.00      6.70    716.53      1.00\n",
      " lambda[76]      3.21      9.42      0.94      0.00      6.48    679.33      1.00\n",
      " lambda[77]      2.89      7.77      1.05      0.00      6.49    684.58      1.00\n",
      " lambda[78]      3.21     15.16      1.13      0.00      6.42   1036.15      1.00\n",
      " lambda[79]      3.63     13.27      1.01      0.00      5.59    617.16      1.00\n",
      " lambda[80]      3.41     11.81      1.03      0.00      6.05    707.50      1.00\n",
      " lambda[81]      2.87     10.43      0.94      0.00      5.75    711.60      1.00\n",
      " lambda[82]      2.77      7.66      0.87      0.00      5.48    487.07      1.00\n",
      " lambda[83]      3.23     11.22      0.97      0.00      5.45    686.08      1.00\n",
      " lambda[84]      3.39     12.12      0.99      0.00      5.93    817.29      1.00\n",
      " lambda[85]      2.74      6.95      0.93      0.00      5.93    605.82      1.00\n",
      " lambda[86]      2.68      6.11      0.97      0.00      5.80    761.83      1.00\n",
      " lambda[87]      3.71     18.08      0.98      0.00      6.63    743.21      1.00\n",
      " lambda[88]      2.77      5.85      1.04      0.00      6.64    654.92      1.00\n",
      " lambda[89]    167.42   2755.51      1.08      0.00     23.26    831.83      1.00\n",
      " lambda[90]      2.91      7.71      0.98      0.00      5.02    465.45      1.00\n",
      " lambda[91]      2.59      6.85      1.04      0.00      5.43    954.22      1.00\n",
      " lambda[92]      2.98      8.15      1.03      0.00      6.01    654.70      1.00\n",
      " lambda[93]      2.99     10.38      1.00      0.00      5.40    474.06      1.00\n",
      " lambda[94]      2.58      6.17      0.93      0.00      5.58    827.09      1.00\n",
      " lambda[95]      2.57      5.77      1.03      0.00      5.77   1088.05      1.00\n",
      " lambda[96]      2.42      5.33      0.94      0.00      4.90    496.90      1.00\n",
      " lambda[97]      3.69     15.21      1.03      0.00      6.16    601.16      1.00\n",
      " lambda[98]      5.92     47.79      1.05      0.00      6.30    467.95      1.00\n",
      " lambda[99]      2.66     10.08      0.93      0.00      5.00    669.65      1.00\n",
      "lambda[100]      2.94      7.95      0.94      0.00      6.14    724.40      1.00\n",
      "lambda[101]      2.31      4.65      0.91      0.00      5.24    696.19      1.00\n",
      "lambda[102]      3.67     14.10      1.01      0.00      5.97    419.97      1.00\n",
      "lambda[103]      2.47      5.23      0.99      0.00      5.52    910.41      1.00\n",
      "lambda[104]      2.53      5.39      1.03      0.01      5.85    676.26      1.00\n",
      "lambda[105]      3.41     10.91      1.06      0.00      6.37    471.37      1.00\n",
      "lambda[106]      2.47      6.01      0.96      0.00      5.24    795.01      1.00\n",
      "lambda[107]      3.59     14.32      1.05      0.00      5.98    662.26      1.00\n",
      "lambda[108]      2.64      6.43      0.98      0.00      5.53    414.30      1.00\n",
      "lambda[109]      4.10     38.42      0.99      0.00      5.49    998.13      1.00\n",
      "lambda[110]      3.88     12.72      0.98      0.00      7.50    582.50      1.00\n",
      "lambda[111]      3.49     12.02      0.98      0.00      6.50    563.77      1.00\n",
      "lambda[112]      2.66      6.34      0.95      0.01      5.51    702.27      1.00\n",
      "lambda[113]      3.34     10.18      1.03      0.00      6.09    644.85      1.00\n",
      "lambda[114]      5.51     64.93      0.99      0.00      5.81    982.49      1.00\n",
      "lambda[115]      7.46     73.48      1.06      0.00      7.04    846.70      1.00\n",
      "lambda[116]      4.37     34.80      1.02      0.00      5.53    870.68      1.00\n",
      "lambda[117]      3.89     14.18      0.97      0.00      6.63    479.95      1.00\n",
      "lambda[118]      3.52     13.98      1.02      0.00      6.03    829.25      1.00\n",
      "lambda[119]      2.78     14.11      1.00      0.00      4.78   1004.47      1.00\n",
      "lambda[120]      4.29     19.88      0.92      0.00      6.60    707.92      1.00\n",
      "lambda[121]      3.18     11.77      0.91      0.00      5.67    849.98      1.00\n",
      "lambda[122]      2.80      7.24      0.99      0.00      6.11    718.65      1.00\n",
      "lambda[123]      2.48      5.61      0.92      0.00      5.44    740.00      1.00\n",
      "lambda[124]      2.48      5.49      0.94      0.00      5.80    839.57      1.00\n",
      "lambda[125]      3.12     10.36      0.96      0.00      5.83    578.79      1.00\n",
      "lambda[126]      2.86      8.81      0.96      0.00      5.15    793.35      1.00\n",
      "lambda[127]      3.27      9.47      1.06      0.00      5.86    572.48      1.00\n",
      "lambda[128]      3.16     13.03      1.00      0.00      5.15    518.42      1.00\n",
      "lambda[129]      4.09     24.23      1.01      0.00      6.83    982.39      1.00\n",
      "lambda[130]      2.90      6.68      0.97      0.00      6.09    648.45      1.00\n",
      "lambda[131]      2.86      8.28      0.98      0.01      5.84    959.77      1.00\n",
      "lambda[132]      3.52     10.90      0.98      0.00      7.32    665.22      1.00\n",
      "lambda[133]      3.05     10.71      0.99      0.00      5.40    547.24      1.00\n",
      "lambda[134]      2.93      6.82      0.86      0.00      6.80    770.33      1.00\n",
      "lambda[135]      2.71      6.70      0.91      0.00      5.68    562.48      1.00\n",
      "lambda[136]      2.72      6.80      0.97      0.00      5.62    678.84      1.00\n",
      "lambda[137]      3.74     16.57      0.88      0.00      6.00    556.62      1.00\n",
      "lambda[138]      3.23     12.31      0.99      0.00      5.96    737.15      1.00\n",
      "lambda[139]      2.80      7.43      1.03      0.00      5.21    783.92      1.00\n",
      "lambda[140]      3.11      9.22      0.97      0.00      6.03    816.89      1.00\n",
      "lambda[141]      2.37      5.08      0.89      0.00      5.18    727.36      1.00\n",
      "lambda[142]      4.83     35.72      1.00      0.01      6.41    655.43      1.00\n",
      "lambda[143]      2.13      4.07      0.91      0.01      4.72    711.76      1.00\n",
      "        msq      1.43      0.85      1.23      0.50      2.41   1136.78      1.00\n",
      "      sigma      5.60      8.15      2.14      0.00     15.59   1120.35      1.00\n",
      "    var_obs      0.09      0.01      0.08      0.06      0.11    977.79      1.00\n",
      "       xisq      2.76     10.42      0.96      0.08      5.17    849.42      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 32.415926933288574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t2.34e-06 +- 1.31e-02\n",
      "[dimension 02/145]  inactive:\t-2.28e-05 +- 1.88e-02\n",
      "[dimension 03/145]  inactive:\t1.04e-04 +- 1.67e-02\n",
      "[dimension 04/145]  inactive:\t3.89e-03 +- 3.08e-02\n",
      "[dimension 05/145]  inactive:\t-2.23e-04 +- 2.16e-02\n",
      "[dimension 06/145]  inactive:\t1.99e-03 +- 3.14e-02\n",
      "[dimension 07/145]  inactive:\t7.53e-04 +- 1.86e-02\n",
      "[dimension 08/145]  inactive:\t7.52e-04 +- 2.45e-02\n",
      "[dimension 09/145]  inactive:\t3.31e-04 +- 1.83e-02\n",
      "[dimension 10/145]  inactive:\t3.82e-04 +- 1.29e-02\n",
      "[dimension 11/145]  inactive:\t-6.43e-04 +- 1.93e-02\n",
      "[dimension 12/145]  inactive:\t-2.51e-04 +- 1.97e-02\n",
      "[dimension 13/145]  inactive:\t3.57e-03 +- 3.24e-02\n",
      "[dimension 14/145]  inactive:\t-5.83e-04 +- 2.06e-02\n",
      "[dimension 15/145]  inactive:\t1.03e-03 +- 2.49e-02\n",
      "[dimension 16/145]  inactive:\t3.77e-04 +- 1.77e-02\n",
      "[dimension 17/145]  inactive:\t5.64e-04 +- 2.63e-02\n",
      "[dimension 18/145]  inactive:\t8.33e-04 +- 3.12e-02\n",
      "[dimension 19/145]  inactive:\t-1.40e-03 +- 1.64e-02\n",
      "[dimension 20/145]  inactive:\t-8.73e-04 +- 2.13e-02\n",
      "[dimension 21/145]  inactive:\t-1.12e-03 +- 1.91e-02\n",
      "[dimension 22/145]  inactive:\t9.51e-05 +- 1.72e-02\n",
      "[dimension 23/145]  inactive:\t-3.68e-04 +- 2.11e-02\n",
      "[dimension 24/145]  inactive:\t1.06e-03 +- 2.35e-02\n",
      "[dimension 25/145]  inactive:\t2.74e-03 +- 2.19e-02\n",
      "[dimension 26/145]  inactive:\t-1.66e-04 +- 2.38e-02\n",
      "[dimension 27/145]  inactive:\t5.90e-04 +- 1.84e-02\n",
      "[dimension 28/145]  inactive:\t6.00e-04 +- 1.46e-02\n",
      "[dimension 29/145]  inactive:\t1.59e-04 +- 2.18e-02\n",
      "[dimension 30/145]  inactive:\t7.10e-04 +- 2.06e-02\n",
      "[dimension 31/145]  inactive:\t2.80e-03 +- 2.48e-02\n",
      "[dimension 32/145]  inactive:\t-4.89e-04 +- 1.85e-02\n",
      "[dimension 33/145]  inactive:\t2.61e-03 +- 4.16e-02\n",
      "[dimension 34/145]  inactive:\t7.48e-04 +- 1.69e-02\n",
      "[dimension 35/145]  inactive:\t4.41e-04 +- 2.12e-02\n",
      "[dimension 36/145]  inactive:\t1.17e-03 +- 2.47e-02\n",
      "[dimension 37/145]  inactive:\t2.82e-03 +- 2.04e-02\n",
      "[dimension 38/145]  inactive:\t-1.12e-03 +- 2.71e-02\n",
      "[dimension 39/145]  inactive:\t8.35e-04 +- 2.50e-02\n",
      "[dimension 40/145]  inactive:\t3.86e-03 +- 3.35e-02\n",
      "[dimension 41/145]  inactive:\t-5.36e-04 +- 2.88e-02\n",
      "[dimension 42/145]  inactive:\t1.02e-02 +- 7.98e-02\n",
      "[dimension 43/145]  inactive:\t-7.99e-05 +- 1.50e-02\n",
      "[dimension 44/145]  inactive:\t-3.55e-04 +- 2.44e-02\n",
      "[dimension 45/145]  inactive:\t4.53e-05 +- 2.29e-02\n",
      "[dimension 46/145]  inactive:\t7.66e-04 +- 1.36e-02\n",
      "[dimension 47/145]  inactive:\t-4.99e-04 +- 2.39e-02\n",
      "[dimension 48/145]  inactive:\t1.70e-03 +- 2.78e-02\n",
      "[dimension 49/145]  inactive:\t1.53e-03 +- 1.87e-02\n",
      "[dimension 50/145]  inactive:\t-1.40e-03 +- 2.27e-02\n",
      "[dimension 51/145]  inactive:\t2.27e-03 +- 2.76e-02\n",
      "[dimension 52/145]  inactive:\t4.84e-03 +- 2.37e-02\n",
      "[dimension 53/145]  inactive:\t-8.48e-04 +- 2.10e-02\n",
      "[dimension 54/145]  inactive:\t5.49e-04 +- 1.93e-02\n",
      "[dimension 55/145]  inactive:\t3.74e-04 +- 1.21e-02\n",
      "[dimension 56/145]  inactive:\t-1.83e-03 +- 1.87e-02\n",
      "[dimension 57/145]  inactive:\t2.09e-03 +- 3.26e-02\n",
      "[dimension 58/145]  inactive:\t1.15e-02 +- 6.86e-02\n",
      "[dimension 59/145]  inactive:\t-4.81e-04 +- 1.47e-02\n",
      "[dimension 60/145]  inactive:\t3.56e-04 +- 2.02e-02\n",
      "[dimension 61/145]  inactive:\t1.85e-03 +- 2.24e-02\n",
      "[dimension 62/145]  inactive:\t-4.89e-04 +- 1.68e-02\n",
      "[dimension 63/145]  active:\t7.76e-01 +- 3.71e-01\n",
      "[dimension 64/145]  inactive:\t-2.00e-03 +- 1.97e-02\n",
      "[dimension 65/145]  inactive:\t-5.84e-04 +- 2.12e-02\n",
      "[dimension 66/145]  inactive:\t4.57e-04 +- 1.86e-02\n",
      "[dimension 67/145]  inactive:\t1.43e-03 +- 2.65e-02\n",
      "[dimension 68/145]  inactive:\t-2.87e-04 +- 1.83e-02\n",
      "[dimension 69/145]  inactive:\t2.08e-03 +- 3.08e-02\n",
      "[dimension 70/145]  inactive:\t3.13e-03 +- 2.25e-02\n",
      "[dimension 71/145]  inactive:\t1.73e-04 +- 1.81e-02\n",
      "[dimension 72/145]  inactive:\t4.12e-04 +- 1.84e-02\n",
      "[dimension 73/145]  inactive:\t2.29e-04 +- 1.32e-02\n",
      "[dimension 74/145]  inactive:\t-8.16e-04 +- 2.73e-02\n",
      "[dimension 75/145]  inactive:\t2.10e-04 +- 1.82e-02\n",
      "[dimension 76/145]  inactive:\t5.06e-03 +- 3.57e-02\n",
      "[dimension 77/145]  inactive:\t-9.48e-04 +- 2.38e-02\n",
      "[dimension 78/145]  inactive:\t2.15e-03 +- 3.07e-02\n",
      "[dimension 79/145]  inactive:\t3.56e-03 +- 2.48e-02\n",
      "[dimension 80/145]  inactive:\t6.24e-05 +- 3.18e-02\n",
      "[dimension 81/145]  inactive:\t1.02e-03 +- 2.55e-02\n",
      "[dimension 82/145]  inactive:\t3.14e-04 +- 1.39e-02\n",
      "[dimension 83/145]  inactive:\t-1.14e-03 +- 1.51e-02\n",
      "[dimension 84/145]  inactive:\t-1.28e-03 +- 2.12e-02\n",
      "[dimension 85/145]  inactive:\t2.09e-03 +- 2.57e-02\n",
      "[dimension 86/145]  inactive:\t-4.12e-04 +- 1.59e-02\n",
      "[dimension 87/145]  inactive:\t1.29e-03 +- 2.56e-02\n",
      "[dimension 88/145]  inactive:\t2.48e-03 +- 2.17e-02\n",
      "[dimension 89/145]  inactive:\t-2.95e-04 +- 1.86e-02\n",
      "[dimension 90/145]  inactive:\t6.78e-02 +- 2.33e-01\n",
      "[dimension 91/145]  inactive:\t1.21e-04 +- 1.52e-02\n",
      "[dimension 92/145]  inactive:\t-8.13e-04 +- 1.72e-02\n",
      "[dimension 93/145]  inactive:\t-4.16e-04 +- 2.23e-02\n",
      "[dimension 94/145]  inactive:\t1.44e-03 +- 2.12e-02\n",
      "[dimension 95/145]  inactive:\t-3.79e-05 +- 1.77e-02\n",
      "[dimension 96/145]  inactive:\t-2.44e-04 +- 2.62e-02\n",
      "[dimension 97/145]  inactive:\t1.60e-03 +- 1.76e-02\n",
      "[dimension 98/145]  inactive:\t-7.25e-04 +- 2.20e-02\n",
      "[dimension 99/145]  inactive:\t5.64e-03 +- 5.70e-02\n",
      "[dimension 100/145]  inactive:\t-4.28e-04 +- 1.33e-02\n",
      "[dimension 101/145]  inactive:\t-1.75e-03 +- 1.75e-02\n",
      "[dimension 102/145]  inactive:\t-6.41e-04 +- 1.82e-02\n",
      "[dimension 103/145]  inactive:\t1.11e-03 +- 2.45e-02\n",
      "[dimension 104/145]  inactive:\t-8.20e-04 +- 1.51e-02\n",
      "[dimension 105/145]  inactive:\t2.99e-04 +- 2.13e-02\n",
      "[dimension 106/145]  inactive:\t4.81e-03 +- 3.43e-02\n",
      "[dimension 107/145]  inactive:\t-7.85e-04 +- 1.55e-02\n",
      "[dimension 108/145]  inactive:\t4.35e-03 +- 5.85e-02\n",
      "[dimension 109/145]  inactive:\t-2.31e-04 +- 1.65e-02\n",
      "[dimension 110/145]  inactive:\t-7.43e-04 +- 2.40e-02\n",
      "[dimension 111/145]  inactive:\t1.85e-03 +- 3.20e-02\n",
      "[dimension 112/145]  inactive:\t2.84e-03 +- 3.01e-02\n",
      "[dimension 113/145]  inactive:\t-8.37e-04 +- 1.93e-02\n",
      "[dimension 114/145]  inactive:\t8.73e-04 +- 3.39e-02\n",
      "[dimension 115/145]  inactive:\t1.25e-03 +- 1.57e-02\n",
      "[dimension 116/145]  inactive:\t4.46e-03 +- 7.56e-02\n",
      "[dimension 117/145]  inactive:\t3.63e-03 +- 4.40e-02\n",
      "[dimension 118/145]  inactive:\t2.97e-03 +- 2.29e-02\n",
      "[dimension 119/145]  inactive:\t-1.50e-03 +- 2.41e-02\n",
      "[dimension 120/145]  inactive:\t-8.23e-05 +- 1.97e-02\n",
      "[dimension 121/145]  inactive:\t3.62e-03 +- 3.12e-02\n",
      "[dimension 122/145]  inactive:\t-1.27e-03 +- 2.36e-02\n",
      "[dimension 123/145]  inactive:\t1.19e-03 +- 3.19e-02\n",
      "[dimension 124/145]  inactive:\t-7.47e-04 +- 1.31e-02\n",
      "[dimension 125/145]  inactive:\t-7.22e-04 +- 1.71e-02\n",
      "[dimension 126/145]  inactive:\t-7.44e-04 +- 1.93e-02\n",
      "[dimension 127/145]  inactive:\t2.65e-04 +- 1.47e-02\n",
      "[dimension 128/145]  inactive:\t1.44e-04 +- 2.71e-02\n",
      "[dimension 129/145]  inactive:\t6.90e-04 +- 2.54e-02\n",
      "[dimension 130/145]  inactive:\t3.29e-03 +- 2.79e-02\n",
      "[dimension 131/145]  inactive:\t-3.55e-05 +- 2.77e-02\n",
      "[dimension 132/145]  inactive:\t1.87e-03 +- 2.66e-02\n",
      "[dimension 133/145]  inactive:\t2.74e-03 +- 2.22e-02\n",
      "[dimension 134/145]  inactive:\t-4.44e-04 +- 2.62e-02\n",
      "[dimension 135/145]  inactive:\t1.07e-04 +- 1.98e-02\n",
      "[dimension 136/145]  inactive:\t9.81e-04 +- 1.71e-02\n",
      "[dimension 137/145]  inactive:\t1.29e-04 +- 2.13e-02\n",
      "[dimension 138/145]  inactive:\t6.48e-04 +- 2.02e-02\n",
      "[dimension 139/145]  inactive:\t4.56e-04 +- 2.09e-02\n",
      "[dimension 140/145]  inactive:\t-4.87e-04 +- 2.50e-02\n",
      "[dimension 141/145]  inactive:\t9.73e-04 +- 2.27e-02\n",
      "[dimension 142/145]  inactive:\t1.19e-03 +- 1.56e-02\n",
      "[dimension 143/145]  inactive:\t2.11e-03 +- 3.80e-02\n",
      "[dimension 144/145]  inactive:\t2.00e-04 +- 1.45e-02\n",
      "[dimension 145/145]  inactive:\t3.40e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8892226]\n",
      "cov_act[[0.01841734]]\n",
      "Active_dimensions: [62]\n",
      "46, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 53.48it/s, 31 steps of size 1.67e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    788.34      1.00\n",
      "  lambda[0]      2.33      8.18      0.94      0.00      4.87    955.48      1.00\n",
      "  lambda[1]      2.96      9.27      1.00      0.00      5.33    578.59      1.00\n",
      "  lambda[2]      2.74      8.27      0.94      0.00      5.27    591.77      1.00\n",
      "  lambda[3]      6.28     40.44      0.99      0.00      6.98    598.47      1.00\n",
      "  lambda[4]      2.59      6.32      0.95      0.00      5.41    646.34      1.00\n",
      "  lambda[5]      3.95     13.91      1.02      0.00      6.56    546.71      1.00\n",
      "  lambda[6]      2.50      6.55      1.02      0.00      4.80    873.44      1.00\n",
      "  lambda[7]      3.38     14.26      1.00      0.00      6.09    656.76      1.00\n",
      "  lambda[8]      2.32      4.13      0.99      0.02      5.49    735.67      1.00\n",
      "  lambda[9]      2.58      8.11      0.95      0.00      4.92    733.56      1.00\n",
      " lambda[10]      3.82     16.03      1.04      0.00      6.19    810.14      1.00\n",
      " lambda[11]      2.82      7.24      1.01      0.00      6.02    503.61      1.00\n",
      " lambda[12]      5.71     38.35      1.01      0.00      8.73    627.55      1.00\n",
      " lambda[13]      2.70      9.98      0.97      0.00      5.46    828.70      1.00\n",
      " lambda[14]      4.92     41.69      0.94      0.00      5.47    887.07      1.00\n",
      " lambda[15]      2.79      8.40      0.96      0.00      4.82    601.40      1.00\n",
      " lambda[16]      4.00     12.54      1.03      0.00      8.62    685.96      1.00\n",
      " lambda[17]      3.33     25.36      0.98      0.00      5.01    716.80      1.00\n",
      " lambda[18]      2.70      5.77      0.92      0.00      6.52    720.53      1.00\n",
      " lambda[19]      3.61     17.81      1.03      0.00      6.53    926.44      1.00\n",
      " lambda[20]      2.83      8.54      0.92      0.00      5.65    729.44      1.00\n",
      " lambda[21]      2.81      6.54      1.00      0.00      6.59    951.86      1.00\n",
      " lambda[22]      2.73      7.72      1.05      0.00      5.28    837.94      1.00\n",
      " lambda[23]      3.03      9.82      0.96      0.00      5.43    874.39      1.00\n",
      " lambda[24]      3.13     11.13      1.01      0.00      5.26    443.22      1.00\n",
      " lambda[25]      3.78     21.55      0.97      0.01      5.88    434.03      1.00\n",
      " lambda[26]      4.68     43.98      0.97      0.00      5.36    771.88      1.00\n",
      " lambda[27]      2.64      8.50      0.95      0.00      5.72    589.78      1.00\n",
      " lambda[28]      2.90     11.99      0.99      0.00      5.09    663.97      1.00\n",
      " lambda[29]      2.92      7.74      0.92      0.00      5.77    711.58      1.00\n",
      " lambda[30]      4.44     30.15      1.03      0.01      5.91    900.32      1.00\n",
      " lambda[31]      3.96     18.71      1.02      0.00      6.36    806.34      1.00\n",
      " lambda[32]      3.46     10.32      0.95      0.00      6.31    376.97      1.00\n",
      " lambda[33]      2.84      9.70      0.92      0.01      5.95    925.50      1.00\n",
      " lambda[34]      3.00     10.34      0.95      0.00      5.41    635.68      1.00\n",
      " lambda[35]      2.34      5.26      1.05      0.00      4.75    944.02      1.00\n",
      " lambda[36]      4.04     22.92      0.98      0.00      7.15    952.18      1.00\n",
      " lambda[37]      3.02      9.81      0.96      0.00      5.63    796.47      1.00\n",
      " lambda[38]      2.98      7.94      0.96      0.00      6.28    819.40      1.00\n",
      " lambda[39]      3.54     11.24      0.99      0.00      6.00    562.53      1.00\n",
      " lambda[40]      4.17     17.65      0.99      0.00      6.64    683.84      1.00\n",
      " lambda[41]     11.78    150.62      0.94      0.00      9.43    674.79      1.00\n",
      " lambda[42]      2.76      7.97      1.01      0.00      5.49    725.23      1.00\n",
      " lambda[43]      5.04     56.53      0.91      0.00      5.67   1013.51      1.00\n",
      " lambda[44]      2.90      7.26      0.99      0.01      6.42    538.72      1.00\n",
      " lambda[45]      2.62      6.49      0.97      0.00      5.08    711.08      1.00\n",
      " lambda[46]      3.22     10.87      0.99      0.00      5.11    655.49      1.00\n",
      " lambda[47]      2.83      6.87      0.93      0.00      6.31    719.41      1.00\n",
      " lambda[48]      2.85      9.96      1.03      0.01      4.99    799.43      1.00\n",
      " lambda[49]      3.41     13.15      0.96      0.00      6.54    669.04      1.00\n",
      " lambda[50]      2.98      7.87      0.97      0.00      6.33    653.21      1.00\n",
      " lambda[51]      5.68     33.70      0.97      0.00      8.46    876.42      1.00\n",
      " lambda[52]      3.05      8.48      0.98      0.01      5.46    620.61      1.00\n",
      " lambda[53]      2.88      7.80      0.99      0.00      5.76    682.36      1.00\n",
      " lambda[54]      2.32      6.75      0.96      0.00      4.48    619.32      1.00\n",
      " lambda[55]      4.10     20.09      1.00      0.00      6.02    660.98      1.00\n",
      " lambda[56]      2.65      5.95      0.99      0.00      5.71    702.33      1.00\n",
      " lambda[57]      7.47     44.07      1.01      0.00      9.80    754.98      1.00\n",
      " lambda[58]      2.48      5.68      0.98      0.00      5.43    612.35      1.00\n",
      " lambda[59]      3.34     15.08      0.95      0.00      5.98    878.67      1.00\n",
      " lambda[60]      2.88      8.05      0.99      0.00      5.74    709.08      1.00\n",
      " lambda[61]      2.55      5.82      1.05      0.00      5.44    841.32      1.00\n",
      " lambda[62]    993.13  12406.04    132.75      0.00    959.66    537.50      1.00\n",
      " lambda[63]      2.58      6.32      0.98      0.00      5.14    915.81      1.00\n",
      " lambda[64]      2.83      7.64      0.99      0.00      5.31    807.85      1.00\n",
      " lambda[65]      2.86      9.15      0.98      0.00      5.35    981.65      1.00\n",
      " lambda[66]      3.25      8.80      1.02      0.00      6.81    767.93      1.00\n",
      " lambda[67]      2.54      6.63      0.91      0.00      5.14    791.65      1.00\n",
      " lambda[68]      3.98     17.91      0.99      0.00      6.80    568.21      1.00\n",
      " lambda[69]      3.11     13.12      0.95      0.00      5.56    918.64      1.00\n",
      " lambda[70]      2.47      5.67      0.96      0.00      4.97    478.27      1.00\n",
      " lambda[71]      3.47     17.64      0.93      0.00      5.65    539.17      1.00\n",
      " lambda[72]      2.52      6.57      0.94      0.01      5.10    557.72      1.00\n",
      " lambda[73]      2.79      6.54      1.06      0.00      5.45    662.99      1.00\n",
      " lambda[74]      2.36      3.93      1.03      0.00      5.63   1010.47      1.00\n",
      " lambda[75]      3.89     14.14      1.00      0.01      7.50    751.02      1.00\n",
      " lambda[76]      3.53     10.35      1.04      0.00      7.40    752.25      1.00\n",
      " lambda[77]      3.06      8.52      1.09      0.00      6.61    623.63      1.00\n",
      " lambda[78]      4.18     17.61      1.06      0.00      6.36    514.03      1.00\n",
      " lambda[79]      3.03      9.84      0.99      0.00      5.54    610.99      1.00\n",
      " lambda[80]      4.49     23.52      1.01      0.00      6.20    743.49      1.00\n",
      " lambda[81]      2.36      5.19      0.93      0.00      4.99    988.22      1.00\n",
      " lambda[82]      2.45      6.45      0.91      0.00      4.65    673.06      1.00\n",
      " lambda[83]      3.29     11.15      0.92      0.00      5.72    726.94      1.00\n",
      " lambda[84]      4.77     45.22      0.99      0.00      6.27    548.66      1.00\n",
      " lambda[85]      2.79     13.10      0.94      0.00      5.16    769.96      1.00\n",
      " lambda[86]      2.78      6.83      1.03      0.00      5.77    747.90      1.00\n",
      " lambda[87]      3.27     12.26      0.94      0.00      6.10    543.21      1.00\n",
      " lambda[88]      2.78      7.54      0.95      0.00      6.06    769.49      1.00\n",
      " lambda[89]    157.70   1088.04      1.55      0.00    233.09    677.97      1.00\n",
      " lambda[90]      2.63      6.03      0.96      0.00      5.44    455.80      1.00\n",
      " lambda[91]      2.64      7.42      0.95      0.01      4.67    666.16      1.00\n",
      " lambda[92]      2.95      8.42      1.02      0.01      5.48    659.98      1.00\n",
      " lambda[93]      2.93     10.24      1.01      0.00      5.31    469.28      1.00\n",
      " lambda[94]      2.70      8.46      0.98      0.00      5.58    944.99      1.00\n",
      " lambda[95]      3.49     11.84      0.95      0.00      6.39    602.02      1.00\n",
      " lambda[96]      2.78     11.28      0.96      0.00      5.07    720.55      1.00\n",
      " lambda[97]      3.98     22.53      0.99      0.00      5.20    552.60      1.00\n",
      " lambda[98]      4.66     44.35      1.03      0.00      5.81    843.05      1.00\n",
      " lambda[99]      2.56      7.04      0.93      0.00      4.71    744.67      1.00\n",
      "lambda[100]      2.93      8.52      0.90      0.00      6.23    656.23      1.00\n",
      "lambda[101]      3.09      8.74      0.89      0.00      6.08    766.98      1.00\n",
      "lambda[102]      2.65      7.92      0.88      0.00      4.82    898.07      1.00\n",
      "lambda[103]      2.32      5.37      0.93      0.00      5.36    856.11      1.00\n",
      "lambda[104]      3.79     25.71      0.97      0.00      6.34    419.56      1.00\n",
      "lambda[105]      3.00      8.27      0.99      0.01      6.67    597.73      1.01\n",
      "lambda[106]      2.54      5.27      1.03      0.00      5.63    801.07      1.00\n",
      "lambda[107]      6.68     40.31      1.03      0.00      6.46    520.22      1.00\n",
      "lambda[108]      2.22      3.83      0.96      0.00      4.84    523.25      1.00\n",
      "lambda[109]      5.57     65.65      1.02      0.00      6.90   1002.50      1.00\n",
      "lambda[110]      3.51     14.22      0.97      0.00      6.38    879.23      1.00\n",
      "lambda[111]      4.35     25.49      0.92      0.00      6.28    737.84      1.00\n",
      "lambda[112]      2.76      7.15      0.94      0.00      5.79    990.98      1.00\n",
      "lambda[113]      3.84     20.36      0.98      0.00      6.04    720.71      1.00\n",
      "lambda[114]      3.56     10.59      0.97      0.00      6.65    810.28      1.00\n",
      "lambda[115]      3.96     16.79      0.93      0.00      5.79    847.90      1.00\n",
      "lambda[116]      4.57     35.71      1.03      0.00      6.15    621.09      1.00\n",
      "lambda[117]      3.56     16.60      1.00      0.00      5.18    517.29      1.00\n",
      "lambda[118]      3.76     18.07      0.97      0.00      6.17    907.31      1.00\n",
      "lambda[119]      3.16     16.51      1.01      0.00      5.70    875.92      1.00\n",
      "lambda[120]      5.09     23.63      0.93      0.00      7.02    810.25      1.00\n",
      "lambda[121]      3.81     15.93      0.95      0.00      6.46    859.37      1.00\n",
      "lambda[122]      3.42     11.62      1.02      0.00      6.37    701.73      1.00\n",
      "lambda[123]      3.20     11.76      0.94      0.00      5.27    677.38      1.00\n",
      "lambda[124]      2.91      8.49      1.01      0.00      6.13    684.82      1.00\n",
      "lambda[125]      2.69      6.69      0.94      0.00      5.45    861.79      1.00\n",
      "lambda[126]      2.43      6.53      0.95      0.00      5.01    873.29      1.00\n",
      "lambda[127]      4.31     18.48      1.00      0.00      6.52    634.72      1.00\n",
      "lambda[128]      3.00     12.27      1.01      0.00      5.36    504.87      1.00\n",
      "lambda[129]      4.73     42.60      0.98      0.00      5.57   1001.97      1.00\n",
      "lambda[130]      2.96     10.38      0.94      0.00      5.68    697.38      1.01\n",
      "lambda[131]      3.37     12.84      0.98      0.00      6.08    582.00      1.00\n",
      "lambda[132]      2.91     10.47      0.96      0.00      5.94   1009.16      1.00\n",
      "lambda[133]      2.62      7.23      1.01      0.00      5.39    871.41      1.00\n",
      "lambda[134]      3.69      9.42      0.91      0.00      7.55    657.44      1.00\n",
      "lambda[135]      2.90     10.44      0.92      0.00      4.63    731.86      1.00\n",
      "lambda[136]      2.95      7.12      0.98      0.00      6.34    751.51      1.00\n",
      "lambda[137]      2.57      7.81      0.98      0.00      5.04    898.14      1.00\n",
      "lambda[138]      3.39     13.78      1.02      0.00      5.35    808.57      1.00\n",
      "lambda[139]      3.19      9.47      1.03      0.01      6.44    717.66      1.01\n",
      "lambda[140]      3.16      9.29      1.00      0.00      6.76    697.22      1.00\n",
      "lambda[141]      2.46      5.73      0.92      0.00      5.40    632.36      1.00\n",
      "lambda[142]      4.36     24.39      0.97      0.01      5.79    674.92      1.00\n",
      "lambda[143]      2.34      4.95      0.96      0.00      5.07    563.11      1.00\n",
      "        msq   1788.99  15901.23     23.42      0.95    600.28    469.29      1.00\n",
      "      sigma      6.17      8.53      2.84      0.02     17.22   1384.28      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    598.84      1.00\n",
      "       xisq      0.12      0.06      0.11      0.04      0.21   1258.69      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 31.699504137039185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-5.64e-04 +- 1.99e-02\n",
      "[dimension 02/145]  inactive:\t-1.30e-05 +- 3.04e-02\n",
      "[dimension 03/145]  inactive:\t7.30e-04 +- 2.91e-02\n",
      "[dimension 04/145]  inactive:\t8.25e-03 +- 4.78e-02\n",
      "[dimension 05/145]  inactive:\t-3.71e-04 +- 3.02e-02\n",
      "[dimension 06/145]  inactive:\t4.43e-03 +- 5.51e-02\n",
      "[dimension 07/145]  inactive:\t2.02e-04 +- 2.04e-02\n",
      "[dimension 08/145]  inactive:\t1.15e-03 +- 3.61e-02\n",
      "[dimension 09/145]  inactive:\t-1.51e-04 +- 2.24e-02\n",
      "[dimension 10/145]  inactive:\t2.06e-04 +- 2.05e-02\n",
      "[dimension 11/145]  inactive:\t-1.47e-03 +- 2.62e-02\n",
      "[dimension 12/145]  inactive:\t-1.60e-04 +- 3.26e-02\n",
      "[dimension 13/145]  inactive:\t7.79e-03 +- 5.29e-02\n",
      "[dimension 14/145]  inactive:\t-1.93e-03 +- 2.91e-02\n",
      "[dimension 15/145]  inactive:\t7.15e-04 +- 4.04e-02\n",
      "[dimension 16/145]  inactive:\t9.04e-04 +- 2.23e-02\n",
      "[dimension 17/145]  inactive:\t8.01e-04 +- 4.13e-02\n",
      "[dimension 18/145]  inactive:\t-4.27e-04 +- 3.20e-02\n",
      "[dimension 19/145]  inactive:\t-3.88e-03 +- 2.72e-02\n",
      "[dimension 20/145]  inactive:\t-1.97e-03 +- 3.40e-02\n",
      "[dimension 21/145]  inactive:\t-2.79e-03 +- 3.11e-02\n",
      "[dimension 22/145]  inactive:\t-8.58e-04 +- 2.89e-02\n",
      "[dimension 23/145]  inactive:\t-6.92e-04 +- 2.72e-02\n",
      "[dimension 24/145]  inactive:\t2.42e-03 +- 3.26e-02\n",
      "[dimension 25/145]  inactive:\t3.70e-03 +- 2.56e-02\n",
      "[dimension 26/145]  inactive:\t-1.40e-03 +- 3.22e-02\n",
      "[dimension 27/145]  inactive:\t7.05e-04 +- 2.85e-02\n",
      "[dimension 28/145]  inactive:\t6.99e-04 +- 2.15e-02\n",
      "[dimension 29/145]  inactive:\t-3.65e-04 +- 3.11e-02\n",
      "[dimension 30/145]  inactive:\t1.44e-03 +- 3.39e-02\n",
      "[dimension 31/145]  inactive:\t8.27e-03 +- 5.68e-02\n",
      "[dimension 32/145]  inactive:\t-2.46e-03 +- 3.33e-02\n",
      "[dimension 33/145]  inactive:\t2.74e-03 +- 3.89e-02\n",
      "[dimension 34/145]  inactive:\t8.06e-04 +- 2.27e-02\n",
      "[dimension 35/145]  inactive:\t3.50e-04 +- 2.84e-02\n",
      "[dimension 36/145]  inactive:\t8.45e-04 +- 2.77e-02\n",
      "[dimension 37/145]  inactive:\t5.98e-03 +- 3.40e-02\n",
      "[dimension 38/145]  inactive:\t-2.26e-03 +- 3.75e-02\n",
      "[dimension 39/145]  inactive:\t7.44e-04 +- 3.18e-02\n",
      "[dimension 40/145]  inactive:\t7.27e-03 +- 4.64e-02\n",
      "[dimension 41/145]  inactive:\t-3.56e-03 +- 4.56e-02\n",
      "[dimension 42/145]  inactive:\t1.04e-02 +- 7.46e-02\n",
      "[dimension 43/145]  inactive:\t-9.97e-04 +- 2.28e-02\n",
      "[dimension 44/145]  inactive:\t-3.72e-04 +- 3.71e-02\n",
      "[dimension 45/145]  inactive:\t-1.36e-03 +- 3.17e-02\n",
      "[dimension 46/145]  inactive:\t1.38e-03 +- 1.86e-02\n",
      "[dimension 47/145]  inactive:\t-3.87e-03 +- 4.23e-02\n",
      "[dimension 48/145]  inactive:\t2.05e-03 +- 3.02e-02\n",
      "[dimension 49/145]  inactive:\t3.67e-03 +- 2.76e-02\n",
      "[dimension 50/145]  inactive:\t-2.40e-03 +- 3.42e-02\n",
      "[dimension 51/145]  inactive:\t4.51e-03 +- 3.80e-02\n",
      "[dimension 52/145]  inactive:\t8.15e-03 +- 3.13e-02\n",
      "[dimension 53/145]  inactive:\t-1.38e-03 +- 2.75e-02\n",
      "[dimension 54/145]  inactive:\t-4.28e-04 +- 2.18e-02\n",
      "[dimension 55/145]  inactive:\t5.27e-04 +- 1.88e-02\n",
      "[dimension 56/145]  inactive:\t-3.90e-03 +- 3.20e-02\n",
      "[dimension 57/145]  inactive:\t9.87e-05 +- 2.96e-02\n",
      "[dimension 58/145]  inactive:\t2.22e-02 +- 9.37e-02\n",
      "[dimension 59/145]  inactive:\t-9.89e-04 +- 1.97e-02\n",
      "[dimension 60/145]  inactive:\t1.16e-03 +- 3.70e-02\n",
      "[dimension 61/145]  inactive:\t2.72e-03 +- 2.77e-02\n",
      "[dimension 62/145]  inactive:\t-5.78e-04 +- 2.78e-02\n",
      "[dimension 63/145]  active:\t6.29e-01 +- 4.61e-01\n",
      "[dimension 64/145]  inactive:\t-4.06e-03 +- 3.06e-02\n",
      "[dimension 65/145]  inactive:\t-1.50e-04 +- 3.04e-02\n",
      "[dimension 66/145]  inactive:\t6.87e-04 +- 2.57e-02\n",
      "[dimension 67/145]  inactive:\t1.69e-03 +- 3.25e-02\n",
      "[dimension 68/145]  inactive:\t-8.90e-04 +- 2.92e-02\n",
      "[dimension 69/145]  inactive:\t5.21e-03 +- 4.73e-02\n",
      "[dimension 70/145]  inactive:\t3.58e-03 +- 2.36e-02\n",
      "[dimension 71/145]  inactive:\t-1.56e-05 +- 2.57e-02\n",
      "[dimension 72/145]  inactive:\t1.96e-04 +- 2.58e-02\n",
      "[dimension 73/145]  inactive:\t4.83e-04 +- 2.16e-02\n",
      "[dimension 74/145]  inactive:\t-2.02e-03 +- 3.80e-02\n",
      "[dimension 75/145]  inactive:\t-7.03e-05 +- 2.54e-02\n",
      "[dimension 76/145]  inactive:\t6.30e-03 +- 4.05e-02\n",
      "[dimension 77/145]  inactive:\t-2.85e-03 +- 4.05e-02\n",
      "[dimension 78/145]  inactive:\t3.80e-03 +- 4.14e-02\n",
      "[dimension 79/145]  inactive:\t8.18e-03 +- 3.99e-02\n",
      "[dimension 80/145]  inactive:\t-9.73e-04 +- 3.51e-02\n",
      "[dimension 81/145]  inactive:\t1.59e-03 +- 3.50e-02\n",
      "[dimension 82/145]  inactive:\t3.19e-04 +- 1.79e-02\n",
      "[dimension 83/145]  inactive:\t-2.20e-03 +- 2.26e-02\n",
      "[dimension 84/145]  inactive:\t-2.03e-03 +- 3.08e-02\n",
      "[dimension 85/145]  inactive:\t2.58e-03 +- 2.84e-02\n",
      "[dimension 86/145]  inactive:\t-9.06e-04 +- 2.49e-02\n",
      "[dimension 87/145]  inactive:\t3.69e-03 +- 4.42e-02\n",
      "[dimension 88/145]  inactive:\t3.23e-03 +- 2.81e-02\n",
      "[dimension 89/145]  inactive:\t-1.24e-03 +- 2.73e-02\n",
      "[dimension 90/145]  inactive:\t1.86e-01 +- 3.67e-01\n",
      "[dimension 91/145]  inactive:\t-2.89e-04 +- 2.27e-02\n",
      "[dimension 92/145]  inactive:\t-1.57e-03 +- 2.74e-02\n",
      "[dimension 93/145]  inactive:\t-1.19e-03 +- 3.31e-02\n",
      "[dimension 94/145]  inactive:\t2.14e-03 +- 3.12e-02\n",
      "[dimension 95/145]  inactive:\t-8.25e-04 +- 2.48e-02\n",
      "[dimension 96/145]  inactive:\t-2.41e-04 +- 5.04e-02\n",
      "[dimension 97/145]  inactive:\t1.86e-03 +- 2.28e-02\n",
      "[dimension 98/145]  inactive:\t-1.92e-03 +- 3.07e-02\n",
      "[dimension 99/145]  inactive:\t5.03e-03 +- 5.90e-02\n",
      "[dimension 100/145]  inactive:\t-8.42e-04 +- 1.74e-02\n",
      "[dimension 101/145]  inactive:\t-3.30e-03 +- 2.57e-02\n",
      "[dimension 102/145]  inactive:\t-1.29e-03 +- 3.12e-02\n",
      "[dimension 103/145]  inactive:\t6.67e-04 +- 2.28e-02\n",
      "[dimension 104/145]  inactive:\t-1.38e-03 +- 2.05e-02\n",
      "[dimension 105/145]  inactive:\t-8.62e-04 +- 3.28e-02\n",
      "[dimension 106/145]  inactive:\t4.71e-03 +- 3.26e-02\n",
      "[dimension 107/145]  inactive:\t-1.69e-03 +- 2.47e-02\n",
      "[dimension 108/145]  inactive:\t1.50e-02 +- 1.03e-01\n",
      "[dimension 109/145]  inactive:\t-7.62e-04 +- 1.97e-02\n",
      "[dimension 110/145]  inactive:\t-1.31e-03 +- 3.16e-02\n",
      "[dimension 111/145]  inactive:\t2.38e-03 +- 3.66e-02\n",
      "[dimension 112/145]  inactive:\t8.11e-03 +- 5.80e-02\n",
      "[dimension 113/145]  inactive:\t-2.33e-03 +- 2.74e-02\n",
      "[dimension 114/145]  inactive:\t5.36e-04 +- 3.72e-02\n",
      "[dimension 115/145]  inactive:\t2.79e-03 +- 2.65e-02\n",
      "[dimension 116/145]  inactive:\t1.54e-03 +- 6.29e-02\n",
      "[dimension 117/145]  inactive:\t5.89e-03 +- 5.19e-02\n",
      "[dimension 118/145]  inactive:\t3.81e-03 +- 2.93e-02\n",
      "[dimension 119/145]  inactive:\t-2.99e-03 +- 3.39e-02\n",
      "[dimension 120/145]  inactive:\t-5.27e-04 +- 3.78e-02\n",
      "[dimension 121/145]  inactive:\t7.06e-03 +- 4.75e-02\n",
      "[dimension 122/145]  inactive:\t-4.33e-03 +- 4.51e-02\n",
      "[dimension 123/145]  inactive:\t1.10e-03 +- 4.11e-02\n",
      "[dimension 124/145]  inactive:\t-2.23e-03 +- 2.27e-02\n",
      "[dimension 125/145]  inactive:\t-2.14e-03 +- 3.21e-02\n",
      "[dimension 126/145]  inactive:\t-1.40e-03 +- 2.67e-02\n",
      "[dimension 127/145]  inactive:\t-4.04e-04 +- 2.08e-02\n",
      "[dimension 128/145]  inactive:\t-2.09e-03 +- 4.02e-02\n",
      "[dimension 129/145]  inactive:\t-3.18e-04 +- 2.98e-02\n",
      "[dimension 130/145]  inactive:\t3.99e-03 +- 2.91e-02\n",
      "[dimension 131/145]  inactive:\t-1.37e-03 +- 2.97e-02\n",
      "[dimension 132/145]  inactive:\t4.34e-03 +- 4.00e-02\n",
      "[dimension 133/145]  inactive:\t2.70e-03 +- 2.35e-02\n",
      "[dimension 134/145]  inactive:\t-3.73e-04 +- 3.29e-02\n",
      "[dimension 135/145]  inactive:\t5.41e-04 +- 3.87e-02\n",
      "[dimension 136/145]  inactive:\t1.62e-03 +- 2.46e-02\n",
      "[dimension 137/145]  inactive:\t-7.74e-04 +- 4.22e-02\n",
      "[dimension 138/145]  inactive:\t5.01e-04 +- 2.61e-02\n",
      "[dimension 139/145]  inactive:\t2.80e-04 +- 2.78e-02\n",
      "[dimension 140/145]  inactive:\t-1.37e-03 +- 3.32e-02\n",
      "[dimension 141/145]  inactive:\t1.63e-03 +- 3.02e-02\n",
      "[dimension 142/145]  inactive:\t1.50e-03 +- 2.15e-02\n",
      "[dimension 143/145]  inactive:\t2.23e-03 +- 4.09e-02\n",
      "[dimension 144/145]  inactive:\t-3.53e-04 +- 2.41e-02\n",
      "[dimension 145/145]  inactive:\t-1.43e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.77378476]\n",
      "cov_act[[0.0218805]]\n",
      "Active_dimensions: [62]\n",
      "47, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:23<00:00, 63.01it/s, 15 steps of size 2.43e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    337.45      1.01\n",
      "  lambda[0]      2.51      8.96      0.99      0.00      5.05   1025.94      1.00\n",
      "  lambda[1]     18.58    383.98      0.96      0.00      4.98    582.49      1.00\n",
      "  lambda[2]      2.86      6.46      1.03      0.01      6.23    473.67      1.00\n",
      "  lambda[3]      4.86     40.83      1.01      0.00      7.09    995.21      1.00\n",
      "  lambda[4]      2.77      6.75      1.02      0.00      6.28    785.77      1.00\n",
      "  lambda[5]      3.12     11.36      1.01      0.00      5.99    862.06      1.00\n",
      "  lambda[6]      3.04      8.73      0.92      0.00      5.59    684.07      1.00\n",
      "  lambda[7]      2.84      8.06      0.91      0.00      5.89    837.64      1.00\n",
      "  lambda[8]      2.79      7.45      0.96      0.00      5.54    725.84      1.00\n",
      "  lambda[9]      2.92      9.00      1.05      0.00      5.56    844.17      1.00\n",
      " lambda[10]      3.22     13.01      1.01      0.00      5.44    863.86      1.00\n",
      " lambda[11]      2.87      8.37      0.99      0.01      6.06    796.22      1.00\n",
      " lambda[12]      4.96     28.44      1.01      0.00      7.20    513.83      1.00\n",
      " lambda[13]      2.71      6.91      0.96      0.00      5.58    702.44      1.00\n",
      " lambda[14]      4.06     25.36      1.05      0.00      5.86    503.69      1.00\n",
      " lambda[15]      2.77      7.55      1.01      0.00      5.42    865.84      1.00\n",
      " lambda[16]      2.72      7.54      0.95      0.00      5.87    987.69      1.00\n",
      " lambda[17]      2.82      8.73      1.02      0.00      5.19    730.26      1.00\n",
      " lambda[18]      2.93      8.47      0.93      0.00      5.32    859.13      1.00\n",
      " lambda[19]      2.51      5.80      1.06      0.00      5.61   1046.76      1.00\n",
      " lambda[20]      3.50     10.53      1.03      0.00      6.98    532.33      1.00\n",
      " lambda[21]      2.44      5.44      0.95      0.00      5.67    534.53      1.00\n",
      " lambda[22]      3.00     11.07      1.01      0.00      5.55    767.36      1.00\n",
      " lambda[23]      3.49     17.89      1.01      0.00      5.59    943.07      1.00\n",
      " lambda[24]      4.35     26.48      1.04      0.00      6.30    902.43      1.00\n",
      " lambda[25]      2.86     10.88      0.95      0.00      5.30    502.85      1.00\n",
      " lambda[26]      2.58      5.92      0.93      0.00      5.81    689.38      1.00\n",
      " lambda[27]      2.83      7.16      0.90      0.00      6.12    794.91      1.00\n",
      " lambda[28]      2.48      5.49      0.95      0.01      5.73    746.17      1.01\n",
      " lambda[29]      2.88     10.77      0.94      0.01      5.15    835.37      1.00\n",
      " lambda[30]      3.31     14.59      0.97      0.00      6.16    729.93      1.00\n",
      " lambda[31]      3.36     11.24      1.00      0.00      6.06    618.74      1.00\n",
      " lambda[32]      3.61     17.63      1.01      0.00      6.74    870.04      1.00\n",
      " lambda[33]      2.53      5.77      0.94      0.00      5.52    747.06      1.00\n",
      " lambda[34]      3.07     13.41      1.00      0.00      5.91    440.91      1.00\n",
      " lambda[35]      3.00     12.49      1.05      0.00      5.79    931.30      1.00\n",
      " lambda[36]      2.96      7.55      1.04      0.01      6.13    815.55      1.00\n",
      " lambda[37]      3.07     11.85      1.03      0.00      6.07    947.44      1.00\n",
      " lambda[38]      4.93     52.70      0.98      0.00      6.35    846.57      1.00\n",
      " lambda[39]      4.14     24.46      0.97      0.00      6.33    744.42      1.00\n",
      " lambda[40]      2.70      7.26      0.96      0.00      5.68    831.99      1.00\n",
      " lambda[41]      9.52     63.43      1.00      0.00      9.77    430.98      1.00\n",
      " lambda[42]      2.22      4.48      0.92      0.00      5.07    908.02      1.00\n",
      " lambda[43]     12.81    274.35      0.98      0.00      5.69    753.58      1.00\n",
      " lambda[44]      2.73      5.86      0.95      0.00      5.57    737.66      1.00\n",
      " lambda[45]      2.63      7.16      0.94      0.00      5.33    986.63      1.00\n",
      " lambda[46]      3.38     13.48      0.94      0.00      4.96    332.40      1.00\n",
      " lambda[47]      2.52      4.73      1.05      0.00      5.71    867.84      1.00\n",
      " lambda[48]      3.04      7.23      1.02      0.00      6.73    698.04      1.00\n",
      " lambda[49]      3.13      7.93      1.05      0.00      6.99    950.03      1.00\n",
      " lambda[50]      4.54     36.42      0.98      0.01      6.34    649.24      1.00\n",
      " lambda[51]      4.07     18.92      1.03      0.00      6.64    490.76      1.00\n",
      " lambda[52]      2.72      9.09      0.98      0.00      4.48    886.22      1.00\n",
      " lambda[53]      2.73      7.05      1.02      0.00      5.15    793.48      1.00\n",
      " lambda[54]      2.22      5.30      0.95      0.00      4.45    735.56      1.00\n",
      " lambda[55]      3.39     18.84      0.87      0.00      5.39    981.38      1.00\n",
      " lambda[56]      2.56      7.82      0.98      0.01      5.11   1022.41      1.00\n",
      " lambda[57]      8.23     55.86      1.10      0.01     12.12    567.94      1.00\n",
      " lambda[58]      2.49      5.76      0.97      0.00      5.05    611.76      1.00\n",
      " lambda[59]      2.82      7.24      1.04      0.00      5.64    850.84      1.00\n",
      " lambda[60]      2.78      7.77      0.98      0.00      5.06    394.20      1.01\n",
      " lambda[61]      2.50      6.10      1.00      0.00      5.44    832.91      1.00\n",
      " lambda[62]    897.03   2925.53    197.59      0.02   1636.54    424.03      1.00\n",
      " lambda[63]      2.53      5.13      1.04      0.00      5.78    805.54      1.00\n",
      " lambda[64]      2.71      9.75      1.01      0.00      5.40    880.35      1.00\n",
      " lambda[65]      3.24     13.43      0.99      0.00      5.29    874.32      1.00\n",
      " lambda[66]      2.85      8.11      0.93      0.00      5.61    840.37      1.00\n",
      " lambda[67]      3.46     12.81      1.04      0.00      6.22    903.13      1.00\n",
      " lambda[68]      3.58     11.59      1.00      0.01      6.84    802.16      1.00\n",
      " lambda[69]      3.91     12.29      0.96      0.00      6.96    836.21      1.00\n",
      " lambda[70]      2.93      9.31      0.97      0.00      5.35    742.10      1.00\n",
      " lambda[71]      3.04      9.20      1.05      0.00      5.78    429.71      1.00\n",
      " lambda[72]      2.34      6.55      1.01      0.00      4.86    611.90      1.00\n",
      " lambda[73]      3.55     25.86      0.98      0.00      5.84    993.94      1.00\n",
      " lambda[74]      2.53      6.09      0.96      0.00      5.42    709.47      1.00\n",
      " lambda[75]      5.90     27.02      1.05      0.00      8.07    531.54      1.00\n",
      " lambda[76]      2.72      7.02      0.98      0.00      5.46    624.09      1.00\n",
      " lambda[77]      6.82     49.27      1.02      0.00      6.51    429.17      1.00\n",
      " lambda[78]      3.06      8.35      0.99      0.00      5.39    593.06      1.00\n",
      " lambda[79]      2.47      7.61      0.93      0.01      4.84    713.90      1.00\n",
      " lambda[80]      3.79     19.14      0.98      0.00      6.58    785.55      1.00\n",
      " lambda[81]      2.89      7.55      1.00      0.00      6.35    484.01      1.00\n",
      " lambda[82]      2.53      9.44      0.96      0.00      4.72    753.89      1.00\n",
      " lambda[83]      3.58     11.25      1.04      0.01      6.77    785.98      1.00\n",
      " lambda[84]      5.79     56.84      1.01      0.00      6.30    837.40      1.00\n",
      " lambda[85]      2.96     12.63      0.95      0.00      5.57    517.71      1.00\n",
      " lambda[86]      4.00     15.33      0.94      0.00      5.75    748.89      1.00\n",
      " lambda[87]      2.72      7.13      0.94      0.00      5.39    697.92      1.00\n",
      " lambda[88]      3.43     14.00      0.95      0.00      6.61    500.38      1.00\n",
      " lambda[89]    172.22   2324.72      1.23      0.00     59.78    396.23      1.00\n",
      " lambda[90]      2.47      6.19      0.96      0.00      4.94    595.09      1.00\n",
      " lambda[91]      3.05     12.57      0.98      0.00      5.09    424.22      1.00\n",
      " lambda[92]      2.66      6.54      0.95      0.00      5.46    801.52      1.00\n",
      " lambda[93]      2.65     10.32      0.99      0.00      4.50    678.06      1.00\n",
      " lambda[94]      3.64     13.18      1.00      0.00      6.54    628.40      1.00\n",
      " lambda[95]      3.99     16.98      1.00      0.00      7.04    661.13      1.00\n",
      " lambda[96]      2.91      7.63      0.97      0.00      6.45    602.69      1.00\n",
      " lambda[97]      2.67      6.82      1.00      0.01      5.61    624.47      1.00\n",
      " lambda[98]      3.27     12.50      0.95      0.00      5.24    634.18      1.00\n",
      " lambda[99]      2.86     10.26      0.94      0.00      5.62    954.52      1.00\n",
      "lambda[100]      2.93      9.13      0.95      0.00      5.92    864.43      1.00\n",
      "lambda[101]      3.38     12.47      1.00      0.00      5.68    573.05      1.00\n",
      "lambda[102]      2.54      6.99      0.93      0.00      4.99    997.54      1.00\n",
      "lambda[103]      5.90     71.48      0.96      0.00      5.77    382.28      1.00\n",
      "lambda[104]      3.09     12.48      0.96      0.00      4.46    469.99      1.00\n",
      "lambda[105]      3.12      9.06      1.00      0.00      5.92    847.85      1.00\n",
      "lambda[106]      3.71     16.48      0.97      0.00      5.60    346.91      1.00\n",
      "lambda[107]      5.96     49.89      1.00      0.00      5.27    408.35      1.00\n",
      "lambda[108]      2.22      5.51      0.95      0.00      4.78    953.19      1.00\n",
      "lambda[109]      4.32     22.88      1.00      0.00      7.59    791.01      1.00\n",
      "lambda[110]      3.51     13.31      1.01      0.00      6.01    763.63      1.00\n",
      "lambda[111]      4.62     29.79      1.02      0.00      6.23    725.12      1.00\n",
      "lambda[112]      2.44      6.34      1.01      0.01      4.81    528.84      1.00\n",
      "lambda[113]      3.04     10.85      1.00      0.00      5.28    797.57      1.00\n",
      "lambda[114]      2.57      6.29      0.93      0.00      5.18    738.47      1.00\n",
      "lambda[115]      3.37     11.94      1.02      0.00      6.55    832.21      1.00\n",
      "lambda[116]      3.30     20.71      1.01      0.01      5.15    974.56      1.00\n",
      "lambda[117]      3.40     13.46      0.98      0.00      6.36    884.40      1.00\n",
      "lambda[118]      3.50     17.87      0.97      0.00      5.26    730.83      1.00\n",
      "lambda[119]      4.94     33.34      1.00      0.00      6.96    974.03      1.00\n",
      "lambda[120]      3.32     11.17      0.95      0.00      7.24    835.16      1.00\n",
      "lambda[121]      3.30     10.68      1.00      0.00      6.27    709.98      1.00\n",
      "lambda[122]      5.54     58.34      0.97      0.01      5.51    533.74      1.00\n",
      "lambda[123]      2.79      5.94      0.90      0.00      6.66    717.50      1.00\n",
      "lambda[124]      3.17      8.69      0.97      0.01      6.99    729.19      1.00\n",
      "lambda[125]      2.90      8.54      1.01      0.01      6.09    477.97      1.00\n",
      "lambda[126]      2.51      7.67      0.95      0.00      5.23    807.83      1.00\n",
      "lambda[127]      3.50     19.49      0.99      0.00      5.53    980.94      1.00\n",
      "lambda[128]      5.04     42.99      0.97      0.00      5.73    379.88      1.00\n",
      "lambda[129]      4.08     31.27      0.85      0.00      5.80    691.31      1.00\n",
      "lambda[130]      3.08      8.79      1.00      0.01      6.41    682.94      1.01\n",
      "lambda[131]     11.15    236.91      1.04      0.00      5.74    940.92      1.00\n",
      "lambda[132]      2.74      6.97      1.00      0.00      5.80    759.25      1.00\n",
      "lambda[133]      2.93      9.59      0.98      0.00      5.30    646.10      1.00\n",
      "lambda[134]      3.19      9.21      1.03      0.00      6.62    852.16      1.00\n",
      "lambda[135]      2.18      4.87      0.97      0.00      4.41    913.29      1.00\n",
      "lambda[136]      2.74      6.76      0.95      0.00      5.89    755.66      1.00\n",
      "lambda[137]      3.05      9.91      1.01      0.00      5.77    660.20      1.00\n",
      "lambda[138]      3.10     10.18      0.98      0.00      6.12    682.83      1.00\n",
      "lambda[139]      2.63      6.14      0.98      0.00      5.55    629.20      1.00\n",
      "lambda[140]      3.12     10.87      0.96      0.00      5.53    778.47      1.00\n",
      "lambda[141]      2.99      9.98      0.96      0.00      6.63    570.13      1.00\n",
      "lambda[142]      3.38     10.51      0.99      0.00      6.40    792.38      1.00\n",
      "lambda[143]      2.73     10.72      0.97      0.00      4.90    957.31      1.00\n",
      "        msq      1.36      0.82      1.16      0.47      2.22    792.45      1.00\n",
      "      sigma      5.81      7.67      2.57      0.01     16.54   1114.47      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    779.00      1.00\n",
      "       xisq      0.12      0.06      0.11      0.04      0.20    871.16      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 27.47332000732422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-4.54e-04 +- 1.95e-02\n",
      "[dimension 02/145]  inactive:\t-6.61e-04 +- 2.99e-02\n",
      "[dimension 03/145]  inactive:\t8.60e-05 +- 2.41e-02\n",
      "[dimension 04/145]  inactive:\t6.66e-03 +- 4.31e-02\n",
      "[dimension 05/145]  inactive:\t-8.58e-04 +- 2.74e-02\n",
      "[dimension 06/145]  inactive:\t2.58e-03 +- 3.39e-02\n",
      "[dimension 07/145]  inactive:\t7.97e-04 +- 2.06e-02\n",
      "[dimension 08/145]  inactive:\t9.56e-04 +- 2.60e-02\n",
      "[dimension 09/145]  inactive:\t2.65e-04 +- 2.07e-02\n",
      "[dimension 10/145]  inactive:\t3.30e-04 +- 2.04e-02\n",
      "[dimension 11/145]  inactive:\t-7.20e-04 +- 2.86e-02\n",
      "[dimension 12/145]  inactive:\t1.92e-04 +- 2.75e-02\n",
      "[dimension 13/145]  inactive:\t5.68e-03 +- 4.45e-02\n",
      "[dimension 14/145]  inactive:\t-1.68e-03 +- 2.33e-02\n",
      "[dimension 15/145]  inactive:\t1.29e-03 +- 3.25e-02\n",
      "[dimension 16/145]  inactive:\t6.38e-04 +- 2.16e-02\n",
      "[dimension 17/145]  inactive:\t2.18e-04 +- 2.77e-02\n",
      "[dimension 18/145]  inactive:\t-1.60e-04 +- 2.80e-02\n",
      "[dimension 19/145]  inactive:\t-2.01e-03 +- 1.95e-02\n",
      "[dimension 20/145]  inactive:\t-1.13e-03 +- 2.84e-02\n",
      "[dimension 21/145]  inactive:\t-1.13e-03 +- 2.19e-02\n",
      "[dimension 22/145]  inactive:\t-8.71e-04 +- 2.52e-02\n",
      "[dimension 23/145]  inactive:\t-4.11e-04 +- 2.83e-02\n",
      "[dimension 24/145]  inactive:\t1.66e-03 +- 2.92e-02\n",
      "[dimension 25/145]  inactive:\t3.71e-03 +- 2.42e-02\n",
      "[dimension 26/145]  inactive:\t-2.70e-04 +- 2.88e-02\n",
      "[dimension 27/145]  inactive:\t4.33e-04 +- 2.07e-02\n",
      "[dimension 28/145]  inactive:\t9.25e-04 +- 2.07e-02\n",
      "[dimension 29/145]  inactive:\t-1.70e-04 +- 2.40e-02\n",
      "[dimension 30/145]  inactive:\t1.48e-03 +- 2.93e-02\n",
      "[dimension 31/145]  inactive:\t5.83e-03 +- 4.41e-02\n",
      "[dimension 32/145]  inactive:\t-1.86e-03 +- 2.76e-02\n",
      "[dimension 33/145]  inactive:\t4.07e-03 +- 4.75e-02\n",
      "[dimension 34/145]  inactive:\t7.50e-04 +- 1.86e-02\n",
      "[dimension 35/145]  inactive:\t1.03e-03 +- 3.28e-02\n",
      "[dimension 36/145]  inactive:\t8.24e-04 +- 2.24e-02\n",
      "[dimension 37/145]  inactive:\t3.98e-03 +- 2.48e-02\n",
      "[dimension 38/145]  inactive:\t-1.36e-03 +- 2.67e-02\n",
      "[dimension 39/145]  inactive:\t2.26e-03 +- 4.06e-02\n",
      "[dimension 40/145]  inactive:\t4.87e-03 +- 3.87e-02\n",
      "[dimension 41/145]  inactive:\t-1.20e-03 +- 2.53e-02\n",
      "[dimension 42/145]  inactive:\t1.61e-02 +- 9.91e-02\n",
      "[dimension 43/145]  inactive:\t-5.37e-04 +- 1.89e-02\n",
      "[dimension 44/145]  inactive:\t-7.57e-04 +- 3.21e-02\n",
      "[dimension 45/145]  inactive:\t-5.23e-04 +- 2.55e-02\n",
      "[dimension 46/145]  inactive:\t9.80e-04 +- 1.68e-02\n",
      "[dimension 47/145]  inactive:\t-2.09e-03 +- 3.35e-02\n",
      "[dimension 48/145]  inactive:\t1.19e-03 +- 2.28e-02\n",
      "[dimension 49/145]  inactive:\t3.37e-03 +- 2.58e-02\n",
      "[dimension 50/145]  inactive:\t-2.05e-03 +- 3.12e-02\n",
      "[dimension 51/145]  inactive:\t4.32e-03 +- 4.04e-02\n",
      "[dimension 52/145]  inactive:\t6.45e-03 +- 2.73e-02\n",
      "[dimension 53/145]  inactive:\t-1.14e-03 +- 2.55e-02\n",
      "[dimension 54/145]  inactive:\t3.13e-04 +- 2.32e-02\n",
      "[dimension 55/145]  inactive:\t5.14e-04 +- 1.73e-02\n",
      "[dimension 56/145]  inactive:\t-2.16e-03 +- 2.17e-02\n",
      "[dimension 57/145]  inactive:\t9.41e-04 +- 2.89e-02\n",
      "[dimension 58/145]  inactive:\t1.97e-02 +- 8.51e-02\n",
      "[dimension 59/145]  inactive:\t-4.34e-04 +- 2.03e-02\n",
      "[dimension 60/145]  inactive:\t3.71e-04 +- 2.31e-02\n",
      "[dimension 61/145]  inactive:\t2.61e-03 +- 2.34e-02\n",
      "[dimension 62/145]  inactive:\t-6.66e-04 +- 2.03e-02\n",
      "[dimension 63/145]  active:\t7.07e-01 +- 4.19e-01\n",
      "[dimension 64/145]  inactive:\t-2.82e-03 +- 2.34e-02\n",
      "[dimension 65/145]  inactive:\t-8.08e-04 +- 2.44e-02\n",
      "[dimension 66/145]  inactive:\t2.12e-04 +- 2.47e-02\n",
      "[dimension 67/145]  inactive:\t1.21e-03 +- 2.48e-02\n",
      "[dimension 68/145]  inactive:\t-1.59e-03 +- 3.67e-02\n",
      "[dimension 69/145]  inactive:\t4.52e-03 +- 4.44e-02\n",
      "[dimension 70/145]  inactive:\t4.75e-03 +- 2.80e-02\n",
      "[dimension 71/145]  inactive:\t1.78e-05 +- 2.61e-02\n",
      "[dimension 72/145]  inactive:\t8.06e-04 +- 2.44e-02\n",
      "[dimension 73/145]  inactive:\t-1.59e-04 +- 1.83e-02\n",
      "[dimension 74/145]  inactive:\t-2.01e-03 +- 2.86e-02\n",
      "[dimension 75/145]  inactive:\t3.30e-04 +- 2.51e-02\n",
      "[dimension 76/145]  inactive:\t8.78e-03 +- 5.28e-02\n",
      "[dimension 77/145]  inactive:\t-1.59e-03 +- 3.15e-02\n",
      "[dimension 78/145]  inactive:\t9.72e-03 +- 7.60e-02\n",
      "[dimension 79/145]  inactive:\t5.84e-03 +- 3.19e-02\n",
      "[dimension 80/145]  inactive:\t-3.02e-04 +- 3.19e-02\n",
      "[dimension 81/145]  inactive:\t1.10e-03 +- 3.91e-02\n",
      "[dimension 82/145]  inactive:\t4.31e-04 +- 1.97e-02\n",
      "[dimension 83/145]  inactive:\t-1.65e-03 +- 1.96e-02\n",
      "[dimension 84/145]  inactive:\t-1.70e-03 +- 2.97e-02\n",
      "[dimension 85/145]  inactive:\t4.82e-03 +- 4.36e-02\n",
      "[dimension 86/145]  inactive:\t-6.43e-04 +- 2.03e-02\n",
      "[dimension 87/145]  inactive:\t3.64e-03 +- 5.05e-02\n",
      "[dimension 88/145]  inactive:\t2.43e-03 +- 2.21e-02\n",
      "[dimension 89/145]  inactive:\t-1.13e-03 +- 2.44e-02\n",
      "[dimension 90/145]  inactive:\t9.72e-02 +- 2.74e-01\n",
      "[dimension 91/145]  inactive:\t8.65e-05 +- 1.88e-02\n",
      "[dimension 92/145]  inactive:\t-1.38e-03 +- 2.39e-02\n",
      "[dimension 93/145]  inactive:\t-7.34e-04 +- 2.52e-02\n",
      "[dimension 94/145]  inactive:\t1.25e-03 +- 2.46e-02\n",
      "[dimension 95/145]  inactive:\t-6.37e-04 +- 2.59e-02\n",
      "[dimension 96/145]  inactive:\t9.02e-04 +- 4.33e-02\n",
      "[dimension 97/145]  inactive:\t2.51e-03 +- 2.26e-02\n",
      "[dimension 98/145]  inactive:\t-3.16e-04 +- 2.45e-02\n",
      "[dimension 99/145]  inactive:\t1.84e-03 +- 3.14e-02\n",
      "[dimension 100/145]  inactive:\t-7.23e-04 +- 1.81e-02\n",
      "[dimension 101/145]  inactive:\t-2.37e-03 +- 2.09e-02\n",
      "[dimension 102/145]  inactive:\t-9.52e-04 +- 2.83e-02\n",
      "[dimension 103/145]  inactive:\t8.98e-04 +- 2.32e-02\n",
      "[dimension 104/145]  inactive:\t-8.61e-04 +- 1.83e-02\n",
      "[dimension 105/145]  inactive:\t-5.45e-04 +- 2.46e-02\n",
      "[dimension 106/145]  inactive:\t3.91e-03 +- 2.73e-02\n",
      "[dimension 107/145]  inactive:\t-1.77e-03 +- 2.23e-02\n",
      "[dimension 108/145]  inactive:\t7.28e-03 +- 6.74e-02\n",
      "[dimension 109/145]  inactive:\t-7.06e-04 +- 1.93e-02\n",
      "[dimension 110/145]  inactive:\t-1.10e-03 +- 3.29e-02\n",
      "[dimension 111/145]  inactive:\t1.93e-03 +- 3.04e-02\n",
      "[dimension 112/145]  inactive:\t7.47e-03 +- 5.97e-02\n",
      "[dimension 113/145]  inactive:\t-1.50e-03 +- 2.22e-02\n",
      "[dimension 114/145]  inactive:\t1.06e-03 +- 3.39e-02\n",
      "[dimension 115/145]  inactive:\t1.81e-03 +- 1.98e-02\n",
      "[dimension 116/145]  inactive:\t7.56e-04 +- 3.60e-02\n",
      "[dimension 117/145]  inactive:\t2.60e-03 +- 3.52e-02\n",
      "[dimension 118/145]  inactive:\t3.54e-03 +- 2.79e-02\n",
      "[dimension 119/145]  inactive:\t-2.46e-03 +- 3.70e-02\n",
      "[dimension 120/145]  inactive:\t-2.80e-04 +- 3.99e-02\n",
      "[dimension 121/145]  inactive:\t3.58e-03 +- 3.18e-02\n",
      "[dimension 122/145]  inactive:\t-2.66e-03 +- 3.32e-02\n",
      "[dimension 123/145]  inactive:\t2.70e-03 +- 4.46e-02\n",
      "[dimension 124/145]  inactive:\t-1.66e-03 +- 1.91e-02\n",
      "[dimension 125/145]  inactive:\t-2.03e-03 +- 2.72e-02\n",
      "[dimension 126/145]  inactive:\t-1.20e-03 +- 2.43e-02\n",
      "[dimension 127/145]  inactive:\t1.47e-04 +- 1.58e-02\n",
      "[dimension 128/145]  inactive:\t-8.75e-04 +- 3.29e-02\n",
      "[dimension 129/145]  inactive:\t1.74e-04 +- 2.80e-02\n",
      "[dimension 130/145]  inactive:\t4.20e-03 +- 3.18e-02\n",
      "[dimension 131/145]  inactive:\t-6.05e-04 +- 2.82e-02\n",
      "[dimension 132/145]  inactive:\t6.06e-03 +- 5.68e-02\n",
      "[dimension 133/145]  inactive:\t2.41e-03 +- 1.98e-02\n",
      "[dimension 134/145]  inactive:\t-4.43e-04 +- 2.44e-02\n",
      "[dimension 135/145]  inactive:\t1.33e-05 +- 3.01e-02\n",
      "[dimension 136/145]  inactive:\t7.16e-04 +- 1.74e-02\n",
      "[dimension 137/145]  inactive:\t-1.45e-04 +- 3.37e-02\n",
      "[dimension 138/145]  inactive:\t6.21e-04 +- 2.86e-02\n",
      "[dimension 139/145]  inactive:\t-1.96e-05 +- 2.49e-02\n",
      "[dimension 140/145]  inactive:\t-9.68e-04 +- 2.97e-02\n",
      "[dimension 141/145]  inactive:\t1.75e-03 +- 2.75e-02\n",
      "[dimension 142/145]  inactive:\t1.67e-03 +- 2.00e-02\n",
      "[dimension 143/145]  inactive:\t1.69e-03 +- 4.02e-02\n",
      "[dimension 144/145]  inactive:\t2.53e-04 +- 1.98e-02\n",
      "[dimension 145/145]  inactive:\t3.87e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[2.5421381e-05]\n",
      "cov_act[[2.9541552e-06]]\n",
      "Active_dimensions: [62]\n",
      "48, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 51.80it/s, 31 steps of size 1.57e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    688.21      1.00\n",
      "  lambda[0]      2.21      4.79      0.94      0.00      4.89    675.27      1.00\n",
      "  lambda[1]      3.34     11.09      1.04      0.00      6.13    597.59      1.01\n",
      "  lambda[2]      2.96     12.09      0.97      0.00      5.45    761.94      1.00\n",
      "  lambda[3]      4.77     27.24      0.95      0.00      6.78    686.40      1.00\n",
      "  lambda[4]      2.71      6.41      1.08      0.00      5.28    798.19      1.00\n",
      "  lambda[5]      3.64     24.26      0.96      0.00      5.44    777.51      1.00\n",
      "  lambda[6]      3.35     13.04      0.97      0.00      5.51    689.50      1.00\n",
      "  lambda[7]      3.38     11.83      1.01      0.00      5.78    544.24      1.00\n",
      "  lambda[8]      2.39      5.26      0.98      0.00      5.20    924.30      1.00\n",
      "  lambda[9]      2.31      5.59      0.93      0.00      4.61    789.13      1.00\n",
      " lambda[10]      3.70     16.54      1.05      0.00      5.53    543.96      1.00\n",
      " lambda[11]      2.89      8.89      0.94      0.01      6.15    772.11      1.00\n",
      " lambda[12]      4.97     15.48      0.99      0.00      9.61    530.64      1.00\n",
      " lambda[13]      2.48      5.66      0.93      0.00      5.23    811.12      1.00\n",
      " lambda[14]      4.90     37.19      0.95      0.00      5.42    767.81      1.00\n",
      " lambda[15]      3.06      9.14      0.99      0.00      5.79    633.23      1.00\n",
      " lambda[16]      3.88     13.32      0.98      0.00      8.08    735.27      1.00\n",
      " lambda[17]      3.29     15.51      0.96      0.00      5.36    680.22      1.00\n",
      " lambda[18]      2.53      5.26      0.96      0.00      5.92    675.33      1.00\n",
      " lambda[19]      3.34     15.82      0.99      0.01      5.88    898.59      1.00\n",
      " lambda[20]      3.09      8.91      0.90      0.00      6.35    502.65      1.00\n",
      " lambda[21]      3.04      8.18      0.98      0.01      6.33    715.15      1.00\n",
      " lambda[22]      2.82      6.87      1.04      0.00      5.39    576.07      1.00\n",
      " lambda[23]      3.03      8.86      0.99      0.00      5.93    769.68      1.00\n",
      " lambda[24]      3.54     13.61      1.03      0.00      6.50    637.96      1.00\n",
      " lambda[25]      3.05      7.82      0.93      0.01      6.41    602.67      1.00\n",
      " lambda[26]      2.70      6.83      1.01      0.00      5.37    802.23      1.00\n",
      " lambda[27]      3.05      8.70      0.99      0.00      5.62    620.06      1.00\n",
      " lambda[28]      2.67      8.26      1.04      0.00      5.43    772.90      1.00\n",
      " lambda[29]      2.94      8.10      0.94      0.00      6.14    680.67      1.00\n",
      " lambda[30]      3.69     15.76      1.02      0.01      6.45    853.15      1.00\n",
      " lambda[31]      3.87     15.36      0.98      0.00      6.56    768.36      1.00\n",
      " lambda[32]      3.14      7.85      0.95      0.00      6.72    567.93      1.00\n",
      " lambda[33]      2.83     10.41      0.90      0.00      5.34    816.93      1.00\n",
      " lambda[34]      2.80      9.93      0.93      0.00      5.13    594.50      1.00\n",
      " lambda[35]      2.70      7.15      1.02      0.00      5.43    578.90      1.00\n",
      " lambda[36]      3.17     10.45      0.99      0.00      6.12    834.58      1.00\n",
      " lambda[37]      3.39     12.74      1.03      0.00      5.66    590.81      1.00\n",
      " lambda[38]      3.36      9.99      0.97      0.00      6.25    791.59      1.00\n",
      " lambda[39]      3.32      9.55      1.01      0.00      5.98    672.24      1.00\n",
      " lambda[40]      4.33     32.13      0.92      0.00      5.48    696.31      1.00\n",
      " lambda[41]      7.07     41.72      0.92      0.00      9.36    523.26      1.01\n",
      " lambda[42]      2.71      7.54      0.98      0.00      5.54    564.19      1.00\n",
      " lambda[43]      3.87     25.76      1.08      0.00      5.88    962.06      1.00\n",
      " lambda[44]      2.63      7.57      0.96      0.00      5.18    776.82      1.00\n",
      " lambda[45]      2.63      6.47      0.97      0.00      4.97    946.72      1.00\n",
      " lambda[46]      2.29      5.19      1.03      0.01      4.56    818.23      1.00\n",
      " lambda[47]      2.45      4.77      0.94      0.01      5.91    709.40      1.00\n",
      " lambda[48]      2.66      8.58      1.03      0.01      4.87    815.29      1.00\n",
      " lambda[49]      2.72      7.52      0.95      0.00      5.25    772.58      1.00\n",
      " lambda[50]      2.87      8.65      0.96      0.00      5.74    705.58      1.00\n",
      " lambda[51]      3.98     11.69      0.98      0.00      7.81    692.49      1.00\n",
      " lambda[52]      2.82      8.94      0.93      0.00      5.04    579.70      1.00\n",
      " lambda[53]      3.70     16.77      0.93      0.00      5.61    748.55      1.00\n",
      " lambda[54]      2.22      5.20      0.96      0.01      4.77    638.76      1.00\n",
      " lambda[55]      3.82     16.23      0.97      0.00      6.30    665.63      1.00\n",
      " lambda[56]      2.59      5.94      0.97      0.00      5.04    765.04      1.00\n",
      " lambda[57]     12.52    212.53      1.00      0.00      7.87    909.57      1.00\n",
      " lambda[58]      2.47      5.99      0.92      0.00      5.15    671.96      1.00\n",
      " lambda[59]      2.89      6.87      0.99      0.00      6.03    454.19      1.00\n",
      " lambda[60]      3.24     13.46      0.96      0.00      5.05    866.06      1.00\n",
      " lambda[61]      2.90      7.84      0.93      0.00      5.89    639.58      1.01\n",
      " lambda[62]   1323.71  17773.50    190.27      0.01   1154.96    757.52      1.00\n",
      " lambda[63]      2.29      5.31      0.96      0.00      5.35    652.87      1.00\n",
      " lambda[64]      2.87      7.35      0.95      0.01      5.42    679.63      1.00\n",
      " lambda[65]      3.07      9.63      0.94      0.00      5.19    590.02      1.00\n",
      " lambda[66]      2.94      6.73      1.01      0.00      6.38    717.33      1.00\n",
      " lambda[67]      2.71      6.33      0.93      0.01      5.73    844.55      1.00\n",
      " lambda[68]      3.66     21.22      0.98      0.00      5.64    949.56      1.00\n",
      " lambda[69]      3.53     13.26      0.94      0.00      5.85    900.14      1.00\n",
      " lambda[70]      2.71      7.68      0.95      0.01      5.39    691.19      1.00\n",
      " lambda[71]      2.97      9.67      0.98      0.00      5.49    663.84      1.00\n",
      " lambda[72]      2.64      7.56      0.98      0.00      5.18    558.74      1.00\n",
      " lambda[73]      3.05     10.56      1.00      0.00      6.09    647.44      1.00\n",
      " lambda[74]      2.21      3.91      1.00      0.02      5.11    889.08      1.00\n",
      " lambda[75]      3.98     14.19      1.01      0.00      6.57    787.27      1.00\n",
      " lambda[76]      3.23     10.32      0.99      0.00      5.60    805.97      1.00\n",
      " lambda[77]      5.48     56.02      1.07      0.00      6.56    504.68      1.00\n",
      " lambda[78]      2.86      5.90      1.05      0.00      6.15    871.38      1.00\n",
      " lambda[79]      2.88      8.00      1.05      0.00      5.81    529.79      1.01\n",
      " lambda[80]      4.00     26.91      0.97      0.00      5.99    746.72      1.00\n",
      " lambda[81]      2.45      5.70      0.94      0.00      5.17    874.38      1.00\n",
      " lambda[82]      3.04      9.70      0.94      0.00      5.35    571.38      1.00\n",
      " lambda[83]      3.18      9.63      0.91      0.00      5.75    964.37      1.00\n",
      " lambda[84]      4.51     48.16      0.96      0.01      5.98    962.79      1.00\n",
      " lambda[85]      2.70      6.77      0.92      0.00      5.92    721.05      1.00\n",
      " lambda[86]      3.42     11.95      0.98      0.00      5.61    884.91      1.00\n",
      " lambda[87]      3.83     16.65      0.94      0.00      6.19    521.93      1.00\n",
      " lambda[88]      2.86      9.34      0.96      0.00      5.58    945.99      1.00\n",
      " lambda[89]    143.52   1838.35      1.23      0.00    114.85    556.82      1.00\n",
      " lambda[90]      2.88      8.26      1.04      0.00      5.13    768.83      1.00\n",
      " lambda[91]      2.69      7.58      0.96      0.01      5.01    664.92      1.00\n",
      " lambda[92]      2.48      5.43      1.02      0.00      5.54    880.17      1.00\n",
      " lambda[93]      2.63      7.06      1.00      0.00      4.38    497.40      1.00\n",
      " lambda[94]      2.46      6.84      0.96      0.00      4.81    729.84      1.00\n",
      " lambda[95]      3.15      8.12      1.02      0.00      6.69    573.37      1.00\n",
      " lambda[96]      2.75      8.62      1.00      0.00      5.26    429.75      1.00\n",
      " lambda[97]      2.89      8.22      0.96      0.00      5.64    695.32      1.00\n",
      " lambda[98]      4.69     35.35      0.95      0.00      6.21    526.80      1.00\n",
      " lambda[99]      2.46      6.65      0.98      0.00      4.61    758.72      1.00\n",
      "lambda[100]      4.06     30.90      0.97      0.00      6.58    835.13      1.00\n",
      "lambda[101]      2.66      7.25      0.98      0.00      5.21    636.90      1.00\n",
      "lambda[102]      2.61      7.85      0.92      0.00      5.07    926.75      1.00\n",
      "lambda[103]      2.41      5.37      0.96      0.00      5.55    600.54      1.00\n",
      "lambda[104]      2.61      5.70      0.94      0.00      6.06    375.72      1.00\n",
      "lambda[105]      3.23      9.47      1.03      0.00      6.31    832.87      1.00\n",
      "lambda[106]      2.56      6.26      0.99      0.00      5.43    635.01      1.00\n",
      "lambda[107]      4.42     29.28      0.98      0.00      5.28    640.54      1.00\n",
      "lambda[108]      2.60     12.28      0.94      0.00      4.77    892.91      1.00\n",
      "lambda[109]      3.49      9.60      1.01      0.00      6.18    393.61      1.01\n",
      "lambda[110]      3.02      8.67      1.03      0.01      6.03    991.43      1.00\n",
      "lambda[111]      3.19      9.71      0.87      0.00      6.17    714.13      1.00\n",
      "lambda[112]      2.62      6.39      0.93      0.01      5.59    834.80      1.00\n",
      "lambda[113]      3.30     10.31      1.03      0.00      6.04    605.50      1.00\n",
      "lambda[114]      3.86     10.86      1.01      0.00      7.55    743.62      1.00\n",
      "lambda[115]      3.78     15.52      0.92      0.00      5.98    658.07      1.00\n",
      "lambda[116]      3.58     11.09      1.02      0.00      6.15    493.91      1.00\n",
      "lambda[117]      3.38     13.42      1.00      0.00      6.30    832.08      1.00\n",
      "lambda[118]      3.48     15.78      0.99      0.00      6.26    708.14      1.00\n",
      "lambda[119]      2.76      8.86      0.98      0.00      5.58    915.85      1.00\n",
      "lambda[120]      4.14     17.82      1.01      0.00      6.70    749.18      1.00\n",
      "lambda[121]      3.30     11.71      0.89      0.00      5.74    786.72      1.00\n",
      "lambda[122]      3.35     13.25      1.01      0.00      5.85    703.94      1.00\n",
      "lambda[123]      2.86      8.50      0.92      0.00      6.34    723.57      1.00\n",
      "lambda[124]      2.55      5.78      0.99      0.01      5.81    734.64      1.00\n",
      "lambda[125]      3.06      9.69      1.00      0.01      6.07    576.97      1.00\n",
      "lambda[126]      2.61      7.26      0.92      0.00      5.42    829.71      1.00\n",
      "lambda[127]      4.19     16.38      1.02      0.00      6.55    794.61      1.00\n",
      "lambda[128]      2.95     11.04      0.99      0.00      4.98    713.00      1.00\n",
      "lambda[129]      3.83     14.45      0.99      0.00      6.63    921.01      1.00\n",
      "lambda[130]      3.54      9.91      0.94      0.00      7.14    645.99      1.00\n",
      "lambda[131]      3.54     15.57      0.96      0.01      6.38    742.81      1.00\n",
      "lambda[132]      2.50      5.18      0.93      0.00      5.34    914.77      1.00\n",
      "lambda[133]      2.60      6.61      0.98      0.00      5.55    796.76      1.00\n",
      "lambda[134]      3.52      9.61      0.96      0.00      7.44    785.08      1.00\n",
      "lambda[135]      2.65     10.09      0.92      0.00      4.23    753.44      1.00\n",
      "lambda[136]      2.88      6.74      1.02      0.00      6.03    650.59      1.00\n",
      "lambda[137]      2.82      9.69      0.97      0.00      5.77    764.12      1.00\n",
      "lambda[138]      3.28     14.02      1.00      0.00      5.29    738.00      1.00\n",
      "lambda[139]      3.19     10.42      0.98      0.00      5.79    713.72      1.01\n",
      "lambda[140]      2.95      8.29      0.99      0.00      5.54    932.52      1.00\n",
      "lambda[141]      2.78      9.81      0.90      0.00      5.35    555.77      1.00\n",
      "lambda[142]      4.00     19.21      0.97      0.01      6.31    654.48      1.00\n",
      "lambda[143]      2.35      4.85      0.93      0.00      4.78    528.37      1.00\n",
      "        msq  12933.36 298322.78     19.58      0.15    664.02    980.83      1.00\n",
      "      sigma      3.31      4.31      1.59      0.01      9.28   1356.25      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    711.87      1.00\n",
      "       xisq    232.90   2525.80     13.34      0.80    121.05    657.44      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 32.598658084869385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.13e-04 +- 1.59e-02\n",
      "[dimension 02/145]  inactive:\t1.70e-04 +- 2.54e-02\n",
      "[dimension 03/145]  inactive:\t8.30e-05 +- 2.15e-02\n",
      "[dimension 04/145]  inactive:\t5.70e-03 +- 4.07e-02\n",
      "[dimension 05/145]  inactive:\t-5.86e-04 +- 2.23e-02\n",
      "[dimension 06/145]  inactive:\t2.16e-03 +- 3.77e-02\n",
      "[dimension 07/145]  inactive:\t5.63e-04 +- 1.76e-02\n",
      "[dimension 08/145]  inactive:\t1.30e-03 +- 2.89e-02\n",
      "[dimension 09/145]  inactive:\t1.44e-04 +- 2.07e-02\n",
      "[dimension 10/145]  inactive:\t3.28e-04 +- 1.51e-02\n",
      "[dimension 11/145]  inactive:\t-1.38e-03 +- 2.48e-02\n",
      "[dimension 12/145]  inactive:\t3.85e-04 +- 2.74e-02\n",
      "[dimension 13/145]  inactive:\t6.29e-03 +- 4.74e-02\n",
      "[dimension 14/145]  inactive:\t-7.25e-04 +- 2.22e-02\n",
      "[dimension 15/145]  inactive:\t1.55e-03 +- 4.05e-02\n",
      "[dimension 16/145]  inactive:\t7.85e-04 +- 2.00e-02\n",
      "[dimension 17/145]  inactive:\t4.82e-06 +- 2.95e-02\n",
      "[dimension 18/145]  inactive:\t6.36e-04 +- 3.46e-02\n",
      "[dimension 19/145]  inactive:\t-1.94e-03 +- 1.99e-02\n",
      "[dimension 20/145]  inactive:\t-9.37e-04 +- 2.70e-02\n",
      "[dimension 21/145]  inactive:\t-2.20e-03 +- 2.90e-02\n",
      "[dimension 22/145]  inactive:\t1.20e-04 +- 2.06e-02\n",
      "[dimension 23/145]  inactive:\t-6.72e-04 +- 2.45e-02\n",
      "[dimension 24/145]  inactive:\t1.23e-03 +- 2.58e-02\n",
      "[dimension 25/145]  inactive:\t3.79e-03 +- 2.65e-02\n",
      "[dimension 26/145]  inactive:\t-7.17e-04 +- 2.77e-02\n",
      "[dimension 27/145]  inactive:\t9.24e-04 +- 2.21e-02\n",
      "[dimension 28/145]  inactive:\t8.97e-04 +- 1.89e-02\n",
      "[dimension 29/145]  inactive:\t6.30e-04 +- 2.68e-02\n",
      "[dimension 30/145]  inactive:\t1.87e-03 +- 2.96e-02\n",
      "[dimension 31/145]  inactive:\t5.31e-03 +- 4.01e-02\n",
      "[dimension 32/145]  inactive:\t-1.61e-03 +- 2.82e-02\n",
      "[dimension 33/145]  inactive:\t2.28e-03 +- 3.48e-02\n",
      "[dimension 34/145]  inactive:\t5.88e-04 +- 1.85e-02\n",
      "[dimension 35/145]  inactive:\t3.51e-04 +- 2.45e-02\n",
      "[dimension 36/145]  inactive:\t1.39e-03 +- 2.67e-02\n",
      "[dimension 37/145]  inactive:\t3.19e-03 +- 2.34e-02\n",
      "[dimension 38/145]  inactive:\t-1.45e-03 +- 3.05e-02\n",
      "[dimension 39/145]  inactive:\t1.62e-03 +- 3.08e-02\n",
      "[dimension 40/145]  inactive:\t4.75e-03 +- 3.68e-02\n",
      "[dimension 41/145]  inactive:\t-1.53e-03 +- 2.86e-02\n",
      "[dimension 42/145]  inactive:\t9.09e-03 +- 7.24e-02\n",
      "[dimension 43/145]  inactive:\t-1.68e-04 +- 1.82e-02\n",
      "[dimension 44/145]  inactive:\t-3.23e-04 +- 3.12e-02\n",
      "[dimension 45/145]  inactive:\t-1.23e-04 +- 2.05e-02\n",
      "[dimension 46/145]  inactive:\t1.08e-03 +- 1.54e-02\n",
      "[dimension 47/145]  inactive:\t-1.05e-03 +- 2.14e-02\n",
      "[dimension 48/145]  inactive:\t1.31e-03 +- 2.56e-02\n",
      "[dimension 49/145]  inactive:\t2.19e-03 +- 2.11e-02\n",
      "[dimension 50/145]  inactive:\t-1.33e-03 +- 2.43e-02\n",
      "[dimension 51/145]  inactive:\t3.01e-03 +- 3.10e-02\n",
      "[dimension 52/145]  inactive:\t6.05e-03 +- 2.73e-02\n",
      "[dimension 53/145]  inactive:\t-1.04e-03 +- 2.65e-02\n",
      "[dimension 54/145]  inactive:\t2.45e-04 +- 2.30e-02\n",
      "[dimension 55/145]  inactive:\t4.84e-04 +- 1.53e-02\n",
      "[dimension 56/145]  inactive:\t-2.44e-03 +- 2.55e-02\n",
      "[dimension 57/145]  inactive:\t9.92e-04 +- 2.89e-02\n",
      "[dimension 58/145]  inactive:\t1.79e-02 +- 9.01e-02\n",
      "[dimension 59/145]  inactive:\t-5.62e-04 +- 1.69e-02\n",
      "[dimension 60/145]  inactive:\t7.54e-04 +- 2.85e-02\n",
      "[dimension 61/145]  inactive:\t2.58e-03 +- 2.53e-02\n",
      "[dimension 62/145]  inactive:\t-6.53e-04 +- 2.44e-02\n",
      "[dimension 63/145]  active:\t6.93e-01 +- 4.28e-01\n",
      "[dimension 64/145]  inactive:\t-2.02e-03 +- 2.30e-02\n",
      "[dimension 65/145]  inactive:\t-5.77e-04 +- 2.81e-02\n",
      "[dimension 66/145]  inactive:\t6.86e-04 +- 2.30e-02\n",
      "[dimension 67/145]  inactive:\t1.32e-03 +- 2.20e-02\n",
      "[dimension 68/145]  inactive:\t-5.03e-04 +- 2.51e-02\n",
      "[dimension 69/145]  inactive:\t4.04e-03 +- 4.31e-02\n",
      "[dimension 70/145]  inactive:\t3.14e-03 +- 2.27e-02\n",
      "[dimension 71/145]  inactive:\t-1.38e-04 +- 2.13e-02\n",
      "[dimension 72/145]  inactive:\t-9.23e-06 +- 2.29e-02\n",
      "[dimension 73/145]  inactive:\t1.89e-04 +- 1.74e-02\n",
      "[dimension 74/145]  inactive:\t-9.66e-04 +- 2.91e-02\n",
      "[dimension 75/145]  inactive:\t4.48e-04 +- 1.77e-02\n",
      "[dimension 76/145]  inactive:\t5.56e-03 +- 3.78e-02\n",
      "[dimension 77/145]  inactive:\t-1.91e-03 +- 3.14e-02\n",
      "[dimension 78/145]  inactive:\t3.80e-03 +- 4.84e-02\n",
      "[dimension 79/145]  inactive:\t4.71e-03 +- 2.99e-02\n",
      "[dimension 80/145]  inactive:\t-1.58e-05 +- 2.73e-02\n",
      "[dimension 81/145]  inactive:\t2.25e-03 +- 4.04e-02\n",
      "[dimension 82/145]  inactive:\t2.49e-04 +- 1.41e-02\n",
      "[dimension 83/145]  inactive:\t-1.70e-03 +- 1.88e-02\n",
      "[dimension 84/145]  inactive:\t-1.64e-03 +- 3.07e-02\n",
      "[dimension 85/145]  inactive:\t3.12e-03 +- 3.32e-02\n",
      "[dimension 86/145]  inactive:\t-8.60e-04 +- 1.92e-02\n",
      "[dimension 87/145]  inactive:\t2.16e-03 +- 3.92e-02\n",
      "[dimension 88/145]  inactive:\t2.72e-03 +- 2.45e-02\n",
      "[dimension 89/145]  inactive:\t-7.43e-04 +- 2.13e-02\n",
      "[dimension 90/145]  inactive:\t1.23e-01 +- 3.05e-01\n",
      "[dimension 91/145]  inactive:\t7.95e-05 +- 1.81e-02\n",
      "[dimension 92/145]  inactive:\t-1.23e-03 +- 2.15e-02\n",
      "[dimension 93/145]  inactive:\t-3.17e-04 +- 2.35e-02\n",
      "[dimension 94/145]  inactive:\t1.80e-03 +- 2.54e-02\n",
      "[dimension 95/145]  inactive:\t-4.29e-04 +- 2.02e-02\n",
      "[dimension 96/145]  inactive:\t1.22e-03 +- 3.89e-02\n",
      "[dimension 97/145]  inactive:\t2.30e-03 +- 2.30e-02\n",
      "[dimension 98/145]  inactive:\t-6.13e-04 +- 2.31e-02\n",
      "[dimension 99/145]  inactive:\t3.98e-03 +- 5.18e-02\n",
      "[dimension 100/145]  inactive:\t-3.71e-04 +- 1.52e-02\n",
      "[dimension 101/145]  inactive:\t-2.07e-03 +- 1.92e-02\n",
      "[dimension 102/145]  inactive:\t-6.13e-05 +- 2.32e-02\n",
      "[dimension 103/145]  inactive:\t5.77e-04 +- 1.97e-02\n",
      "[dimension 104/145]  inactive:\t-8.18e-04 +- 1.55e-02\n",
      "[dimension 105/145]  inactive:\t9.45e-05 +- 2.34e-02\n",
      "[dimension 106/145]  inactive:\t4.28e-03 +- 3.11e-02\n",
      "[dimension 107/145]  inactive:\t-9.58e-04 +- 1.97e-02\n",
      "[dimension 108/145]  inactive:\t9.40e-03 +- 7.76e-02\n",
      "[dimension 109/145]  inactive:\t-2.33e-04 +- 1.74e-02\n",
      "[dimension 110/145]  inactive:\t-1.25e-03 +- 2.95e-02\n",
      "[dimension 111/145]  inactive:\t1.57e-03 +- 2.63e-02\n",
      "[dimension 112/145]  inactive:\t3.85e-03 +- 3.69e-02\n",
      "[dimension 113/145]  inactive:\t-1.11e-03 +- 1.86e-02\n",
      "[dimension 114/145]  inactive:\t5.91e-04 +- 2.64e-02\n",
      "[dimension 115/145]  inactive:\t2.69e-03 +- 2.48e-02\n",
      "[dimension 116/145]  inactive:\t2.08e-03 +- 5.76e-02\n",
      "[dimension 117/145]  inactive:\t6.85e-03 +- 5.98e-02\n",
      "[dimension 118/145]  inactive:\t2.40e-03 +- 2.24e-02\n",
      "[dimension 119/145]  inactive:\t-1.95e-03 +- 2.97e-02\n",
      "[dimension 120/145]  inactive:\t2.06e-04 +- 2.49e-02\n",
      "[dimension 121/145]  inactive:\t4.09e-03 +- 3.45e-02\n",
      "[dimension 122/145]  inactive:\t-2.57e-03 +- 3.14e-02\n",
      "[dimension 123/145]  inactive:\t2.73e-03 +- 4.67e-02\n",
      "[dimension 124/145]  inactive:\t-8.80e-04 +- 1.78e-02\n",
      "[dimension 125/145]  inactive:\t-1.02e-03 +- 2.26e-02\n",
      "[dimension 126/145]  inactive:\t-6.11e-04 +- 2.24e-02\n",
      "[dimension 127/145]  inactive:\t1.64e-04 +- 1.73e-02\n",
      "[dimension 128/145]  inactive:\t-7.63e-04 +- 2.98e-02\n",
      "[dimension 129/145]  inactive:\t4.28e-04 +- 2.42e-02\n",
      "[dimension 130/145]  inactive:\t3.62e-03 +- 3.02e-02\n",
      "[dimension 131/145]  inactive:\t-1.03e-03 +- 2.91e-02\n",
      "[dimension 132/145]  inactive:\t4.70e-03 +- 4.81e-02\n",
      "[dimension 133/145]  inactive:\t2.22e-03 +- 2.09e-02\n",
      "[dimension 134/145]  inactive:\t-4.13e-04 +- 2.67e-02\n",
      "[dimension 135/145]  inactive:\t5.59e-04 +- 2.69e-02\n",
      "[dimension 136/145]  inactive:\t7.71e-04 +- 1.82e-02\n",
      "[dimension 137/145]  inactive:\t-3.45e-04 +- 2.82e-02\n",
      "[dimension 138/145]  inactive:\t3.94e-04 +- 1.94e-02\n",
      "[dimension 139/145]  inactive:\t6.89e-04 +- 2.10e-02\n",
      "[dimension 140/145]  inactive:\t-7.10e-04 +- 2.59e-02\n",
      "[dimension 141/145]  inactive:\t1.15e-03 +- 2.53e-02\n",
      "[dimension 142/145]  inactive:\t1.33e-03 +- 1.64e-02\n",
      "[dimension 143/145]  inactive:\t2.34e-03 +- 3.96e-02\n",
      "[dimension 144/145]  inactive:\t2.13e-04 +- 2.00e-02\n",
      "[dimension 145/145]  inactive:\t3.64e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.67924124]\n",
      "cov_act[[0.0282014]]\n",
      "Active_dimensions: [62]\n",
      "49, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.13it/s, 31 steps of size 1.34e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    256.88      1.00\n",
      "  lambda[0]      2.41      6.19      0.93      0.00      4.81    607.56      1.00\n",
      "  lambda[1]      3.29     11.64      1.00      0.00      6.09    730.18      1.01\n",
      "  lambda[2]      3.01     10.24      0.99      0.00      5.55    568.30      1.00\n",
      "  lambda[3]      2.71      6.89      1.04      0.00      6.45    729.66      1.00\n",
      "  lambda[4]      2.75      7.62      1.02      0.00      5.72    860.00      1.00\n",
      "  lambda[5]      2.64      7.89      0.92      0.00      5.05    891.29      1.00\n",
      "  lambda[6]      4.52     16.27      1.03      0.00      8.61    892.67      1.00\n",
      "  lambda[7]      2.87      8.54      0.93      0.00      5.54    571.07      1.00\n",
      "  lambda[8]      2.75      7.13      0.98      0.00      6.41    846.81      1.01\n",
      "  lambda[9]      2.71      7.54      0.99      0.00      5.71    835.08      1.00\n",
      " lambda[10]      3.60     12.07      1.06      0.00      6.12    842.37      1.00\n",
      " lambda[11]      2.80      6.94      1.01      0.00      5.53    883.50      1.00\n",
      " lambda[12]      4.27     15.08      1.01      0.00      7.62    781.07      1.00\n",
      " lambda[13]      2.55      5.60      0.91      0.00      5.78    720.01      1.00\n",
      " lambda[14]      3.96     22.38      0.95      0.00      6.29    815.96      1.00\n",
      " lambda[15]      4.28     16.37      1.01      0.00      6.05    530.05      1.00\n",
      " lambda[16]      4.56     24.64      0.96      0.00      7.40    411.01      1.00\n",
      " lambda[17]      3.54     20.54      0.96      0.00      4.94    615.19      1.00\n",
      " lambda[18]      3.02     12.15      0.96      0.00      5.62    730.05      1.00\n",
      " lambda[19]      4.36     27.84      1.00      0.00      6.80    600.97      1.00\n",
      " lambda[20]      2.86      6.96      0.91      0.00      5.84    704.79      1.00\n",
      " lambda[21]      3.63     13.65      1.04      0.00      6.72    576.64      1.00\n",
      " lambda[22]      2.76      9.87      1.01      0.00      4.74    333.39      1.00\n",
      " lambda[23]      3.01      8.33      0.98      0.00      5.94    774.39      1.00\n",
      " lambda[24]      3.41     13.99      0.98      0.00      6.26    862.35      1.00\n",
      " lambda[25]      3.01      7.48      1.00      0.01      6.29    555.53      1.00\n",
      " lambda[26]      3.40     23.04      0.98      0.00      6.33    829.84      1.00\n",
      " lambda[27]      2.70      6.60      0.96      0.00      5.35    665.72      1.00\n",
      " lambda[28]      2.80      6.96      1.06      0.00      5.82    587.27      1.00\n",
      " lambda[29]      2.92      8.57      0.96      0.00      5.69    909.17      1.00\n",
      " lambda[30]      3.25     12.72      0.99      0.01      6.64    719.86      1.00\n",
      " lambda[31]      3.25     10.13      1.08      0.00      5.65    599.56      1.00\n",
      " lambda[32]      2.96      7.27      0.95      0.00      5.66    486.87      1.01\n",
      " lambda[33]      3.24     11.64      0.97      0.01      6.35    917.37      1.00\n",
      " lambda[34]     16.32    421.88      0.98      0.00      6.39    950.61      1.00\n",
      " lambda[35]      2.18      3.96      0.98      0.00      4.68   1076.41      1.00\n",
      " lambda[36]      3.29     10.76      1.03      0.00      5.44    756.23      1.00\n",
      " lambda[37]      3.39      8.99      1.03      0.00      6.75    542.89      1.00\n",
      " lambda[38]      3.08      7.96      0.91      0.00      6.34    860.88      1.00\n",
      " lambda[39]      3.57     13.49      0.98      0.00      5.97    580.16      1.00\n",
      " lambda[40]      3.73     17.09      0.93      0.01      6.24    898.29      1.00\n",
      " lambda[41]      3.90     15.69      1.03      0.00      6.38    828.91      1.00\n",
      " lambda[42]      3.45     15.40      0.98      0.00      5.49    717.31      1.00\n",
      " lambda[43]      3.69     23.89      1.01      0.00      6.26    924.21      1.00\n",
      " lambda[44]      2.58      7.77      0.93      0.00      5.06    858.95      1.00\n",
      " lambda[45]      2.27      4.61      0.96      0.00      4.96    613.87      1.00\n",
      " lambda[46]      3.22     13.58      0.99      0.00      5.23    587.69      1.00\n",
      " lambda[47]      2.59      6.00      0.95      0.00      5.43    348.45      1.01\n",
      " lambda[48]      2.65      8.31      0.97      0.00      4.92    720.79      1.00\n",
      " lambda[49]      2.45      6.19      0.94      0.00      5.38    860.68      1.00\n",
      " lambda[50]      2.26      5.24      0.95      0.00      4.75   1000.88      1.00\n",
      " lambda[51]      5.39     19.83      1.03      0.00      8.27    783.45      1.00\n",
      " lambda[52]      3.27     12.51      0.92      0.00      5.61    614.49      1.00\n",
      " lambda[53]      3.50     16.44      0.91      0.00      5.61    890.54      1.00\n",
      " lambda[54]      2.28      6.04      0.93      0.00      5.22    612.73      1.00\n",
      " lambda[55]      3.09     12.32      0.98      0.00      6.04    969.65      1.00\n",
      " lambda[56]      2.39      5.27      0.94      0.00      4.88    736.01      1.00\n",
      " lambda[57]      3.21     10.39      0.97      0.01      5.61    388.12      1.00\n",
      " lambda[58]      2.41      6.42      0.97      0.00      4.30    820.29      1.00\n",
      " lambda[59]      2.51      6.35      0.92      0.00      5.14    828.51      1.00\n",
      " lambda[60]      3.35     11.03      1.05      0.00      6.60    731.50      1.00\n",
      " lambda[61]      2.97      8.76      1.03      0.00      6.41    900.85      1.00\n",
      " lambda[62]  14528.26 186530.28   1050.66      0.00  10580.35    647.98      1.00\n",
      " lambda[63]      2.70     17.69      1.01      0.00      4.51    831.16      1.00\n",
      " lambda[64]      2.51      5.64      0.97      0.01      5.27    810.13      1.00\n",
      " lambda[65]      3.30     13.35      1.01      0.00      4.95    711.52      1.00\n",
      " lambda[66]      3.34     11.14      1.00      0.00      6.43    600.27      1.00\n",
      " lambda[67]      2.94      7.12      0.98      0.00      6.32    868.21      1.00\n",
      " lambda[68]      4.32     33.91      0.90      0.00      6.09    574.08      1.00\n",
      " lambda[69]      4.05     12.73      1.02      0.00      7.36    728.64      1.00\n",
      " lambda[70]      2.59      6.67      0.99      0.01      5.51    703.64      1.00\n",
      " lambda[71]      2.60      8.83      1.03      0.00      4.71    608.00      1.00\n",
      " lambda[72]      2.70      6.57      0.97      0.01      5.71    743.83      1.00\n",
      " lambda[73]      3.06     12.66      0.96      0.00      6.02    529.79      1.00\n",
      " lambda[74]      2.16      3.90      1.04      0.01      5.00    738.46      1.00\n",
      " lambda[75]      3.42     10.35      1.00      0.00      6.29   1001.47      1.00\n",
      " lambda[76]      3.40     10.54      0.97      0.00      6.68    651.50      1.00\n",
      " lambda[77]     24.99    252.84      1.07      0.00      7.01    176.16      1.01\n",
      " lambda[78]      3.68     17.56      0.99      0.01      5.01    761.62      1.00\n",
      " lambda[79]      2.99      8.55      0.98      0.00      6.15    946.79      1.01\n",
      " lambda[80]      4.66     33.04      1.04      0.00      6.29    934.70      1.00\n",
      " lambda[81]      2.26      5.66      0.97      0.00      4.64    965.42      1.00\n",
      " lambda[82]      2.63      7.08      0.94      0.00      4.91    763.01      1.00\n",
      " lambda[83]      2.49      6.55      0.89      0.00      4.74    805.35      1.00\n",
      " lambda[84]      2.94     14.35      0.95      0.01      5.37    881.69      1.00\n",
      " lambda[85]      2.71      7.21      0.94      0.00      5.63    576.60      1.00\n",
      " lambda[86]      3.26     11.57      1.00      0.00      5.60    746.77      1.00\n",
      " lambda[87]      3.35     11.68      0.98      0.00      6.10    576.42      1.00\n",
      " lambda[88]      2.77      8.56      1.00      0.00      5.68    952.53      1.00\n",
      " lambda[89]    450.59   5132.47      1.13      0.00     42.52    294.38      1.00\n",
      " lambda[90]      2.85      8.59      1.01      0.00      5.52    666.19      1.00\n",
      " lambda[91]      2.50      6.10      0.95      0.01      4.62    715.04      1.00\n",
      " lambda[92]      2.62      6.65      0.96      0.00      5.82    837.04      1.00\n",
      " lambda[93]     15.29    301.69      0.90      0.00      4.97    571.06      1.00\n",
      " lambda[94]      2.33      5.23      0.94      0.00      4.94   1010.49      1.00\n",
      " lambda[95]      3.08      9.96      1.05      0.00      5.99    635.55      1.00\n",
      " lambda[96]      2.60      6.69      0.95      0.00      5.56    605.47      1.00\n",
      " lambda[97]      3.64     19.37      1.02      0.00      5.67    576.52      1.00\n",
      " lambda[98]      4.53     41.58      0.93      0.00      5.06    746.07      1.00\n",
      " lambda[99]      2.94      7.39      0.97      0.00      5.87    500.89      1.00\n",
      "lambda[100]      2.87      7.51      0.94      0.01      5.63    690.25      1.00\n",
      "lambda[101]      2.34      4.59      0.94      0.00      5.34    730.55      1.00\n",
      "lambda[102]      2.69      7.92      0.88      0.00      5.61    804.69      1.00\n",
      "lambda[103]      2.48      8.64      0.94      0.00      5.14    979.25      1.00\n",
      "lambda[104]      2.65      6.42      1.02      0.00      5.34    644.86      1.00\n",
      "lambda[105]      3.34     10.80      0.99      0.00      6.59    611.44      1.00\n",
      "lambda[106]      2.51      5.48      1.00      0.00      5.76    694.90      1.00\n",
      "lambda[107]      8.65    122.48      0.94      0.00      5.93    425.40      1.00\n",
      "lambda[108]      2.49      9.61      0.98      0.00      5.21    821.16      1.00\n",
      "lambda[109]      2.79      6.52      0.95      0.00      6.07    813.06      1.00\n",
      "lambda[110]      3.64     15.44      1.01      0.00      6.32    847.35      1.00\n",
      "lambda[111]     55.47    979.90      1.00      0.00      7.04    357.64      1.00\n",
      "lambda[112]      2.94     14.17      0.98      0.00      5.42    924.42      1.00\n",
      "lambda[113]      4.10     18.63      1.02      0.00      7.13    738.46      1.00\n",
      "lambda[114]      4.02     13.02      0.99      0.00      7.46    614.99      1.00\n",
      "lambda[115]      3.49     14.71      0.94      0.00      5.88    988.65      1.00\n",
      "lambda[116]      2.44      5.42      1.00      0.00      5.08    780.71      1.00\n",
      "lambda[117]      3.01      8.38      1.02      0.00      5.53    737.49      1.00\n",
      "lambda[118]      2.91      9.05      0.97      0.00      6.34    825.33      1.00\n",
      "lambda[119]      2.50      6.30      1.00      0.00      5.46   1007.08      1.00\n",
      "lambda[120]      3.49     11.99      0.99      0.00      6.57    716.19      1.00\n",
      "lambda[121]      3.33     11.98      0.96      0.00      6.81    853.05      1.00\n",
      "lambda[122]      2.74      6.40      0.97      0.00      5.56    898.51      1.00\n",
      "lambda[123]      2.80      8.00      0.93      0.00      5.84    811.05      1.00\n",
      "lambda[124]      2.99     14.14      0.96      0.00      4.98    487.84      1.00\n",
      "lambda[125]      3.13      9.71      1.00      0.00      6.00    614.03      1.00\n",
      "lambda[126]      2.68      6.73      0.95      0.00      5.05    530.62      1.00\n",
      "lambda[127]      4.34     22.68      0.97      0.00      6.94    866.37      1.00\n",
      "lambda[128]      3.14     16.58      0.95      0.00      4.53    449.22      1.00\n",
      "lambda[129]      3.84     14.45      0.97      0.00      7.29    884.17      1.00\n",
      "lambda[130]      3.18      7.90      1.00      0.01      6.99    713.33      1.00\n",
      "lambda[131]      3.75     15.23      0.99      0.00      6.19    559.32      1.00\n",
      "lambda[132]      2.50      4.96      0.95      0.00      6.00   1125.49      1.00\n",
      "lambda[133]      2.69      6.60      1.00      0.00      5.64    779.22      1.00\n",
      "lambda[134]      5.14     26.54      1.02      0.00      6.99    175.98      1.01\n",
      "lambda[135]      3.16     12.69      0.97      0.00      5.47    594.88      1.00\n",
      "lambda[136]      3.10      9.54      1.01      0.00      5.68    710.11      1.00\n",
      "lambda[137]      2.78      8.28      1.02      0.00      5.06    779.43      1.00\n",
      "lambda[138]      3.19     13.12      1.03      0.00      4.72    645.20      1.00\n",
      "lambda[139]      3.04      8.90      0.98      0.00      5.68   1034.20      1.00\n",
      "lambda[140]      3.14      8.64      1.02      0.00      6.61    622.02      1.00\n",
      "lambda[141]      2.57      7.64      0.98      0.00      5.25    674.73      1.00\n",
      "lambda[142]      5.47     46.45      0.92      0.01      6.08    602.72      1.00\n",
      "lambda[143]      2.55      5.87      0.98      0.00      4.87    495.41      1.01\n",
      "        msq      0.28      0.18      0.23      0.08      0.49    761.02      1.00\n",
      "      sigma      2.39      3.69      0.87      0.00      7.16    897.54      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    517.78      1.00\n",
      "       xisq     10.27     24.49      5.18      0.64     19.58    573.95      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 32.40145301818848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t2.16e-04 +- 7.07e-03\n",
      "[dimension 02/145]  inactive:\t3.41e-04 +- 1.06e-02\n",
      "[dimension 03/145]  inactive:\t1.01e-03 +- 1.85e-02\n",
      "[dimension 04/145]  inactive:\t5.41e-04 +- 9.00e-03\n",
      "[dimension 05/145]  inactive:\t1.47e-04 +- 7.51e-03\n",
      "[dimension 06/145]  inactive:\t3.45e-04 +- 9.54e-03\n",
      "[dimension 07/145]  inactive:\t6.50e-04 +- 1.07e-02\n",
      "[dimension 08/145]  inactive:\t3.52e-04 +- 8.61e-03\n",
      "[dimension 09/145]  inactive:\t6.25e-04 +- 1.18e-02\n",
      "[dimension 10/145]  inactive:\t3.13e-04 +- 7.19e-03\n",
      "[dimension 11/145]  inactive:\t5.01e-04 +- 1.20e-02\n",
      "[dimension 12/145]  inactive:\t3.64e-04 +- 1.14e-02\n",
      "[dimension 13/145]  inactive:\t1.92e-03 +- 2.49e-02\n",
      "[dimension 14/145]  inactive:\t3.04e-04 +- 1.19e-02\n",
      "[dimension 15/145]  inactive:\t1.21e-03 +- 2.11e-02\n",
      "[dimension 16/145]  inactive:\t7.06e-04 +- 1.25e-02\n",
      "[dimension 17/145]  inactive:\t3.58e-03 +- 4.70e-02\n",
      "[dimension 18/145]  inactive:\t1.39e-03 +- 2.37e-02\n",
      "[dimension 19/145]  inactive:\t-7.35e-05 +- 7.51e-03\n",
      "[dimension 20/145]  inactive:\t3.00e-04 +- 1.09e-02\n",
      "[dimension 21/145]  inactive:\t5.67e-06 +- 8.83e-03\n",
      "[dimension 22/145]  inactive:\t2.18e-04 +- 6.98e-03\n",
      "[dimension 23/145]  inactive:\t3.94e-04 +- 1.18e-02\n",
      "[dimension 24/145]  inactive:\t8.02e-04 +- 1.44e-02\n",
      "[dimension 25/145]  inactive:\t6.87e-04 +- 8.58e-03\n",
      "[dimension 26/145]  inactive:\t1.92e-04 +- 1.08e-02\n",
      "[dimension 27/145]  inactive:\t7.24e-04 +- 1.41e-02\n",
      "[dimension 28/145]  inactive:\t3.25e-04 +- 7.47e-03\n",
      "[dimension 29/145]  inactive:\t5.96e-04 +- 1.31e-02\n",
      "[dimension 30/145]  inactive:\t6.40e-04 +- 1.23e-02\n",
      "[dimension 31/145]  inactive:\t1.42e-03 +- 1.83e-02\n",
      "[dimension 32/145]  inactive:\t1.93e-04 +- 1.00e-02\n",
      "[dimension 33/145]  inactive:\t1.80e-03 +- 2.39e-02\n",
      "[dimension 34/145]  inactive:\t3.93e-04 +- 9.08e-03\n",
      "[dimension 35/145]  inactive:\t2.76e-03 +- 4.25e-02\n",
      "[dimension 36/145]  inactive:\t4.43e-04 +- 9.92e-03\n",
      "[dimension 37/145]  inactive:\t1.32e-03 +- 1.39e-02\n",
      "[dimension 38/145]  inactive:\t6.57e-05 +- 8.70e-03\n",
      "[dimension 39/145]  inactive:\t4.86e-04 +- 1.02e-02\n",
      "[dimension 40/145]  inactive:\t2.45e-03 +- 2.88e-02\n",
      "[dimension 41/145]  inactive:\t3.30e-04 +- 1.27e-02\n",
      "[dimension 42/145]  inactive:\t1.19e-03 +- 1.70e-02\n",
      "[dimension 43/145]  inactive:\t9.26e-04 +- 1.50e-02\n",
      "[dimension 44/145]  inactive:\t3.70e-04 +- 1.30e-02\n",
      "[dimension 45/145]  inactive:\t2.94e-04 +- 8.36e-03\n",
      "[dimension 46/145]  inactive:\t2.07e-04 +- 5.75e-03\n",
      "[dimension 47/145]  inactive:\t1.43e-04 +- 1.08e-02\n",
      "[dimension 48/145]  inactive:\t2.57e-04 +- 1.27e-02\n",
      "[dimension 49/145]  inactive:\t5.87e-04 +- 1.09e-02\n",
      "[dimension 50/145]  inactive:\t9.41e-05 +- 1.01e-02\n",
      "[dimension 51/145]  inactive:\t2.88e-04 +- 7.82e-03\n",
      "[dimension 52/145]  inactive:\t2.70e-03 +- 1.79e-02\n",
      "[dimension 53/145]  inactive:\t9.89e-06 +- 9.81e-03\n",
      "[dimension 54/145]  inactive:\t9.88e-04 +- 1.73e-02\n",
      "[dimension 55/145]  inactive:\t1.44e-04 +- 5.21e-03\n",
      "[dimension 56/145]  inactive:\t-4.54e-04 +- 1.04e-02\n",
      "[dimension 57/145]  inactive:\t6.17e-04 +- 1.42e-02\n",
      "[dimension 58/145]  inactive:\t3.50e-03 +- 4.08e-02\n",
      "[dimension 59/145]  inactive:\t-1.48e-04 +- 6.98e-03\n",
      "[dimension 60/145]  inactive:\t3.06e-04 +- 9.06e-03\n",
      "[dimension 61/145]  inactive:\t7.82e-04 +- 1.13e-02\n",
      "[dimension 62/145]  inactive:\t1.82e-04 +- 8.78e-03\n",
      "[dimension 63/145]  active:\t7.58e-01 +- 3.67e-01\n",
      "[dimension 64/145]  inactive:\t-2.53e-04 +- 8.44e-03\n",
      "[dimension 65/145]  inactive:\t3.45e-04 +- 1.06e-02\n",
      "[dimension 66/145]  inactive:\t9.48e-04 +- 1.65e-02\n",
      "[dimension 67/145]  inactive:\t6.60e-04 +- 1.12e-02\n",
      "[dimension 68/145]  inactive:\t3.53e-04 +- 1.17e-02\n",
      "[dimension 69/145]  inactive:\t1.36e-03 +- 2.46e-02\n",
      "[dimension 70/145]  inactive:\t1.58e-03 +- 1.43e-02\n",
      "[dimension 71/145]  inactive:\t5.41e-04 +- 1.29e-02\n",
      "[dimension 72/145]  inactive:\t3.69e-04 +- 8.47e-03\n",
      "[dimension 73/145]  inactive:\t3.25e-04 +- 7.47e-03\n",
      "[dimension 74/145]  inactive:\t6.67e-04 +- 1.92e-02\n",
      "[dimension 75/145]  inactive:\t3.44e-04 +- 8.47e-03\n",
      "[dimension 76/145]  inactive:\t1.45e-03 +- 1.85e-02\n",
      "[dimension 77/145]  inactive:\t1.13e-04 +- 1.42e-02\n",
      "[dimension 78/145]  inactive:\t1.35e-02 +- 9.83e-02\n",
      "[dimension 79/145]  inactive:\t2.10e-03 +- 2.17e-02\n",
      "[dimension 80/145]  inactive:\t7.86e-04 +- 1.51e-02\n",
      "[dimension 81/145]  inactive:\t2.01e-03 +- 2.76e-02\n",
      "[dimension 82/145]  inactive:\t1.06e-04 +- 5.83e-03\n",
      "[dimension 83/145]  inactive:\t-2.58e-04 +- 8.32e-03\n",
      "[dimension 84/145]  inactive:\t3.40e-05 +- 6.59e-03\n",
      "[dimension 85/145]  inactive:\t3.65e-04 +- 8.67e-03\n",
      "[dimension 86/145]  inactive:\t-1.01e-04 +- 7.52e-03\n",
      "[dimension 87/145]  inactive:\t2.84e-04 +- 1.03e-02\n",
      "[dimension 88/145]  inactive:\t1.28e-03 +- 1.72e-02\n",
      "[dimension 89/145]  inactive:\t-1.51e-05 +- 8.02e-03\n",
      "[dimension 90/145]  inactive:\t7.93e-02 +- 2.52e-01\n",
      "[dimension 91/145]  inactive:\t1.30e-04 +- 8.15e-03\n",
      "[dimension 92/145]  inactive:\t1.02e-04 +- 9.39e-03\n",
      "[dimension 93/145]  inactive:\t3.19e-04 +- 1.05e-02\n",
      "[dimension 94/145]  inactive:\t5.55e-03 +- 6.25e-02\n",
      "[dimension 95/145]  inactive:\t4.27e-05 +- 8.47e-03\n",
      "[dimension 96/145]  inactive:\t2.19e-04 +- 9.35e-03\n",
      "[dimension 97/145]  inactive:\t7.78e-04 +- 1.06e-02\n",
      "[dimension 98/145]  inactive:\t-9.04e-05 +- 1.20e-02\n",
      "[dimension 99/145]  inactive:\t1.53e-03 +- 2.84e-02\n",
      "[dimension 100/145]  inactive:\t7.94e-05 +- 7.28e-03\n",
      "[dimension 101/145]  inactive:\t-2.74e-04 +- 7.13e-03\n",
      "[dimension 102/145]  inactive:\t5.04e-05 +- 9.07e-03\n",
      "[dimension 103/145]  inactive:\t2.26e-04 +- 7.94e-03\n",
      "[dimension 104/145]  inactive:\t-1.39e-04 +- 6.15e-03\n",
      "[dimension 105/145]  inactive:\t9.91e-05 +- 7.55e-03\n",
      "[dimension 106/145]  inactive:\t2.15e-03 +- 2.28e-02\n",
      "[dimension 107/145]  inactive:\t-5.83e-05 +- 8.26e-03\n",
      "[dimension 108/145]  inactive:\t5.46e-03 +- 6.29e-02\n",
      "[dimension 109/145]  inactive:\t1.57e-04 +- 7.00e-03\n",
      "[dimension 110/145]  inactive:\t2.15e-04 +- 8.66e-03\n",
      "[dimension 111/145]  inactive:\t1.10e-03 +- 2.21e-02\n",
      "[dimension 112/145]  inactive:\t6.66e-03 +- 7.24e-02\n",
      "[dimension 113/145]  inactive:\t5.23e-05 +- 9.19e-03\n",
      "[dimension 114/145]  inactive:\t1.50e-03 +- 2.68e-02\n",
      "[dimension 115/145]  inactive:\t1.32e-03 +- 1.45e-02\n",
      "[dimension 116/145]  inactive:\t1.37e-03 +- 2.51e-02\n",
      "[dimension 117/145]  inactive:\t4.74e-04 +- 1.04e-02\n",
      "[dimension 118/145]  inactive:\t7.21e-04 +- 1.00e-02\n",
      "[dimension 119/145]  inactive:\t8.40e-05 +- 1.02e-02\n",
      "[dimension 120/145]  inactive:\t4.39e-04 +- 1.28e-02\n",
      "[dimension 121/145]  inactive:\t1.35e-03 +- 1.75e-02\n",
      "[dimension 122/145]  inactive:\t2.17e-05 +- 9.46e-03\n",
      "[dimension 123/145]  inactive:\t3.09e-04 +- 9.27e-03\n",
      "[dimension 124/145]  inactive:\t2.46e-04 +- 9.16e-03\n",
      "[dimension 125/145]  inactive:\t1.07e-04 +- 9.77e-03\n",
      "[dimension 126/145]  inactive:\t1.07e-04 +- 7.89e-03\n",
      "[dimension 127/145]  inactive:\t2.19e-04 +- 7.12e-03\n",
      "[dimension 128/145]  inactive:\t3.14e-04 +- 1.21e-02\n",
      "[dimension 129/145]  inactive:\t5.03e-04 +- 1.24e-02\n",
      "[dimension 130/145]  inactive:\t9.27e-04 +- 1.25e-02\n",
      "[dimension 131/145]  inactive:\t6.62e-04 +- 1.73e-02\n",
      "[dimension 132/145]  inactive:\t1.28e-03 +- 1.85e-02\n",
      "[dimension 133/145]  inactive:\t5.72e-04 +- 7.94e-03\n",
      "[dimension 134/145]  inactive:\t2.99e-04 +- 1.11e-02\n",
      "[dimension 135/145]  inactive:\t4.10e-03 +- 4.51e-02\n",
      "[dimension 136/145]  inactive:\t7.15e-04 +- 1.00e-02\n",
      "[dimension 137/145]  inactive:\t7.88e-04 +- 1.65e-02\n",
      "[dimension 138/145]  inactive:\t3.19e-04 +- 7.66e-03\n",
      "[dimension 139/145]  inactive:\t4.89e-04 +- 1.07e-02\n",
      "[dimension 140/145]  inactive:\t4.16e-04 +- 1.39e-02\n",
      "[dimension 141/145]  inactive:\t6.71e-04 +- 1.32e-02\n",
      "[dimension 142/145]  inactive:\t4.29e-04 +- 6.82e-03\n",
      "[dimension 143/145]  inactive:\t1.01e-03 +- 1.75e-02\n",
      "[dimension 144/145]  inactive:\t3.01e-04 +- 7.55e-03\n",
      "[dimension 145/145]  inactive:\t4.14e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.86171657]\n",
      "cov_act[[0.02114891]]\n",
      "Active_dimensions: [62]\n",
      "50, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [02:30<00:00,  9.99it/s, 63 steps of size 2.00e+01. acc. prob=0.96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    632.38      1.00\n",
      "  lambda[0]      2.28      5.05      1.02      0.00      4.37    709.22      1.00\n",
      "  lambda[1]      2.73      7.48      0.97      0.00      6.09    613.20      1.00\n",
      "  lambda[2]      2.84     12.91      1.04      0.01      4.75    850.73      1.00\n",
      "  lambda[3]      3.54     10.23      1.04      0.00      6.87    604.07      1.01\n",
      "  lambda[4]      5.16     41.42      1.00      0.00      6.45    723.17      1.00\n",
      "  lambda[5]      3.73     16.30      0.98      0.00      5.20    811.61      1.00\n",
      "  lambda[6]      2.64      6.06      0.95      0.00      5.28    764.94      1.00\n",
      "  lambda[7]      3.47     15.80      0.96      0.00      6.49    735.52      1.00\n",
      "  lambda[8]      2.93      8.48      0.97      0.00      5.80    606.43      1.00\n",
      "  lambda[9]      2.46      6.18      0.98      0.00      4.95    948.42      1.00\n",
      " lambda[10]      3.21     12.18      0.92      0.00      5.60    705.40      1.01\n",
      " lambda[11]      3.16      9.54      0.96      0.00      6.10    779.20      1.00\n",
      " lambda[12]      4.75     26.49      1.01      0.00      6.10    851.28      1.00\n",
      " lambda[13]      2.88      7.95      1.10      0.00      5.51    654.79      1.00\n",
      " lambda[14]      3.41     10.07      1.06      0.00      6.77    645.92      1.00\n",
      " lambda[15]      3.06     10.88      1.02      0.00      5.83    623.84      1.00\n",
      " lambda[16]      3.06      8.36      1.03      0.00      6.30    694.54      1.00\n",
      " lambda[17]      3.20     10.37      0.94      0.00      5.64    679.95      1.00\n",
      " lambda[18]      3.70     17.60      0.91      0.00      5.94    742.47      1.00\n",
      " lambda[19]      3.72     24.86      1.05      0.00      5.61    988.40      1.00\n",
      " lambda[20]      3.13      9.90      0.94      0.00      6.89   1032.66      1.00\n",
      " lambda[21]      2.87      9.47      1.03      0.00      6.03    866.68      1.00\n",
      " lambda[22]      2.78     10.22      0.97      0.00      5.36    791.86      1.00\n",
      " lambda[23]      5.73     47.45      1.00      0.00      6.39    698.48      1.00\n",
      " lambda[24]      2.77      6.32      1.05      0.00      6.26    663.46      1.00\n",
      " lambda[25]      2.88      8.75      0.96      0.00      5.37    740.07      1.00\n",
      " lambda[26]      4.09     35.05      0.94      0.00      5.40    754.99      1.00\n",
      " lambda[27]      2.98      8.98      0.99      0.00      5.62    518.54      1.00\n",
      " lambda[28]      2.71      7.92      0.91      0.00      5.14    896.79      1.00\n",
      " lambda[29]      2.98      8.77      0.99      0.00      5.68    674.66      1.00\n",
      " lambda[30]      3.89     13.65      1.08      0.00      5.82    585.21      1.00\n",
      " lambda[31]      3.09     11.68      0.94      0.00      6.33    901.53      1.00\n",
      " lambda[32]      3.06      9.30      1.01      0.00      5.58    642.58      1.00\n",
      " lambda[33]      2.36      4.63      1.00      0.01      5.20    903.96      1.00\n",
      " lambda[34]      2.91      8.82      0.98      0.00      5.69    773.56      1.00\n",
      " lambda[35]      2.58      6.70      1.00      0.00      5.57    909.09      1.00\n",
      " lambda[36]      2.74      7.51      0.96      0.00      5.36    669.76      1.01\n",
      " lambda[37]      3.26     10.04      0.99      0.00      5.88    786.23      1.00\n",
      " lambda[38]      2.98      9.26      1.06      0.00      5.38    672.47      1.00\n",
      " lambda[39]      3.37     11.84      0.99      0.01      5.64    880.48      1.00\n",
      " lambda[40]      2.92      9.95      0.93      0.00      5.78    931.92      1.00\n",
      " lambda[41]     10.85     72.68      1.05      0.00      8.55    406.86      1.00\n",
      " lambda[42]      2.69     12.40      0.94      0.00      5.52    866.50      1.00\n",
      " lambda[43]      3.45     10.65      0.89      0.00      6.70    648.27      1.00\n",
      " lambda[44]      2.50      5.56      0.99      0.02      5.51    790.38      1.00\n",
      " lambda[45]      2.55      6.28      0.94      0.00      5.46   1031.35      1.01\n",
      " lambda[46]      2.96      8.65      0.99      0.00      5.54    818.57      1.00\n",
      " lambda[47]      2.57      8.56      0.93      0.00      4.97   1022.19      1.00\n",
      " lambda[48]      3.30     12.92      1.01      0.01      5.40    603.94      1.00\n",
      " lambda[49]      3.63     12.41      0.99      0.00      6.76    634.89      1.00\n",
      " lambda[50]      3.10     10.56      0.96      0.00      5.60    586.88      1.00\n",
      " lambda[51]      3.28      8.12      1.02      0.00      7.19    926.08      1.00\n",
      " lambda[52]      3.08     10.19      0.90      0.00      5.28    521.71      1.00\n",
      " lambda[53]      2.62      5.94      1.00      0.00      5.61    953.61      1.00\n",
      " lambda[54]      2.40      9.16      0.96      0.00      4.58    859.19      1.00\n",
      " lambda[55]      2.81      9.62      0.93      0.00      5.37    875.46      1.00\n",
      " lambda[56]      3.13      8.30      1.01      0.00      6.19    829.23      1.00\n",
      " lambda[57]      6.21     25.89      1.10      0.00      9.26    433.69      1.00\n",
      " lambda[58]      2.70      7.60      0.99      0.01      5.24    691.85      1.00\n",
      " lambda[59]      3.11     10.02      0.97      0.00      5.10    760.59      1.00\n",
      " lambda[60]      3.00      8.10      1.02      0.01      5.81    766.40      1.00\n",
      " lambda[61]      3.16     12.42      0.94      0.00      6.15    668.48      1.00\n",
      " lambda[62]    824.14   4078.78    206.36      0.01   1165.80    477.82      1.00\n",
      " lambda[63]      2.69     15.19      0.96      0.00      4.71   1037.71      1.00\n",
      " lambda[64]      2.99      8.44      0.98      0.00      5.93    916.45      1.00\n",
      " lambda[65]      2.78      9.12      1.00      0.00      5.12    454.14      1.00\n",
      " lambda[66]      3.31     14.43      0.99      0.00      5.63    872.31      1.00\n",
      " lambda[67]      3.21     11.21      0.99      0.00      5.36    533.24      1.00\n",
      " lambda[68]      2.92      6.85      0.99      0.00      6.73    947.20      1.00\n",
      " lambda[69]      3.56     12.49      1.08      0.00      6.21    622.57      1.00\n",
      " lambda[70]      2.91      8.62      1.03      0.00      5.32    732.86      1.01\n",
      " lambda[71]      2.66      6.91      0.97      0.00      5.50    537.08      1.00\n",
      " lambda[72]      2.68      7.24      0.96      0.00      5.12    705.74      1.00\n",
      " lambda[73]      3.68     28.00      0.99      0.00      5.21   1002.67      1.00\n",
      " lambda[74]      2.70      6.08      0.93      0.01      6.32    586.13      1.00\n",
      " lambda[75]      3.53     10.92      1.05      0.00      6.78    708.50      1.00\n",
      " lambda[76]      3.27     15.34      0.92      0.00      5.73    785.19      1.00\n",
      " lambda[77]     12.40     83.29      1.06      0.00      8.77    444.13      1.00\n",
      " lambda[78]      2.50      5.84      0.93      0.01      5.55    936.97      1.00\n",
      " lambda[79]      4.83     44.26      0.97      0.00      6.18    478.93      1.00\n",
      " lambda[80]      2.57      6.18      0.95      0.00      6.07    639.04      1.00\n",
      " lambda[81]      2.60      9.18      0.98      0.00      5.13    744.21      1.00\n",
      " lambda[82]      2.39      4.98      0.99      0.00      5.57    752.59      1.00\n",
      " lambda[83]      2.84      6.58      1.03      0.00      6.21    757.19      1.00\n",
      " lambda[84]      3.00      9.76      1.08      0.00      5.85    853.73      1.00\n",
      " lambda[85]      2.93      9.80      0.99      0.00      5.07    837.39      1.00\n",
      " lambda[86]      3.32     14.55      1.04      0.00      6.00    807.19      1.00\n",
      " lambda[87]      2.84      7.45      0.97      0.00      5.54    661.25      1.00\n",
      " lambda[88]      2.69      5.88      0.96      0.00      5.99    793.96      1.00\n",
      " lambda[89]     28.32    145.85      1.10      0.00     20.85    357.63      1.00\n",
      " lambda[90]      3.45     16.92      1.05      0.00      5.93    913.18      1.00\n",
      " lambda[91]      2.80      6.42      0.99      0.00      6.66    595.46      1.00\n",
      " lambda[92]      3.19     10.35      0.94      0.00      6.65    808.16      1.00\n",
      " lambda[93]      2.94      8.79      0.99      0.01      5.24    703.60      1.00\n",
      " lambda[94]      3.13     10.78      0.96      0.00      5.45    710.82      1.00\n",
      " lambda[95]      2.46      5.30      1.03      0.00      5.47    669.03      1.00\n",
      " lambda[96]      2.68      6.23      0.95      0.00      5.72    664.94      1.00\n",
      " lambda[97]      3.24     11.76      0.96      0.00      5.87    767.64      1.00\n",
      " lambda[98]      3.91     16.60      0.95      0.00      5.12    828.85      1.00\n",
      " lambda[99]      2.57      5.91      0.93      0.00      5.26    594.86      1.00\n",
      "lambda[100]      2.81     10.29      0.91      0.00      4.81    949.34      1.00\n",
      "lambda[101]      2.83     10.57      1.02      0.00      5.48    760.28      1.00\n",
      "lambda[102]      3.00      8.32      0.99      0.00      5.78    546.43      1.00\n",
      "lambda[103]      2.52      6.04      0.96      0.01      5.52    832.29      1.00\n",
      "lambda[104]      2.38      5.10      0.98      0.01      5.56    814.74      1.00\n",
      "lambda[105]      3.14     10.21      0.95      0.00      5.82    575.05      1.00\n",
      "lambda[106]      3.12     10.58      0.95      0.01      6.38    662.63      1.00\n",
      "lambda[107]      3.22     12.07      0.97      0.00      6.21    894.52      1.00\n",
      "lambda[108]      2.40      5.36      0.98      0.01      4.97    400.80      1.00\n",
      "lambda[109]      4.47     20.84      0.97      0.00      7.87    615.64      1.00\n",
      "lambda[110]      2.38      5.51      0.96      0.00      5.08    597.51      1.00\n",
      "lambda[111]      4.65     17.94      0.99      0.00      7.41    566.94      1.00\n",
      "lambda[112]      2.80      6.37      1.02      0.00      5.93    729.14      1.00\n",
      "lambda[113]      3.26     10.38      0.97      0.00      5.49    902.30      1.00\n",
      "lambda[114]      2.50      6.34      0.97      0.00      5.29    834.17      1.00\n",
      "lambda[115]      4.18     17.71      0.91      0.00      7.11    835.36      1.00\n",
      "lambda[116]      7.66    149.11      1.03      0.00      6.16   1000.89      1.00\n",
      "lambda[117]      3.74     16.15      1.01      0.00      5.98    514.58      1.00\n",
      "lambda[118]      4.27     50.16      0.94      0.00      5.18   1004.58      1.00\n",
      "lambda[119]      3.32     15.29      1.06      0.00      5.46    767.59      1.00\n",
      "lambda[120]      5.38     29.60      1.07      0.00      8.48    943.16      1.00\n",
      "lambda[121]      2.92      7.35      1.01      0.00      6.27    700.01      1.00\n",
      "lambda[122]      3.18     10.20      1.00      0.00      5.10    660.14      1.00\n",
      "lambda[123]      2.91      9.31      1.01      0.00      5.97    721.97      1.00\n",
      "lambda[124]      2.65      6.36      1.07      0.00      5.49    599.95      1.00\n",
      "lambda[125]      3.34     10.34      1.00      0.00      5.94    504.92      1.00\n",
      "lambda[126]      3.17     18.19      0.98      0.00      5.85    983.65      1.00\n",
      "lambda[127]      3.02     11.59      0.97      0.00      4.89    928.95      1.00\n",
      "lambda[128]      2.74      6.83      1.00      0.01      5.96    727.39      1.00\n",
      "lambda[129]      4.36     13.84      0.99      0.00      7.37    704.64      1.00\n",
      "lambda[130]      2.80      6.79      0.94      0.00      5.77    532.41      1.00\n",
      "lambda[131]      3.45     13.70      0.99      0.00      5.65    719.97      1.00\n",
      "lambda[132]      2.54      5.04      1.02      0.00      5.71    745.00      1.00\n",
      "lambda[133]      3.10      8.77      0.97      0.00      6.22    544.03      1.00\n",
      "lambda[134]      3.04      9.00      1.00      0.00      5.99    826.04      1.00\n",
      "lambda[135]      2.89      8.53      0.95      0.00      5.82    554.26      1.00\n",
      "lambda[136]      3.75     12.69      0.97      0.00      6.28    608.33      1.00\n",
      "lambda[137]      2.65      6.52      0.91      0.00      5.78    945.65      1.00\n",
      "lambda[138]      5.79     56.56      0.96      0.00      5.52    557.68      1.00\n",
      "lambda[139]      2.50      6.34      0.95      0.00      5.36    557.12      1.00\n",
      "lambda[140]      3.19     10.39      0.95      0.00      5.85    722.17      1.00\n",
      "lambda[141]      2.79      9.55      0.97      0.00      4.87    723.96      1.00\n",
      "lambda[142]      3.70     14.32      1.03      0.00      6.29    746.33      1.00\n",
      "lambda[143]      2.13      4.03      0.98      0.01      4.78    619.16      1.00\n",
      "        msq    190.37   1185.78      6.44      0.20    167.48    900.56      1.00\n",
      "      sigma      3.25      3.88      1.75      0.01      8.83   1482.83      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    653.58      1.00\n",
      "       xisq      1.22      0.69      1.05      0.42      2.01    655.26      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 153.94018578529358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.03e-04 +- 1.70e-02\n",
      "[dimension 02/145]  inactive:\t1.98e-04 +- 2.45e-02\n",
      "[dimension 03/145]  inactive:\t3.59e-04 +- 2.21e-02\n",
      "[dimension 04/145]  inactive:\t6.29e-03 +- 4.22e-02\n",
      "[dimension 05/145]  inactive:\t-1.60e-03 +- 4.36e-02\n",
      "[dimension 06/145]  inactive:\t2.46e-03 +- 3.58e-02\n",
      "[dimension 07/145]  inactive:\t6.99e-04 +- 1.85e-02\n",
      "[dimension 08/145]  inactive:\t9.50e-04 +- 3.09e-02\n",
      "[dimension 09/145]  inactive:\t6.58e-04 +- 2.15e-02\n",
      "[dimension 10/145]  inactive:\t3.89e-04 +- 1.86e-02\n",
      "[dimension 11/145]  inactive:\t-3.75e-04 +- 2.59e-02\n",
      "[dimension 12/145]  inactive:\t-1.86e-04 +- 2.58e-02\n",
      "[dimension 13/145]  inactive:\t5.32e-03 +- 4.39e-02\n",
      "[dimension 14/145]  inactive:\t-1.53e-03 +- 2.69e-02\n",
      "[dimension 15/145]  inactive:\t1.94e-03 +- 4.01e-02\n",
      "[dimension 16/145]  inactive:\t1.18e-03 +- 1.94e-02\n",
      "[dimension 17/145]  inactive:\t1.23e-04 +- 2.79e-02\n",
      "[dimension 18/145]  inactive:\t9.19e-04 +- 3.47e-02\n",
      "[dimension 19/145]  inactive:\t-1.89e-03 +- 2.09e-02\n",
      "[dimension 20/145]  inactive:\t-8.25e-04 +- 2.29e-02\n",
      "[dimension 21/145]  inactive:\t-1.72e-03 +- 2.65e-02\n",
      "[dimension 22/145]  inactive:\t1.41e-04 +- 2.12e-02\n",
      "[dimension 23/145]  inactive:\t-9.60e-05 +- 3.38e-02\n",
      "[dimension 24/145]  inactive:\t2.63e-03 +- 3.08e-02\n",
      "[dimension 25/145]  inactive:\t2.88e-03 +- 2.14e-02\n",
      "[dimension 26/145]  inactive:\t-6.52e-04 +- 2.57e-02\n",
      "[dimension 27/145]  inactive:\t8.10e-04 +- 2.33e-02\n",
      "[dimension 28/145]  inactive:\t7.36e-04 +- 2.05e-02\n",
      "[dimension 29/145]  inactive:\t5.09e-04 +- 3.00e-02\n",
      "[dimension 30/145]  inactive:\t1.43e-03 +- 3.01e-02\n",
      "[dimension 31/145]  inactive:\t6.30e-03 +- 4.92e-02\n",
      "[dimension 32/145]  inactive:\t-1.36e-03 +- 2.54e-02\n",
      "[dimension 33/145]  inactive:\t2.44e-03 +- 3.67e-02\n",
      "[dimension 34/145]  inactive:\t6.22e-04 +- 1.75e-02\n",
      "[dimension 35/145]  inactive:\t-8.92e-05 +- 2.44e-02\n",
      "[dimension 36/145]  inactive:\t1.47e-03 +- 2.87e-02\n",
      "[dimension 37/145]  inactive:\t3.28e-03 +- 2.53e-02\n",
      "[dimension 38/145]  inactive:\t-1.19e-03 +- 2.98e-02\n",
      "[dimension 39/145]  inactive:\t2.72e-03 +- 3.63e-02\n",
      "[dimension 40/145]  inactive:\t4.04e-03 +- 3.49e-02\n",
      "[dimension 41/145]  inactive:\t-8.27e-04 +- 3.08e-02\n",
      "[dimension 42/145]  inactive:\t1.73e-02 +- 1.10e-01\n",
      "[dimension 43/145]  inactive:\t-8.07e-05 +- 1.90e-02\n",
      "[dimension 44/145]  inactive:\t-9.71e-04 +- 3.44e-02\n",
      "[dimension 45/145]  inactive:\t1.29e-04 +- 2.24e-02\n",
      "[dimension 46/145]  inactive:\t1.00e-03 +- 1.61e-02\n",
      "[dimension 47/145]  inactive:\t-1.77e-03 +- 2.61e-02\n",
      "[dimension 48/145]  inactive:\t1.72e-03 +- 2.63e-02\n",
      "[dimension 49/145]  inactive:\t3.16e-03 +- 2.57e-02\n",
      "[dimension 50/145]  inactive:\t-2.01e-03 +- 2.84e-02\n",
      "[dimension 51/145]  inactive:\t2.59e-03 +- 2.88e-02\n",
      "[dimension 52/145]  inactive:\t5.83e-03 +- 2.61e-02\n",
      "[dimension 53/145]  inactive:\t-9.26e-04 +- 2.80e-02\n",
      "[dimension 54/145]  inactive:\t3.85e-04 +- 1.71e-02\n",
      "[dimension 55/145]  inactive:\t5.18e-04 +- 1.54e-02\n",
      "[dimension 56/145]  inactive:\t-2.02e-03 +- 2.75e-02\n",
      "[dimension 57/145]  inactive:\t9.20e-04 +- 3.15e-02\n",
      "[dimension 58/145]  inactive:\t1.70e-02 +- 8.77e-02\n",
      "[dimension 59/145]  inactive:\t-5.95e-04 +- 2.00e-02\n",
      "[dimension 60/145]  inactive:\t2.75e-03 +- 3.88e-02\n",
      "[dimension 61/145]  inactive:\t2.34e-03 +- 2.30e-02\n",
      "[dimension 62/145]  inactive:\t3.14e-05 +- 3.48e-02\n",
      "[dimension 63/145]  active:\t7.16e-01 +- 4.14e-01\n",
      "[dimension 64/145]  inactive:\t-3.03e-03 +- 3.08e-02\n",
      "[dimension 65/145]  inactive:\t-6.09e-04 +- 2.78e-02\n",
      "[dimension 66/145]  inactive:\t7.18e-04 +- 2.25e-02\n",
      "[dimension 67/145]  inactive:\t1.24e-03 +- 2.36e-02\n",
      "[dimension 68/145]  inactive:\t-7.37e-04 +- 3.14e-02\n",
      "[dimension 69/145]  inactive:\t2.24e-03 +- 2.87e-02\n",
      "[dimension 70/145]  inactive:\t3.23e-03 +- 2.34e-02\n",
      "[dimension 71/145]  inactive:\t5.21e-04 +- 3.32e-02\n",
      "[dimension 72/145]  inactive:\t5.90e-04 +- 2.40e-02\n",
      "[dimension 73/145]  inactive:\t2.57e-04 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-1.10e-03 +- 2.64e-02\n",
      "[dimension 75/145]  inactive:\t4.89e-04 +- 2.43e-02\n",
      "[dimension 76/145]  inactive:\t4.41e-03 +- 3.43e-02\n",
      "[dimension 77/145]  inactive:\t-1.73e-03 +- 3.42e-02\n",
      "[dimension 78/145]  inactive:\t2.28e-02 +- 1.25e-01\n",
      "[dimension 79/145]  inactive:\t4.05e-03 +- 2.75e-02\n",
      "[dimension 80/145]  inactive:\t-6.10e-04 +- 3.72e-02\n",
      "[dimension 81/145]  inactive:\t1.45e-03 +- 2.92e-02\n",
      "[dimension 82/145]  inactive:\t3.04e-04 +- 1.65e-02\n",
      "[dimension 83/145]  inactive:\t-1.39e-03 +- 1.94e-02\n",
      "[dimension 84/145]  inactive:\t-7.26e-04 +- 2.50e-02\n",
      "[dimension 85/145]  inactive:\t3.20e-03 +- 3.58e-02\n",
      "[dimension 86/145]  inactive:\t-3.73e-04 +- 1.85e-02\n",
      "[dimension 87/145]  inactive:\t2.70e-03 +- 4.15e-02\n",
      "[dimension 88/145]  inactive:\t2.47e-03 +- 2.20e-02\n",
      "[dimension 89/145]  inactive:\t-8.21e-04 +- 2.35e-02\n",
      "[dimension 90/145]  inactive:\t6.56e-02 +- 2.31e-01\n",
      "[dimension 91/145]  inactive:\t1.99e-04 +- 2.09e-02\n",
      "[dimension 92/145]  inactive:\t-1.21e-03 +- 2.69e-02\n",
      "[dimension 93/145]  inactive:\t-4.96e-04 +- 2.73e-02\n",
      "[dimension 94/145]  inactive:\t2.39e-03 +- 3.12e-02\n",
      "[dimension 95/145]  inactive:\t-3.62e-04 +- 2.30e-02\n",
      "[dimension 96/145]  inactive:\t2.39e-04 +- 2.57e-02\n",
      "[dimension 97/145]  inactive:\t2.65e-03 +- 2.40e-02\n",
      "[dimension 98/145]  inactive:\t-2.77e-04 +- 2.94e-02\n",
      "[dimension 99/145]  inactive:\t3.49e-03 +- 4.41e-02\n",
      "[dimension 100/145]  inactive:\t-3.74e-04 +- 1.66e-02\n",
      "[dimension 101/145]  inactive:\t-1.73e-03 +- 1.95e-02\n",
      "[dimension 102/145]  inactive:\t-4.59e-04 +- 2.59e-02\n",
      "[dimension 103/145]  inactive:\t1.68e-03 +- 2.49e-02\n",
      "[dimension 104/145]  inactive:\t-8.15e-04 +- 1.66e-02\n",
      "[dimension 105/145]  inactive:\t2.82e-04 +- 2.18e-02\n",
      "[dimension 106/145]  inactive:\t4.27e-03 +- 3.27e-02\n",
      "[dimension 107/145]  inactive:\t-1.23e-03 +- 2.01e-02\n",
      "[dimension 108/145]  inactive:\t6.21e-03 +- 6.16e-02\n",
      "[dimension 109/145]  inactive:\t-3.58e-04 +- 1.66e-02\n",
      "[dimension 110/145]  inactive:\t-1.11e-03 +- 3.67e-02\n",
      "[dimension 111/145]  inactive:\t8.99e-04 +- 2.13e-02\n",
      "[dimension 112/145]  inactive:\t7.17e-03 +- 5.54e-02\n",
      "[dimension 113/145]  inactive:\t-1.80e-03 +- 2.65e-02\n",
      "[dimension 114/145]  inactive:\t2.72e-03 +- 4.03e-02\n",
      "[dimension 115/145]  inactive:\t1.39e-03 +- 1.81e-02\n",
      "[dimension 116/145]  inactive:\t3.49e-04 +- 3.51e-02\n",
      "[dimension 117/145]  inactive:\t4.01e-03 +- 4.99e-02\n",
      "[dimension 118/145]  inactive:\t3.77e-03 +- 3.12e-02\n",
      "[dimension 119/145]  inactive:\t-1.74e-03 +- 2.92e-02\n",
      "[dimension 120/145]  inactive:\t5.13e-04 +- 3.29e-02\n",
      "[dimension 121/145]  inactive:\t5.77e-03 +- 4.60e-02\n",
      "[dimension 122/145]  inactive:\t-1.68e-03 +- 2.49e-02\n",
      "[dimension 123/145]  inactive:\t2.65e-03 +- 4.12e-02\n",
      "[dimension 124/145]  inactive:\t-1.57e-03 +- 2.09e-02\n",
      "[dimension 125/145]  inactive:\t-1.28e-03 +- 2.39e-02\n",
      "[dimension 126/145]  inactive:\t-8.47e-04 +- 2.83e-02\n",
      "[dimension 127/145]  inactive:\t9.88e-05 +- 1.75e-02\n",
      "[dimension 128/145]  inactive:\t-8.41e-04 +- 2.76e-02\n",
      "[dimension 129/145]  inactive:\t5.79e-04 +- 2.60e-02\n",
      "[dimension 130/145]  inactive:\t5.18e-03 +- 3.59e-02\n",
      "[dimension 131/145]  inactive:\t-5.95e-04 +- 2.67e-02\n",
      "[dimension 132/145]  inactive:\t5.00e-03 +- 4.63e-02\n",
      "[dimension 133/145]  inactive:\t2.65e-03 +- 2.32e-02\n",
      "[dimension 134/145]  inactive:\t-3.73e-04 +- 3.48e-02\n",
      "[dimension 135/145]  inactive:\t5.52e-04 +- 2.38e-02\n",
      "[dimension 136/145]  inactive:\t1.17e-03 +- 1.98e-02\n",
      "[dimension 137/145]  inactive:\t-4.25e-04 +- 3.31e-02\n",
      "[dimension 138/145]  inactive:\t4.96e-04 +- 2.58e-02\n",
      "[dimension 139/145]  inactive:\t9.82e-04 +- 2.50e-02\n",
      "[dimension 140/145]  inactive:\t-8.06e-04 +- 2.57e-02\n",
      "[dimension 141/145]  inactive:\t1.84e-03 +- 3.46e-02\n",
      "[dimension 142/145]  inactive:\t1.22e-03 +- 1.69e-02\n",
      "[dimension 143/145]  inactive:\t2.03e-03 +- 3.44e-02\n",
      "[dimension 144/145]  inactive:\t1.00e-04 +- 1.77e-02\n",
      "[dimension 145/145]  inactive:\t1.94e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9235309]\n",
      "cov_act[[0.00767061]]\n",
      "Active_dimensions: [62]\n",
      "51, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.18it/s, 31 steps of size 1.80e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    626.44      1.01\n",
      "  lambda[0]      2.42      4.88      0.97      0.00      5.64    563.16      1.00\n",
      "  lambda[1]      2.61      5.98      1.01      0.00      5.77    524.68      1.00\n",
      "  lambda[2]      3.06     10.57      1.03      0.00      5.91    580.03      1.00\n",
      "  lambda[3]      3.28     10.35      1.00      0.00      6.40    548.90      1.00\n",
      "  lambda[4]      2.69      6.80      1.00      0.00      5.55    496.12      1.00\n",
      "  lambda[5]      3.00      8.95      0.97      0.00      6.15    649.22      1.00\n",
      "  lambda[6]      3.86     11.37      0.96      0.00      8.26    446.62      1.00\n",
      "  lambda[7]      3.72     13.15      0.98      0.00      7.15    436.19      1.00\n",
      "  lambda[8]      2.47      5.07      1.03      0.00      5.44    712.86      1.00\n",
      "  lambda[9]      2.17      4.58      0.96      0.01      4.88    826.61      1.00\n",
      " lambda[10]      3.25     11.35      1.02      0.00      5.99    799.56      1.00\n",
      " lambda[11]      2.66      6.18      0.98      0.01      5.56    649.20      1.00\n",
      " lambda[12]      4.99     23.77      1.05      0.00      8.64    626.30      1.00\n",
      " lambda[13]      2.77      7.52      0.99      0.00      6.00    588.67      1.00\n",
      " lambda[14]      5.60     51.66      0.97      0.00      5.19    695.75      1.00\n",
      " lambda[15]      2.87      7.17      1.01      0.00      5.82    797.06      1.00\n",
      " lambda[16]      3.97     13.25      0.98      0.00      8.05    650.74      1.00\n",
      " lambda[17]      5.72     88.95      1.00      0.00      5.39    868.18      1.00\n",
      " lambda[18]      2.51      5.65      0.90      0.00      5.69   1031.11      1.00\n",
      " lambda[19]      3.06      9.69      0.98      0.00      5.97    709.70      1.00\n",
      " lambda[20]      2.40      5.50      0.88      0.00      5.16    859.92      1.00\n",
      " lambda[21]      2.37      4.74      1.01      0.01      5.48   1003.54      1.00\n",
      " lambda[22]      2.58      6.58      1.01      0.00      5.19    741.42      1.00\n",
      " lambda[23]      3.63     19.79      0.96      0.00      5.88    557.27      1.00\n",
      " lambda[24]      5.55     51.25      0.97      0.00      6.22    629.13      1.00\n",
      " lambda[25]      2.69      7.36      0.97      0.01      5.43    488.30      1.00\n",
      " lambda[26]      2.53      6.21      1.08      0.00      4.94    719.07      1.00\n",
      " lambda[27]      2.93      7.64      0.99      0.00      6.19    442.20      1.00\n",
      " lambda[28]      2.93      9.50      1.01      0.01      5.95    524.95      1.00\n",
      " lambda[29]     19.96    517.85      1.02      0.00      6.12    979.99      1.00\n",
      " lambda[30]      5.81     43.71      0.97      0.01      7.01    664.26      1.00\n",
      " lambda[31]      2.73      7.43      0.97      0.00      5.64    794.32      1.00\n",
      " lambda[32]      3.39     11.79      0.98      0.00      6.22    548.49      1.00\n",
      " lambda[33]      3.21      9.70      1.05      0.02      5.83    746.98      1.00\n",
      " lambda[34]      2.75      6.56      0.99      0.01      5.58    561.27      1.00\n",
      " lambda[35]      2.57      6.35      1.03      0.00      5.20    860.91      1.00\n",
      " lambda[36]      3.77     21.30      0.98      0.00      5.88    559.49      1.00\n",
      " lambda[37]      4.64     23.46      1.07      0.00      6.59    589.13      1.00\n",
      " lambda[38]      2.80      7.08      0.93      0.00      5.59    761.30      1.00\n",
      " lambda[39]      7.83    135.34      1.00      0.00      6.09    847.17      1.00\n",
      " lambda[40]      4.29     27.49      0.90      0.00      5.73    887.38      1.00\n",
      " lambda[41]    177.26   1931.17      1.07      0.00      9.97    459.49      1.01\n",
      " lambda[42]      2.64      6.09      0.95      0.00      5.63    683.46      1.00\n",
      " lambda[43]      7.13    123.33      0.99      0.00      6.09    992.89      1.00\n",
      " lambda[44]      4.02     17.69      0.96      0.00      6.76    412.78      1.00\n",
      " lambda[45]      2.44      5.53      0.92      0.01      4.33    713.01      1.00\n",
      " lambda[46]      2.53      6.64      0.98      0.00      4.75    843.99      1.00\n",
      " lambda[47]      2.63      6.90      0.94      0.00      5.60    605.28      1.00\n",
      " lambda[48]      2.50      6.47      0.94      0.00      5.74    659.95      1.00\n",
      " lambda[49]      3.09      9.01      0.95      0.00      5.60    751.68      1.00\n",
      " lambda[50]      2.92     10.61      0.95      0.00      5.56    881.46      1.00\n",
      " lambda[51]      6.34     64.50      1.00      0.00      6.63    921.24      1.00\n",
      " lambda[52]      2.74      6.76      0.95      0.00      5.45    491.77      1.00\n",
      " lambda[53]      3.25     17.56      0.94      0.00      5.63    746.03      1.00\n",
      " lambda[54]      2.20      6.13      0.93      0.00      4.46    645.17      1.00\n",
      " lambda[55]      2.78      8.84      1.03      0.00      5.23    808.87      1.00\n",
      " lambda[56]      2.56      5.98      1.00      0.00      5.30    676.91      1.00\n",
      " lambda[57]      8.03     87.52      0.98      0.00      7.88    617.87      1.00\n",
      " lambda[58]      2.13      4.29      0.97      0.01      4.53    657.92      1.00\n",
      " lambda[59]      3.45     20.53      0.94      0.00      5.86    842.79      1.00\n",
      " lambda[60]      4.69     23.39      1.06      0.00      6.30    778.95      1.00\n",
      " lambda[61]      2.87     11.01      1.03      0.01      5.37    702.93      1.00\n",
      " lambda[62]   6354.92 123936.80    326.09      0.01   3866.60    754.89      1.00\n",
      " lambda[63]      2.33      5.17      0.98      0.00      5.04    803.97      1.00\n",
      " lambda[64]      3.31     10.95      0.98      0.00      5.95    652.39      1.00\n",
      " lambda[65]      2.52      5.56      0.98      0.00      5.18    738.80      1.00\n",
      " lambda[66]     34.64    620.20      1.06      0.00      7.08    390.77      1.00\n",
      " lambda[67]      2.50      6.62      0.93      0.00      5.20    639.87      1.00\n",
      " lambda[68]      2.78      9.48      0.94      0.00      4.68    728.28      1.01\n",
      " lambda[69]      4.29     30.36      0.92      0.00      6.52    757.19      1.00\n",
      " lambda[70]      2.89      8.70      0.95      0.00      6.12    700.88      1.00\n",
      " lambda[71]      3.50     15.73      0.95      0.00      4.98    382.66      1.00\n",
      " lambda[72]      2.52      6.25      1.00      0.01      5.03    619.77      1.00\n",
      " lambda[73]      3.21     11.62      1.02      0.00      6.41    656.54      1.00\n",
      " lambda[74]      7.16    103.23      1.04      0.00      6.03    502.87      1.00\n",
      " lambda[75]      5.94     37.03      0.95      0.00      6.68    522.38      1.00\n",
      " lambda[76]      3.24     11.61      0.95      0.00      5.55    674.11      1.00\n",
      " lambda[77]    126.70   2426.86      1.06      0.00      7.82    431.60      1.00\n",
      " lambda[78]      6.29     61.64      1.05      0.00      5.62   1011.52      1.00\n",
      " lambda[79]      3.60     12.80      0.99      0.00      5.95    567.92      1.00\n",
      " lambda[80]     20.63    556.07      1.02      0.01      5.73   1002.59      1.00\n",
      " lambda[81]      2.54      6.20      0.86      0.00      5.64    864.56      1.00\n",
      " lambda[82]      2.31      5.59      0.89      0.00      4.37    742.30      1.00\n",
      " lambda[83]      2.69      7.55      0.92      0.00      5.16    694.68      1.00\n",
      " lambda[84]      4.11     27.15      1.10      0.00      5.95    982.44      1.00\n",
      " lambda[85]      2.57      6.85      0.99      0.00      5.83    824.97      1.00\n",
      " lambda[86]      4.50     48.22      0.94      0.00      4.90    513.93      1.00\n",
      " lambda[87]      3.22     10.19      0.95      0.01      5.87    782.02      1.00\n",
      " lambda[88]      2.70      6.64      0.98      0.00      5.72    726.03      1.00\n",
      " lambda[89]    920.32  16817.18      1.33      0.00    253.52    729.98      1.00\n",
      " lambda[90]      2.46      5.11      1.00      0.00      5.19    566.49      1.00\n",
      " lambda[91]      2.66      7.40      0.97      0.00      5.14    729.38      1.00\n",
      " lambda[92]      3.18     19.98      0.95      0.00      5.40    945.78      1.00\n",
      " lambda[93]      3.11     12.05      1.01      0.00      5.17    416.24      1.00\n",
      " lambda[94]      2.70      6.63      0.99      0.01      5.77    914.01      1.00\n",
      " lambda[95]      2.82      7.75      1.00      0.00      5.94    861.62      1.00\n",
      " lambda[96]      3.22     14.17      0.99      0.00      5.45    433.15      1.00\n",
      " lambda[97]      5.16     49.60      1.00      0.00      5.57    519.12      1.00\n",
      " lambda[98]     16.80    203.43      0.98      0.00      6.00    297.41      1.00\n",
      " lambda[99]      2.45      6.71      0.95      0.00      4.35    644.17      1.00\n",
      "lambda[100]      2.52      7.49      0.92      0.00      5.01    669.13      1.00\n",
      "lambda[101]      3.11     10.04      1.00      0.00      6.26    661.39      1.00\n",
      "lambda[102]      2.49      5.71      1.06      0.00      4.98    502.08      1.00\n",
      "lambda[103]      2.51      5.51      1.01      0.00      5.36    575.45      1.00\n",
      "lambda[104]      3.74     19.82      1.00      0.00      6.71    473.23      1.00\n",
      "lambda[105]      3.37      9.48      1.05      0.00      6.35    519.28      1.00\n",
      "lambda[106]      2.28      4.44      0.98      0.01      5.11    959.10      1.00\n",
      "lambda[107]      6.45     38.76      0.99      0.00      5.71    427.08      1.00\n",
      "lambda[108]      2.17      4.87      0.95      0.00      4.32    547.25      1.01\n",
      "lambda[109]      3.60     10.05      1.05      0.00      6.25    380.93      1.00\n",
      "lambda[110]      4.42     20.01      0.93      0.00      7.09    603.94      1.00\n",
      "lambda[111]      4.54     24.44      1.01      0.00      6.72    779.21      1.00\n",
      "lambda[112]      2.31      4.69      0.89      0.01      5.42   1123.94      1.00\n",
      "lambda[113]      4.55     29.76      1.05      0.00      6.62    836.33      1.00\n",
      "lambda[114]      4.34     23.67      0.99      0.00      6.79    905.49      1.00\n",
      "lambda[115]      4.21     20.59      0.99      0.00      5.43    872.71      1.00\n",
      "lambda[116]      7.60     92.60      1.02      0.00      5.68    599.33      1.00\n",
      "lambda[117]      3.41     12.14      0.95      0.00      6.13    805.06      1.00\n",
      "lambda[118]      3.94     14.60      0.97      0.00      7.03    489.47      1.00\n",
      "lambda[119]      3.13     14.85      1.02      0.00      5.09    902.35      1.00\n",
      "lambda[120]      9.09    169.06      1.01      0.00      6.93   1005.22      1.00\n",
      "lambda[121]      2.72      8.17      0.91      0.00      5.57    935.27      1.00\n",
      "lambda[122]     10.63    185.82      1.00      0.00      6.33    926.88      1.00\n",
      "lambda[123]      2.72      7.92      0.94      0.00      5.33    990.33      1.00\n",
      "lambda[124]      2.74      6.54      0.99      0.00      6.46    803.24      1.00\n",
      "lambda[125]      2.68      6.74      0.98      0.00      5.45    658.52      1.00\n",
      "lambda[126]      2.50      6.85      0.98      0.00      5.11    779.15      1.00\n",
      "lambda[127]      4.34     19.47      0.98      0.00      6.89    503.48      1.00\n",
      "lambda[128]      3.39     16.33      1.01      0.00      5.25    415.16      1.00\n",
      "lambda[129]      5.28     57.76      1.00      0.00      6.34   1008.85      1.00\n",
      "lambda[130]      3.30      8.95      0.96      0.00      6.95    588.05      1.00\n",
      "lambda[131]      6.77    104.40      0.98      0.00      5.10    828.01      1.00\n",
      "lambda[132]      2.71      6.44      0.99      0.00      6.02    428.09      1.00\n",
      "lambda[133]      2.61      5.92      0.97      0.00      5.85    894.85      1.00\n",
      "lambda[134]      2.93      7.03      0.88      0.00      6.47    681.75      1.00\n",
      "lambda[135]      2.86      7.96      0.90      0.00      4.99    537.84      1.00\n",
      "lambda[136]      2.88     11.58      0.96      0.00      5.64    933.34      1.00\n",
      "lambda[137]      3.00      9.50      0.94      0.00      5.20    492.40      1.01\n",
      "lambda[138]      3.23     12.81      1.03      0.00      5.67    878.47      1.00\n",
      "lambda[139]      3.09      9.74      1.00      0.00      5.58    709.94      1.00\n",
      "lambda[140]      3.17      9.47      1.00      0.00      5.77    893.53      1.00\n",
      "lambda[141]      2.62      6.94      0.90      0.00      5.27    728.52      1.00\n",
      "lambda[142]      5.50     33.12      1.01      0.00      5.85    678.83      1.00\n",
      "lambda[143]      2.47      5.84      0.97      0.00      5.35    579.41      1.00\n",
      "        msq      0.25      0.19      0.20      0.08      0.43    729.49      1.00\n",
      "      sigma      2.97      4.03      1.33      0.00      8.66   1246.48      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    448.09      1.00\n",
      "       xisq      1.05      0.52      0.93      0.36      1.70   1388.63      1.00\n",
      "\n",
      "Number of divergences: 3\n",
      "\n",
      "MCMC elapsed time: 32.42108106613159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t3.34e-04 +- 1.11e-02\n",
      "[dimension 02/145]  inactive:\t5.58e-04 +- 1.32e-02\n",
      "[dimension 03/145]  inactive:\t8.02e-04 +- 1.55e-02\n",
      "[dimension 04/145]  inactive:\t2.46e-03 +- 2.21e-02\n",
      "[dimension 05/145]  inactive:\t5.26e-04 +- 1.44e-02\n",
      "[dimension 06/145]  inactive:\t1.34e-03 +- 2.04e-02\n",
      "[dimension 07/145]  inactive:\t1.13e-03 +- 1.48e-02\n",
      "[dimension 08/145]  inactive:\t1.62e-03 +- 2.13e-02\n",
      "[dimension 09/145]  inactive:\t6.85e-04 +- 1.30e-02\n",
      "[dimension 10/145]  inactive:\t3.96e-04 +- 9.53e-03\n",
      "[dimension 11/145]  inactive:\t5.78e-04 +- 1.51e-02\n",
      "[dimension 12/145]  inactive:\t5.17e-04 +- 1.27e-02\n",
      "[dimension 13/145]  inactive:\t4.14e-03 +- 3.75e-02\n",
      "[dimension 14/145]  inactive:\t6.86e-04 +- 1.87e-02\n",
      "[dimension 15/145]  inactive:\t3.12e-03 +- 3.87e-02\n",
      "[dimension 16/145]  inactive:\t8.34e-04 +- 1.48e-02\n",
      "[dimension 17/145]  inactive:\t1.83e-03 +- 2.73e-02\n",
      "[dimension 18/145]  inactive:\t2.10e-03 +- 2.92e-02\n",
      "[dimension 19/145]  inactive:\t-5.48e-04 +- 1.30e-02\n",
      "[dimension 20/145]  inactive:\t3.22e-04 +- 1.69e-02\n",
      "[dimension 21/145]  inactive:\t-1.62e-04 +- 1.17e-02\n",
      "[dimension 22/145]  inactive:\t3.37e-04 +- 1.18e-02\n",
      "[dimension 23/145]  inactive:\t6.10e-04 +- 1.66e-02\n",
      "[dimension 24/145]  inactive:\t1.64e-03 +- 2.13e-02\n",
      "[dimension 25/145]  inactive:\t2.19e-03 +- 1.79e-02\n",
      "[dimension 26/145]  inactive:\t4.22e-04 +- 1.58e-02\n",
      "[dimension 27/145]  inactive:\t4.71e-04 +- 1.31e-02\n",
      "[dimension 28/145]  inactive:\t8.89e-04 +- 1.37e-02\n",
      "[dimension 29/145]  inactive:\t1.68e-03 +- 2.35e-02\n",
      "[dimension 30/145]  inactive:\t2.63e-03 +- 3.20e-02\n",
      "[dimension 31/145]  inactive:\t4.50e-03 +- 3.83e-02\n",
      "[dimension 32/145]  inactive:\t6.03e-04 +- 1.57e-02\n",
      "[dimension 33/145]  inactive:\t2.84e-03 +- 3.22e-02\n",
      "[dimension 34/145]  inactive:\t8.30e-04 +- 1.30e-02\n",
      "[dimension 35/145]  inactive:\t1.18e-03 +- 1.76e-02\n",
      "[dimension 36/145]  inactive:\t1.22e-03 +- 1.94e-02\n",
      "[dimension 37/145]  inactive:\t2.36e-03 +- 1.99e-02\n",
      "[dimension 38/145]  inactive:\t9.00e-04 +- 2.24e-02\n",
      "[dimension 39/145]  inactive:\t1.08e-03 +- 1.56e-02\n",
      "[dimension 40/145]  inactive:\t4.42e-03 +- 3.73e-02\n",
      "[dimension 41/145]  inactive:\t7.31e-04 +- 2.23e-02\n",
      "[dimension 42/145]  inactive:\t3.28e-02 +- 1.56e-01\n",
      "[dimension 43/145]  inactive:\t6.09e-04 +- 1.31e-02\n",
      "[dimension 44/145]  inactive:\t1.06e-03 +- 2.66e-02\n",
      "[dimension 45/145]  inactive:\t2.01e-03 +- 2.49e-02\n",
      "[dimension 46/145]  inactive:\t5.09e-04 +- 9.65e-03\n",
      "[dimension 47/145]  inactive:\t-1.03e-04 +- 1.55e-02\n",
      "[dimension 48/145]  inactive:\t1.02e-03 +- 1.72e-02\n",
      "[dimension 49/145]  inactive:\t9.31e-04 +- 1.29e-02\n",
      "[dimension 50/145]  inactive:\t2.46e-05 +- 1.65e-02\n",
      "[dimension 51/145]  inactive:\t2.94e-03 +- 3.46e-02\n",
      "[dimension 52/145]  inactive:\t3.63e-03 +- 2.03e-02\n",
      "[dimension 53/145]  inactive:\t1.58e-04 +- 1.44e-02\n",
      "[dimension 54/145]  inactive:\t7.87e-04 +- 1.47e-02\n",
      "[dimension 55/145]  inactive:\t2.86e-04 +- 8.01e-03\n",
      "[dimension 56/145]  inactive:\t-8.19e-04 +- 1.48e-02\n",
      "[dimension 57/145]  inactive:\t6.95e-04 +- 1.28e-02\n",
      "[dimension 58/145]  inactive:\t9.99e-03 +- 6.48e-02\n",
      "[dimension 59/145]  inactive:\t-8.08e-05 +- 9.85e-03\n",
      "[dimension 60/145]  inactive:\t1.53e-03 +- 2.20e-02\n",
      "[dimension 61/145]  inactive:\t3.68e-03 +- 2.83e-02\n",
      "[dimension 62/145]  inactive:\t3.99e-04 +- 1.42e-02\n",
      "[dimension 63/145]  active:\t5.86e-01 +- 4.29e-01\n",
      "[dimension 64/145]  inactive:\t-5.96e-04 +- 1.18e-02\n",
      "[dimension 65/145]  inactive:\t7.60e-04 +- 1.91e-02\n",
      "[dimension 66/145]  inactive:\t5.50e-04 +- 1.40e-02\n",
      "[dimension 67/145]  inactive:\t2.19e-03 +- 2.59e-02\n",
      "[dimension 68/145]  inactive:\t4.58e-04 +- 1.33e-02\n",
      "[dimension 69/145]  inactive:\t2.04e-03 +- 2.61e-02\n",
      "[dimension 70/145]  inactive:\t3.48e-03 +- 2.41e-02\n",
      "[dimension 71/145]  inactive:\t1.15e-03 +- 2.04e-02\n",
      "[dimension 72/145]  inactive:\t1.84e-03 +- 2.31e-02\n",
      "[dimension 73/145]  inactive:\t4.41e-04 +- 1.02e-02\n",
      "[dimension 74/145]  inactive:\t9.57e-04 +- 1.94e-02\n",
      "[dimension 75/145]  inactive:\t1.53e-03 +- 2.29e-02\n",
      "[dimension 76/145]  inactive:\t5.69e-03 +- 4.05e-02\n",
      "[dimension 77/145]  inactive:\t3.08e-04 +- 1.63e-02\n",
      "[dimension 78/145]  inactive:\t1.40e-02 +- 9.64e-02\n",
      "[dimension 79/145]  inactive:\t4.22e-03 +- 3.14e-02\n",
      "[dimension 80/145]  inactive:\t1.66e-03 +- 2.66e-02\n",
      "[dimension 81/145]  inactive:\t3.49e-03 +- 3.90e-02\n",
      "[dimension 82/145]  inactive:\t3.13e-04 +- 9.83e-03\n",
      "[dimension 83/145]  inactive:\t-4.10e-04 +- 1.07e-02\n",
      "[dimension 84/145]  inactive:\t-6.01e-06 +- 1.40e-02\n",
      "[dimension 85/145]  inactive:\t2.50e-03 +- 2.83e-02\n",
      "[dimension 86/145]  inactive:\t-3.59e-05 +- 1.05e-02\n",
      "[dimension 87/145]  inactive:\t1.70e-03 +- 2.65e-02\n",
      "[dimension 88/145]  inactive:\t2.62e-03 +- 2.26e-02\n",
      "[dimension 89/145]  inactive:\t1.27e-04 +- 1.54e-02\n",
      "[dimension 90/145]  inactive:\t1.08e-01 +- 2.68e-01\n",
      "[dimension 91/145]  inactive:\t2.01e-04 +- 1.03e-02\n",
      "[dimension 92/145]  inactive:\t3.65e-05 +- 1.41e-02\n",
      "[dimension 93/145]  inactive:\t4.08e-04 +- 1.59e-02\n",
      "[dimension 94/145]  inactive:\t1.79e-03 +- 2.25e-02\n",
      "[dimension 95/145]  inactive:\t4.20e-04 +- 1.47e-02\n",
      "[dimension 96/145]  inactive:\t1.53e-03 +- 2.52e-02\n",
      "[dimension 97/145]  inactive:\t1.96e-03 +- 1.95e-02\n",
      "[dimension 98/145]  inactive:\t4.52e-04 +- 1.70e-02\n",
      "[dimension 99/145]  inactive:\t1.16e-02 +- 8.34e-02\n",
      "[dimension 100/145]  inactive:\t6.61e-05 +- 1.04e-02\n",
      "[dimension 101/145]  inactive:\t-4.13e-04 +- 1.13e-02\n",
      "[dimension 102/145]  inactive:\t5.57e-04 +- 1.70e-02\n",
      "[dimension 103/145]  inactive:\t5.24e-04 +- 1.25e-02\n",
      "[dimension 104/145]  inactive:\t-2.45e-04 +- 1.10e-02\n",
      "[dimension 105/145]  inactive:\t8.43e-04 +- 2.24e-02\n",
      "[dimension 106/145]  inactive:\t3.77e-03 +- 2.93e-02\n",
      "[dimension 107/145]  inactive:\t-3.78e-05 +- 1.33e-02\n",
      "[dimension 108/145]  inactive:\t9.10e-03 +- 7.27e-02\n",
      "[dimension 109/145]  inactive:\t1.46e-04 +- 9.55e-03\n",
      "[dimension 110/145]  inactive:\t1.78e-03 +- 2.60e-02\n",
      "[dimension 111/145]  inactive:\t2.83e-03 +- 3.46e-02\n",
      "[dimension 112/145]  inactive:\t4.00e-03 +- 4.21e-02\n",
      "[dimension 113/145]  inactive:\t3.33e-05 +- 1.24e-02\n",
      "[dimension 114/145]  inactive:\t1.64e-03 +- 2.68e-02\n",
      "[dimension 115/145]  inactive:\t1.73e-03 +- 1.82e-02\n",
      "[dimension 116/145]  inactive:\t4.15e-03 +- 4.59e-02\n",
      "[dimension 117/145]  inactive:\t4.76e-03 +- 4.64e-02\n",
      "[dimension 118/145]  inactive:\t1.57e-03 +- 1.56e-02\n",
      "[dimension 119/145]  inactive:\t4.45e-04 +- 1.91e-02\n",
      "[dimension 120/145]  inactive:\t7.07e-04 +- 1.56e-02\n",
      "[dimension 121/145]  inactive:\t2.20e-03 +- 2.33e-02\n",
      "[dimension 122/145]  inactive:\t6.36e-06 +- 1.67e-02\n",
      "[dimension 123/145]  inactive:\t4.88e-03 +- 5.51e-02\n",
      "[dimension 124/145]  inactive:\t2.12e-04 +- 1.11e-02\n",
      "[dimension 125/145]  inactive:\t-8.81e-05 +- 1.89e-02\n",
      "[dimension 126/145]  inactive:\t2.87e-04 +- 1.23e-02\n",
      "[dimension 127/145]  inactive:\t4.09e-04 +- 1.06e-02\n",
      "[dimension 128/145]  inactive:\t1.39e-03 +- 2.76e-02\n",
      "[dimension 129/145]  inactive:\t1.22e-03 +- 2.04e-02\n",
      "[dimension 130/145]  inactive:\t1.90e-03 +- 1.94e-02\n",
      "[dimension 131/145]  inactive:\t1.07e-03 +- 2.27e-02\n",
      "[dimension 132/145]  inactive:\t3.66e-03 +- 4.17e-02\n",
      "[dimension 133/145]  inactive:\t1.77e-03 +- 1.70e-02\n",
      "[dimension 134/145]  inactive:\t4.04e-04 +- 1.74e-02\n",
      "[dimension 135/145]  inactive:\t1.19e-03 +- 1.72e-02\n",
      "[dimension 136/145]  inactive:\t9.59e-04 +- 1.31e-02\n",
      "[dimension 137/145]  inactive:\t9.55e-04 +- 1.81e-02\n",
      "[dimension 138/145]  inactive:\t1.33e-03 +- 2.20e-02\n",
      "[dimension 139/145]  inactive:\t6.63e-04 +- 1.30e-02\n",
      "[dimension 140/145]  inactive:\t7.38e-04 +- 2.02e-02\n",
      "[dimension 141/145]  inactive:\t1.90e-03 +- 2.71e-02\n",
      "[dimension 142/145]  inactive:\t1.42e-03 +- 1.36e-02\n",
      "[dimension 143/145]  inactive:\t3.94e-03 +- 3.93e-02\n",
      "[dimension 144/145]  inactive:\t9.64e-04 +- 1.38e-02\n",
      "[dimension 145/145]  inactive:\t-9.83e-10 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8602185]\n",
      "cov_act[[0.01790421]]\n",
      "Active_dimensions: [62]\n",
      "52, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:24<00:00, 60.63it/s, 15 steps of size 2.47e-01. acc. prob=0.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    334.58      1.00\n",
      "  lambda[0]      2.61      7.23      1.00      0.00      5.49    868.90      1.00\n",
      "  lambda[1]      3.40     16.81      1.00      0.01      5.96    459.09      1.00\n",
      "  lambda[2]      2.93      7.16      1.01      0.00      5.57    546.43      1.00\n",
      "  lambda[3]      3.49     11.82      1.04      0.00      7.08    812.19      1.00\n",
      "  lambda[4]      2.91      7.62      0.99      0.00      6.37    936.95      1.00\n",
      "  lambda[5]      5.03     54.21      1.00      0.00      5.70    538.79      1.00\n",
      "  lambda[6]      2.92      8.46      0.92      0.00      5.44    823.84      1.00\n",
      "  lambda[7]      2.98      9.19      0.94      0.00      6.75    881.87      1.00\n",
      "  lambda[8]      2.63      5.85      0.92      0.01      5.82    729.32      1.00\n",
      "  lambda[9]      2.60      5.64      1.06      0.00      5.41    673.19      1.00\n",
      " lambda[10]      3.16     10.88      1.05      0.00      6.26    828.75      1.00\n",
      " lambda[11]      2.73      7.88      0.97      0.01      5.91    926.65      1.00\n",
      " lambda[12]      4.28     16.73      0.98      0.00      7.39    531.74      1.01\n",
      " lambda[13]      2.89     12.23      0.96      0.00      5.26    986.54      1.00\n",
      " lambda[14]      5.21     38.29      1.10      0.00      7.08    483.18      1.00\n",
      " lambda[15]      3.21     11.29      1.00      0.00      6.12    952.37      1.00\n",
      " lambda[16]      2.67      6.02      0.96      0.00      6.32    862.48      1.00\n",
      " lambda[17]      3.02      7.10      1.03      0.00      6.24    716.36      1.00\n",
      " lambda[18]      2.95      9.76      0.98      0.00      5.14    790.31      1.00\n",
      " lambda[19]      2.58      5.93      1.02      0.00      5.80    946.77      1.00\n",
      " lambda[20]      2.71      6.21      1.00      0.00      6.04    715.02      1.00\n",
      " lambda[21]      2.60      5.30      1.02      0.00      6.16    694.83      1.00\n",
      " lambda[22]      2.80      7.87      1.09      0.00      5.19    862.66      1.00\n",
      " lambda[23]      3.54     20.80      1.02      0.00      5.62    991.07      1.00\n",
      " lambda[24]      3.45     11.84      1.01      0.00      6.46    860.56      1.00\n",
      " lambda[25]      2.53      6.72      0.95      0.01      5.44    590.63      1.00\n",
      " lambda[26]      2.69      8.01      0.94      0.00      5.31    929.19      1.00\n",
      " lambda[27]      2.60      6.52      0.89      0.00      6.08    948.67      1.00\n",
      " lambda[28]      2.66      7.56      0.97      0.01      5.48    716.71      1.00\n",
      " lambda[29]      3.43     23.79      0.96      0.00      5.50    966.22      1.00\n",
      " lambda[30]      2.70      6.47      0.96      0.01      6.60    725.97      1.00\n",
      " lambda[31]      3.46     15.87      0.99      0.00      5.42    706.03      1.00\n",
      " lambda[32]      2.84      7.34      1.01      0.00      6.38    866.91      1.00\n",
      " lambda[33]      2.65      6.03      0.97      0.00      5.62    669.39      1.00\n",
      " lambda[34]      2.74      7.32      1.01      0.00      5.29    768.14      1.00\n",
      " lambda[35]      2.86      6.72      1.09      0.00      6.26    788.33      1.00\n",
      " lambda[36]      2.81      6.49      1.02      0.01      5.59    701.04      1.00\n",
      " lambda[37]      3.57     13.91      1.01      0.00      6.28    982.92      1.00\n",
      " lambda[38]      4.11     32.34      0.99      0.00      6.10    986.18      1.00\n",
      " lambda[39]      3.26     11.97      0.96      0.00      6.22    669.25      1.00\n",
      " lambda[40]      2.78      8.09      0.96      0.00      5.88    816.06      1.00\n",
      " lambda[41]     16.16    110.17      1.01      0.00      9.18    146.52      1.00\n",
      " lambda[42]      2.26      5.37      0.96      0.00      5.10   1021.84      1.00\n",
      " lambda[43]      2.98      9.24      0.97      0.01      5.57    597.97      1.00\n",
      " lambda[44]      3.13     12.50      0.93      0.00      6.19    985.07      1.00\n",
      " lambda[45]      2.56      7.74      0.97      0.00      5.12    919.75      1.00\n",
      " lambda[46]      3.12     10.95      0.93      0.00      4.90    824.79      1.00\n",
      " lambda[47]      2.58      5.04      1.00      0.00      5.65    746.58      1.00\n",
      " lambda[48]      2.98      7.55      1.04      0.00      6.51    563.34      1.00\n",
      " lambda[49]      2.86      7.67      1.02      0.00      5.57    826.80      1.00\n",
      " lambda[50]      3.61     15.12      0.93      0.00      5.99    733.15      1.00\n",
      " lambda[51]      3.48     10.88      0.96      0.00      6.94    695.79      1.00\n",
      " lambda[52]      5.64     52.57      0.98      0.01      5.80    298.60      1.00\n",
      " lambda[53]      3.20     10.01      1.01      0.00      5.78    522.20      1.00\n",
      " lambda[54]      2.48      5.37      0.95      0.00      4.83    728.72      1.00\n",
      " lambda[55]      3.79     21.76      0.87      0.00      6.15    945.20      1.00\n",
      " lambda[56]      2.64      7.30      0.95      0.01      5.02    969.38      1.00\n",
      " lambda[57]      7.31     38.98      1.03      0.01      9.01    497.17      1.00\n",
      " lambda[58]      2.46      5.80      0.94      0.00      4.48    606.70      1.00\n",
      " lambda[59]      2.75      6.79      1.04      0.00      5.72    851.83      1.00\n",
      " lambda[60]      2.81      8.25      1.04      0.00      5.32    606.13      1.00\n",
      " lambda[61]      2.26      4.76      1.03      0.00      4.80    700.88      1.00\n",
      " lambda[62]    994.68   7555.94    166.21      0.01   1203.21    602.55      1.00\n",
      " lambda[63]      2.51      5.31      0.96      0.00      5.67    905.90      1.00\n",
      " lambda[64]      2.55      8.81      0.95      0.00      4.97    939.48      1.00\n",
      " lambda[65]      3.51     13.51      0.98      0.00      5.64    839.59      1.00\n",
      " lambda[66]      3.02     10.28      0.95      0.00      5.16    818.72      1.00\n",
      " lambda[67]      2.99      9.85      1.00      0.00      5.94   1029.63      1.00\n",
      " lambda[68]      3.61     13.04      0.98      0.00      6.83    859.45      1.00\n",
      " lambda[69]      3.80     12.53      1.03      0.00      7.10    792.12      1.00\n",
      " lambda[70]      2.74     12.88      0.95      0.00      4.51    845.68      1.00\n",
      " lambda[71]      3.19     11.82      1.01      0.01      5.75    800.25      1.00\n",
      " lambda[72]      2.26      6.13      1.00      0.00      4.77    926.26      1.00\n",
      " lambda[73]      3.23     17.29      0.95      0.00      5.53    954.13      1.00\n",
      " lambda[74]      2.48      5.63      0.96      0.00      5.57    777.86      1.00\n",
      " lambda[75]      4.70     31.22      1.06      0.00      6.40    866.96      1.00\n",
      " lambda[76]      2.92      7.67      0.99      0.00      6.16    535.15      1.00\n",
      " lambda[77]      7.13     48.97      1.06      0.00      7.64    468.21      1.00\n",
      " lambda[78]      2.73      6.96      1.00      0.00      4.94    554.77      1.01\n",
      " lambda[79]      2.59      7.59      0.94      0.00      5.12    669.86      1.00\n",
      " lambda[80]      3.24      8.77      0.96      0.00      6.27    643.63      1.00\n",
      " lambda[81]      2.85      6.69      1.03      0.00      6.04    570.18      1.00\n",
      " lambda[82]      2.73      7.78      0.95      0.01      5.68    566.61      1.00\n",
      " lambda[83]      3.30      9.88      1.02      0.00      6.13    664.60      1.00\n",
      " lambda[84]      3.33     12.26      0.99      0.01      5.23    745.48      1.00\n",
      " lambda[85]      3.05      9.91      0.94      0.00      5.95    682.88      1.00\n",
      " lambda[86]      4.22     18.89      0.97      0.00      6.58    823.62      1.00\n",
      " lambda[87]      2.56      5.66      0.97      0.00      5.92    911.22      1.00\n",
      " lambda[88]      2.80      6.10      1.03      0.00      6.53    726.80      1.00\n",
      " lambda[89]     75.92    595.79      1.21      0.00     92.42    259.64      1.00\n",
      " lambda[90]      2.60      6.16      0.94      0.00      5.64    761.50      1.00\n",
      " lambda[91]      2.98      8.93      0.98      0.00      5.34    494.74      1.00\n",
      " lambda[92]      2.65      6.57      0.95      0.00      5.23    888.32      1.00\n",
      " lambda[93]      2.64      8.17      1.01      0.00      4.84    553.36      1.00\n",
      " lambda[94]      3.17      7.69      1.03      0.00      6.38    692.57      1.00\n",
      " lambda[95]      3.14     10.02      1.00      0.00      6.83    785.04      1.00\n",
      " lambda[96]      2.98      9.08      0.97      0.00      5.49    512.98      1.00\n",
      " lambda[97]      2.68      6.35      0.99      0.00      5.65    594.74      1.00\n",
      " lambda[98]      3.31     13.42      0.99      0.00      5.66    560.62      1.00\n",
      " lambda[99]      2.71      7.83      0.91      0.00      5.46    961.63      1.00\n",
      "lambda[100]      3.35     11.06      0.97      0.00      6.60    750.03      1.00\n",
      "lambda[101]      2.81      6.96      0.99      0.00      5.64    537.03      1.00\n",
      "lambda[102]      2.70      9.13      0.90      0.00      5.50    569.24      1.00\n",
      "lambda[103]      3.89     26.31      0.97      0.00      5.94    375.94      1.00\n",
      "lambda[104]      2.71      7.51      1.04      0.00      5.14    547.22      1.00\n",
      "lambda[105]      3.60     14.03      1.02      0.00      6.09    719.16      1.00\n",
      "lambda[106]      3.57     16.56      0.93      0.00      5.34    294.27      1.00\n",
      "lambda[107]      3.47     19.24      0.96      0.01      5.12    586.27      1.00\n",
      "lambda[108]      2.39      5.95      0.90      0.01      5.27    858.69      1.00\n",
      "lambda[109]      4.43     16.92      1.02      0.00      7.02    827.34      1.00\n",
      "lambda[110]      3.17     12.26      0.99      0.00      5.45    946.04      1.00\n",
      "lambda[111]      4.27     17.67      1.07      0.00      6.60    576.27      1.00\n",
      "lambda[112]      2.43      5.92      1.03      0.01      5.31    517.73      1.00\n",
      "lambda[113]      2.78      6.71      0.97      0.00      5.47    769.99      1.00\n",
      "lambda[114]      2.74      6.95      0.99      0.00      5.94    739.84      1.00\n",
      "lambda[115]      3.08     13.26      1.00      0.00      5.18    942.90      1.00\n",
      "lambda[116]      2.68      8.79      1.03      0.00      5.21    805.02      1.00\n",
      "lambda[117]      3.15      9.87      0.95      0.00      5.83    764.85      1.00\n",
      "lambda[118]      3.58     22.44      0.93      0.00      5.42    827.69      1.00\n",
      "lambda[119]      4.27     13.74      0.99      0.01      6.33    500.77      1.00\n",
      "lambda[120]      3.92     15.93      0.97      0.00      6.73    575.98      1.00\n",
      "lambda[121]      3.13     10.50      0.96      0.00      6.28    773.52      1.00\n",
      "lambda[122]      3.20     11.23      0.98      0.00      5.60    736.68      1.00\n",
      "lambda[123]      2.70      6.40      0.90      0.00      6.26    784.95      1.01\n",
      "lambda[124]      3.01      8.73      0.96      0.00      6.07    738.12      1.00\n",
      "lambda[125]      2.85      9.82      0.96      0.00      5.51    615.03      1.00\n",
      "lambda[126]      2.55      7.26      0.97      0.00      5.19    747.88      1.00\n",
      "lambda[127]      3.13      9.83      1.00      0.00      5.86    742.40      1.00\n",
      "lambda[128]      3.78     18.62      0.95      0.00      6.15    354.17      1.00\n",
      "lambda[129]      3.41     14.60      0.95      0.00      5.58    619.88      1.00\n",
      "lambda[130]      2.85      8.29      0.93      0.00      5.71    770.51      1.01\n",
      "lambda[131]      4.74     32.35      1.05      0.00      6.84    528.80      1.00\n",
      "lambda[132]      2.80      7.18      1.00      0.00      5.34    844.55      1.00\n",
      "lambda[133]      2.51      6.13      0.91      0.00      4.93    771.47      1.00\n",
      "lambda[134]      2.76      6.31      1.04      0.00      6.08    836.68      1.00\n",
      "lambda[135]      2.29      5.65      0.94      0.00      4.33    769.16      1.00\n",
      "lambda[136]      2.98      8.59      0.95      0.00      5.65    719.70      1.00\n",
      "lambda[137]      3.34     12.46      1.03      0.00      5.54    656.13      1.00\n",
      "lambda[138]      3.43     11.47      0.95      0.00      5.81    569.07      1.00\n",
      "lambda[139]      2.93      6.37      1.02      0.00      6.53    454.20      1.00\n",
      "lambda[140]      3.14      9.30      1.02      0.00      6.40    907.06      1.00\n",
      "lambda[141]      2.87      5.75      1.01      0.00      6.98    572.76      1.00\n",
      "lambda[142]      3.03      7.87      0.96      0.00      5.98    738.40      1.00\n",
      "lambda[143]      2.57      8.76      0.95      0.00      5.49    958.11      1.00\n",
      "        msq  36384.16 1028072.06     22.49      0.30    819.38   1002.01      1.00\n",
      "      sigma      4.57      6.13      1.98      0.01     12.71   1012.23      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    502.32      1.00\n",
      "       xisq    105.39    438.49     13.57      0.75    146.20    458.73      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 28.436461925506592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t5.07e-05 +- 1.74e-02\n",
      "[dimension 02/145]  inactive:\t-4.61e-04 +- 2.72e-02\n",
      "[dimension 03/145]  inactive:\t3.55e-04 +- 2.32e-02\n",
      "[dimension 04/145]  inactive:\t4.95e-03 +- 3.72e-02\n",
      "[dimension 05/145]  inactive:\t-7.10e-04 +- 2.92e-02\n",
      "[dimension 06/145]  inactive:\t4.01e-03 +- 4.66e-02\n",
      "[dimension 07/145]  inactive:\t7.26e-04 +- 1.87e-02\n",
      "[dimension 08/145]  inactive:\t8.57e-04 +- 2.51e-02\n",
      "[dimension 09/145]  inactive:\t3.21e-04 +- 2.08e-02\n",
      "[dimension 10/145]  inactive:\t4.39e-04 +- 1.76e-02\n",
      "[dimension 11/145]  inactive:\t-3.28e-04 +- 2.51e-02\n",
      "[dimension 12/145]  inactive:\t-1.63e-04 +- 2.41e-02\n",
      "[dimension 13/145]  inactive:\t4.66e-03 +- 4.21e-02\n",
      "[dimension 14/145]  inactive:\t-1.31e-03 +- 2.61e-02\n",
      "[dimension 15/145]  inactive:\t1.76e-03 +- 3.63e-02\n",
      "[dimension 16/145]  inactive:\t8.83e-04 +- 2.23e-02\n",
      "[dimension 17/145]  inactive:\t5.40e-04 +- 2.86e-02\n",
      "[dimension 18/145]  inactive:\t-2.39e-05 +- 3.01e-02\n",
      "[dimension 19/145]  inactive:\t-1.80e-03 +- 1.99e-02\n",
      "[dimension 20/145]  inactive:\t-7.03e-04 +- 2.37e-02\n",
      "[dimension 21/145]  inactive:\t-9.66e-04 +- 1.95e-02\n",
      "[dimension 22/145]  inactive:\t5.52e-05 +- 2.13e-02\n",
      "[dimension 23/145]  inactive:\t-7.48e-04 +- 2.66e-02\n",
      "[dimension 24/145]  inactive:\t1.89e-03 +- 2.69e-02\n",
      "[dimension 25/145]  inactive:\t3.04e-03 +- 2.26e-02\n",
      "[dimension 26/145]  inactive:\t-4.10e-04 +- 2.78e-02\n",
      "[dimension 27/145]  inactive:\t8.28e-04 +- 2.27e-02\n",
      "[dimension 28/145]  inactive:\t7.47e-04 +- 1.73e-02\n",
      "[dimension 29/145]  inactive:\t7.33e-04 +- 2.69e-02\n",
      "[dimension 30/145]  inactive:\t1.78e-03 +- 3.17e-02\n",
      "[dimension 31/145]  inactive:\t3.01e-03 +- 2.65e-02\n",
      "[dimension 32/145]  inactive:\t-8.33e-05 +- 3.28e-02\n",
      "[dimension 33/145]  inactive:\t2.49e-03 +- 3.21e-02\n",
      "[dimension 34/145]  inactive:\t1.02e-03 +- 1.87e-02\n",
      "[dimension 35/145]  inactive:\t9.95e-04 +- 3.37e-02\n",
      "[dimension 36/145]  inactive:\t2.12e-03 +- 3.25e-02\n",
      "[dimension 37/145]  inactive:\t3.74e-03 +- 2.69e-02\n",
      "[dimension 38/145]  inactive:\t-1.71e-03 +- 3.25e-02\n",
      "[dimension 39/145]  inactive:\t3.10e-03 +- 4.52e-02\n",
      "[dimension 40/145]  inactive:\t3.83e-03 +- 3.18e-02\n",
      "[dimension 41/145]  inactive:\t-8.79e-04 +- 2.34e-02\n",
      "[dimension 42/145]  inactive:\t2.22e-02 +- 1.30e-01\n",
      "[dimension 43/145]  inactive:\t-8.11e-05 +- 1.64e-02\n",
      "[dimension 44/145]  inactive:\t3.46e-04 +- 3.05e-02\n",
      "[dimension 45/145]  inactive:\t-4.28e-04 +- 2.64e-02\n",
      "[dimension 46/145]  inactive:\t8.07e-04 +- 1.45e-02\n",
      "[dimension 47/145]  inactive:\t-1.76e-03 +- 3.15e-02\n",
      "[dimension 48/145]  inactive:\t1.55e-03 +- 2.58e-02\n",
      "[dimension 49/145]  inactive:\t3.20e-03 +- 2.72e-02\n",
      "[dimension 50/145]  inactive:\t-1.26e-03 +- 2.86e-02\n",
      "[dimension 51/145]  inactive:\t3.48e-03 +- 3.41e-02\n",
      "[dimension 52/145]  inactive:\t5.04e-03 +- 2.39e-02\n",
      "[dimension 53/145]  inactive:\t-7.77e-04 +- 2.25e-02\n",
      "[dimension 54/145]  inactive:\t2.40e-04 +- 2.13e-02\n",
      "[dimension 55/145]  inactive:\t5.92e-04 +- 1.82e-02\n",
      "[dimension 56/145]  inactive:\t-2.10e-03 +- 2.14e-02\n",
      "[dimension 57/145]  inactive:\t2.26e-03 +- 3.61e-02\n",
      "[dimension 58/145]  inactive:\t1.50e-02 +- 8.05e-02\n",
      "[dimension 59/145]  inactive:\t-3.90e-04 +- 1.82e-02\n",
      "[dimension 60/145]  inactive:\t2.10e-03 +- 3.23e-02\n",
      "[dimension 61/145]  inactive:\t2.15e-03 +- 2.14e-02\n",
      "[dimension 62/145]  inactive:\t-3.60e-04 +- 1.83e-02\n",
      "[dimension 63/145]  active:\t6.83e-01 +- 4.33e-01\n",
      "[dimension 64/145]  inactive:\t-2.56e-03 +- 2.50e-02\n",
      "[dimension 65/145]  inactive:\t-4.44e-04 +- 2.00e-02\n",
      "[dimension 66/145]  inactive:\t6.84e-04 +- 2.55e-02\n",
      "[dimension 67/145]  inactive:\t1.29e-03 +- 2.42e-02\n",
      "[dimension 68/145]  inactive:\t-1.42e-03 +- 3.54e-02\n",
      "[dimension 69/145]  inactive:\t5.25e-03 +- 4.96e-02\n",
      "[dimension 70/145]  inactive:\t3.74e-03 +- 2.44e-02\n",
      "[dimension 71/145]  inactive:\t-6.49e-05 +- 2.35e-02\n",
      "[dimension 72/145]  inactive:\t5.62e-04 +- 2.54e-02\n",
      "[dimension 73/145]  inactive:\t2.24e-04 +- 1.70e-02\n",
      "[dimension 74/145]  inactive:\t-1.23e-03 +- 2.40e-02\n",
      "[dimension 75/145]  inactive:\t3.98e-04 +- 1.98e-02\n",
      "[dimension 76/145]  inactive:\t4.99e-03 +- 3.45e-02\n",
      "[dimension 77/145]  inactive:\t-1.49e-03 +- 2.90e-02\n",
      "[dimension 78/145]  inactive:\t1.22e-02 +- 8.71e-02\n",
      "[dimension 79/145]  inactive:\t5.00e-03 +- 3.37e-02\n",
      "[dimension 80/145]  inactive:\t1.63e-04 +- 2.67e-02\n",
      "[dimension 81/145]  inactive:\t3.28e-04 +- 2.79e-02\n",
      "[dimension 82/145]  inactive:\t6.42e-04 +- 1.95e-02\n",
      "[dimension 83/145]  inactive:\t-1.71e-03 +- 1.97e-02\n",
      "[dimension 84/145]  inactive:\t-1.92e-03 +- 3.09e-02\n",
      "[dimension 85/145]  inactive:\t3.26e-03 +- 3.42e-02\n",
      "[dimension 86/145]  inactive:\t-9.24e-04 +- 2.01e-02\n",
      "[dimension 87/145]  inactive:\t6.09e-03 +- 5.71e-02\n",
      "[dimension 88/145]  inactive:\t1.97e-03 +- 1.98e-02\n",
      "[dimension 89/145]  inactive:\t-7.48e-04 +- 2.06e-02\n",
      "[dimension 90/145]  inactive:\t1.12e-01 +- 2.91e-01\n",
      "[dimension 91/145]  inactive:\t-2.91e-05 +- 1.85e-02\n",
      "[dimension 92/145]  inactive:\t-1.38e-03 +- 2.26e-02\n",
      "[dimension 93/145]  inactive:\t-4.44e-04 +- 2.30e-02\n",
      "[dimension 94/145]  inactive:\t1.42e-03 +- 2.36e-02\n",
      "[dimension 95/145]  inactive:\t-1.74e-04 +- 2.72e-02\n",
      "[dimension 96/145]  inactive:\t7.95e-04 +- 3.31e-02\n",
      "[dimension 97/145]  inactive:\t2.64e-03 +- 2.36e-02\n",
      "[dimension 98/145]  inactive:\t-3.49e-04 +- 2.16e-02\n",
      "[dimension 99/145]  inactive:\t1.99e-03 +- 3.12e-02\n",
      "[dimension 100/145]  inactive:\t-5.68e-04 +- 1.79e-02\n",
      "[dimension 101/145]  inactive:\t-2.35e-03 +- 2.13e-02\n",
      "[dimension 102/145]  inactive:\t-3.24e-04 +- 2.41e-02\n",
      "[dimension 103/145]  inactive:\t1.23e-03 +- 2.37e-02\n",
      "[dimension 104/145]  inactive:\t-7.23e-04 +- 1.82e-02\n",
      "[dimension 105/145]  inactive:\t-2.23e-04 +- 1.96e-02\n",
      "[dimension 106/145]  inactive:\t4.67e-03 +- 3.36e-02\n",
      "[dimension 107/145]  inactive:\t-9.97e-04 +- 1.91e-02\n",
      "[dimension 108/145]  inactive:\t3.80e-03 +- 5.19e-02\n",
      "[dimension 109/145]  inactive:\t-1.25e-04 +- 1.55e-02\n",
      "[dimension 110/145]  inactive:\t-1.24e-03 +- 3.51e-02\n",
      "[dimension 111/145]  inactive:\t2.23e-03 +- 3.57e-02\n",
      "[dimension 112/145]  inactive:\t8.43e-03 +- 6.52e-02\n",
      "[dimension 113/145]  inactive:\t-1.01e-03 +- 1.78e-02\n",
      "[dimension 114/145]  inactive:\t6.92e-04 +- 2.66e-02\n",
      "[dimension 115/145]  inactive:\t1.88e-03 +- 2.08e-02\n",
      "[dimension 116/145]  inactive:\t4.90e-04 +- 2.87e-02\n",
      "[dimension 117/145]  inactive:\t2.27e-03 +- 3.11e-02\n",
      "[dimension 118/145]  inactive:\t2.95e-03 +- 2.71e-02\n",
      "[dimension 119/145]  inactive:\t-1.55e-03 +- 2.73e-02\n",
      "[dimension 120/145]  inactive:\t-2.21e-04 +- 3.86e-02\n",
      "[dimension 121/145]  inactive:\t4.23e-03 +- 3.96e-02\n",
      "[dimension 122/145]  inactive:\t-2.10e-03 +- 3.01e-02\n",
      "[dimension 123/145]  inactive:\t2.18e-03 +- 3.73e-02\n",
      "[dimension 124/145]  inactive:\t-1.12e-03 +- 1.84e-02\n",
      "[dimension 125/145]  inactive:\t-1.29e-03 +- 2.46e-02\n",
      "[dimension 126/145]  inactive:\t-9.08e-04 +- 2.73e-02\n",
      "[dimension 127/145]  inactive:\t1.85e-04 +- 1.66e-02\n",
      "[dimension 128/145]  inactive:\t1.08e-04 +- 3.12e-02\n",
      "[dimension 129/145]  inactive:\t7.17e-04 +- 2.68e-02\n",
      "[dimension 130/145]  inactive:\t3.48e-03 +- 2.90e-02\n",
      "[dimension 131/145]  inactive:\t-8.42e-04 +- 2.63e-02\n",
      "[dimension 132/145]  inactive:\t4.23e-03 +- 4.17e-02\n",
      "[dimension 133/145]  inactive:\t2.20e-03 +- 1.95e-02\n",
      "[dimension 134/145]  inactive:\t-3.22e-04 +- 2.04e-02\n",
      "[dimension 135/145]  inactive:\t5.95e-04 +- 2.57e-02\n",
      "[dimension 136/145]  inactive:\t7.64e-04 +- 1.76e-02\n",
      "[dimension 137/145]  inactive:\t-2.86e-04 +- 3.32e-02\n",
      "[dimension 138/145]  inactive:\t-8.09e-05 +- 2.40e-02\n",
      "[dimension 139/145]  inactive:\t1.49e-04 +- 2.59e-02\n",
      "[dimension 140/145]  inactive:\t-5.43e-04 +- 2.54e-02\n",
      "[dimension 141/145]  inactive:\t1.47e-03 +- 2.87e-02\n",
      "[dimension 142/145]  inactive:\t1.54e-03 +- 1.83e-02\n",
      "[dimension 143/145]  inactive:\t2.00e-03 +- 3.91e-02\n",
      "[dimension 144/145]  inactive:\t5.55e-04 +- 2.03e-02\n",
      "[dimension 145/145]  inactive:\t9.05e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00028369]\n",
      "cov_act[[2.387166e-05]]\n",
      "Active_dimensions: [62]\n",
      "53, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.13it/s, 31 steps of size 1.37e-01. acc. prob=0.95] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    259.57      1.00\n",
      "  lambda[0]      2.50      8.07      0.96      0.00      5.30    943.73      1.00\n",
      "  lambda[1]      3.26     10.94      1.00      0.00      6.09    572.44      1.00\n",
      "  lambda[2]      3.62     14.08      1.07      0.00      5.70    431.95      1.01\n",
      "  lambda[3]      3.39     11.24      1.06      0.00      6.81    639.98      1.00\n",
      "  lambda[4]      2.85     10.16      1.04      0.00      5.16    906.44      1.00\n",
      "  lambda[5]      3.04     11.72      0.99      0.00      5.32    787.57      1.00\n",
      "  lambda[6]      4.59     15.84      1.09      0.00      7.41    868.93      1.00\n",
      "  lambda[7]      3.08      9.07      0.95      0.00      6.32    655.13      1.00\n",
      "  lambda[8]      2.34      4.18      1.00      0.00      5.60   1131.73      1.00\n",
      "  lambda[9]      2.66      8.69      0.95      0.00      4.54    809.40      1.00\n",
      " lambda[10]      3.52     11.33      1.05      0.00      6.07    617.81      1.00\n",
      " lambda[11]      2.85      7.00      1.02      0.00      6.03    715.59      1.00\n",
      " lambda[12]      4.53     18.70      1.08      0.00      6.77    793.51      1.00\n",
      " lambda[13]      2.42      5.25      0.89      0.00      5.33    803.75      1.00\n",
      " lambda[14]      4.30     27.24      0.94      0.00      5.58    908.11      1.00\n",
      " lambda[15]      4.13     15.77      1.03      0.00      6.30    680.50      1.00\n",
      " lambda[16]      3.38      7.85      0.94      0.01      8.07    651.58      1.00\n",
      " lambda[17]      3.61     17.30      0.99      0.00      5.11    570.86      1.00\n",
      " lambda[18]      2.47      5.87      0.91      0.00      5.31    824.20      1.00\n",
      " lambda[19]      4.63     38.39      1.04      0.01      6.12    562.73      1.00\n",
      " lambda[20]      2.83      6.71      0.99      0.00      6.06    793.05      1.00\n",
      " lambda[21]      3.72     15.20      1.05      0.00      6.51    610.35      1.00\n",
      " lambda[22]      2.83     10.81      0.96      0.00      5.18    461.50      1.00\n",
      " lambda[23]      3.16      9.07      1.02      0.00      5.89    683.21      1.00\n",
      " lambda[24]      3.62     13.98      0.98      0.00      6.34    829.21      1.00\n",
      " lambda[25]      3.10      7.81      1.00      0.01      6.58    464.44      1.00\n",
      " lambda[26]      3.80     28.75      0.97      0.00      5.82    807.16      1.00\n",
      " lambda[27]      2.94      7.76      0.96      0.00      5.78    614.17      1.00\n",
      " lambda[28]      2.53      5.43      1.05      0.00      5.22    784.64      1.00\n",
      " lambda[29]      3.04      9.83      0.95      0.00      5.37    783.76      1.00\n",
      " lambda[30]      3.34     13.91      1.05      0.01      6.72    741.32      1.00\n",
      " lambda[31]      3.43     11.89      1.02      0.00      6.26    609.45      1.00\n",
      " lambda[32]      3.43     14.18      0.99      0.00      5.96    854.02      1.00\n",
      " lambda[33]      3.29     11.39      0.99      0.00      5.85    950.23      1.00\n",
      " lambda[34]      3.53     17.93      1.03      0.00      5.51    301.91      1.00\n",
      " lambda[35]      2.47      6.00      1.00      0.00      5.12    701.30      1.00\n",
      " lambda[36]      3.03     10.84      1.00      0.00      5.86    934.69      1.00\n",
      " lambda[37]      2.95      6.64      0.98      0.00      6.30    640.54      1.00\n",
      " lambda[38]      3.05      8.20      0.95      0.00      6.95    787.90      1.00\n",
      " lambda[39]      2.93      7.93      1.00      0.00      5.90    628.00      1.00\n",
      " lambda[40]      4.38     18.07      0.88      0.00      6.34    507.42      1.00\n",
      " lambda[41]      6.58     40.57      0.92      0.00      8.43    461.86      1.01\n",
      " lambda[42]      2.80      9.65      1.00      0.00      4.98    764.61      1.00\n",
      " lambda[43]      3.36     18.43      0.98      0.00      6.16    925.13      1.00\n",
      " lambda[44]      2.61      8.63      0.98      0.00      4.96    756.72      1.00\n",
      " lambda[45]      2.47      6.10      0.98      0.00      4.92    865.70      1.00\n",
      " lambda[46]      2.38      5.03      1.01      0.00      4.88    771.15      1.00\n",
      " lambda[47]      2.49      5.00      0.96      0.00      5.53    645.27      1.00\n",
      " lambda[48]      2.55      6.93      1.00      0.01      4.97    749.87      1.00\n",
      " lambda[49]      2.53      6.03      0.94      0.00      5.33    784.23      1.00\n",
      " lambda[50]      2.89      8.41      0.96      0.00      5.56    658.17      1.00\n",
      " lambda[51]      5.66     21.04      1.06      0.00      9.08    669.62      1.00\n",
      " lambda[52]      2.97      7.14      0.91      0.00      5.88    589.87      1.00\n",
      " lambda[53]      2.94      7.61      0.95      0.00      5.64    804.45      1.00\n",
      " lambda[54]      2.14      4.42      0.91      0.00      4.62    828.18      1.00\n",
      " lambda[55]      3.40     10.49      0.97      0.00      6.83    494.43      1.00\n",
      " lambda[56]      2.34      5.05      0.99      0.00      4.68    697.40      1.00\n",
      " lambda[57]      8.27     87.60      1.00      0.00      5.94    328.66      1.00\n",
      " lambda[58]      2.29      5.53      0.91      0.00      4.56    706.99      1.00\n",
      " lambda[59]      2.65      6.62      0.89      0.00      5.62    789.19      1.00\n",
      " lambda[60]      3.13      9.03      1.01      0.00      6.40    667.20      1.00\n",
      " lambda[61]      3.02      9.46      0.99      0.00      6.73    819.83      1.00\n",
      " lambda[62]   4311.17  18666.52    578.45      0.02   7836.62    407.02      1.00\n",
      " lambda[63]      2.13      4.65      0.92      0.00      4.96    674.04      1.00\n",
      " lambda[64]      2.53      5.93      1.01      0.01      4.93    787.29      1.00\n",
      " lambda[65]      3.37     12.95      1.01      0.00      5.33    685.65      1.00\n",
      " lambda[66]      3.42     10.88      1.02      0.00      6.47    627.93      1.00\n",
      " lambda[67]      3.16      9.95      0.96      0.00      6.45    826.28      1.00\n",
      " lambda[68]      3.62     17.68      0.94      0.00      6.36    724.76      1.00\n",
      " lambda[69]      4.25     19.27      0.94      0.00      6.24    886.09      1.00\n",
      " lambda[70]      2.67      7.28      1.01      0.00      5.58    826.26      1.00\n",
      " lambda[71]      2.84     12.22      1.01      0.00      4.88    814.48      1.00\n",
      " lambda[72]      2.74      7.07      1.00      0.00      5.65    739.83      1.00\n",
      " lambda[73]      2.85     11.95      0.95      0.00      5.48    480.14      1.00\n",
      " lambda[74]      2.26      4.92      1.00      0.02      5.07    924.56      1.00\n",
      " lambda[75]      3.71     13.25      0.98      0.00      7.03    899.50      1.00\n",
      " lambda[76]      3.08      7.97      0.97      0.00      6.86    724.85      1.00\n",
      " lambda[77]     73.39    513.15      1.08      0.00     10.67    136.80      1.00\n",
      " lambda[78]      3.73     16.62      1.02      0.00      5.64    708.22      1.00\n",
      " lambda[79]      2.64      6.70      1.01      0.00      5.20    784.64      1.01\n",
      " lambda[80]      8.94    101.50      1.01      0.00      6.83    393.20      1.00\n",
      " lambda[81]      2.44      7.56      0.94      0.00      5.32    705.42      1.00\n",
      " lambda[82]      2.62      7.91      0.93      0.00      4.96    660.02      1.00\n",
      " lambda[83]      2.47      6.25      0.93      0.00      4.99    943.41      1.00\n",
      " lambda[84]      3.54     21.74      0.97      0.01      5.45    762.91      1.00\n",
      " lambda[85]      2.78      7.78      0.96      0.00      5.84    442.37      1.00\n",
      " lambda[86]      3.75     19.01      0.96      0.00      5.64    670.62      1.00\n",
      " lambda[87]      2.93      8.90      0.98      0.00      5.85    738.37      1.00\n",
      " lambda[88]      2.84      9.25      1.01      0.00      5.76    902.86      1.00\n",
      " lambda[89]   2085.44  19691.16      1.41      0.00   1448.31    463.23      1.00\n",
      " lambda[90]      2.32      4.79      0.91      0.00      5.19    823.92      1.00\n",
      " lambda[91]      2.50      6.69      0.98      0.01      4.71    719.96      1.00\n",
      " lambda[92]      2.64      7.44      0.99      0.00      5.48    579.99      1.00\n",
      " lambda[93]     39.60    926.42      0.99      0.00      5.26    662.28      1.00\n",
      " lambda[94]      2.50      6.17      0.93      0.00      5.28    785.24      1.00\n",
      " lambda[95]      2.73      6.62      1.05      0.00      5.17    768.81      1.00\n",
      " lambda[96]      2.80     10.33      0.95      0.00      5.51    545.01      1.00\n",
      " lambda[97]      3.22     14.26      0.94      0.00      5.70    570.91      1.00\n",
      " lambda[98]      9.71    106.45      0.98      0.00      5.82    398.40      1.00\n",
      " lambda[99]      2.68      7.75      0.99      0.00      5.04    737.53      1.00\n",
      "lambda[100]      2.82      7.25      0.93      0.00      5.68    777.01      1.00\n",
      "lambda[101]      2.47      5.64      0.96      0.00      5.25    570.54      1.00\n",
      "lambda[102]      2.70      8.06      0.88      0.00      5.21    900.69      1.00\n",
      "lambda[103]      2.43      7.10      0.97      0.00      5.09    932.14      1.00\n",
      "lambda[104]      3.30     18.27      0.98      0.00      6.02    644.04      1.00\n",
      "lambda[105]      3.74     15.26      1.03      0.00      6.92    783.23      1.00\n",
      "lambda[106]      2.56      5.44      1.03      0.00      6.12    781.58      1.00\n",
      "lambda[107]      2.81      8.07      0.98      0.00      5.50    649.60      1.00\n",
      "lambda[108]      2.59     11.17      0.98      0.00      5.29    737.42      1.00\n",
      "lambda[109]      3.08      8.27      0.98      0.00      6.57    871.83      1.00\n",
      "lambda[110]      3.04      8.18      1.04      0.01      5.91    717.26      1.00\n",
      "lambda[111]      3.16      8.97      0.96      0.00      7.44    795.02      1.00\n",
      "lambda[112]      2.99     16.64      0.99      0.00      5.78    924.35      1.00\n",
      "lambda[113]      4.17     28.59      1.04      0.00      6.18    962.87      1.00\n",
      "lambda[114]      3.77     11.13      1.02      0.00      7.34    757.39      1.00\n",
      "lambda[115]      3.73     16.60      0.98      0.00      6.11    791.63      1.00\n",
      "lambda[116]      3.66     21.55      1.00      0.00      5.56    438.53      1.00\n",
      "lambda[117]      3.03      9.07      0.96      0.00      5.79    809.84      1.00\n",
      "lambda[118]      3.02      9.39      0.95      0.00      6.34    796.36      1.00\n",
      "lambda[119]      2.83      8.60      1.03      0.00      5.10    791.91      1.00\n",
      "lambda[120]      3.82     17.67      0.93      0.00      6.81    806.69      1.00\n",
      "lambda[121]      3.09     11.38      0.88      0.00      5.62    758.03      1.00\n",
      "lambda[122]      3.27     13.09      1.02      0.00      5.89    629.28      1.00\n",
      "lambda[123]      2.52      5.96      0.92      0.00      5.98    641.65      1.00\n",
      "lambda[124]      2.75      6.11      0.95      0.00      6.14    691.66      1.00\n",
      "lambda[125]      3.11      9.17      1.01      0.01      6.06    572.27      1.00\n",
      "lambda[126]      2.35      5.11      0.99      0.00      5.08    680.07      1.00\n",
      "lambda[127]      6.30     43.84      1.03      0.00      7.01    380.62      1.00\n",
      "lambda[128]      2.77     11.64      0.94      0.00      4.99    777.42      1.00\n",
      "lambda[129]      3.96     16.97      0.96      0.00      6.43    986.20      1.00\n",
      "lambda[130]      3.24     10.98      0.99      0.00      6.50    860.37      1.00\n",
      "lambda[131]      3.30     11.96      0.96      0.00      5.87    671.84      1.00\n",
      "lambda[132]      2.59      6.00      0.94      0.00      5.84    851.87      1.00\n",
      "lambda[133]      2.43      5.47      0.95      0.00      5.04    942.74      1.00\n",
      "lambda[134]      3.47     10.15      0.97      0.00      6.72    907.32      1.00\n",
      "lambda[135]      3.31     13.49      0.97      0.00      5.62    596.48      1.00\n",
      "lambda[136]      2.91      7.66      0.99      0.00      5.86    593.34      1.00\n",
      "lambda[137]      2.77      8.54      1.00      0.00      5.07    731.04      1.00\n",
      "lambda[138]      3.26     12.27      1.00      0.00      5.12    556.22      1.00\n",
      "lambda[139]      3.08      8.02      0.99      0.00      5.62    931.45      1.00\n",
      "lambda[140]      3.01      9.25      0.97      0.00      5.28    917.24      1.00\n",
      "lambda[141]      2.65      7.49      0.90      0.00      5.43    657.39      1.00\n",
      "lambda[142]      5.27     51.69      0.95      0.01      5.68    653.36      1.00\n",
      "lambda[143]      2.42      4.92      0.96      0.00      5.30    612.24      1.00\n",
      "        msq      0.28      0.18      0.23      0.06      0.48    875.25      1.00\n",
      "      sigma      3.38      5.14      1.13      0.00     10.49   1329.38      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    332.66      1.00\n",
      "       xisq     11.07     25.75      5.05      0.66     20.59    575.08      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.53022503852844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.14e-04 +- 6.10e-03\n",
      "[dimension 02/145]  inactive:\t4.97e-04 +- 1.09e-02\n",
      "[dimension 03/145]  inactive:\t1.55e-03 +- 2.14e-02\n",
      "[dimension 04/145]  inactive:\t1.03e-03 +- 1.32e-02\n",
      "[dimension 05/145]  inactive:\t2.57e-04 +- 9.22e-03\n",
      "[dimension 06/145]  inactive:\t7.64e-04 +- 1.70e-02\n",
      "[dimension 07/145]  inactive:\t7.88e-04 +- 1.10e-02\n",
      "[dimension 08/145]  inactive:\t6.61e-04 +- 1.18e-02\n",
      "[dimension 09/145]  inactive:\t4.52e-04 +- 9.20e-03\n",
      "[dimension 10/145]  inactive:\t2.70e-04 +- 6.75e-03\n",
      "[dimension 11/145]  inactive:\t4.57e-04 +- 1.15e-02\n",
      "[dimension 12/145]  inactive:\t3.90e-04 +- 9.45e-03\n",
      "[dimension 13/145]  inactive:\t1.51e-03 +- 2.07e-02\n",
      "[dimension 14/145]  inactive:\t3.83e-04 +- 1.21e-02\n",
      "[dimension 15/145]  inactive:\t1.26e-03 +- 2.14e-02\n",
      "[dimension 16/145]  inactive:\t5.16e-04 +- 1.23e-02\n",
      "[dimension 17/145]  inactive:\t6.45e-04 +- 1.28e-02\n",
      "[dimension 18/145]  inactive:\t1.56e-03 +- 2.26e-02\n",
      "[dimension 19/145]  inactive:\t-6.02e-05 +- 6.96e-03\n",
      "[dimension 20/145]  inactive:\t2.21e-04 +- 9.56e-03\n",
      "[dimension 21/145]  inactive:\t8.74e-05 +- 8.41e-03\n",
      "[dimension 22/145]  inactive:\t3.04e-04 +- 8.35e-03\n",
      "[dimension 23/145]  inactive:\t7.20e-04 +- 1.49e-02\n",
      "[dimension 24/145]  inactive:\t8.60e-04 +- 1.48e-02\n",
      "[dimension 25/145]  inactive:\t1.07e-03 +- 1.12e-02\n",
      "[dimension 26/145]  inactive:\t1.95e-04 +- 9.30e-03\n",
      "[dimension 27/145]  inactive:\t6.05e-04 +- 1.34e-02\n",
      "[dimension 28/145]  inactive:\t4.92e-04 +- 9.15e-03\n",
      "[dimension 29/145]  inactive:\t4.89e-04 +- 1.01e-02\n",
      "[dimension 30/145]  inactive:\t8.61e-04 +- 1.76e-02\n",
      "[dimension 31/145]  inactive:\t1.41e-03 +- 1.60e-02\n",
      "[dimension 32/145]  inactive:\t5.81e-04 +- 1.56e-02\n",
      "[dimension 33/145]  inactive:\t2.49e-03 +- 2.97e-02\n",
      "[dimension 34/145]  inactive:\t4.79e-04 +- 9.04e-03\n",
      "[dimension 35/145]  inactive:\t2.77e-03 +- 3.97e-02\n",
      "[dimension 36/145]  inactive:\t4.18e-04 +- 9.04e-03\n",
      "[dimension 37/145]  inactive:\t8.75e-04 +- 9.81e-03\n",
      "[dimension 38/145]  inactive:\t3.12e-04 +- 1.10e-02\n",
      "[dimension 39/145]  inactive:\t4.71e-04 +- 1.24e-02\n",
      "[dimension 40/145]  inactive:\t1.91e-03 +- 2.02e-02\n",
      "[dimension 41/145]  inactive:\t4.98e-04 +- 1.68e-02\n",
      "[dimension 42/145]  inactive:\t3.88e-03 +- 4.74e-02\n",
      "[dimension 43/145]  inactive:\t3.17e-04 +- 8.84e-03\n",
      "[dimension 44/145]  inactive:\t7.71e-04 +- 1.61e-02\n",
      "[dimension 45/145]  inactive:\t9.91e-04 +- 1.86e-02\n",
      "[dimension 46/145]  inactive:\t2.56e-04 +- 6.26e-03\n",
      "[dimension 47/145]  inactive:\t3.65e-06 +- 7.48e-03\n",
      "[dimension 48/145]  inactive:\t3.53e-04 +- 9.22e-03\n",
      "[dimension 49/145]  inactive:\t5.81e-04 +- 1.01e-02\n",
      "[dimension 50/145]  inactive:\t5.97e-05 +- 1.12e-02\n",
      "[dimension 51/145]  inactive:\t1.19e-03 +- 2.17e-02\n",
      "[dimension 52/145]  inactive:\t2.87e-03 +- 1.90e-02\n",
      "[dimension 53/145]  inactive:\t5.84e-05 +- 1.14e-02\n",
      "[dimension 54/145]  inactive:\t2.52e-04 +- 9.23e-03\n",
      "[dimension 55/145]  inactive:\t1.70e-04 +- 5.81e-03\n",
      "[dimension 56/145]  inactive:\t-3.66e-04 +- 9.63e-03\n",
      "[dimension 57/145]  inactive:\t8.84e-04 +- 1.65e-02\n",
      "[dimension 58/145]  inactive:\t6.83e-03 +- 6.20e-02\n",
      "[dimension 59/145]  inactive:\t-1.02e-04 +- 6.64e-03\n",
      "[dimension 60/145]  inactive:\t7.38e-04 +- 1.64e-02\n",
      "[dimension 61/145]  inactive:\t1.44e-03 +- 1.61e-02\n",
      "[dimension 62/145]  inactive:\t4.78e-05 +- 7.07e-03\n",
      "[dimension 63/145]  active:\t6.25e-01 +- 4.37e-01\n",
      "[dimension 64/145]  inactive:\t-1.29e-04 +- 6.72e-03\n",
      "[dimension 65/145]  inactive:\t5.79e-04 +- 1.16e-02\n",
      "[dimension 66/145]  inactive:\t1.36e-03 +- 1.93e-02\n",
      "[dimension 67/145]  inactive:\t1.04e-03 +- 1.42e-02\n",
      "[dimension 68/145]  inactive:\t3.89e-04 +- 1.07e-02\n",
      "[dimension 69/145]  inactive:\t1.30e-03 +- 1.84e-02\n",
      "[dimension 70/145]  inactive:\t1.94e-03 +- 1.76e-02\n",
      "[dimension 71/145]  inactive:\t6.83e-04 +- 1.49e-02\n",
      "[dimension 72/145]  inactive:\t4.12e-04 +- 7.98e-03\n",
      "[dimension 73/145]  inactive:\t2.62e-04 +- 6.63e-03\n",
      "[dimension 74/145]  inactive:\t3.24e-04 +- 1.43e-02\n",
      "[dimension 75/145]  inactive:\t5.16e-04 +- 1.18e-02\n",
      "[dimension 76/145]  inactive:\t2.13e-03 +- 2.33e-02\n",
      "[dimension 77/145]  inactive:\t5.25e-04 +- 1.70e-02\n",
      "[dimension 78/145]  inactive:\t3.31e-02 +- 1.55e-01\n",
      "[dimension 79/145]  inactive:\t2.51e-03 +- 2.54e-02\n",
      "[dimension 80/145]  inactive:\t6.08e-04 +- 1.34e-02\n",
      "[dimension 81/145]  inactive:\t3.28e-03 +- 4.13e-02\n",
      "[dimension 82/145]  inactive:\t1.25e-04 +- 6.39e-03\n",
      "[dimension 83/145]  inactive:\t-3.62e-04 +- 7.16e-03\n",
      "[dimension 84/145]  inactive:\t6.31e-05 +- 8.25e-03\n",
      "[dimension 85/145]  inactive:\t1.83e-03 +- 2.76e-02\n",
      "[dimension 86/145]  inactive:\t-2.24e-04 +- 8.27e-03\n",
      "[dimension 87/145]  inactive:\t1.35e-03 +- 2.29e-02\n",
      "[dimension 88/145]  inactive:\t8.40e-04 +- 1.27e-02\n",
      "[dimension 89/145]  inactive:\t-3.68e-05 +- 7.16e-03\n",
      "[dimension 90/145]  inactive:\t1.72e-01 +- 3.50e-01\n",
      "[dimension 91/145]  inactive:\t8.89e-05 +- 6.08e-03\n",
      "[dimension 92/145]  inactive:\t5.79e-05 +- 8.50e-03\n",
      "[dimension 93/145]  inactive:\t1.93e-04 +- 8.74e-03\n",
      "[dimension 94/145]  inactive:\t6.68e-03 +- 6.55e-02\n",
      "[dimension 95/145]  inactive:\t9.59e-05 +- 7.92e-03\n",
      "[dimension 96/145]  inactive:\t2.61e-04 +- 1.07e-02\n",
      "[dimension 97/145]  inactive:\t8.54e-04 +- 1.11e-02\n",
      "[dimension 98/145]  inactive:\t1.16e-04 +- 1.02e-02\n",
      "[dimension 99/145]  inactive:\t4.65e-03 +- 5.52e-02\n",
      "[dimension 100/145]  inactive:\t-3.72e-05 +- 6.39e-03\n",
      "[dimension 101/145]  inactive:\t-5.61e-04 +- 8.28e-03\n",
      "[dimension 102/145]  inactive:\t7.04e-05 +- 8.26e-03\n",
      "[dimension 103/145]  inactive:\t4.53e-04 +- 1.17e-02\n",
      "[dimension 104/145]  inactive:\t-1.33e-04 +- 6.28e-03\n",
      "[dimension 105/145]  inactive:\t2.10e-04 +- 1.01e-02\n",
      "[dimension 106/145]  inactive:\t2.40e-03 +- 2.35e-02\n",
      "[dimension 107/145]  inactive:\t-1.93e-05 +- 7.74e-03\n",
      "[dimension 108/145]  inactive:\t2.23e-03 +- 3.31e-02\n",
      "[dimension 109/145]  inactive:\t1.85e-04 +- 7.31e-03\n",
      "[dimension 110/145]  inactive:\t6.95e-04 +- 1.84e-02\n",
      "[dimension 111/145]  inactive:\t6.61e-04 +- 1.27e-02\n",
      "[dimension 112/145]  inactive:\t9.50e-04 +- 1.52e-02\n",
      "[dimension 113/145]  inactive:\t1.81e-04 +- 1.08e-02\n",
      "[dimension 114/145]  inactive:\t1.24e-03 +- 2.61e-02\n",
      "[dimension 115/145]  inactive:\t1.46e-03 +- 1.58e-02\n",
      "[dimension 116/145]  inactive:\t2.29e-03 +- 4.06e-02\n",
      "[dimension 117/145]  inactive:\t1.58e-03 +- 2.55e-02\n",
      "[dimension 118/145]  inactive:\t7.00e-04 +- 9.43e-03\n",
      "[dimension 119/145]  inactive:\t1.77e-04 +- 1.06e-02\n",
      "[dimension 120/145]  inactive:\t5.54e-04 +- 1.49e-02\n",
      "[dimension 121/145]  inactive:\t1.70e-03 +- 2.25e-02\n",
      "[dimension 122/145]  inactive:\t1.56e-04 +- 1.26e-02\n",
      "[dimension 123/145]  inactive:\t1.27e-03 +- 2.28e-02\n",
      "[dimension 124/145]  inactive:\t1.51e-04 +- 8.39e-03\n",
      "[dimension 125/145]  inactive:\t1.44e-04 +- 9.36e-03\n",
      "[dimension 126/145]  inactive:\t1.52e-04 +- 9.46e-03\n",
      "[dimension 127/145]  inactive:\t1.94e-04 +- 6.40e-03\n",
      "[dimension 128/145]  inactive:\t3.00e-03 +- 4.18e-02\n",
      "[dimension 129/145]  inactive:\t5.27e-04 +- 1.32e-02\n",
      "[dimension 130/145]  inactive:\t1.27e-03 +- 1.55e-02\n",
      "[dimension 131/145]  inactive:\t9.95e-04 +- 2.23e-02\n",
      "[dimension 132/145]  inactive:\t1.01e-03 +- 1.69e-02\n",
      "[dimension 133/145]  inactive:\t7.00e-04 +- 9.51e-03\n",
      "[dimension 134/145]  inactive:\t3.44e-04 +- 1.14e-02\n",
      "[dimension 135/145]  inactive:\t9.68e-04 +- 1.73e-02\n",
      "[dimension 136/145]  inactive:\t8.27e-04 +- 1.12e-02\n",
      "[dimension 137/145]  inactive:\t6.62e-04 +- 1.40e-02\n",
      "[dimension 138/145]  inactive:\t3.35e-04 +- 7.90e-03\n",
      "[dimension 139/145]  inactive:\t6.91e-04 +- 1.29e-02\n",
      "[dimension 140/145]  inactive:\t3.87e-04 +- 1.32e-02\n",
      "[dimension 141/145]  inactive:\t8.71e-04 +- 1.80e-02\n",
      "[dimension 142/145]  inactive:\t6.52e-04 +- 8.75e-03\n",
      "[dimension 143/145]  inactive:\t1.09e-03 +- 1.77e-02\n",
      "[dimension 144/145]  inactive:\t3.18e-04 +- 7.42e-03\n",
      "[dimension 145/145]  inactive:\t-5.42e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.90074855]\n",
      "cov_act[[0.01014425]]\n",
      "Active_dimensions: [62]\n",
      "54, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 51.37it/s, 31 steps of size 1.47e-01. acc. prob=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    632.86      1.00\n",
      "  lambda[0]      2.66      8.74      1.01      0.00      6.11    877.46      1.00\n",
      "  lambda[1]      3.23     11.02      0.98      0.00      5.63    632.87      1.01\n",
      "  lambda[2]      3.00      9.38      1.03      0.00      6.16    678.59      1.00\n",
      "  lambda[3]      3.36     12.51      1.03      0.00      6.56    712.65      1.01\n",
      "  lambda[4]      2.72      6.36      0.98      0.00      5.71    521.15      1.00\n",
      "  lambda[5]      3.59     20.71      0.96      0.00      5.33    549.01      1.00\n",
      "  lambda[6]      3.67     17.54      1.02      0.00      5.78    450.74      1.00\n",
      "  lambda[7]      3.59     14.97      0.93      0.00      5.79    608.31      1.01\n",
      "  lambda[8]      2.49      6.24      0.98      0.00      5.40    968.71      1.00\n",
      "  lambda[9]      2.66      8.38      0.93      0.00      5.02    816.69      1.00\n",
      " lambda[10]      3.51     11.59      1.07      0.00      6.30    851.35      1.00\n",
      " lambda[11]      2.75      6.69      1.00      0.00      5.91    802.94      1.00\n",
      " lambda[12]      4.64     15.73      0.97      0.00      8.72    709.08      1.00\n",
      " lambda[13]      2.53      5.81      0.93      0.00      5.59    826.77      1.00\n",
      " lambda[14]      4.76     28.97      0.91      0.00      6.18    913.78      1.00\n",
      " lambda[15]      2.70      8.03      0.96      0.00      5.24    547.11      1.00\n",
      " lambda[16]      4.08     11.79      0.98      0.00      9.47    579.64      1.00\n",
      " lambda[17]      3.27     15.56      0.96      0.00      5.18    664.82      1.00\n",
      " lambda[18]      2.49      6.53      0.96      0.00      4.78    853.42      1.00\n",
      " lambda[19]      3.39     16.43      0.94      0.01      6.12    768.50      1.00\n",
      " lambda[20]      2.75      6.67      0.99      0.00      5.54    772.16      1.00\n",
      " lambda[21]      3.23      9.34      0.97      0.00      6.44    803.49      1.00\n",
      " lambda[22]      3.63     21.00      1.00      0.00      4.99    283.86      1.00\n",
      " lambda[23]      2.93      8.40      0.99      0.00      5.65    699.65      1.00\n",
      " lambda[24]      3.65     19.00      1.02      0.00      5.75    619.57      1.00\n",
      " lambda[25]      2.97      7.70      0.99      0.01      5.83    547.94      1.00\n",
      " lambda[26]      3.23     16.38      0.98      0.00      5.40    922.68      1.00\n",
      " lambda[27]      2.90      7.72      0.95      0.00      6.14    664.29      1.00\n",
      " lambda[28]      2.70      7.16      0.95      0.00      5.45    527.12      1.00\n",
      " lambda[29]      2.92      7.00      0.95      0.00      7.02    608.34      1.00\n",
      " lambda[30]      3.74     16.34      1.07      0.01      6.47    806.44      1.00\n",
      " lambda[31]      3.77     13.98      0.96      0.00      6.99    723.82      1.00\n",
      " lambda[32]      3.46     13.09      0.97      0.00      6.49   1010.14      1.00\n",
      " lambda[33]      3.09     11.38      0.93      0.00      6.66    850.54      1.00\n",
      " lambda[34]      2.94     10.49      0.97      0.00      5.42    583.67      1.00\n",
      " lambda[35]      2.49      5.75      1.01      0.00      5.81    878.64      1.00\n",
      " lambda[36]      3.60     14.46      1.03      0.00      6.10    872.50      1.00\n",
      " lambda[37]      3.09      7.81      1.02      0.00      6.69    574.28      1.00\n",
      " lambda[38]      2.74      7.03      0.99      0.00      5.41    918.15      1.00\n",
      " lambda[39]      3.32     14.79      1.00      0.00      5.79    838.28      1.00\n",
      " lambda[40]      4.10     18.76      0.96      0.00      6.33    609.01      1.00\n",
      " lambda[41]     38.33    441.51      1.00      0.00     12.30    540.60      1.01\n",
      " lambda[42]      2.73      8.76      0.97      0.00      5.11    922.35      1.00\n",
      " lambda[43]      3.08     19.52      0.99      0.00      5.27    997.92      1.00\n",
      " lambda[44]      2.53      5.41      1.00      0.00      5.48    563.58      1.00\n",
      " lambda[45]      2.55      5.99      0.95      0.00      4.96    694.58      1.00\n",
      " lambda[46]      2.28      4.99      0.98      0.00      4.71    775.30      1.00\n",
      " lambda[47]      2.88      6.74      0.92      0.00      6.54    676.27      1.00\n",
      " lambda[48]      2.65      8.33      1.03      0.00      4.77    744.12      1.00\n",
      " lambda[49]      3.06      9.51      0.96      0.00      5.84    627.22      1.00\n",
      " lambda[50]      2.53      6.56      0.95      0.00      5.48    934.19      1.00\n",
      " lambda[51]      4.17     16.29      1.06      0.00      7.36    769.56      1.00\n",
      " lambda[52]      3.13     16.14      0.93      0.00      5.71    805.95      1.00\n",
      " lambda[53]      3.19     10.44      0.92      0.00      5.80    878.61      1.00\n",
      " lambda[54]      2.42      7.48      0.95      0.00      5.08    574.23      1.00\n",
      " lambda[55]      3.94     16.36      0.99      0.00      6.20    663.58      1.00\n",
      " lambda[56]      2.63      6.32      0.96      0.00      5.13    713.19      1.00\n",
      " lambda[57]      7.00     78.95      1.00      0.00      8.38    990.49      1.00\n",
      " lambda[58]      2.39      5.85      0.89      0.00      4.84    821.13      1.00\n",
      " lambda[59]      3.10      8.57      0.98      0.00      6.44    470.07      1.00\n",
      " lambda[60]      3.05     14.01      0.93      0.00      5.56    947.00      1.00\n",
      " lambda[61]      2.57      5.42      1.01      0.00      5.63    756.24      1.00\n",
      " lambda[62]   3793.22  77506.90    143.95      0.01   1287.92    884.42      1.00\n",
      " lambda[63]      2.41      5.58      0.97      0.00      5.56    777.19      1.00\n",
      " lambda[64]      2.76      7.61      0.99      0.01      4.66    772.65      1.00\n",
      " lambda[65]      3.48     14.07      0.98      0.00      5.88    806.28      1.00\n",
      " lambda[66]      3.61     10.86      0.99      0.00      7.30    676.43      1.00\n",
      " lambda[67]      2.77      7.97      0.96      0.00      5.03    876.22      1.00\n",
      " lambda[68]      2.88      8.17      0.95      0.00      5.56    519.99      1.00\n",
      " lambda[69]      3.73     12.73      0.93      0.00      6.33    610.93      1.00\n",
      " lambda[70]      2.77      8.41      1.01      0.01      5.45    541.48      1.00\n",
      " lambda[71]      3.03     12.67      1.00      0.00      4.90    551.03      1.00\n",
      " lambda[72]      2.87      8.56      0.96      0.01      5.19    762.66      1.00\n",
      " lambda[73]      2.71      6.70      1.03      0.00      5.46    648.06      1.00\n",
      " lambda[74]      2.38      4.41      1.05      0.01      5.34    694.58      1.00\n",
      " lambda[75]      3.96     14.26      1.01      0.00      6.46   1024.33      1.00\n",
      " lambda[76]      3.19      8.68      1.02      0.00      6.97    789.10      1.00\n",
      " lambda[77]      5.44     30.08      1.02      0.00      6.97    422.09      1.01\n",
      " lambda[78]      4.18     23.48      1.04      0.00      6.29    636.43      1.00\n",
      " lambda[79]      3.05     10.13      1.01      0.00      5.52    700.08      1.00\n",
      " lambda[80]      4.10     21.22      1.00      0.00      7.35    730.58      1.00\n",
      " lambda[81]      2.48      6.76      0.94      0.00      4.79   1093.12      1.00\n",
      " lambda[82]      2.39      6.13      0.92      0.00      5.05    908.90      1.00\n",
      " lambda[83]      2.61      7.98      0.91      0.00      4.77    926.53      1.00\n",
      " lambda[84]      2.60      7.24      1.03      0.00      5.56    909.87      1.00\n",
      " lambda[85]      2.84      8.18      0.95      0.00      5.59    660.55      1.00\n",
      " lambda[86]      3.47     14.05      0.98      0.01      5.42    736.12      1.00\n",
      " lambda[87]      3.75     16.31      1.00      0.00      5.68    484.95      1.00\n",
      " lambda[88]      2.71      8.10      0.94      0.00      5.63    887.08      1.00\n",
      " lambda[89]    155.20   1422.91      1.45      0.00    175.30    678.08      1.00\n",
      " lambda[90]      3.02      7.60      1.03      0.00      6.57    533.44      1.00\n",
      " lambda[91]      3.02      9.83      0.95      0.00      6.21    425.02      1.00\n",
      " lambda[92]      2.50      6.11      1.07      0.00      5.31    774.01      1.00\n",
      " lambda[93]      2.75      7.77      1.01      0.00      5.64    649.98      1.00\n",
      " lambda[94]      2.61     10.85      0.96      0.00      4.78    787.90      1.00\n",
      " lambda[95]      3.29     12.50      1.04      0.00      5.74    622.48      1.00\n",
      " lambda[96]      2.78      6.68      1.00      0.00      5.95    501.24      1.00\n",
      " lambda[97]      3.11     10.35      1.02      0.00      5.89    634.96      1.01\n",
      " lambda[98]      4.45     31.63      0.95      0.00      5.21    479.44      1.00\n",
      " lambda[99]      2.33      6.16      0.98      0.00      4.41    938.50      1.00\n",
      "lambda[100]      3.82     17.34      0.94      0.00      6.99    933.96      1.00\n",
      "lambda[101]      2.54      7.02      1.02      0.00      5.18    521.53      1.00\n",
      "lambda[102]      2.68      7.03      0.90      0.00      5.07    866.03      1.00\n",
      "lambda[103]      2.33      4.26      0.94      0.00      5.72    776.47      1.00\n",
      "lambda[104]      3.27     14.29      0.95      0.00      6.17    669.89      1.00\n",
      "lambda[105]      3.04      9.24      1.00      0.00      6.72    774.78      1.00\n",
      "lambda[106]      2.55      5.85      1.05      0.01      5.35    601.55      1.00\n",
      "lambda[107]      3.49     12.10      1.04      0.00      5.61    481.57      1.00\n",
      "lambda[108]      2.70      9.25      0.93      0.00      5.27    808.74      1.00\n",
      "lambda[109]      2.81      6.23      0.94      0.00      6.46    716.69      1.00\n",
      "lambda[110]      3.57     17.67      1.05      0.01      6.29    838.96      1.00\n",
      "lambda[111]      4.31     17.31      0.94      0.00      7.00    761.90      1.01\n",
      "lambda[112]      2.58      5.64      0.92      0.00      5.92    986.06      1.00\n",
      "lambda[113]      3.97     18.52      0.98      0.00      6.90    624.82      1.00\n",
      "lambda[114]      3.57     11.69      0.97      0.00      6.53    748.68      1.00\n",
      "lambda[115]      4.15     17.20      0.94      0.00      6.22    750.38      1.00\n",
      "lambda[116]      3.75     17.99      1.00      0.00      5.72    509.16      1.00\n",
      "lambda[117]      3.19     10.07      0.93      0.00      6.24    809.12      1.00\n",
      "lambda[118]      3.00     10.74      0.97      0.00      6.29    905.12      1.00\n",
      "lambda[119]      3.20     13.67      1.05      0.00      6.09    689.20      1.00\n",
      "lambda[120]      4.05     25.70      0.95      0.00      5.46    805.89      1.00\n",
      "lambda[121]      3.17     11.20      0.96      0.00      6.03    857.71      1.00\n",
      "lambda[122]      3.36     10.00      1.00      0.00      6.10    936.32      1.00\n",
      "lambda[123]      2.59      5.49      0.92      0.00      6.38    760.22      1.01\n",
      "lambda[124]      2.84      8.20      0.98      0.01      5.51    524.34      1.00\n",
      "lambda[125]      2.77      7.21      0.95      0.01      5.94    579.36      1.00\n",
      "lambda[126]      2.39      5.16      0.94      0.00      5.18    828.35      1.00\n",
      "lambda[127]      3.62     11.49      0.97      0.00      6.65    572.10      1.00\n",
      "lambda[128]      3.10     13.90      0.96      0.00      5.01    385.77      1.00\n",
      "lambda[129]      3.92     18.10      0.95      0.00      6.26    919.36      1.00\n",
      "lambda[130]      3.12      8.02      0.97      0.00      6.34    625.73      1.00\n",
      "lambda[131]      3.34     12.43      0.95      0.00      5.93    776.33      1.00\n",
      "lambda[132]      2.35      4.61      0.97      0.00      5.13    908.81      1.00\n",
      "lambda[133]      2.55      6.49      0.99      0.00      5.56    874.27      1.00\n",
      "lambda[134]      3.38      8.51      0.90      0.00      7.17    770.70      1.00\n",
      "lambda[135]      2.90     15.26      0.94      0.00      4.18    802.64      1.00\n",
      "lambda[136]      3.07     10.45      0.99      0.00      6.43    915.23      1.00\n",
      "lambda[137]      2.59      6.58      0.99      0.00      5.57    657.49      1.00\n",
      "lambda[138]      3.07     10.69      1.05      0.00      5.51    797.43      1.00\n",
      "lambda[139]      3.42      9.73      1.00      0.00      6.25    937.66      1.00\n",
      "lambda[140]      2.98      8.28      0.94      0.00      5.50    916.54      1.00\n",
      "lambda[141]      2.28      4.36      0.98      0.00      5.05    771.24      1.00\n",
      "lambda[142]      4.27     23.15      0.96      0.01      5.55    718.91      1.00\n",
      "lambda[143]      2.56      5.95      1.00      0.00      5.08    563.57      1.00\n",
      "        msq    916.96  14267.06      6.27      0.20    197.18   1000.78      1.00\n",
      "      sigma      4.49      6.05      2.00      0.01     12.56   1147.57      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1004.22      1.00\n",
      "       xisq      1.19      0.63      1.03      0.40      1.99   1274.69      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 32.829785108566284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.38e-04 +- 2.01e-02\n",
      "[dimension 02/145]  inactive:\t-2.01e-04 +- 2.60e-02\n",
      "[dimension 03/145]  inactive:\t3.09e-04 +- 2.27e-02\n",
      "[dimension 04/145]  inactive:\t5.19e-03 +- 4.00e-02\n",
      "[dimension 05/145]  inactive:\t-5.97e-04 +- 2.80e-02\n",
      "[dimension 06/145]  inactive:\t1.76e-03 +- 3.67e-02\n",
      "[dimension 07/145]  inactive:\t9.19e-04 +- 1.89e-02\n",
      "[dimension 08/145]  inactive:\t9.61e-04 +- 2.94e-02\n",
      "[dimension 09/145]  inactive:\t1.65e-04 +- 2.30e-02\n",
      "[dimension 10/145]  inactive:\t4.04e-04 +- 1.83e-02\n",
      "[dimension 11/145]  inactive:\t-8.50e-04 +- 2.44e-02\n",
      "[dimension 12/145]  inactive:\t-2.67e-04 +- 2.54e-02\n",
      "[dimension 13/145]  inactive:\t5.87e-03 +- 4.54e-02\n",
      "[dimension 14/145]  inactive:\t-9.43e-04 +- 2.26e-02\n",
      "[dimension 15/145]  inactive:\t1.57e-03 +- 4.18e-02\n",
      "[dimension 16/145]  inactive:\t9.69e-04 +- 1.95e-02\n",
      "[dimension 17/145]  inactive:\t4.55e-04 +- 3.66e-02\n",
      "[dimension 18/145]  inactive:\t1.02e-03 +- 3.16e-02\n",
      "[dimension 19/145]  inactive:\t-1.70e-03 +- 1.86e-02\n",
      "[dimension 20/145]  inactive:\t-9.25e-04 +- 2.65e-02\n",
      "[dimension 21/145]  inactive:\t-2.56e-03 +- 2.92e-02\n",
      "[dimension 22/145]  inactive:\t1.70e-04 +- 2.49e-02\n",
      "[dimension 23/145]  inactive:\t-7.91e-04 +- 3.00e-02\n",
      "[dimension 24/145]  inactive:\t1.77e-03 +- 2.80e-02\n",
      "[dimension 25/145]  inactive:\t3.03e-03 +- 2.23e-02\n",
      "[dimension 26/145]  inactive:\t-9.57e-04 +- 2.95e-02\n",
      "[dimension 27/145]  inactive:\t1.01e-03 +- 2.52e-02\n",
      "[dimension 28/145]  inactive:\t9.37e-04 +- 2.15e-02\n",
      "[dimension 29/145]  inactive:\t6.95e-05 +- 2.76e-02\n",
      "[dimension 30/145]  inactive:\t1.38e-03 +- 2.84e-02\n",
      "[dimension 31/145]  inactive:\t5.13e-03 +- 3.73e-02\n",
      "[dimension 32/145]  inactive:\t-1.66e-03 +- 3.09e-02\n",
      "[dimension 33/145]  inactive:\t2.61e-03 +- 3.98e-02\n",
      "[dimension 34/145]  inactive:\t9.47e-04 +- 2.06e-02\n",
      "[dimension 35/145]  inactive:\t1.30e-04 +- 2.64e-02\n",
      "[dimension 36/145]  inactive:\t5.54e-04 +- 2.17e-02\n",
      "[dimension 37/145]  inactive:\t3.91e-03 +- 2.66e-02\n",
      "[dimension 38/145]  inactive:\t-1.50e-03 +- 2.94e-02\n",
      "[dimension 39/145]  inactive:\t9.26e-04 +- 2.80e-02\n",
      "[dimension 40/145]  inactive:\t4.61e-03 +- 3.80e-02\n",
      "[dimension 41/145]  inactive:\t-1.81e-03 +- 3.61e-02\n",
      "[dimension 42/145]  inactive:\t2.85e-02 +- 1.47e-01\n",
      "[dimension 43/145]  inactive:\t-2.22e-04 +- 1.98e-02\n",
      "[dimension 44/145]  inactive:\t-6.51e-04 +- 2.38e-02\n",
      "[dimension 45/145]  inactive:\t3.31e-04 +- 2.35e-02\n",
      "[dimension 46/145]  inactive:\t1.03e-03 +- 1.76e-02\n",
      "[dimension 47/145]  inactive:\t-1.36e-03 +- 2.39e-02\n",
      "[dimension 48/145]  inactive:\t1.46e-03 +- 2.72e-02\n",
      "[dimension 49/145]  inactive:\t2.48e-03 +- 2.42e-02\n",
      "[dimension 50/145]  inactive:\t-1.51e-03 +- 2.56e-02\n",
      "[dimension 51/145]  inactive:\t2.10e-03 +- 2.46e-02\n",
      "[dimension 52/145]  inactive:\t6.26e-03 +- 2.73e-02\n",
      "[dimension 53/145]  inactive:\t-1.13e-03 +- 2.83e-02\n",
      "[dimension 54/145]  inactive:\t-2.39e-04 +- 2.31e-02\n",
      "[dimension 55/145]  inactive:\t6.93e-04 +- 1.76e-02\n",
      "[dimension 56/145]  inactive:\t-2.94e-03 +- 2.54e-02\n",
      "[dimension 57/145]  inactive:\t1.18e-03 +- 2.80e-02\n",
      "[dimension 58/145]  inactive:\t1.39e-02 +- 7.44e-02\n",
      "[dimension 59/145]  inactive:\t-8.90e-04 +- 1.82e-02\n",
      "[dimension 60/145]  inactive:\t1.88e-03 +- 3.67e-02\n",
      "[dimension 61/145]  inactive:\t2.57e-03 +- 2.53e-02\n",
      "[dimension 62/145]  inactive:\t-5.58e-04 +- 2.09e-02\n",
      "[dimension 63/145]  active:\t6.30e-01 +- 4.49e-01\n",
      "[dimension 64/145]  inactive:\t-3.27e-03 +- 2.89e-02\n",
      "[dimension 65/145]  inactive:\t-1.93e-06 +- 2.35e-02\n",
      "[dimension 66/145]  inactive:\t8.19e-04 +- 2.61e-02\n",
      "[dimension 67/145]  inactive:\t2.32e-03 +- 2.73e-02\n",
      "[dimension 68/145]  inactive:\t-2.89e-04 +- 2.66e-02\n",
      "[dimension 69/145]  inactive:\t3.50e-03 +- 3.75e-02\n",
      "[dimension 70/145]  inactive:\t3.76e-03 +- 2.43e-02\n",
      "[dimension 71/145]  inactive:\t8.60e-05 +- 2.42e-02\n",
      "[dimension 72/145]  inactive:\t5.27e-04 +- 2.29e-02\n",
      "[dimension 73/145]  inactive:\t1.96e-04 +- 1.97e-02\n",
      "[dimension 74/145]  inactive:\t-1.16e-03 +- 3.61e-02\n",
      "[dimension 75/145]  inactive:\t4.15e-04 +- 2.21e-02\n",
      "[dimension 76/145]  inactive:\t5.84e-03 +- 4.10e-02\n",
      "[dimension 77/145]  inactive:\t-1.89e-03 +- 3.15e-02\n",
      "[dimension 78/145]  inactive:\t1.06e-02 +- 8.04e-02\n",
      "[dimension 79/145]  inactive:\t5.50e-03 +- 3.20e-02\n",
      "[dimension 80/145]  inactive:\t2.56e-04 +- 3.31e-02\n",
      "[dimension 81/145]  inactive:\t1.32e-03 +- 3.29e-02\n",
      "[dimension 82/145]  inactive:\t2.68e-04 +- 1.61e-02\n",
      "[dimension 83/145]  inactive:\t-1.66e-03 +- 1.75e-02\n",
      "[dimension 84/145]  inactive:\t-9.49e-04 +- 2.24e-02\n",
      "[dimension 85/145]  inactive:\t2.12e-03 +- 2.60e-02\n",
      "[dimension 86/145]  inactive:\t-8.98e-04 +- 2.12e-02\n",
      "[dimension 87/145]  inactive:\t1.85e-03 +- 3.64e-02\n",
      "[dimension 88/145]  inactive:\t3.47e-03 +- 2.96e-02\n",
      "[dimension 89/145]  inactive:\t-7.60e-04 +- 2.03e-02\n",
      "[dimension 90/145]  inactive:\t1.64e-01 +- 3.41e-01\n",
      "[dimension 91/145]  inactive:\t1.90e-04 +- 1.98e-02\n",
      "[dimension 92/145]  inactive:\t-1.72e-03 +- 2.81e-02\n",
      "[dimension 93/145]  inactive:\t-6.69e-04 +- 2.69e-02\n",
      "[dimension 94/145]  inactive:\t2.23e-03 +- 2.81e-02\n",
      "[dimension 95/145]  inactive:\t-3.51e-04 +- 2.31e-02\n",
      "[dimension 96/145]  inactive:\t2.52e-03 +- 4.73e-02\n",
      "[dimension 97/145]  inactive:\t2.36e-03 +- 2.35e-02\n",
      "[dimension 98/145]  inactive:\t-9.40e-04 +- 2.82e-02\n",
      "[dimension 99/145]  inactive:\t3.50e-03 +- 4.64e-02\n",
      "[dimension 100/145]  inactive:\t-5.10e-04 +- 1.59e-02\n",
      "[dimension 101/145]  inactive:\t-2.61e-03 +- 2.25e-02\n",
      "[dimension 102/145]  inactive:\t-3.43e-04 +- 2.12e-02\n",
      "[dimension 103/145]  inactive:\t1.42e-03 +- 2.55e-02\n",
      "[dimension 104/145]  inactive:\t-1.01e-03 +- 1.76e-02\n",
      "[dimension 105/145]  inactive:\t2.71e-05 +- 2.66e-02\n",
      "[dimension 106/145]  inactive:\t4.78e-03 +- 3.24e-02\n",
      "[dimension 107/145]  inactive:\t-1.27e-03 +- 2.18e-02\n",
      "[dimension 108/145]  inactive:\t7.59e-03 +- 6.58e-02\n",
      "[dimension 109/145]  inactive:\t-5.11e-04 +- 2.09e-02\n",
      "[dimension 110/145]  inactive:\t-1.10e-03 +- 2.91e-02\n",
      "[dimension 111/145]  inactive:\t1.51e-03 +- 2.90e-02\n",
      "[dimension 112/145]  inactive:\t5.82e-03 +- 4.35e-02\n",
      "[dimension 113/145]  inactive:\t-9.83e-04 +- 1.95e-02\n",
      "[dimension 114/145]  inactive:\t9.37e-04 +- 3.25e-02\n",
      "[dimension 115/145]  inactive:\t2.26e-03 +- 2.49e-02\n",
      "[dimension 116/145]  inactive:\t7.00e-04 +- 3.67e-02\n",
      "[dimension 117/145]  inactive:\t5.31e-03 +- 5.14e-02\n",
      "[dimension 118/145]  inactive:\t3.15e-03 +- 2.68e-02\n",
      "[dimension 119/145]  inactive:\t-1.67e-03 +- 2.77e-02\n",
      "[dimension 120/145]  inactive:\t7.36e-04 +- 3.30e-02\n",
      "[dimension 121/145]  inactive:\t4.06e-03 +- 3.63e-02\n",
      "[dimension 122/145]  inactive:\t-2.39e-03 +- 2.95e-02\n",
      "[dimension 123/145]  inactive:\t2.89e-03 +- 4.63e-02\n",
      "[dimension 124/145]  inactive:\t-1.34e-03 +- 1.99e-02\n",
      "[dimension 125/145]  inactive:\t-1.35e-03 +- 2.93e-02\n",
      "[dimension 126/145]  inactive:\t-5.95e-04 +- 2.25e-02\n",
      "[dimension 127/145]  inactive:\t2.08e-04 +- 1.73e-02\n",
      "[dimension 128/145]  inactive:\t-2.84e-04 +- 3.19e-02\n",
      "[dimension 129/145]  inactive:\t6.47e-04 +- 2.80e-02\n",
      "[dimension 130/145]  inactive:\t3.29e-03 +- 2.76e-02\n",
      "[dimension 131/145]  inactive:\t-9.77e-04 +- 3.10e-02\n",
      "[dimension 132/145]  inactive:\t5.00e-03 +- 4.62e-02\n",
      "[dimension 133/145]  inactive:\t1.89e-03 +- 1.87e-02\n",
      "[dimension 134/145]  inactive:\t-4.50e-04 +- 2.36e-02\n",
      "[dimension 135/145]  inactive:\t7.45e-04 +- 2.88e-02\n",
      "[dimension 136/145]  inactive:\t1.12e-03 +- 1.96e-02\n",
      "[dimension 137/145]  inactive:\t1.80e-04 +- 3.23e-02\n",
      "[dimension 138/145]  inactive:\t4.20e-04 +- 2.20e-02\n",
      "[dimension 139/145]  inactive:\t5.67e-04 +- 2.28e-02\n",
      "[dimension 140/145]  inactive:\t-1.21e-03 +- 3.24e-02\n",
      "[dimension 141/145]  inactive:\t1.74e-03 +- 3.30e-02\n",
      "[dimension 142/145]  inactive:\t1.18e-03 +- 1.81e-02\n",
      "[dimension 143/145]  inactive:\t9.39e-04 +- 3.16e-02\n",
      "[dimension 144/145]  inactive:\t2.72e-04 +- 2.09e-02\n",
      "[dimension 145/145]  inactive:\t-2.12e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.0039902]\n",
      "cov_act[[0.03329992]]\n",
      "Active_dimensions: [62]\n",
      "55, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.57it/s, 31 steps of size 1.60e-01. acc. prob=0.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    428.13      1.00\n",
      "  lambda[0]      2.22      4.65      0.96      0.00      4.43    665.42      1.00\n",
      "  lambda[1]      2.78     12.01      1.04      0.00      5.26    746.46      1.00\n",
      "  lambda[2]      3.25      9.54      1.08      0.00      6.35    508.72      1.00\n",
      "  lambda[3]      5.33     39.56      0.97      0.00      7.06    601.04      1.00\n",
      "  lambda[4]      2.78      5.97      1.01      0.00      5.67    536.85      1.00\n",
      "  lambda[5]     16.19    368.59      0.95      0.00      5.92    832.56      1.00\n",
      "  lambda[6]      4.44     15.31      1.05      0.00      8.07    702.41      1.00\n",
      "  lambda[7]      2.74      6.98      0.97      0.00      5.60    584.61      1.01\n",
      "  lambda[8]      2.55      5.79      1.04      0.00      5.53    784.18      1.00\n",
      "  lambda[9]      2.60      8.36      0.97      0.00      5.27    832.01      1.00\n",
      " lambda[10]      3.34      9.88      0.98      0.00      5.72    568.02      1.01\n",
      " lambda[11]      2.77      7.65      0.96      0.00      5.30    619.39      1.00\n",
      " lambda[12]      4.48     15.09      0.99      0.00      8.49    604.49      1.00\n",
      " lambda[13]      2.35      5.49      0.96      0.00      5.20    872.48      1.00\n",
      " lambda[14]      4.28     23.91      0.98      0.00      6.49    987.12      1.00\n",
      " lambda[15]      3.72     11.88      1.05      0.00      5.80    552.01      1.00\n",
      " lambda[16]      3.37      9.20      0.95      0.00      7.60    713.79      1.01\n",
      " lambda[17]      6.31    107.85      0.99      0.00      5.25   1003.43      1.00\n",
      " lambda[18]      2.68      5.59      0.98      0.00      6.65    536.44      1.00\n",
      " lambda[19]      3.50     14.92      1.01      0.00      6.21    619.93      1.00\n",
      " lambda[20]      2.51      5.26      0.94      0.00      5.81    518.51      1.00\n",
      " lambda[21]      3.59     13.76      1.01      0.00      6.84    510.81      1.00\n",
      " lambda[22]      2.33      7.43      0.93      0.00      4.64    729.81      1.00\n",
      " lambda[23]      2.59      5.98      0.94      0.00      5.82    854.06      1.00\n",
      " lambda[24]      3.98     18.36      1.00      0.00      6.10    585.22      1.00\n",
      " lambda[25]      3.05      7.64      0.96      0.00      6.91    445.26      1.00\n",
      " lambda[26]      2.89     13.94      1.00      0.00      5.27    830.34      1.00\n",
      " lambda[27]      3.08      9.08      0.99      0.00      5.69    535.65      1.00\n",
      " lambda[28]      3.12     11.94      1.01      0.00      5.69    626.27      1.00\n",
      " lambda[29]      2.57      5.86      0.95      0.00      5.61    734.71      1.00\n",
      " lambda[30]      4.50     27.22      1.02      0.00      6.47    836.10      1.00\n",
      " lambda[31]      3.39     13.33      1.03      0.00      6.06    818.48      1.00\n",
      " lambda[32]      3.03      7.54      0.97      0.00      6.25    774.27      1.00\n",
      " lambda[33]      3.33     12.07      0.97      0.00      6.31    804.93      1.00\n",
      " lambda[34]      2.97     12.22      0.96      0.00      4.99    566.62      1.00\n",
      " lambda[35]      2.79      7.96      1.00      0.00      5.35    675.62      1.00\n",
      " lambda[36]      3.63     14.89      1.03      0.00      6.17    767.62      1.00\n",
      " lambda[37]      4.50     28.91      0.99      0.00      7.43    945.77      1.00\n",
      " lambda[38]      3.35     10.18      0.99      0.00      6.91    673.08      1.00\n",
      " lambda[39]      3.59     10.57      0.98      0.00      5.99    509.93      1.00\n",
      " lambda[40]      3.71     16.32      0.90      0.01      5.44    711.31      1.00\n",
      " lambda[41]     36.89    355.81      0.94      0.00     10.62    227.42      1.00\n",
      " lambda[42]      2.77      7.79      0.97      0.00      6.23    841.06      1.00\n",
      " lambda[43]      3.35     18.30      1.01      0.00      5.80    988.06      1.00\n",
      " lambda[44]      2.80     10.47      0.91      0.00      5.42    731.45      1.00\n",
      " lambda[45]      2.51      6.47      0.94      0.00      4.85    615.21      1.00\n",
      " lambda[46]      2.37      5.44      0.99      0.00      4.66    642.41      1.00\n",
      " lambda[47]      2.41      5.20      1.00      0.01      5.35    664.66      1.00\n",
      " lambda[48]      2.71      9.85      0.98      0.01      5.17    942.95      1.00\n",
      " lambda[49]      2.86      7.41      1.00      0.00      6.02    678.61      1.00\n",
      " lambda[50]      2.55      6.36      0.93      0.00      5.45    869.04      1.00\n",
      " lambda[51]      5.46     33.37      1.02      0.00      7.62    804.38      1.00\n",
      " lambda[52]      2.77      7.26      1.02      0.00      5.43    907.32      1.00\n",
      " lambda[53]      2.88      8.66      0.99      0.00      5.27    780.92      1.00\n",
      " lambda[54]      2.19      5.40      0.95      0.00      4.17    723.16      1.00\n",
      " lambda[55]      2.87     10.09      0.95      0.00      5.55    787.99      1.00\n",
      " lambda[56]      2.41      5.01      0.97      0.00      4.98    778.63      1.00\n",
      " lambda[57]      5.16     32.27      0.97      0.00      6.72    576.10      1.00\n",
      " lambda[58]      2.40      5.10      1.02      0.00      5.64    621.06      1.00\n",
      " lambda[59]      3.38      9.73      0.97      0.00      7.66    554.01      1.00\n",
      " lambda[60]      3.57     12.38      0.97      0.00      7.12    694.16      1.00\n",
      " lambda[61]      2.58      5.71      1.02      0.00      5.50    649.26      1.00\n",
      " lambda[62]   6426.26  97754.75    489.16      0.00   4644.13    627.85      1.00\n",
      " lambda[63]      2.42      7.35      0.98      0.00      4.87    713.82      1.00\n",
      " lambda[64]      2.81      6.68      0.96      0.00      5.52    626.37      1.00\n",
      " lambda[65]      2.38      6.13      0.95      0.00      5.20    994.00      1.00\n",
      " lambda[66]      3.30     12.03      0.99      0.00      6.56    719.91      1.00\n",
      " lambda[67]      3.36     26.99      0.95      0.00      5.64    941.68      1.00\n",
      " lambda[68]      4.52     35.57      0.96      0.01      5.54    560.83      1.00\n",
      " lambda[69]      3.95     20.07      0.96      0.00      6.14    775.28      1.00\n",
      " lambda[70]      3.34     11.33      1.00      0.00      5.77    592.13      1.00\n",
      " lambda[71]      2.55      6.77      1.04      0.00      5.12    648.56      1.00\n",
      " lambda[72]      2.59      6.55      0.97      0.01      5.27    938.33      1.00\n",
      " lambda[73]      2.80      7.63      1.01      0.00      5.31    504.89      1.00\n",
      " lambda[74]      2.58      5.12      1.04      0.00      5.74    802.54      1.00\n",
      " lambda[75]      5.09     21.30      1.10      0.00      7.63    600.18      1.00\n",
      " lambda[76]      2.75      6.60      0.99      0.00      6.05    815.20      1.00\n",
      " lambda[77]     16.88    208.73      1.01      0.00      5.94    527.42      1.00\n",
      " lambda[78]      3.36     12.21      1.04      0.00      6.59    621.83      1.00\n",
      " lambda[79]      3.12      9.65      0.97      0.00      5.61    561.00      1.00\n",
      " lambda[80]      7.35     57.63      1.00      0.00      6.43    648.46      1.00\n",
      " lambda[81]      2.37      5.59      0.97      0.00      4.79    979.02      1.00\n",
      " lambda[82]      2.27      5.26      0.95      0.01      4.81    801.25      1.00\n",
      " lambda[83]      2.57      7.10      0.87      0.00      5.54    834.23      1.00\n",
      " lambda[84]      4.24     27.17      0.95      0.00      6.02    506.74      1.00\n",
      " lambda[85]      2.91      6.96      0.93      0.00      6.77    490.57      1.00\n",
      " lambda[86]      3.08      7.85      1.02      0.00      6.24    758.32      1.00\n",
      " lambda[87]      2.88      9.31      1.01      0.01      5.36    585.90      1.00\n",
      " lambda[88]      2.52      5.34      0.92      0.00      5.85    696.76      1.00\n",
      " lambda[89]    227.54   2777.37      1.21      0.00     60.49    677.63      1.00\n",
      " lambda[90]      2.85      6.42      1.04      0.00      6.31    699.70      1.00\n",
      " lambda[91]      2.29      4.52      0.98      0.01      4.80    701.20      1.00\n",
      " lambda[92]      2.84      9.06      1.01      0.00      5.02    572.41      1.00\n",
      " lambda[93]      2.68      9.15      1.08      0.00      5.23    790.63      1.00\n",
      " lambda[94]      2.79      8.41      0.94      0.00      5.72    623.27      1.00\n",
      " lambda[95]      3.16     11.46      0.98      0.00      5.81    626.45      1.00\n",
      " lambda[96]      3.31     15.07      0.96      0.00      5.37    599.39      1.00\n",
      " lambda[97]      6.71     86.60      0.94      0.00      5.36    511.90      1.00\n",
      " lambda[98]      5.35     37.18      0.98      0.00      5.76    557.53      1.00\n",
      " lambda[99]      2.47      6.60      0.97      0.00      5.00    814.80      1.00\n",
      "lambda[100]      2.59      6.76      0.94      0.00      5.46    773.31      1.00\n",
      "lambda[101]      2.52      6.84      0.97      0.00      4.93    641.60      1.00\n",
      "lambda[102]      2.83      8.61      0.85      0.00      4.63    435.74      1.00\n",
      "lambda[103]      2.39      4.72      0.97      0.00      5.69    827.28      1.00\n",
      "lambda[104]      2.70      8.67      0.99      0.00      5.97    530.12      1.00\n",
      "lambda[105]      3.46     13.48      1.02      0.00      7.14    647.91      1.00\n",
      "lambda[106]      2.29      4.30      0.96      0.00      5.28    814.00      1.00\n",
      "lambda[107]      4.26     22.56      1.03      0.00      5.94    661.32      1.00\n",
      "lambda[108]      2.23      4.82      0.93      0.01      4.43    654.56      1.00\n",
      "lambda[109]      3.69     14.44      0.98      0.00      7.07    792.06      1.00\n",
      "lambda[110]      3.11     13.69      0.95      0.00      5.08    880.72      1.00\n",
      "lambda[111]      3.98     14.82      0.97      0.00      6.41    489.49      1.00\n",
      "lambda[112]      2.71     11.51      0.96      0.00      5.13    830.98      1.00\n",
      "lambda[113]      3.66     16.34      1.01      0.00      6.55    534.91      1.00\n",
      "lambda[114]      3.52     10.81      1.04      0.00      6.45    787.97      1.00\n",
      "lambda[115]      3.92     15.16      0.92      0.00      5.33    615.58      1.00\n",
      "lambda[116]      6.25     62.53      1.02      0.00      5.34    482.55      1.00\n",
      "lambda[117]      3.20     10.19      0.98      0.00      6.43    950.74      1.00\n",
      "lambda[118]      2.79      9.20      0.91      0.00      5.45    869.19      1.00\n",
      "lambda[119]      3.03     12.37      1.03      0.00      5.90    797.60      1.00\n",
      "lambda[120]      4.10     19.81      0.95      0.00      6.52    744.97      1.00\n",
      "lambda[121]      2.95     11.54      0.90      0.00      5.25    918.73      1.00\n",
      "lambda[122]      4.38     23.62      1.00      0.00      7.58    480.94      1.00\n",
      "lambda[123]      2.64      6.78      0.91      0.00      5.30    605.26      1.00\n",
      "lambda[124]      2.40      4.05      0.98      0.00      5.78    592.44      1.00\n",
      "lambda[125]      2.69      6.10      0.92      0.00      5.54    535.28      1.00\n",
      "lambda[126]      2.87      8.59      1.00      0.00      5.00    761.27      1.00\n",
      "lambda[127]      4.23     19.25      1.01      0.00      7.24    512.12      1.00\n",
      "lambda[128]      3.63     24.51      0.99      0.00      4.89    438.94      1.00\n",
      "lambda[129]      5.96     49.87      0.99      0.00      8.35    960.83      1.00\n",
      "lambda[130]      3.42     14.33      1.00      0.00      6.50    844.49      1.00\n",
      "lambda[131]      3.96     18.89      0.96      0.00      5.98    642.92      1.00\n",
      "lambda[132]      3.60     13.92      0.99      0.00      6.30    469.81      1.00\n",
      "lambda[133]      2.69      6.41      0.99      0.00      5.81    775.18      1.00\n",
      "lambda[134]      3.23      8.27      0.95      0.00      6.81    717.55      1.00\n",
      "lambda[135]      2.31      5.40      0.96      0.00      4.69    511.65      1.00\n",
      "lambda[136]      3.08     10.63      0.97      0.00      5.50    753.43      1.00\n",
      "lambda[137]      2.79     10.28      0.90      0.00      4.84    607.49      1.00\n",
      "lambda[138]      2.96      7.79      1.05      0.00      5.01    537.02      1.00\n",
      "lambda[139]      4.14     27.78      1.04      0.00      5.98    769.80      1.00\n",
      "lambda[140]      3.15     10.65      1.00      0.00      5.48    893.90      1.00\n",
      "lambda[141]      2.78     11.27      0.87      0.00      5.49    637.91      1.00\n",
      "lambda[142]     19.30    358.70      1.00      0.00      6.63    684.66      1.00\n",
      "lambda[143]      2.47      6.81      0.98      0.00      4.91    711.76      1.00\n",
      "        msq      0.25      0.17      0.21      0.06      0.43    809.06      1.00\n",
      "      sigma      3.77      5.73      1.30      0.00     11.19   1344.98      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    641.50      1.00\n",
      "       xisq      1.06      0.52      0.94      0.43      1.75   1116.94      1.00\n",
      "\n",
      "Number of divergences: 6\n",
      "\n",
      "MCMC elapsed time: 32.19644808769226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.59e-04 +- 9.86e-03\n",
      "[dimension 02/145]  inactive:\t4.05e-04 +- 1.21e-02\n",
      "[dimension 03/145]  inactive:\t8.53e-04 +- 1.63e-02\n",
      "[dimension 04/145]  inactive:\t3.50e-03 +- 3.12e-02\n",
      "[dimension 05/145]  inactive:\t2.26e-04 +- 1.18e-02\n",
      "[dimension 06/145]  inactive:\t2.23e-03 +- 3.09e-02\n",
      "[dimension 07/145]  inactive:\t1.13e-03 +- 1.39e-02\n",
      "[dimension 08/145]  inactive:\t1.14e-03 +- 1.98e-02\n",
      "[dimension 09/145]  inactive:\t7.73e-04 +- 1.49e-02\n",
      "[dimension 10/145]  inactive:\t4.09e-04 +- 9.20e-03\n",
      "[dimension 11/145]  inactive:\t8.66e-04 +- 1.81e-02\n",
      "[dimension 12/145]  inactive:\t6.35e-04 +- 1.37e-02\n",
      "[dimension 13/145]  inactive:\t2.58e-03 +- 2.54e-02\n",
      "[dimension 14/145]  inactive:\t3.31e-04 +- 1.53e-02\n",
      "[dimension 15/145]  inactive:\t1.67e-03 +- 2.60e-02\n",
      "[dimension 16/145]  inactive:\t8.30e-04 +- 1.73e-02\n",
      "[dimension 17/145]  inactive:\t6.37e-04 +- 1.51e-02\n",
      "[dimension 18/145]  inactive:\t1.51e-03 +- 2.51e-02\n",
      "[dimension 19/145]  inactive:\t-2.52e-04 +- 9.59e-03\n",
      "[dimension 20/145]  inactive:\t4.70e-04 +- 1.57e-02\n",
      "[dimension 21/145]  inactive:\t-2.15e-04 +- 1.22e-02\n",
      "[dimension 22/145]  inactive:\t5.83e-04 +- 1.30e-02\n",
      "[dimension 23/145]  inactive:\t1.89e-04 +- 1.36e-02\n",
      "[dimension 24/145]  inactive:\t6.93e-04 +- 1.43e-02\n",
      "[dimension 25/145]  inactive:\t1.99e-03 +- 1.67e-02\n",
      "[dimension 26/145]  inactive:\t1.27e-04 +- 1.59e-02\n",
      "[dimension 27/145]  inactive:\t6.78e-04 +- 1.36e-02\n",
      "[dimension 28/145]  inactive:\t8.30e-04 +- 1.31e-02\n",
      "[dimension 29/145]  inactive:\t8.97e-04 +- 2.05e-02\n",
      "[dimension 30/145]  inactive:\t7.15e-04 +- 1.34e-02\n",
      "[dimension 31/145]  inactive:\t4.10e-03 +- 3.59e-02\n",
      "[dimension 32/145]  inactive:\t3.21e-04 +- 1.40e-02\n",
      "[dimension 33/145]  inactive:\t2.15e-03 +- 2.85e-02\n",
      "[dimension 34/145]  inactive:\t7.82e-04 +- 1.31e-02\n",
      "[dimension 35/145]  inactive:\t9.12e-04 +- 1.71e-02\n",
      "[dimension 36/145]  inactive:\t1.01e-03 +- 1.54e-02\n",
      "[dimension 37/145]  inactive:\t2.39e-03 +- 1.93e-02\n",
      "[dimension 38/145]  inactive:\t2.79e-04 +- 2.14e-02\n",
      "[dimension 39/145]  inactive:\t1.51e-03 +- 2.18e-02\n",
      "[dimension 40/145]  inactive:\t3.58e-03 +- 3.12e-02\n",
      "[dimension 41/145]  inactive:\t2.60e-04 +- 1.53e-02\n",
      "[dimension 42/145]  inactive:\t2.37e-02 +- 1.32e-01\n",
      "[dimension 43/145]  inactive:\t5.06e-04 +- 1.17e-02\n",
      "[dimension 44/145]  inactive:\t6.76e-04 +- 1.93e-02\n",
      "[dimension 45/145]  inactive:\t5.86e-04 +- 1.46e-02\n",
      "[dimension 46/145]  inactive:\t5.05e-04 +- 9.78e-03\n",
      "[dimension 47/145]  inactive:\t4.74e-05 +- 1.41e-02\n",
      "[dimension 48/145]  inactive:\t5.54e-04 +- 1.45e-02\n",
      "[dimension 49/145]  inactive:\t1.02e-03 +- 1.68e-02\n",
      "[dimension 50/145]  inactive:\t-3.31e-05 +- 1.68e-02\n",
      "[dimension 51/145]  inactive:\t1.36e-03 +- 2.07e-02\n",
      "[dimension 52/145]  inactive:\t3.53e-03 +- 1.94e-02\n",
      "[dimension 53/145]  inactive:\t-1.03e-05 +- 1.35e-02\n",
      "[dimension 54/145]  inactive:\t8.19e-04 +- 1.54e-02\n",
      "[dimension 55/145]  inactive:\t3.05e-04 +- 8.95e-03\n",
      "[dimension 56/145]  inactive:\t-6.43e-04 +- 1.46e-02\n",
      "[dimension 57/145]  inactive:\t6.04e-04 +- 1.26e-02\n",
      "[dimension 58/145]  inactive:\t6.62e-03 +- 4.97e-02\n",
      "[dimension 59/145]  inactive:\t-8.69e-05 +- 1.02e-02\n",
      "[dimension 60/145]  inactive:\t1.55e-03 +- 2.15e-02\n",
      "[dimension 61/145]  inactive:\t2.08e-03 +- 1.99e-02\n",
      "[dimension 62/145]  inactive:\t7.49e-07 +- 1.00e-02\n",
      "[dimension 63/145]  active:\t6.90e-01 +- 3.76e-01\n",
      "[dimension 64/145]  inactive:\t-4.31e-04 +- 1.01e-02\n",
      "[dimension 65/145]  inactive:\t3.91e-04 +- 1.34e-02\n",
      "[dimension 66/145]  inactive:\t4.18e-04 +- 1.19e-02\n",
      "[dimension 67/145]  inactive:\t9.87e-04 +- 1.66e-02\n",
      "[dimension 68/145]  inactive:\t3.61e-04 +- 1.53e-02\n",
      "[dimension 69/145]  inactive:\t1.91e-03 +- 2.41e-02\n",
      "[dimension 70/145]  inactive:\t2.72e-03 +- 2.00e-02\n",
      "[dimension 71/145]  inactive:\t1.30e-03 +- 2.48e-02\n",
      "[dimension 72/145]  inactive:\t7.07e-04 +- 1.29e-02\n",
      "[dimension 73/145]  inactive:\t3.79e-04 +- 1.00e-02\n",
      "[dimension 74/145]  inactive:\t1.41e-03 +- 2.62e-02\n",
      "[dimension 75/145]  inactive:\t6.30e-04 +- 1.29e-02\n",
      "[dimension 76/145]  inactive:\t3.86e-03 +- 2.96e-02\n",
      "[dimension 77/145]  inactive:\t1.61e-04 +- 1.53e-02\n",
      "[dimension 78/145]  inactive:\t7.51e-03 +- 7.07e-02\n",
      "[dimension 79/145]  inactive:\t2.61e-03 +- 1.92e-02\n",
      "[dimension 80/145]  inactive:\t1.21e-03 +- 2.32e-02\n",
      "[dimension 81/145]  inactive:\t4.46e-03 +- 4.46e-02\n",
      "[dimension 82/145]  inactive:\t2.05e-04 +- 9.27e-03\n",
      "[dimension 83/145]  inactive:\t-4.75e-04 +- 1.08e-02\n",
      "[dimension 84/145]  inactive:\t-5.40e-05 +- 1.18e-02\n",
      "[dimension 85/145]  inactive:\t2.85e-03 +- 3.05e-02\n",
      "[dimension 86/145]  inactive:\t-2.43e-04 +- 1.29e-02\n",
      "[dimension 87/145]  inactive:\t7.39e-04 +- 1.75e-02\n",
      "[dimension 88/145]  inactive:\t1.30e-03 +- 1.46e-02\n",
      "[dimension 89/145]  inactive:\t-5.70e-05 +- 9.58e-03\n",
      "[dimension 90/145]  inactive:\t7.97e-02 +- 2.40e-01\n",
      "[dimension 91/145]  inactive:\t1.74e-04 +- 1.12e-02\n",
      "[dimension 92/145]  inactive:\t7.39e-05 +- 1.01e-02\n",
      "[dimension 93/145]  inactive:\t4.03e-04 +- 1.43e-02\n",
      "[dimension 94/145]  inactive:\t9.37e-04 +- 1.72e-02\n",
      "[dimension 95/145]  inactive:\t4.68e-04 +- 1.65e-02\n",
      "[dimension 96/145]  inactive:\t6.88e-04 +- 1.86e-02\n",
      "[dimension 97/145]  inactive:\t1.52e-03 +- 1.65e-02\n",
      "[dimension 98/145]  inactive:\t2.78e-04 +- 1.66e-02\n",
      "[dimension 99/145]  inactive:\t4.94e-03 +- 4.90e-02\n",
      "[dimension 100/145]  inactive:\t-6.00e-05 +- 8.93e-03\n",
      "[dimension 101/145]  inactive:\t-4.90e-04 +- 9.04e-03\n",
      "[dimension 102/145]  inactive:\t6.56e-04 +- 1.68e-02\n",
      "[dimension 103/145]  inactive:\t6.18e-04 +- 1.54e-02\n",
      "[dimension 104/145]  inactive:\t-1.54e-04 +- 8.50e-03\n",
      "[dimension 105/145]  inactive:\t2.47e-04 +- 1.30e-02\n",
      "[dimension 106/145]  inactive:\t2.78e-03 +- 2.42e-02\n",
      "[dimension 107/145]  inactive:\t-2.05e-04 +- 1.23e-02\n",
      "[dimension 108/145]  inactive:\t3.65e-03 +- 3.82e-02\n",
      "[dimension 109/145]  inactive:\t1.44e-04 +- 1.02e-02\n",
      "[dimension 110/145]  inactive:\t6.85e-04 +- 1.97e-02\n",
      "[dimension 111/145]  inactive:\t1.60e-03 +- 2.22e-02\n",
      "[dimension 112/145]  inactive:\t3.42e-03 +- 3.83e-02\n",
      "[dimension 113/145]  inactive:\t1.55e-05 +- 1.40e-02\n",
      "[dimension 114/145]  inactive:\t8.91e-04 +- 2.06e-02\n",
      "[dimension 115/145]  inactive:\t1.56e-03 +- 1.64e-02\n",
      "[dimension 116/145]  inactive:\t1.81e-03 +- 2.80e-02\n",
      "[dimension 117/145]  inactive:\t4.90e-03 +- 5.10e-02\n",
      "[dimension 118/145]  inactive:\t1.47e-03 +- 1.47e-02\n",
      "[dimension 119/145]  inactive:\t9.53e-05 +- 1.29e-02\n",
      "[dimension 120/145]  inactive:\t5.66e-04 +- 1.57e-02\n",
      "[dimension 121/145]  inactive:\t2.28e-03 +- 2.24e-02\n",
      "[dimension 122/145]  inactive:\t-1.75e-04 +- 1.46e-02\n",
      "[dimension 123/145]  inactive:\t3.72e-03 +- 4.08e-02\n",
      "[dimension 124/145]  inactive:\t-1.36e-04 +- 1.12e-02\n",
      "[dimension 125/145]  inactive:\t1.56e-05 +- 1.08e-02\n",
      "[dimension 126/145]  inactive:\t1.18e-04 +- 1.16e-02\n",
      "[dimension 127/145]  inactive:\t4.05e-04 +- 1.06e-02\n",
      "[dimension 128/145]  inactive:\t1.03e-03 +- 2.21e-02\n",
      "[dimension 129/145]  inactive:\t1.09e-03 +- 1.89e-02\n",
      "[dimension 130/145]  inactive:\t2.46e-03 +- 2.21e-02\n",
      "[dimension 131/145]  inactive:\t8.12e-04 +- 1.88e-02\n",
      "[dimension 132/145]  inactive:\t2.41e-03 +- 2.91e-02\n",
      "[dimension 133/145]  inactive:\t1.82e-03 +- 1.60e-02\n",
      "[dimension 134/145]  inactive:\t2.31e-04 +- 1.39e-02\n",
      "[dimension 135/145]  inactive:\t1.08e-03 +- 1.76e-02\n",
      "[dimension 136/145]  inactive:\t5.26e-04 +- 9.87e-03\n",
      "[dimension 137/145]  inactive:\t1.05e-03 +- 2.10e-02\n",
      "[dimension 138/145]  inactive:\t6.16e-04 +- 1.28e-02\n",
      "[dimension 139/145]  inactive:\t6.24e-04 +- 1.23e-02\n",
      "[dimension 140/145]  inactive:\t3.41e-04 +- 1.73e-02\n",
      "[dimension 141/145]  inactive:\t1.15e-03 +- 1.77e-02\n",
      "[dimension 142/145]  inactive:\t1.00e-03 +- 1.13e-02\n",
      "[dimension 143/145]  inactive:\t4.07e-03 +- 4.21e-02\n",
      "[dimension 144/145]  inactive:\t6.88e-04 +- 1.32e-02\n",
      "[dimension 145/145]  inactive:\t-4.35e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.80931395]\n",
      "cov_act[[0.02907309]]\n",
      "Active_dimensions: [62]\n",
      "56, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:27<00:00, 54.76it/s, 15 steps of size 1.92e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    352.52      1.00\n",
      "  lambda[0]      2.67     15.17      0.88      0.00      5.04   1006.67      1.00\n",
      "  lambda[1]      3.12     12.86      0.94      0.00      5.55    929.90      1.00\n",
      "  lambda[2]      2.54      5.22      1.03      0.00      5.79    673.08      1.00\n",
      "  lambda[3]     10.66    218.83      1.02      0.00      6.41   1003.87      1.00\n",
      "  lambda[4]      2.99     10.51      1.04      0.00      4.94    781.80      1.00\n",
      "  lambda[5]      3.82     19.58      0.96      0.00      6.53    883.46      1.00\n",
      "  lambda[6]      2.91      7.61      0.98      0.00      5.82    300.31      1.00\n",
      "  lambda[7]      3.54     12.97      0.92      0.00      7.33    627.71      1.00\n",
      "  lambda[8]      2.65      7.71      1.04      0.00      5.50    780.35      1.00\n",
      "  lambda[9]      2.86      7.08      1.04      0.00      5.03    691.56      1.00\n",
      " lambda[10]      3.54     12.24      1.06      0.00      6.49    721.76      1.00\n",
      " lambda[11]      3.59     11.88      0.97      0.00      7.02    427.10      1.00\n",
      " lambda[12]      4.44     19.60      0.97      0.00      6.69    468.25      1.00\n",
      " lambda[13]      3.36     12.20      0.99      0.00      6.72    796.45      1.00\n",
      " lambda[14]      3.17     10.38      0.99      0.00      5.88    836.83      1.00\n",
      " lambda[15]      2.47      7.38      0.88      0.00      4.47    961.90      1.00\n",
      " lambda[16]      3.45      9.46      0.99      0.00      6.95    709.85      1.00\n",
      " lambda[17]      2.81      9.81      0.92      0.00      5.74    956.10      1.00\n",
      " lambda[18]      2.70      7.15      0.96      0.00      5.39    949.94      1.00\n",
      " lambda[19]      3.50     12.72      0.96      0.00      6.90    772.44      1.00\n",
      " lambda[20]      2.40      4.96      0.92      0.01      5.32    837.60      1.00\n",
      " lambda[21]      2.54      6.37      0.96      0.01      5.09    844.87      1.00\n",
      " lambda[22]      2.33      4.26      1.03      0.01      5.41    847.23      1.00\n",
      " lambda[23]      3.46     15.29      0.97      0.00      5.71    624.29      1.00\n",
      " lambda[24]      3.12      7.78      0.99      0.00      7.03    552.55      1.00\n",
      " lambda[25]      2.60      5.72      0.92      0.01      5.95    505.68      1.00\n",
      " lambda[26]      5.57     42.54      0.99      0.00      5.57    548.91      1.00\n",
      " lambda[27]      2.90      8.03      0.99      0.00      5.86    750.16      1.00\n",
      " lambda[28]      3.08      8.51      1.03      0.01      6.18    518.60      1.00\n",
      " lambda[29]      3.01      7.77      0.98      0.00      6.55    510.36      1.00\n",
      " lambda[30]      3.84     12.12      1.03      0.00      7.15    778.59      1.00\n",
      " lambda[31]      3.60     16.05      0.90      0.00      5.67    563.90      1.00\n",
      " lambda[32]      3.47     10.12      1.00      0.00      6.65    500.46      1.00\n",
      " lambda[33]      2.56      6.02      0.94      0.00      5.68    534.39      1.00\n",
      " lambda[34]      3.29      9.99      1.04      0.00      6.57    684.07      1.00\n",
      " lambda[35]      2.90      7.79      1.00      0.00      5.60    988.65      1.00\n",
      " lambda[36]      2.81      6.75      1.01      0.00      6.52    730.41      1.00\n",
      " lambda[37]      3.71     26.48      1.03      0.00      6.38    929.99      1.00\n",
      " lambda[38]      3.43      8.75      1.01      0.00      6.44    761.11      1.00\n",
      " lambda[39]      3.66     11.30      1.01      0.00      6.81    790.80      1.00\n",
      " lambda[40]      3.51     13.49      0.99      0.00      6.72    669.62      1.00\n",
      " lambda[41]     54.21    825.93      1.05      0.00     10.87    612.09      1.00\n",
      " lambda[42]      3.02      7.48      1.09      0.00      6.44    650.83      1.00\n",
      " lambda[43]      4.58     33.56      1.00      0.00      5.57    584.66      1.00\n",
      " lambda[44]      2.82      8.70      0.91      0.00      5.74    609.92      1.00\n",
      " lambda[45]      2.50     10.25      0.97      0.00      4.46    927.42      1.00\n",
      " lambda[46]      2.70      7.31      1.00      0.00      4.98    826.98      1.00\n",
      " lambda[47]      2.63      7.38      1.01      0.02      5.37    529.68      1.00\n",
      " lambda[48]      2.46      7.15      0.92      0.00      4.81    608.62      1.00\n",
      " lambda[49]      2.99      7.92      1.01      0.00      5.90    682.94      1.00\n",
      " lambda[50]      3.30     10.09      1.01      0.00      5.99    579.47      1.00\n",
      " lambda[51]      4.81     24.85      1.02      0.00      6.75    634.55      1.00\n",
      " lambda[52]      2.84      9.00      0.96      0.00      5.17    715.68      1.00\n",
      " lambda[53]      2.77      6.89      1.01      0.01      5.61    655.33      1.00\n",
      " lambda[54]      2.50      6.19      0.91      0.00      4.90    608.85      1.00\n",
      " lambda[55]      2.67     11.05      1.01      0.00      4.90    748.92      1.00\n",
      " lambda[56]      2.89      7.25      0.94      0.01      5.93    531.54      1.00\n",
      " lambda[57]     22.61    414.61      1.07      0.00     13.29    942.88      1.00\n",
      " lambda[58]      2.27      5.09      0.95      0.00      5.28    614.62      1.00\n",
      " lambda[59]      3.61     19.27      1.05      0.00      6.49    830.44      1.00\n",
      " lambda[60]      3.62     12.98      0.98      0.00      6.47    695.75      1.00\n",
      " lambda[61]      3.50     19.94      1.03      0.00      5.87    999.75      1.00\n",
      " lambda[62]   2112.61  22856.83    168.27      0.00   1429.29    541.88      1.00\n",
      " lambda[63]      2.52      6.28      0.99      0.00      5.03    953.10      1.00\n",
      " lambda[64]      3.30     12.04      0.99      0.00      5.37    659.73      1.00\n",
      " lambda[65]      2.76      8.40      0.94      0.00      5.83    774.24      1.00\n",
      " lambda[66]      2.89      7.57      0.93      0.00      6.29    809.67      1.00\n",
      " lambda[67]      3.29      9.42      0.94      0.00      6.69    665.58      1.00\n",
      " lambda[68]      3.66     16.86      0.94      0.00      5.81    562.90      1.00\n",
      " lambda[69]      3.56     11.56      0.92      0.00      5.40    596.89      1.00\n",
      " lambda[70]      2.63      7.42      1.03      0.02      5.57    652.29      1.00\n",
      " lambda[71]      4.02     19.90      1.03      0.00      5.46    329.91      1.00\n",
      " lambda[72]      2.36      7.03      0.96      0.00      4.42    773.51      1.00\n",
      " lambda[73]      2.82      6.73      1.01      0.01      5.77    820.23      1.00\n",
      " lambda[74]      3.12      9.92      0.94      0.00      5.88    803.00      1.00\n",
      " lambda[75]      4.89     21.97      1.07      0.00      7.54    607.58      1.00\n",
      " lambda[76]      2.57      7.51      0.98      0.01      5.08    922.82      1.00\n",
      " lambda[77]      6.48     31.04      1.13      0.00      8.84    438.58      1.00\n",
      " lambda[78]      3.16      7.40      1.07      0.00      7.27    701.77      1.00\n",
      " lambda[79]      2.49      7.46      0.87      0.01      5.07    912.74      1.00\n",
      " lambda[80]      3.57     12.51      0.99      0.00      6.25    791.27      1.00\n",
      " lambda[81]      2.77     10.14      0.95      0.00      4.95    625.39      1.00\n",
      " lambda[82]      2.44      5.80      0.86      0.00      4.94    889.63      1.00\n",
      " lambda[83]      3.36     14.33      0.97      0.00      5.81    917.83      1.00\n",
      " lambda[84]      3.34     11.87      0.98      0.00      6.50    544.59      1.00\n",
      " lambda[85]      3.10     11.79      0.95      0.00      5.47    582.97      1.00\n",
      " lambda[86]      3.71     11.81      0.91      0.00      6.31    442.91      1.00\n",
      " lambda[87]      3.97     14.12      0.94      0.00      8.31    611.11      1.00\n",
      " lambda[88]      2.71      6.55      1.00      0.01      5.86    641.08      1.00\n",
      " lambda[89]     52.49    429.67      1.16      0.00     44.28    778.45      1.00\n",
      " lambda[90]      3.01      7.72      1.03      0.00      5.81    594.17      1.00\n",
      " lambda[91]      2.84      7.60      0.95      0.00      5.73    605.10      1.00\n",
      " lambda[92]      3.40     10.53      0.99      0.00      7.18    789.87      1.00\n",
      " lambda[93]      3.51     12.82      1.12      0.00      6.78    511.93      1.00\n",
      " lambda[94]      3.00     10.58      0.93      0.00      5.94    885.86      1.00\n",
      " lambda[95]      3.29     11.42      0.92      0.01      6.54    647.31      1.00\n",
      " lambda[96]      3.24     10.37      1.00      0.00      7.23    846.38      1.00\n",
      " lambda[97]      2.91      6.77      1.01      0.00      5.21    518.95      1.00\n",
      " lambda[98]      4.92     34.20      1.00      0.00      5.11    538.37      1.00\n",
      " lambda[99]      3.10      9.30      0.92      0.00      5.63    612.49      1.00\n",
      "lambda[100]      2.76      9.24      1.04      0.00      5.59    946.77      1.00\n",
      "lambda[101]      2.74      6.09      1.01      0.00      5.88    459.71      1.00\n",
      "lambda[102]      3.34      9.91      0.95      0.00      6.01    616.43      1.00\n",
      "lambda[103]      2.11      3.81      0.89      0.00      4.73    678.50      1.00\n",
      "lambda[104]      2.78      8.98      0.96      0.00      5.63    545.90      1.00\n",
      "lambda[105]      3.51     13.15      0.94      0.00      6.22    945.87      1.00\n",
      "lambda[106]      2.40      5.18      0.88      0.00      5.56    808.91      1.00\n",
      "lambda[107]      5.57     46.43      1.01      0.00      6.57    783.67      1.00\n",
      "lambda[108]      2.37      5.16      0.96      0.00      5.18    839.55      1.00\n",
      "lambda[109]      4.60     39.76      0.90      0.00      5.64    943.41      1.00\n",
      "lambda[110]      3.65     13.33      1.10      0.01      6.35    706.04      1.00\n",
      "lambda[111]      3.80     13.01      0.97      0.00      6.85    767.48      1.00\n",
      "lambda[112]      2.29      5.53      0.94      0.00      5.20    977.74      1.00\n",
      "lambda[113]      3.79     13.97      1.01      0.00      6.02    656.22      1.00\n",
      "lambda[114]      3.22     16.36      0.97      0.00      5.02    832.03      1.00\n",
      "lambda[115]      2.77      9.49      0.91      0.00      5.61    750.10      1.00\n",
      "lambda[116]      4.57     32.61      1.06      0.00      5.43    570.98      1.00\n",
      "lambda[117]      4.02     19.78      0.95      0.00      7.02    920.04      1.00\n",
      "lambda[118]      4.01     17.75      0.96      0.00      6.87    484.08      1.00\n",
      "lambda[119]      3.47     18.38      1.01      0.00      6.07    594.81      1.00\n",
      "lambda[120]      4.01     14.07      1.04      0.00      6.84    770.69      1.00\n",
      "lambda[121]      3.27     15.39      0.98      0.00      5.36    662.40      1.00\n",
      "lambda[122]      3.42     15.14      1.05      0.00      4.91    498.91      1.00\n",
      "lambda[123]      2.55      5.57      1.00      0.00      5.50    872.39      1.00\n",
      "lambda[124]      2.46      4.72      0.93      0.01      6.20    907.18      1.00\n",
      "lambda[125]      2.62      6.33      0.95      0.00      5.27    730.54      1.00\n",
      "lambda[126]      2.30      5.71      0.96      0.00      4.84    590.88      1.00\n",
      "lambda[127]      2.90      7.61      0.96      0.00      5.63    616.54      1.00\n",
      "lambda[128]      2.26      4.62      0.94      0.00      4.75    971.72      1.00\n",
      "lambda[129]      4.23     18.23      0.97      0.00      6.80    868.16      1.00\n",
      "lambda[130]      2.93     11.14      0.94      0.00      5.22    631.92      1.00\n",
      "lambda[131]      6.21     53.35      0.95      0.00      6.93    380.09      1.00\n",
      "lambda[132]      2.72      8.34      1.05      0.00      5.33    819.50      1.00\n",
      "lambda[133]      2.86      7.82      1.00      0.01      5.34    859.06      1.00\n",
      "lambda[134]      3.38      9.09      0.93      0.00      7.21    560.58      1.01\n",
      "lambda[135]      2.57      7.11      0.90      0.00      5.59    888.27      1.00\n",
      "lambda[136]      2.75      6.75      0.94      0.00      5.50    685.85      1.00\n",
      "lambda[137]      2.66      7.79      1.01      0.00      5.49   1004.83      1.00\n",
      "lambda[138]      2.61      6.69      0.91      0.00      5.27    879.67      1.00\n",
      "lambda[139]      2.85      6.71      0.89      0.01      6.33    636.04      1.00\n",
      "lambda[140]      2.83      7.69      0.95      0.00      5.44    770.95      1.00\n",
      "lambda[141]      2.78      8.81      0.95      0.00      5.60    667.37      1.00\n",
      "lambda[142]      3.91     12.45      1.00      0.00      6.87    520.00      1.00\n",
      "lambda[143]      2.32      4.75      0.99      0.00      5.17    991.92      1.00\n",
      "        msq   4601.87  57308.37     17.83      0.19    761.88    700.41      1.00\n",
      "      sigma      5.61      7.93      2.21      0.00     15.84   1054.16      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    668.30      1.00\n",
      "       xisq    246.60   2911.81     12.73      0.75    119.94    923.27      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 31.0920729637146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.04e-04 +- 1.61e-02\n",
      "[dimension 02/145]  inactive:\t-5.86e-04 +- 2.43e-02\n",
      "[dimension 03/145]  inactive:\t1.83e-04 +- 2.32e-02\n",
      "[dimension 04/145]  inactive:\t6.46e-03 +- 4.65e-02\n",
      "[dimension 05/145]  inactive:\t-6.28e-04 +- 2.46e-02\n",
      "[dimension 06/145]  inactive:\t3.03e-03 +- 3.72e-02\n",
      "[dimension 07/145]  inactive:\t4.39e-04 +- 1.63e-02\n",
      "[dimension 08/145]  inactive:\t1.10e-03 +- 3.02e-02\n",
      "[dimension 09/145]  inactive:\t7.88e-04 +- 2.52e-02\n",
      "[dimension 10/145]  inactive:\t5.18e-04 +- 2.00e-02\n",
      "[dimension 11/145]  inactive:\t-9.75e-04 +- 2.49e-02\n",
      "[dimension 12/145]  inactive:\t9.19e-04 +- 3.10e-02\n",
      "[dimension 13/145]  inactive:\t6.02e-03 +- 5.49e-02\n",
      "[dimension 14/145]  inactive:\t-8.81e-04 +- 2.72e-02\n",
      "[dimension 15/145]  inactive:\t8.04e-04 +- 2.89e-02\n",
      "[dimension 16/145]  inactive:\t6.76e-04 +- 1.93e-02\n",
      "[dimension 17/145]  inactive:\t5.70e-04 +- 2.95e-02\n",
      "[dimension 18/145]  inactive:\t2.63e-04 +- 2.35e-02\n",
      "[dimension 19/145]  inactive:\t-1.86e-03 +- 2.02e-02\n",
      "[dimension 20/145]  inactive:\t-9.85e-04 +- 2.43e-02\n",
      "[dimension 21/145]  inactive:\t-8.56e-04 +- 2.10e-02\n",
      "[dimension 22/145]  inactive:\t-5.35e-05 +- 2.03e-02\n",
      "[dimension 23/145]  inactive:\t-2.05e-04 +- 1.97e-02\n",
      "[dimension 24/145]  inactive:\t2.74e-03 +- 3.58e-02\n",
      "[dimension 25/145]  inactive:\t3.12e-03 +- 2.29e-02\n",
      "[dimension 26/145]  inactive:\t-4.71e-04 +- 2.28e-02\n",
      "[dimension 27/145]  inactive:\t1.48e-03 +- 2.55e-02\n",
      "[dimension 28/145]  inactive:\t6.21e-04 +- 1.86e-02\n",
      "[dimension 29/145]  inactive:\t-5.83e-05 +- 2.61e-02\n",
      "[dimension 30/145]  inactive:\t1.50e-03 +- 3.05e-02\n",
      "[dimension 31/145]  inactive:\t4.66e-03 +- 3.56e-02\n",
      "[dimension 32/145]  inactive:\t-1.30e-03 +- 2.75e-02\n",
      "[dimension 33/145]  inactive:\t4.24e-03 +- 4.59e-02\n",
      "[dimension 34/145]  inactive:\t1.03e-03 +- 1.97e-02\n",
      "[dimension 35/145]  inactive:\t1.32e-03 +- 3.15e-02\n",
      "[dimension 36/145]  inactive:\t1.91e-03 +- 2.78e-02\n",
      "[dimension 37/145]  inactive:\t3.86e-03 +- 2.70e-02\n",
      "[dimension 38/145]  inactive:\t-7.36e-04 +- 2.56e-02\n",
      "[dimension 39/145]  inactive:\t2.42e-03 +- 3.62e-02\n",
      "[dimension 40/145]  inactive:\t4.76e-03 +- 3.47e-02\n",
      "[dimension 41/145]  inactive:\t-1.52e-03 +- 2.93e-02\n",
      "[dimension 42/145]  inactive:\t2.26e-02 +- 1.29e-01\n",
      "[dimension 43/145]  inactive:\t-2.87e-05 +- 1.93e-02\n",
      "[dimension 44/145]  inactive:\t-8.54e-04 +- 3.62e-02\n",
      "[dimension 45/145]  inactive:\t3.82e-04 +- 2.36e-02\n",
      "[dimension 46/145]  inactive:\t6.10e-04 +- 1.45e-02\n",
      "[dimension 47/145]  inactive:\t-1.80e-03 +- 3.02e-02\n",
      "[dimension 48/145]  inactive:\t1.16e-03 +- 2.14e-02\n",
      "[dimension 49/145]  inactive:\t2.39e-03 +- 2.31e-02\n",
      "[dimension 50/145]  inactive:\t-1.63e-03 +- 2.92e-02\n",
      "[dimension 51/145]  inactive:\t4.97e-03 +- 4.24e-02\n",
      "[dimension 52/145]  inactive:\t5.09e-03 +- 2.41e-02\n",
      "[dimension 53/145]  inactive:\t-1.06e-03 +- 2.46e-02\n",
      "[dimension 54/145]  inactive:\t2.36e-04 +- 1.94e-02\n",
      "[dimension 55/145]  inactive:\t4.28e-04 +- 1.58e-02\n",
      "[dimension 56/145]  inactive:\t-1.28e-03 +- 1.92e-02\n",
      "[dimension 57/145]  inactive:\t2.16e-03 +- 3.58e-02\n",
      "[dimension 58/145]  inactive:\t2.93e-02 +- 1.16e-01\n",
      "[dimension 59/145]  inactive:\t-3.45e-04 +- 1.55e-02\n",
      "[dimension 60/145]  inactive:\t1.05e-03 +- 2.69e-02\n",
      "[dimension 61/145]  inactive:\t3.17e-03 +- 2.95e-02\n",
      "[dimension 62/145]  inactive:\t-2.94e-05 +- 2.65e-02\n",
      "[dimension 63/145]  active:\t6.67e-01 +- 4.39e-01\n",
      "[dimension 64/145]  inactive:\t-2.31e-03 +- 2.21e-02\n",
      "[dimension 65/145]  inactive:\t-7.96e-05 +- 2.51e-02\n",
      "[dimension 66/145]  inactive:\t4.90e-04 +- 2.33e-02\n",
      "[dimension 67/145]  inactive:\t1.35e-03 +- 2.53e-02\n",
      "[dimension 68/145]  inactive:\t-1.30e-03 +- 3.04e-02\n",
      "[dimension 69/145]  inactive:\t5.18e-03 +- 5.02e-02\n",
      "[dimension 70/145]  inactive:\t3.23e-03 +- 2.38e-02\n",
      "[dimension 71/145]  inactive:\t-1.78e-04 +- 2.62e-02\n",
      "[dimension 72/145]  inactive:\t9.14e-04 +- 2.34e-02\n",
      "[dimension 73/145]  inactive:\t1.21e-04 +- 1.62e-02\n",
      "[dimension 74/145]  inactive:\t-9.75e-04 +- 2.81e-02\n",
      "[dimension 75/145]  inactive:\t1.51e-03 +- 3.11e-02\n",
      "[dimension 76/145]  inactive:\t6.85e-03 +- 4.29e-02\n",
      "[dimension 77/145]  inactive:\t-8.26e-04 +- 2.46e-02\n",
      "[dimension 78/145]  inactive:\t1.40e-02 +- 8.92e-02\n",
      "[dimension 79/145]  inactive:\t5.35e-03 +- 3.17e-02\n",
      "[dimension 80/145]  inactive:\t-1.95e-04 +- 2.29e-02\n",
      "[dimension 81/145]  inactive:\t2.32e-03 +- 3.58e-02\n",
      "[dimension 82/145]  inactive:\t3.31e-04 +- 1.58e-02\n",
      "[dimension 83/145]  inactive:\t-1.06e-03 +- 1.72e-02\n",
      "[dimension 84/145]  inactive:\t-1.11e-03 +- 2.61e-02\n",
      "[dimension 85/145]  inactive:\t2.26e-03 +- 2.67e-02\n",
      "[dimension 86/145]  inactive:\t-4.82e-04 +- 1.93e-02\n",
      "[dimension 87/145]  inactive:\t4.42e-03 +- 4.98e-02\n",
      "[dimension 88/145]  inactive:\t3.32e-03 +- 2.55e-02\n",
      "[dimension 89/145]  inactive:\t-3.90e-04 +- 2.04e-02\n",
      "[dimension 90/145]  inactive:\t8.25e-02 +- 2.55e-01\n",
      "[dimension 91/145]  inactive:\t8.32e-06 +- 2.00e-02\n",
      "[dimension 92/145]  inactive:\t-1.06e-03 +- 2.11e-02\n",
      "[dimension 93/145]  inactive:\t-3.74e-04 +- 3.17e-02\n",
      "[dimension 94/145]  inactive:\t2.05e-03 +- 2.77e-02\n",
      "[dimension 95/145]  inactive:\t2.21e-07 +- 2.57e-02\n",
      "[dimension 96/145]  inactive:\t2.15e-03 +- 4.43e-02\n",
      "[dimension 97/145]  inactive:\t2.73e-03 +- 2.57e-02\n",
      "[dimension 98/145]  inactive:\t-3.85e-04 +- 2.37e-02\n",
      "[dimension 99/145]  inactive:\t5.36e-03 +- 5.38e-02\n",
      "[dimension 100/145]  inactive:\t-6.80e-04 +- 1.79e-02\n",
      "[dimension 101/145]  inactive:\t-1.72e-03 +- 1.86e-02\n",
      "[dimension 102/145]  inactive:\t-6.76e-04 +- 2.30e-02\n",
      "[dimension 103/145]  inactive:\t1.17e-03 +- 2.90e-02\n",
      "[dimension 104/145]  inactive:\t-4.12e-04 +- 1.46e-02\n",
      "[dimension 105/145]  inactive:\t-1.91e-04 +- 2.28e-02\n",
      "[dimension 106/145]  inactive:\t4.15e-03 +- 3.03e-02\n",
      "[dimension 107/145]  inactive:\t-9.04e-04 +- 1.89e-02\n",
      "[dimension 108/145]  inactive:\t7.04e-03 +- 7.03e-02\n",
      "[dimension 109/145]  inactive:\t-2.76e-04 +- 1.66e-02\n",
      "[dimension 110/145]  inactive:\t-2.74e-04 +- 2.81e-02\n",
      "[dimension 111/145]  inactive:\t4.06e-03 +- 4.64e-02\n",
      "[dimension 112/145]  inactive:\t5.80e-03 +- 5.14e-02\n",
      "[dimension 113/145]  inactive:\t-9.38e-04 +- 1.88e-02\n",
      "[dimension 114/145]  inactive:\t3.41e-03 +- 5.28e-02\n",
      "[dimension 115/145]  inactive:\t1.37e-03 +- 1.76e-02\n",
      "[dimension 116/145]  inactive:\t8.31e-04 +- 3.22e-02\n",
      "[dimension 117/145]  inactive:\t6.79e-03 +- 6.17e-02\n",
      "[dimension 118/145]  inactive:\t2.82e-03 +- 2.40e-02\n",
      "[dimension 119/145]  inactive:\t-2.31e-03 +- 3.30e-02\n",
      "[dimension 120/145]  inactive:\t6.62e-04 +- 3.10e-02\n",
      "[dimension 121/145]  inactive:\t4.45e-03 +- 3.75e-02\n",
      "[dimension 122/145]  inactive:\t-1.70e-03 +- 2.61e-02\n",
      "[dimension 123/145]  inactive:\t3.31e-03 +- 4.25e-02\n",
      "[dimension 124/145]  inactive:\t-1.17e-03 +- 1.85e-02\n",
      "[dimension 125/145]  inactive:\t-7.44e-04 +- 2.07e-02\n",
      "[dimension 126/145]  inactive:\t-6.55e-04 +- 2.13e-02\n",
      "[dimension 127/145]  inactive:\t3.03e-04 +- 1.53e-02\n",
      "[dimension 128/145]  inactive:\t-6.36e-04 +- 2.48e-02\n",
      "[dimension 129/145]  inactive:\t1.52e-04 +- 2.25e-02\n",
      "[dimension 130/145]  inactive:\t3.57e-03 +- 3.06e-02\n",
      "[dimension 131/145]  inactive:\t-9.59e-04 +- 3.01e-02\n",
      "[dimension 132/145]  inactive:\t4.12e-03 +- 3.87e-02\n",
      "[dimension 133/145]  inactive:\t2.41e-03 +- 2.05e-02\n",
      "[dimension 134/145]  inactive:\t-5.87e-04 +- 2.62e-02\n",
      "[dimension 135/145]  inactive:\t2.65e-04 +- 2.80e-02\n",
      "[dimension 136/145]  inactive:\t1.00e-03 +- 1.95e-02\n",
      "[dimension 137/145]  inactive:\t-1.43e-04 +- 2.73e-02\n",
      "[dimension 138/145]  inactive:\t4.84e-04 +- 2.22e-02\n",
      "[dimension 139/145]  inactive:\t4.53e-05 +- 2.30e-02\n",
      "[dimension 140/145]  inactive:\t-7.36e-04 +- 2.93e-02\n",
      "[dimension 141/145]  inactive:\t1.20e-03 +- 2.44e-02\n",
      "[dimension 142/145]  inactive:\t1.45e-03 +- 1.78e-02\n",
      "[dimension 143/145]  inactive:\t1.26e-03 +- 4.15e-02\n",
      "[dimension 144/145]  inactive:\t7.44e-04 +- 2.01e-02\n",
      "[dimension 145/145]  inactive:\t2.74e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.73149693]\n",
      "cov_act[[0.03410273]]\n",
      "Active_dimensions: [62]\n",
      "57, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:26<00:00, 57.62it/s, 15 steps of size 2.15e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    284.49      1.01\n",
      "  lambda[0]      2.72     10.78      0.94      0.00      5.21    950.43      1.00\n",
      "  lambda[1]      3.38     18.08      0.91      0.00      6.00    460.38      1.00\n",
      "  lambda[2]      3.32      9.11      1.10      0.01      6.47    361.24      1.00\n",
      "  lambda[3]      3.16      9.59      1.00      0.00      6.75    775.78      1.00\n",
      "  lambda[4]      2.53      6.23      0.97      0.00      5.02    982.53      1.00\n",
      "  lambda[5]      3.57     22.51      1.02      0.00      5.68   1005.49      1.00\n",
      "  lambda[6]      4.73     16.29      1.06      0.00      8.67    676.66      1.00\n",
      "  lambda[7]      2.64      6.26      0.94      0.00      5.93    685.67      1.00\n",
      "  lambda[8]      2.85      6.66      1.00      0.01      6.17    691.99      1.00\n",
      "  lambda[9]      2.95      7.83      1.03      0.00      5.70    787.42      1.00\n",
      " lambda[10]      2.93      7.12      1.04      0.00      5.99    628.77      1.00\n",
      " lambda[11]      2.63      6.37      0.97      0.01      5.51    736.84      1.00\n",
      " lambda[12]      3.53     17.23      0.96      0.00      5.98    728.15      1.00\n",
      " lambda[13]      2.46      5.56      0.95      0.00      4.69    661.11      1.00\n",
      " lambda[14]      3.55     10.20      1.06      0.00      6.73    762.70      1.00\n",
      " lambda[15]      3.78     10.94      1.06      0.00      7.14    634.93      1.00\n",
      " lambda[16]      2.59      6.16      0.97      0.00      5.94    792.08      1.00\n",
      " lambda[17]      7.39    103.89      0.98      0.00      5.22    471.59      1.00\n",
      " lambda[18]      2.86      8.38      0.96      0.00      5.22    805.64      1.00\n",
      " lambda[19]      2.99     10.07      1.05      0.00      5.83    851.68      1.00\n",
      " lambda[20]      3.39     10.23      1.06      0.00      6.96    700.11      1.00\n",
      " lambda[21]      2.73      7.13      0.98      0.00      5.65    282.04      1.00\n",
      " lambda[22]      2.78      8.03      1.02      0.00      5.36    919.12      1.00\n",
      " lambda[23]      3.11     15.30      1.04      0.00      5.57    968.11      1.00\n",
      " lambda[24]      3.57     17.08      1.04      0.00      6.44    875.44      1.00\n",
      " lambda[25]      2.43      5.03      0.92      0.00      5.51    609.78      1.00\n",
      " lambda[26]      2.66      6.75      0.94      0.00      5.38    856.24      1.00\n",
      " lambda[27]      2.86      8.05      0.93      0.00      5.41    450.69      1.00\n",
      " lambda[28]      2.75      6.28      0.97      0.01      6.40    657.41      1.01\n",
      " lambda[29]      3.05     12.03      0.98      0.01      5.79    879.76      1.00\n",
      " lambda[30]      3.25     12.97      0.97      0.01      5.91    641.17      1.00\n",
      " lambda[31]      2.93      9.01      0.97      0.00      5.69    950.96      1.00\n",
      " lambda[32]      2.72      7.42      1.00      0.00      5.87    937.68      1.00\n",
      " lambda[33]      3.17      7.85      0.96      0.01      6.05    603.15      1.00\n",
      " lambda[34]      2.86      9.86      1.03      0.00      5.82    694.58      1.00\n",
      " lambda[35]      2.62      5.91      0.97      0.00      5.88    726.37      1.00\n",
      " lambda[36]      2.89      7.40      1.01      0.00      6.25    622.06      1.00\n",
      " lambda[37]      3.31     12.32      1.02      0.01      6.16    659.04      1.00\n",
      " lambda[38]      3.61     24.29      0.97      0.01      5.41    977.08      1.00\n",
      " lambda[39]      2.93     10.69      0.94      0.00      5.58    836.33      1.00\n",
      " lambda[40]      3.14      9.13      1.01      0.00      5.90    739.74      1.00\n",
      " lambda[41]      4.78     24.63      0.99      0.00      7.40    780.56      1.00\n",
      " lambda[42]      2.57      6.69      0.96      0.00      5.76    960.69      1.00\n",
      " lambda[43]      3.86     26.49      0.99      0.00      5.44    597.44      1.00\n",
      " lambda[44]      2.59      5.52      0.98      0.00      5.67    710.67      1.00\n",
      " lambda[45]      2.56      7.81      0.94      0.01      4.81    944.01      1.00\n",
      " lambda[46]      2.59      8.17      0.94      0.00      4.60    828.08      1.00\n",
      " lambda[47]      2.41      4.55      1.05      0.00      5.54    835.13      1.00\n",
      " lambda[48]      2.60      5.11      0.95      0.00      6.24    690.54      1.00\n",
      " lambda[49]      2.92      7.42      1.04      0.00      6.02    716.23      1.00\n",
      " lambda[50]      3.19     12.67      0.95      0.00      5.89    893.45      1.00\n",
      " lambda[51]      3.63     11.91      1.01      0.00      6.79    566.28      1.00\n",
      " lambda[52]      3.09     10.71      0.95      0.00      4.64    688.20      1.00\n",
      " lambda[53]      3.06      8.95      0.96      0.00      6.81    603.44      1.00\n",
      " lambda[54]      2.34      5.11      0.96      0.00      5.08    777.69      1.00\n",
      " lambda[55]      2.76     14.06      0.88      0.00      5.37   1018.17      1.00\n",
      " lambda[56]      2.44      9.86      0.96      0.00      4.73    996.82      1.00\n",
      " lambda[57]      3.15      8.27      1.04      0.00      6.60    650.76      1.00\n",
      " lambda[58]      2.44      5.19      0.95      0.00      5.51    601.01      1.00\n",
      " lambda[59]      2.68      5.82      1.08      0.00      5.78    794.72      1.00\n",
      " lambda[60]      3.40     11.78      0.98      0.00      6.03    684.63      1.00\n",
      " lambda[61]      2.60      8.05      0.97      0.00      5.53    895.53      1.00\n",
      " lambda[62]  11370.95 107805.46   1521.11      0.07  12088.60    920.65      1.00\n",
      " lambda[63]      2.48      6.88      0.89      0.00      4.73    748.11      1.00\n",
      " lambda[64]      2.86     16.16      0.97      0.00      5.22   1013.13      1.00\n",
      " lambda[65]      2.95     11.10      1.02      0.00      5.91    769.40      1.00\n",
      " lambda[66]      2.84      6.71      0.97      0.00      6.03    704.52      1.00\n",
      " lambda[67]      2.99      9.40      1.03      0.00      6.31    968.48      1.00\n",
      " lambda[68]      3.05      8.15      0.98      0.01      5.96    905.61      1.00\n",
      " lambda[69]      5.08     37.27      0.99      0.00      7.51    738.61      1.00\n",
      " lambda[70]      2.64      7.02      0.99      0.00      5.29    804.89      1.00\n",
      " lambda[71]      3.05     10.62      1.07      0.00      5.55    393.74      1.00\n",
      " lambda[72]      2.32      5.75      1.02      0.00      4.76    745.05      1.00\n",
      " lambda[73]      2.89      8.39      0.94      0.00      5.30    612.32      1.01\n",
      " lambda[74]      2.67      6.23      0.96      0.00      6.35    775.05      1.00\n",
      " lambda[75]      3.90     13.03      1.06      0.00      6.81    655.45      1.00\n",
      " lambda[76]      2.58      5.59      1.04      0.00      5.68    564.12      1.00\n",
      " lambda[77]      5.88     57.94      0.97      0.00      5.49    428.55      1.00\n",
      " lambda[78]      2.58      5.97      0.98      0.01      4.90    655.11      1.00\n",
      " lambda[79]      2.69     15.92      0.94      0.00      4.22    937.81      1.00\n",
      " lambda[80]      2.84      7.21      1.00      0.00      6.13    656.67      1.00\n",
      " lambda[81]      2.52      5.09      0.99      0.00      5.99    990.93      1.00\n",
      " lambda[82]      2.74      8.21      0.92      0.00      5.36    629.41      1.00\n",
      " lambda[83]      3.41     10.70      1.07      0.00      6.60    662.01      1.00\n",
      " lambda[84]      4.33     34.13      0.97      0.00      5.52    892.23      1.00\n",
      " lambda[85]      2.77      7.03      0.96      0.00      6.12    699.69      1.00\n",
      " lambda[86]      3.55     18.29      0.95      0.00      5.53    828.35      1.00\n",
      " lambda[87]      2.77      7.91      0.92      0.00      5.48    789.41      1.00\n",
      " lambda[88]      2.76      7.05      1.00      0.00      5.54    558.82      1.00\n",
      " lambda[89]      3.83     14.65      0.94      0.00      5.56    517.02      1.00\n",
      " lambda[90]      2.80      9.08      0.96      0.00      5.08    799.60      1.00\n",
      " lambda[91]      2.73      6.56      0.98      0.00      5.50    517.09      1.00\n",
      " lambda[92]      3.14     10.25      1.02      0.00      6.72    550.53      1.00\n",
      " lambda[93]      2.36      6.28      0.98      0.00      4.41    769.57      1.00\n",
      " lambda[94]      3.75     11.95      1.00      0.00      7.28    622.92      1.01\n",
      " lambda[95]      3.19      9.19      1.01      0.00      6.23    723.18      1.00\n",
      " lambda[96]      3.10      9.59      0.99      0.00      6.03    439.57      1.00\n",
      " lambda[97]      2.75      7.06      1.01      0.00      5.61    817.10      1.00\n",
      " lambda[98]      2.58      6.87      1.00      0.00      5.26    734.70      1.00\n",
      " lambda[99]      2.43      5.75      0.95      0.00      5.41    699.97      1.00\n",
      "lambda[100]      3.09      9.65      0.97      0.00      6.29    775.82      1.00\n",
      "lambda[101]      3.27     10.09      0.99      0.00      6.10    513.55      1.00\n",
      "lambda[102]      2.66      7.12      0.93      0.00      5.18    807.08      1.00\n",
      "lambda[103]      2.85     12.91      0.89      0.00      5.58    680.68      1.00\n",
      "lambda[104]      2.49      6.39      0.96      0.00      4.66    754.64      1.00\n",
      "lambda[105]      2.52      5.67      0.91      0.00      5.77    771.58      1.00\n",
      "lambda[106]      3.74     19.29      0.98      0.00      5.99    291.11      1.00\n",
      "lambda[107]      2.49      6.35      0.97      0.00      4.72    779.48      1.00\n",
      "lambda[108]      2.49      5.70      0.99      0.01      5.51    610.14      1.00\n",
      "lambda[109]      4.07     15.19      0.98      0.00      6.48    840.32      1.00\n",
      "lambda[110]      2.97      9.16      1.03      0.00      6.20    874.38      1.00\n",
      "lambda[111]      3.85     13.76      1.04      0.00      6.28    332.72      1.00\n",
      "lambda[112]      2.07      3.88      0.95      0.00      4.49    600.26      1.00\n",
      "lambda[113]      3.49     10.08      0.98      0.00      6.18    543.09      1.00\n",
      "lambda[114]      3.00      8.85      0.99      0.00      5.65    538.94      1.00\n",
      "lambda[115]      3.88     24.92      1.01      0.00      6.44    953.98      1.00\n",
      "lambda[116]      2.66      9.33      0.98      0.01      5.08    738.63      1.00\n",
      "lambda[117]      3.24     12.25      0.94      0.00      5.46    806.14      1.00\n",
      "lambda[118]      3.23     17.48      0.93      0.00      5.09    864.28      1.00\n",
      "lambda[119]      3.30     11.25      0.96      0.00      6.20    820.90      1.00\n",
      "lambda[120]      3.69     13.38      0.96      0.00      6.51    777.58      1.00\n",
      "lambda[121]      2.87      8.87      1.00      0.00      5.97    687.95      1.00\n",
      "lambda[122]      2.90      9.76      0.93      0.00      5.11    646.97      1.00\n",
      "lambda[123]      2.62      6.56      0.97      0.00      5.62    650.39      1.01\n",
      "lambda[124]      3.13     16.64      0.95      0.01      5.76    944.13      1.00\n",
      "lambda[125]      2.79      7.92      0.98      0.00      5.69    606.25      1.00\n",
      "lambda[126]      2.27      5.52      0.93      0.00      4.99    967.94      1.00\n",
      "lambda[127]      3.53     15.43      1.01      0.00      6.59    956.80      1.00\n",
      "lambda[128]      3.47     13.06      0.98      0.00      6.04    530.34      1.00\n",
      "lambda[129]      3.44     19.20      0.81      0.00      4.78    797.33      1.00\n",
      "lambda[130]      3.21     14.18      0.94      0.00      5.38    858.31      1.00\n",
      "lambda[131]      4.07     28.24      0.97      0.00      5.23    419.20      1.00\n",
      "lambda[132]      2.94      9.28      1.03      0.00      5.34    695.39      1.00\n",
      "lambda[133]      2.45      5.81      0.95      0.00      4.85    910.95      1.00\n",
      "lambda[134]      3.22      9.08      0.99      0.00      6.64    890.37      1.00\n",
      "lambda[135]      2.35      5.11      0.94      0.00      5.14    797.24      1.00\n",
      "lambda[136]      2.85      8.77      0.94      0.00      5.69    821.88      1.00\n",
      "lambda[137]      2.96      9.21      1.05      0.00      5.73    623.02      1.00\n",
      "lambda[138]      3.05      8.26      0.98      0.00      6.97    607.96      1.00\n",
      "lambda[139]      2.85      7.00      0.95      0.00      5.80    502.09      1.00\n",
      "lambda[140]      3.44     12.93      0.97      0.00      5.97    604.77      1.00\n",
      "lambda[141]      3.44     11.29      0.99      0.00      6.88    581.57      1.00\n",
      "lambda[142]      3.44     11.22      1.01      0.00      6.16    676.48      1.00\n",
      "lambda[143]      2.47      5.88      0.94      0.00      5.19    835.70      1.00\n",
      "        msq      0.28      0.17      0.23      0.07      0.47    718.91      1.00\n",
      "      sigma      4.24      6.72      1.18      0.00     13.98    863.09      1.01\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    979.32      1.00\n",
      "       xisq     15.14     64.10      5.78      0.77     24.68    508.00      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 29.60984492301941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.75e-04 +- 6.99e-03\n",
      "[dimension 02/145]  inactive:\t3.03e-04 +- 1.04e-02\n",
      "[dimension 03/145]  inactive:\t2.31e-04 +- 8.32e-03\n",
      "[dimension 04/145]  inactive:\t6.79e-04 +- 1.02e-02\n",
      "[dimension 05/145]  inactive:\t5.59e-05 +- 6.53e-03\n",
      "[dimension 06/145]  inactive:\t1.07e-03 +- 1.94e-02\n",
      "[dimension 07/145]  inactive:\t6.53e-04 +- 1.00e-02\n",
      "[dimension 08/145]  inactive:\t3.66e-04 +- 9.62e-03\n",
      "[dimension 09/145]  inactive:\t1.95e-04 +- 7.25e-03\n",
      "[dimension 10/145]  inactive:\t3.20e-04 +- 8.21e-03\n",
      "[dimension 11/145]  inactive:\t8.60e-05 +- 7.47e-03\n",
      "[dimension 12/145]  inactive:\t2.35e-04 +- 1.07e-02\n",
      "[dimension 13/145]  inactive:\t7.09e-04 +- 1.29e-02\n",
      "[dimension 14/145]  inactive:\t5.05e-05 +- 6.70e-03\n",
      "[dimension 15/145]  inactive:\t5.88e-04 +- 1.43e-02\n",
      "[dimension 16/145]  inactive:\t2.48e-04 +- 9.28e-03\n",
      "[dimension 17/145]  inactive:\t1.58e-04 +- 9.47e-03\n",
      "[dimension 18/145]  inactive:\t7.64e-04 +- 1.74e-02\n",
      "[dimension 19/145]  inactive:\t-1.61e-05 +- 5.88e-03\n",
      "[dimension 20/145]  inactive:\t2.90e-04 +- 1.28e-02\n",
      "[dimension 21/145]  inactive:\t2.31e-05 +- 7.03e-03\n",
      "[dimension 22/145]  inactive:\t1.49e-04 +- 6.62e-03\n",
      "[dimension 23/145]  inactive:\t1.67e-04 +- 8.32e-03\n",
      "[dimension 24/145]  inactive:\t3.57e-04 +- 8.77e-03\n",
      "[dimension 25/145]  inactive:\t7.87e-04 +- 1.06e-02\n",
      "[dimension 26/145]  inactive:\t1.46e-04 +- 8.01e-03\n",
      "[dimension 27/145]  inactive:\t1.56e-04 +- 6.70e-03\n",
      "[dimension 28/145]  inactive:\t3.02e-04 +- 7.25e-03\n",
      "[dimension 29/145]  inactive:\t2.64e-04 +- 1.06e-02\n",
      "[dimension 30/145]  inactive:\t5.35e-04 +- 1.20e-02\n",
      "[dimension 31/145]  inactive:\t8.92e-04 +- 1.46e-02\n",
      "[dimension 32/145]  inactive:\t5.91e-05 +- 7.66e-03\n",
      "[dimension 33/145]  inactive:\t4.88e-04 +- 1.17e-02\n",
      "[dimension 34/145]  inactive:\t3.56e-04 +- 8.70e-03\n",
      "[dimension 35/145]  inactive:\t6.40e-04 +- 1.76e-02\n",
      "[dimension 36/145]  inactive:\t2.44e-04 +- 7.46e-03\n",
      "[dimension 37/145]  inactive:\t6.68e-04 +- 8.75e-03\n",
      "[dimension 38/145]  inactive:\t3.56e-05 +- 8.00e-03\n",
      "[dimension 39/145]  inactive:\t6.88e-04 +- 1.53e-02\n",
      "[dimension 40/145]  inactive:\t5.55e-04 +- 9.52e-03\n",
      "[dimension 41/145]  inactive:\t1.64e-04 +- 1.31e-02\n",
      "[dimension 42/145]  inactive:\t1.09e-03 +- 1.67e-02\n",
      "[dimension 43/145]  inactive:\t1.06e-04 +- 7.01e-03\n",
      "[dimension 44/145]  inactive:\t3.80e-04 +- 1.27e-02\n",
      "[dimension 45/145]  inactive:\t1.26e-04 +- 9.38e-03\n",
      "[dimension 46/145]  inactive:\t1.62e-04 +- 5.17e-03\n",
      "[dimension 47/145]  inactive:\t5.86e-05 +- 1.15e-02\n",
      "[dimension 48/145]  inactive:\t1.95e-04 +- 9.22e-03\n",
      "[dimension 49/145]  inactive:\t3.49e-04 +- 8.70e-03\n",
      "[dimension 50/145]  inactive:\t9.80e-06 +- 8.28e-03\n",
      "[dimension 51/145]  inactive:\t6.73e-04 +- 1.56e-02\n",
      "[dimension 52/145]  inactive:\t1.55e-03 +- 1.28e-02\n",
      "[dimension 53/145]  inactive:\t7.62e-06 +- 8.39e-03\n",
      "[dimension 54/145]  inactive:\t3.00e-04 +- 8.47e-03\n",
      "[dimension 55/145]  inactive:\t1.63e-04 +- 6.34e-03\n",
      "[dimension 56/145]  inactive:\t-2.05e-04 +- 6.51e-03\n",
      "[dimension 57/145]  inactive:\t2.82e-04 +- 9.27e-03\n",
      "[dimension 58/145]  inactive:\t7.25e-04 +- 1.04e-02\n",
      "[dimension 59/145]  inactive:\t-4.76e-05 +- 7.04e-03\n",
      "[dimension 60/145]  inactive:\t1.74e-04 +- 7.11e-03\n",
      "[dimension 61/145]  inactive:\t5.24e-04 +- 1.01e-02\n",
      "[dimension 62/145]  inactive:\t2.75e-05 +- 7.04e-03\n",
      "[dimension 63/145]  active:\t9.12e-01 +- 1.60e-01\n",
      "[dimension 64/145]  inactive:\t-1.02e-04 +- 6.21e-03\n",
      "[dimension 65/145]  inactive:\t5.75e-05 +- 7.85e-03\n",
      "[dimension 66/145]  inactive:\t1.68e-04 +- 7.49e-03\n",
      "[dimension 67/145]  inactive:\t2.54e-04 +- 8.16e-03\n",
      "[dimension 68/145]  inactive:\t5.23e-05 +- 9.25e-03\n",
      "[dimension 69/145]  inactive:\t7.88e-04 +- 1.54e-02\n",
      "[dimension 70/145]  inactive:\t1.10e-03 +- 1.10e-02\n",
      "[dimension 71/145]  inactive:\t2.29e-04 +- 8.93e-03\n",
      "[dimension 72/145]  inactive:\t2.58e-04 +- 8.60e-03\n",
      "[dimension 73/145]  inactive:\t8.89e-05 +- 5.27e-03\n",
      "[dimension 74/145]  inactive:\t2.53e-05 +- 8.19e-03\n",
      "[dimension 75/145]  inactive:\t1.40e-04 +- 6.79e-03\n",
      "[dimension 76/145]  inactive:\t1.04e-03 +- 1.35e-02\n",
      "[dimension 77/145]  inactive:\t5.93e-05 +- 1.04e-02\n",
      "[dimension 78/145]  inactive:\t3.05e-03 +- 3.71e-02\n",
      "[dimension 79/145]  inactive:\t8.53e-04 +- 1.05e-02\n",
      "[dimension 80/145]  inactive:\t3.33e-04 +- 1.13e-02\n",
      "[dimension 81/145]  inactive:\t1.85e-04 +- 8.84e-03\n",
      "[dimension 82/145]  inactive:\t1.47e-04 +- 6.48e-03\n",
      "[dimension 83/145]  inactive:\t-1.36e-04 +- 5.73e-03\n",
      "[dimension 84/145]  inactive:\t-1.37e-04 +- 1.07e-02\n",
      "[dimension 85/145]  inactive:\t9.03e-04 +- 1.52e-02\n",
      "[dimension 86/145]  inactive:\t-3.60e-05 +- 7.32e-03\n",
      "[dimension 87/145]  inactive:\t4.15e-04 +- 1.09e-02\n",
      "[dimension 88/145]  inactive:\t4.69e-04 +- 8.52e-03\n",
      "[dimension 89/145]  inactive:\t-8.97e-05 +- 7.27e-03\n",
      "[dimension 90/145]  inactive:\t8.94e-04 +- 1.83e-02\n",
      "[dimension 91/145]  inactive:\t1.55e-04 +- 7.38e-03\n",
      "[dimension 92/145]  inactive:\t-9.86e-06 +- 7.18e-03\n",
      "[dimension 93/145]  inactive:\t2.20e-04 +- 1.01e-02\n",
      "[dimension 94/145]  inactive:\t3.58e-04 +- 9.30e-03\n",
      "[dimension 95/145]  inactive:\t2.89e-04 +- 1.26e-02\n",
      "[dimension 96/145]  inactive:\t1.50e-04 +- 8.27e-03\n",
      "[dimension 97/145]  inactive:\t6.38e-04 +- 1.05e-02\n",
      "[dimension 98/145]  inactive:\t4.27e-05 +- 7.00e-03\n",
      "[dimension 99/145]  inactive:\t1.90e-04 +- 7.99e-03\n",
      "[dimension 100/145]  inactive:\t1.47e-05 +- 5.12e-03\n",
      "[dimension 101/145]  inactive:\t-3.57e-04 +- 7.85e-03\n",
      "[dimension 102/145]  inactive:\t7.04e-06 +- 7.54e-03\n",
      "[dimension 103/145]  inactive:\t3.89e-04 +- 1.06e-02\n",
      "[dimension 104/145]  inactive:\t-1.08e-04 +- 6.17e-03\n",
      "[dimension 105/145]  inactive:\t4.43e-05 +- 5.99e-03\n",
      "[dimension 106/145]  inactive:\t3.72e-04 +- 6.75e-03\n",
      "[dimension 107/145]  inactive:\t-1.76e-04 +- 7.71e-03\n",
      "[dimension 108/145]  inactive:\t1.08e-04 +- 7.47e-03\n",
      "[dimension 109/145]  inactive:\t6.95e-05 +- 5.10e-03\n",
      "[dimension 110/145]  inactive:\t1.38e-04 +- 1.13e-02\n",
      "[dimension 111/145]  inactive:\t4.66e-04 +- 1.16e-02\n",
      "[dimension 112/145]  inactive:\t1.30e-03 +- 2.10e-02\n",
      "[dimension 113/145]  inactive:\t-1.34e-06 +- 4.77e-03\n",
      "[dimension 114/145]  inactive:\t4.45e-04 +- 1.37e-02\n",
      "[dimension 115/145]  inactive:\t5.67e-04 +- 9.42e-03\n",
      "[dimension 116/145]  inactive:\t3.82e-04 +- 1.23e-02\n",
      "[dimension 117/145]  inactive:\t6.90e-04 +- 1.65e-02\n",
      "[dimension 118/145]  inactive:\t6.92e-04 +- 1.04e-02\n",
      "[dimension 119/145]  inactive:\t2.36e-04 +- 1.21e-02\n",
      "[dimension 120/145]  inactive:\t5.20e-04 +- 1.62e-02\n",
      "[dimension 121/145]  inactive:\t1.46e-03 +- 1.93e-02\n",
      "[dimension 122/145]  inactive:\t-2.22e-05 +- 9.16e-03\n",
      "[dimension 123/145]  inactive:\t3.52e-04 +- 9.97e-03\n",
      "[dimension 124/145]  inactive:\t-5.31e-05 +- 6.88e-03\n",
      "[dimension 125/145]  inactive:\t-4.38e-06 +- 9.21e-03\n",
      "[dimension 126/145]  inactive:\t3.45e-05 +- 6.31e-03\n",
      "[dimension 127/145]  inactive:\t1.39e-04 +- 5.49e-03\n",
      "[dimension 128/145]  inactive:\t1.38e-04 +- 1.02e-02\n",
      "[dimension 129/145]  inactive:\t1.25e-04 +- 1.21e-02\n",
      "[dimension 130/145]  inactive:\t6.53e-04 +- 1.15e-02\n",
      "[dimension 131/145]  inactive:\t2.02e-04 +- 1.11e-02\n",
      "[dimension 132/145]  inactive:\t1.33e-03 +- 2.58e-02\n",
      "[dimension 133/145]  inactive:\t8.37e-04 +- 1.08e-02\n",
      "[dimension 134/145]  inactive:\t1.13e-04 +- 7.30e-03\n",
      "[dimension 135/145]  inactive:\t2.59e-04 +- 1.11e-02\n",
      "[dimension 136/145]  inactive:\t2.37e-04 +- 6.48e-03\n",
      "[dimension 137/145]  inactive:\t9.12e-05 +- 7.20e-03\n",
      "[dimension 138/145]  inactive:\t1.96e-04 +- 7.73e-03\n",
      "[dimension 139/145]  inactive:\t2.71e-04 +- 9.56e-03\n",
      "[dimension 140/145]  inactive:\t1.15e-04 +- 8.79e-03\n",
      "[dimension 141/145]  inactive:\t5.66e-04 +- 1.15e-02\n",
      "[dimension 142/145]  inactive:\t7.72e-04 +- 1.06e-02\n",
      "[dimension 143/145]  inactive:\t1.63e-03 +- 3.17e-02\n",
      "[dimension 144/145]  inactive:\t2.24e-04 +- 7.91e-03\n",
      "[dimension 145/145]  inactive:\t-2.04e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[8.404721e-06]\n",
      "cov_act[[1.2144446e-06]]\n",
      "Active_dimensions: [62]\n",
      "58, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:25<00:00, 59.94it/s, 15 steps of size 2.13e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    484.60      1.00\n",
      "  lambda[0]      2.65      7.95      0.94      0.00      5.70    876.76      1.00\n",
      "  lambda[1]      4.16     28.01      0.99      0.00      6.07    435.45      1.00\n",
      "  lambda[2]      3.13      7.41      1.05      0.00      6.34    358.07      1.00\n",
      "  lambda[3]      4.34     32.61      0.98      0.01      6.02    641.84      1.00\n",
      "  lambda[4]      2.89      8.30      0.99      0.00      6.23    613.47      1.00\n",
      "  lambda[5]      3.26     10.93      1.02      0.00      5.77    757.00      1.00\n",
      "  lambda[6]      2.93      7.75      0.96      0.00      6.33    633.34      1.00\n",
      "  lambda[7]      2.82      6.33      0.92      0.00      6.64    855.11      1.00\n",
      "  lambda[8]      2.75      7.34      1.00      0.01      5.70    741.16      1.00\n",
      "  lambda[9]      2.58      7.73      1.06      0.00      4.93    837.57      1.00\n",
      " lambda[10]      3.18      9.35      1.04      0.00      5.57    636.34      1.00\n",
      " lambda[11]      2.90     11.97      0.98      0.00      5.03    483.15      1.01\n",
      " lambda[12]      4.38     24.62      0.92      0.01      7.17    489.70      1.00\n",
      " lambda[13]      2.45      5.71      0.94      0.00      5.06    621.91      1.00\n",
      " lambda[14]      3.46     10.60      1.05      0.00      6.53    692.94      1.00\n",
      " lambda[15]      2.53      6.66      1.00      0.00      5.19    900.32      1.00\n",
      " lambda[16]      2.89      9.55      0.95      0.01      5.50    844.21      1.00\n",
      " lambda[17]      3.01     10.53      1.02      0.00      5.86    707.75      1.00\n",
      " lambda[18]      3.09     11.15      0.99      0.00      5.61    828.31      1.00\n",
      " lambda[19]      2.84      8.90      1.00      0.00      5.83   1011.74      1.00\n",
      " lambda[20]      3.33      8.94      1.05      0.00      7.74    669.36      1.00\n",
      " lambda[21]      2.59      5.83      1.00      0.00      6.20    502.32      1.00\n",
      " lambda[22]      2.66      7.33      0.99      0.00      5.50    851.66      1.00\n",
      " lambda[23]      3.81     37.57      1.00      0.00      5.26   1008.87      1.00\n",
      " lambda[24]      3.52     12.39      1.05      0.00      6.61    854.97      1.00\n",
      " lambda[25]      2.41      4.98      0.96      0.00      5.39    669.93      1.00\n",
      " lambda[26]      3.03     13.09      1.01      0.00      5.59    916.62      1.00\n",
      " lambda[27]      2.68      6.37      0.93      0.00      5.52    630.92      1.00\n",
      " lambda[28]      2.61      5.97      0.99      0.01      6.47    605.76      1.00\n",
      " lambda[29]      4.05     34.74      0.99      0.00      6.03    946.90      1.00\n",
      " lambda[30]      4.59     23.88      0.99      0.01      7.46    328.56      1.00\n",
      " lambda[31]      3.19     11.23      0.96      0.00      4.64    802.94      1.00\n",
      " lambda[32]      2.99      9.43      0.98      0.00      6.17    928.57      1.00\n",
      " lambda[33]      2.56      5.49      0.96      0.00      5.39    498.89      1.00\n",
      " lambda[34]      2.87      9.06      0.98      0.00      5.33    938.54      1.00\n",
      " lambda[35]      2.85      6.86      1.00      0.00      6.04    782.77      1.00\n",
      " lambda[36]      3.08      7.18      1.04      0.00      6.96    618.93      1.00\n",
      " lambda[37]      3.21     10.30      0.99      0.00      6.11    840.20      1.00\n",
      " lambda[38]      3.82     20.15      1.03      0.00      6.47    965.21      1.00\n",
      " lambda[39]      3.30     14.83      0.97      0.00      6.29    957.92      1.00\n",
      " lambda[40]      3.01      8.84      0.99      0.00      5.80    739.77      1.00\n",
      " lambda[41]      8.25     55.07      1.00      0.00      8.73    637.60      1.00\n",
      " lambda[42]      2.31      5.30      0.96      0.00      5.27    980.69      1.00\n",
      " lambda[43]      4.68     46.90      1.04      0.00      6.03    606.18      1.00\n",
      " lambda[44]      2.97      7.72      0.93      0.00      6.12    767.99      1.00\n",
      " lambda[45]      3.72     36.26      0.98      0.01      5.18    995.98      1.00\n",
      " lambda[46]      2.33      5.78      0.93      0.00      4.72   1021.04      1.00\n",
      " lambda[47]      2.43      4.39      0.99      0.01      5.57    850.65      1.00\n",
      " lambda[48]      2.93      6.33      0.98      0.00      6.27    647.05      1.00\n",
      " lambda[49]      3.43      9.84      1.03      0.00      6.08    611.79      1.00\n",
      " lambda[50]      3.04     11.26      0.95      0.00      5.58    869.28      1.00\n",
      " lambda[51]      3.23     16.79      0.97      0.00      6.09    819.50      1.00\n",
      " lambda[52]      2.76     10.17      0.98      0.00      4.70    857.39      1.00\n",
      " lambda[53]      2.86      9.35      0.95      0.00      5.68    616.62      1.00\n",
      " lambda[54]      2.12      4.26      0.94      0.00      4.38    826.26      1.00\n",
      " lambda[55]      3.16     15.83      0.92      0.00      5.57    976.01      1.00\n",
      " lambda[56]      2.36      6.04      0.90      0.00      4.89    834.44      1.00\n",
      " lambda[57]      6.60     29.89      0.99      0.00     10.04    408.39      1.00\n",
      " lambda[58]      2.60      7.09      0.94      0.00      5.51    766.91      1.00\n",
      " lambda[59]      2.88      7.18      1.02      0.00      5.22    488.64      1.00\n",
      " lambda[60]      3.34     12.39      1.02      0.00      5.91    609.71      1.00\n",
      " lambda[61]      2.56      5.38      1.03      0.00      5.94   1093.65      1.00\n",
      " lambda[62]   1138.94  13510.92    139.38      0.02   1178.46    642.83      1.00\n",
      " lambda[63]      2.81     11.16      0.97      0.01      4.84    585.39      1.00\n",
      " lambda[64]      2.51      5.78      0.97      0.00      5.73    670.21      1.00\n",
      " lambda[65]      2.90      9.46      0.98      0.00      5.74    833.61      1.00\n",
      " lambda[66]      3.13      7.97      0.93      0.00      6.49    758.99      1.00\n",
      " lambda[67]      3.04     10.82      1.03      0.01      5.59   1003.01      1.00\n",
      " lambda[68]      3.32      9.39      1.02      0.01      6.57    888.56      1.00\n",
      " lambda[69]      3.72     17.01      0.97      0.00      6.36    707.70      1.00\n",
      " lambda[70]      3.18     10.98      1.00      0.00      5.58    822.40      1.00\n",
      " lambda[71]      2.88      8.56      1.01      0.00      5.54    497.92      1.00\n",
      " lambda[72]      2.28      5.34      0.99      0.00      4.67    714.53      1.00\n",
      " lambda[73]      3.88     18.99      1.00      0.00      6.26    705.11      1.00\n",
      " lambda[74]      2.65      6.60      0.99      0.01      5.79    710.24      1.00\n",
      " lambda[75]      4.42     15.94      1.08      0.00      7.02    596.47      1.00\n",
      " lambda[76]      2.67      6.42      1.00      0.00      5.91    633.87      1.00\n",
      " lambda[77]      5.17     28.29      0.97      0.00      6.24    551.74      1.00\n",
      " lambda[78]      3.19      9.04      1.00      0.01      5.70    314.66      1.00\n",
      " lambda[79]      2.95     14.54      0.88      0.00      4.59    750.24      1.00\n",
      " lambda[80]      4.90     29.78      0.96      0.00      6.46    543.69      1.00\n",
      " lambda[81]      2.56      5.42      1.03      0.00      5.91    792.81      1.00\n",
      " lambda[82]      2.48      5.30      0.95      0.00      5.69    584.52      1.00\n",
      " lambda[83]      3.46     10.54      1.05      0.00      6.68    741.68      1.00\n",
      " lambda[84]      7.03    100.56      0.96      0.00      6.26    823.62      1.00\n",
      " lambda[85]      2.43      5.94      0.95      0.00      5.31    626.58      1.00\n",
      " lambda[86]      4.81     22.97      1.01      0.00      6.95    766.07      1.00\n",
      " lambda[87]      2.75     10.88      0.93      0.00      5.46    820.69      1.00\n",
      " lambda[88]      2.77      6.43      0.99      0.00      5.50    564.72      1.00\n",
      " lambda[89]    227.59   3497.93      1.38      0.01    105.57    833.19      1.00\n",
      " lambda[90]      2.57      7.14      0.94      0.00      4.65    588.13      1.00\n",
      " lambda[91]      2.76      7.29      1.00      0.00      5.36    522.46      1.00\n",
      " lambda[92]      3.44     13.62      0.97      0.00      5.97    661.71      1.00\n",
      " lambda[93]      2.51      5.88      0.97      0.00      4.92    494.94      1.00\n",
      " lambda[94]      3.35     12.26      0.98      0.00      5.62    460.77      1.00\n",
      " lambda[95]      4.13     22.79      0.97      0.00      6.44    848.15      1.00\n",
      " lambda[96]      3.18      8.79      0.99      0.00      6.15    597.08      1.00\n",
      " lambda[97]      2.68      6.94      1.02      0.00      5.36    590.58      1.00\n",
      " lambda[98]      2.67      9.17      0.96      0.00      4.85    683.75      1.00\n",
      " lambda[99]      2.34      5.96      0.94      0.00      5.52    875.96      1.00\n",
      "lambda[100]      3.16      9.83      1.02      0.00      6.42    579.61      1.00\n",
      "lambda[101]      3.32     13.36      1.00      0.00      5.46    498.16      1.00\n",
      "lambda[102]      2.53      6.08      0.93      0.00      5.52    787.73      1.00\n",
      "lambda[103]      3.20     15.86      0.93      0.00      5.55    371.39      1.00\n",
      "lambda[104]      2.89     10.61      0.90      0.00      4.67    636.66      1.00\n",
      "lambda[105]      3.16      9.49      1.01      0.00      6.20    853.92      1.00\n",
      "lambda[106]      2.79     10.04      0.99      0.00      5.84    932.41      1.00\n",
      "lambda[107]      3.65     14.64      1.02      0.00      5.24    280.88      1.00\n",
      "lambda[108]      2.47      5.94      0.93      0.00      5.50    787.98      1.00\n",
      "lambda[109]      4.24     24.19      1.02      0.00      6.92    753.25      1.00\n",
      "lambda[110]      3.36     12.78      1.05      0.00      5.65    794.62      1.00\n",
      "lambda[111]      8.12    104.04      1.03      0.00      6.76    618.19      1.00\n",
      "lambda[112]      2.16      4.18      0.94      0.01      4.68    728.53      1.00\n",
      "lambda[113]      4.03     15.89      1.02      0.00      6.49    624.22      1.00\n",
      "lambda[114]      4.21     48.06      0.98      0.00      5.75    991.94      1.00\n",
      "lambda[115]      4.61     46.69      1.01      0.00      6.42    991.94      1.00\n",
      "lambda[116]      3.43     17.45      1.00      0.00      5.57    956.34      1.00\n",
      "lambda[117]      3.16     12.74      1.00      0.00      5.74    939.06      1.00\n",
      "lambda[118]      3.26     14.08      0.96      0.00      6.31    781.72      1.00\n",
      "lambda[119]      3.71     12.08      1.00      0.01      6.16    729.80      1.00\n",
      "lambda[120]      4.26     18.86      1.00      0.00      8.16    957.49      1.00\n",
      "lambda[121]      3.51     15.30      1.03      0.00      6.39    888.92      1.00\n",
      "lambda[122]      3.61     14.55      0.98      0.01      5.54    357.36      1.00\n",
      "lambda[123]      2.84      8.10      0.89      0.00      6.07    752.75      1.00\n",
      "lambda[124]      3.37     13.94      0.99      0.00      5.35    699.52      1.00\n",
      "lambda[125]      2.81      8.04      0.94      0.01      5.68    493.86      1.00\n",
      "lambda[126]      2.45      9.11      0.98      0.00      5.09   1007.06      1.00\n",
      "lambda[127]      3.20     16.13      0.98      0.00      5.44    972.36      1.00\n",
      "lambda[128]      4.83     36.51      0.93      0.00      6.10    424.19      1.00\n",
      "lambda[129]      3.17     21.93      0.91      0.00      5.29    921.00      1.00\n",
      "lambda[130]      3.01     10.41      0.95      0.00      5.91    751.10      1.01\n",
      "lambda[131]      6.09     48.63      0.99      0.00      5.70    478.14      1.00\n",
      "lambda[132]      3.15      8.28      1.00      0.01      6.24    775.82      1.00\n",
      "lambda[133]      2.53      5.77      0.94      0.00      5.22    733.49      1.00\n",
      "lambda[134]      2.98      8.41      0.98      0.00      6.53    797.62      1.00\n",
      "lambda[135]      2.46      7.42      0.94      0.00      4.58    967.59      1.00\n",
      "lambda[136]      2.76      7.65      0.93      0.00      5.67    795.26      1.00\n",
      "lambda[137]      2.79      8.80      1.02      0.00      5.82    805.08      1.00\n",
      "lambda[138]      2.89      7.76      0.97      0.00      5.92    528.39      1.00\n",
      "lambda[139]      2.52      5.79      0.95      0.00      5.25    746.99      1.00\n",
      "lambda[140]      3.51     16.83      0.99      0.00      6.13    887.41      1.00\n",
      "lambda[141]      2.89      7.39      0.95      0.00      6.31    625.67      1.00\n",
      "lambda[142]      6.38     79.00      0.99      0.00      6.39    947.64      1.00\n",
      "lambda[143]      2.54      6.51      0.97      0.00      5.31    813.67      1.00\n",
      "        msq   1812.21  41541.16      6.77      0.15    168.82    760.08      1.00\n",
      "      sigma      5.71      7.46      2.68      0.01     15.75    826.70      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    547.44      1.00\n",
      "       xisq      1.27      0.71      1.10      0.43      2.05    537.95      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 28.636818170547485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.61e-04 +- 2.11e-02\n",
      "[dimension 02/145]  inactive:\t6.01e-05 +- 3.20e-02\n",
      "[dimension 03/145]  inactive:\t-4.37e-05 +- 2.86e-02\n",
      "[dimension 04/145]  inactive:\t5.46e-03 +- 4.19e-02\n",
      "[dimension 05/145]  inactive:\t-3.27e-04 +- 2.74e-02\n",
      "[dimension 06/145]  inactive:\t4.63e-03 +- 5.04e-02\n",
      "[dimension 07/145]  inactive:\t7.77e-04 +- 1.98e-02\n",
      "[dimension 08/145]  inactive:\t1.07e-03 +- 3.55e-02\n",
      "[dimension 09/145]  inactive:\t4.39e-04 +- 2.41e-02\n",
      "[dimension 10/145]  inactive:\t2.98e-04 +- 1.94e-02\n",
      "[dimension 11/145]  inactive:\t-9.49e-04 +- 2.51e-02\n",
      "[dimension 12/145]  inactive:\t1.61e-04 +- 2.53e-02\n",
      "[dimension 13/145]  inactive:\t5.17e-03 +- 4.51e-02\n",
      "[dimension 14/145]  inactive:\t-1.10e-03 +- 2.54e-02\n",
      "[dimension 15/145]  inactive:\t1.11e-03 +- 3.61e-02\n",
      "[dimension 16/145]  inactive:\t7.63e-04 +- 2.01e-02\n",
      "[dimension 17/145]  inactive:\t1.63e-04 +- 2.75e-02\n",
      "[dimension 18/145]  inactive:\t4.37e-04 +- 2.98e-02\n",
      "[dimension 19/145]  inactive:\t-1.94e-03 +- 2.13e-02\n",
      "[dimension 20/145]  inactive:\t-8.92e-04 +- 2.68e-02\n",
      "[dimension 21/145]  inactive:\t-1.57e-03 +- 2.65e-02\n",
      "[dimension 22/145]  inactive:\t-1.18e-04 +- 2.42e-02\n",
      "[dimension 23/145]  inactive:\t-5.90e-04 +- 2.58e-02\n",
      "[dimension 24/145]  inactive:\t1.13e-03 +- 2.38e-02\n",
      "[dimension 25/145]  inactive:\t3.49e-03 +- 2.44e-02\n",
      "[dimension 26/145]  inactive:\t-4.13e-04 +- 3.27e-02\n",
      "[dimension 27/145]  inactive:\t9.43e-04 +- 2.65e-02\n",
      "[dimension 28/145]  inactive:\t1.20e-03 +- 2.17e-02\n",
      "[dimension 29/145]  inactive:\t3.01e-04 +- 3.17e-02\n",
      "[dimension 30/145]  inactive:\t1.70e-03 +- 3.15e-02\n",
      "[dimension 31/145]  inactive:\t6.40e-03 +- 4.65e-02\n",
      "[dimension 32/145]  inactive:\t-1.44e-03 +- 3.12e-02\n",
      "[dimension 33/145]  inactive:\t3.57e-03 +- 4.02e-02\n",
      "[dimension 34/145]  inactive:\t1.07e-03 +- 1.99e-02\n",
      "[dimension 35/145]  inactive:\t7.36e-04 +- 2.73e-02\n",
      "[dimension 36/145]  inactive:\t1.25e-03 +- 2.60e-02\n",
      "[dimension 37/145]  inactive:\t4.11e-03 +- 2.65e-02\n",
      "[dimension 38/145]  inactive:\t-1.70e-03 +- 3.19e-02\n",
      "[dimension 39/145]  inactive:\t2.92e-03 +- 4.15e-02\n",
      "[dimension 40/145]  inactive:\t4.36e-03 +- 3.87e-02\n",
      "[dimension 41/145]  inactive:\t-1.29e-03 +- 2.78e-02\n",
      "[dimension 42/145]  inactive:\t1.56e-02 +- 1.00e-01\n",
      "[dimension 43/145]  inactive:\t-5.62e-05 +- 1.93e-02\n",
      "[dimension 44/145]  inactive:\t-3.45e-04 +- 3.15e-02\n",
      "[dimension 45/145]  inactive:\t3.93e-05 +- 2.79e-02\n",
      "[dimension 46/145]  inactive:\t9.02e-04 +- 1.60e-02\n",
      "[dimension 47/145]  inactive:\t-1.22e-03 +- 2.59e-02\n",
      "[dimension 48/145]  inactive:\t1.20e-03 +- 2.27e-02\n",
      "[dimension 49/145]  inactive:\t3.05e-03 +- 2.81e-02\n",
      "[dimension 50/145]  inactive:\t-1.84e-03 +- 3.01e-02\n",
      "[dimension 51/145]  inactive:\t2.67e-03 +- 2.92e-02\n",
      "[dimension 52/145]  inactive:\t4.93e-03 +- 2.44e-02\n",
      "[dimension 53/145]  inactive:\t-6.48e-04 +- 2.29e-02\n",
      "[dimension 54/145]  inactive:\t6.67e-04 +- 2.40e-02\n",
      "[dimension 55/145]  inactive:\t4.82e-04 +- 1.70e-02\n",
      "[dimension 56/145]  inactive:\t-2.04e-03 +- 2.46e-02\n",
      "[dimension 57/145]  inactive:\t1.03e-03 +- 2.74e-02\n",
      "[dimension 58/145]  inactive:\t1.92e-02 +- 9.13e-02\n",
      "[dimension 59/145]  inactive:\t-6.03e-04 +- 2.06e-02\n",
      "[dimension 60/145]  inactive:\t9.35e-04 +- 3.00e-02\n",
      "[dimension 61/145]  inactive:\t3.62e-03 +- 3.04e-02\n",
      "[dimension 62/145]  inactive:\t-2.98e-04 +- 2.24e-02\n",
      "[dimension 63/145]  active:\t6.49e-01 +- 4.44e-01\n",
      "[dimension 64/145]  inactive:\t-2.21e-03 +- 2.30e-02\n",
      "[dimension 65/145]  inactive:\t-5.28e-04 +- 2.35e-02\n",
      "[dimension 66/145]  inactive:\t5.57e-04 +- 2.47e-02\n",
      "[dimension 67/145]  inactive:\t1.68e-03 +- 2.78e-02\n",
      "[dimension 68/145]  inactive:\t-1.11e-03 +- 3.54e-02\n",
      "[dimension 69/145]  inactive:\t4.81e-03 +- 4.88e-02\n",
      "[dimension 70/145]  inactive:\t3.85e-03 +- 2.50e-02\n",
      "[dimension 71/145]  inactive:\t7.09e-04 +- 3.38e-02\n",
      "[dimension 72/145]  inactive:\t1.01e-03 +- 2.56e-02\n",
      "[dimension 73/145]  inactive:\t3.64e-04 +- 1.76e-02\n",
      "[dimension 74/145]  inactive:\t-2.28e-03 +- 3.14e-02\n",
      "[dimension 75/145]  inactive:\t6.63e-04 +- 2.79e-02\n",
      "[dimension 76/145]  inactive:\t6.94e-03 +- 4.42e-02\n",
      "[dimension 77/145]  inactive:\t-1.49e-03 +- 2.94e-02\n",
      "[dimension 78/145]  inactive:\t1.00e-02 +- 7.70e-02\n",
      "[dimension 79/145]  inactive:\t6.40e-03 +- 3.62e-02\n",
      "[dimension 80/145]  inactive:\t2.94e-05 +- 3.08e-02\n",
      "[dimension 81/145]  inactive:\t3.27e-03 +- 4.99e-02\n",
      "[dimension 82/145]  inactive:\t4.13e-04 +- 1.82e-02\n",
      "[dimension 83/145]  inactive:\t-1.59e-03 +- 1.94e-02\n",
      "[dimension 84/145]  inactive:\t-2.44e-03 +- 3.27e-02\n",
      "[dimension 85/145]  inactive:\t4.25e-03 +- 3.81e-02\n",
      "[dimension 86/145]  inactive:\t-5.20e-04 +- 1.99e-02\n",
      "[dimension 87/145]  inactive:\t7.45e-03 +- 6.78e-02\n",
      "[dimension 88/145]  inactive:\t2.49e-03 +- 2.37e-02\n",
      "[dimension 89/145]  inactive:\t-7.18e-04 +- 2.19e-02\n",
      "[dimension 90/145]  inactive:\t1.28e-01 +- 3.08e-01\n",
      "[dimension 91/145]  inactive:\t6.59e-05 +- 2.00e-02\n",
      "[dimension 92/145]  inactive:\t-1.30e-03 +- 2.57e-02\n",
      "[dimension 93/145]  inactive:\t-8.06e-04 +- 2.77e-02\n",
      "[dimension 94/145]  inactive:\t1.52e-03 +- 2.34e-02\n",
      "[dimension 95/145]  inactive:\t-6.04e-04 +- 2.62e-02\n",
      "[dimension 96/145]  inactive:\t7.88e-04 +- 4.39e-02\n",
      "[dimension 97/145]  inactive:\t3.23e-03 +- 2.76e-02\n",
      "[dimension 98/145]  inactive:\t4.36e-04 +- 2.81e-02\n",
      "[dimension 99/145]  inactive:\t2.39e-03 +- 3.20e-02\n",
      "[dimension 100/145]  inactive:\t-6.24e-04 +- 1.86e-02\n",
      "[dimension 101/145]  inactive:\t-2.18e-03 +- 2.19e-02\n",
      "[dimension 102/145]  inactive:\t-9.45e-04 +- 2.47e-02\n",
      "[dimension 103/145]  inactive:\t9.27e-04 +- 2.29e-02\n",
      "[dimension 104/145]  inactive:\t-1.09e-03 +- 1.86e-02\n",
      "[dimension 105/145]  inactive:\t-6.01e-04 +- 3.06e-02\n",
      "[dimension 106/145]  inactive:\t4.90e-03 +- 3.29e-02\n",
      "[dimension 107/145]  inactive:\t-1.10e-03 +- 2.11e-02\n",
      "[dimension 108/145]  inactive:\t5.09e-03 +- 5.49e-02\n",
      "[dimension 109/145]  inactive:\t-5.31e-04 +- 1.91e-02\n",
      "[dimension 110/145]  inactive:\t-1.10e-03 +- 3.19e-02\n",
      "[dimension 111/145]  inactive:\t3.48e-03 +- 4.08e-02\n",
      "[dimension 112/145]  inactive:\t1.06e-02 +- 7.48e-02\n",
      "[dimension 113/145]  inactive:\t-1.01e-03 +- 1.85e-02\n",
      "[dimension 114/145]  inactive:\t3.22e-03 +- 4.90e-02\n",
      "[dimension 115/145]  inactive:\t1.75e-03 +- 2.17e-02\n",
      "[dimension 116/145]  inactive:\t3.71e-04 +- 3.66e-02\n",
      "[dimension 117/145]  inactive:\t3.80e-03 +- 4.58e-02\n",
      "[dimension 118/145]  inactive:\t2.54e-03 +- 2.29e-02\n",
      "[dimension 119/145]  inactive:\t-1.79e-03 +- 3.22e-02\n",
      "[dimension 120/145]  inactive:\t7.37e-04 +- 4.19e-02\n",
      "[dimension 121/145]  inactive:\t4.75e-03 +- 3.96e-02\n",
      "[dimension 122/145]  inactive:\t-2.60e-03 +- 3.31e-02\n",
      "[dimension 123/145]  inactive:\t4.21e-03 +- 5.66e-02\n",
      "[dimension 124/145]  inactive:\t-1.56e-03 +- 2.13e-02\n",
      "[dimension 125/145]  inactive:\t-1.87e-03 +- 3.10e-02\n",
      "[dimension 126/145]  inactive:\t-8.97e-04 +- 2.38e-02\n",
      "[dimension 127/145]  inactive:\t5.18e-05 +- 1.74e-02\n",
      "[dimension 128/145]  inactive:\t-4.20e-04 +- 2.82e-02\n",
      "[dimension 129/145]  inactive:\t9.55e-04 +- 3.02e-02\n",
      "[dimension 130/145]  inactive:\t2.93e-03 +- 2.70e-02\n",
      "[dimension 131/145]  inactive:\t-7.80e-04 +- 2.64e-02\n",
      "[dimension 132/145]  inactive:\t6.33e-03 +- 5.27e-02\n",
      "[dimension 133/145]  inactive:\t3.13e-03 +- 2.48e-02\n",
      "[dimension 134/145]  inactive:\t-4.63e-04 +- 2.42e-02\n",
      "[dimension 135/145]  inactive:\t2.98e-04 +- 2.52e-02\n",
      "[dimension 136/145]  inactive:\t1.04e-03 +- 2.03e-02\n",
      "[dimension 137/145]  inactive:\t-6.65e-04 +- 4.04e-02\n",
      "[dimension 138/145]  inactive:\t2.41e-04 +- 2.19e-02\n",
      "[dimension 139/145]  inactive:\t2.16e-04 +- 2.44e-02\n",
      "[dimension 140/145]  inactive:\t-9.88e-04 +- 3.35e-02\n",
      "[dimension 141/145]  inactive:\t1.63e-03 +- 3.07e-02\n",
      "[dimension 142/145]  inactive:\t1.44e-03 +- 1.94e-02\n",
      "[dimension 143/145]  inactive:\t1.28e-03 +- 3.88e-02\n",
      "[dimension 144/145]  inactive:\t4.29e-04 +- 2.27e-02\n",
      "[dimension 145/145]  inactive:\t-4.62e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[6.5863132e-06]\n",
      "cov_act[[1.1026859e-06]]\n",
      "Active_dimensions: [62]\n",
      "59, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.40it/s, 31 steps of size 1.66e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    323.16      1.00\n",
      "  lambda[0]      2.03      3.84      0.94      0.00      4.17    750.36      1.00\n",
      "  lambda[1]      2.98      8.81      0.98      0.00      5.44    552.52      1.00\n",
      "  lambda[2]      4.01     27.15      0.98      0.00      5.80    562.53      1.00\n",
      "  lambda[3]      4.15     23.97      0.99      0.00      6.29    570.71      1.00\n",
      "  lambda[4]      2.82     10.82      0.99      0.00      4.91    668.25      1.00\n",
      "  lambda[5]      3.31      9.94      1.00      0.00      5.89    726.42      1.00\n",
      "  lambda[6]      3.87     11.89      1.01      0.00      6.07    657.68      1.00\n",
      "  lambda[7]      3.22     11.42      0.99      0.00      5.80    686.52      1.00\n",
      "  lambda[8]      2.58      9.59      1.01      0.00      5.04    872.94      1.00\n",
      "  lambda[9]      2.41      5.71      1.01      0.00      4.84    694.82      1.00\n",
      " lambda[10]      3.30      9.46      1.05      0.00      6.39    678.52      1.00\n",
      " lambda[11]      2.59      5.42      1.02      0.01      6.22    757.73      1.00\n",
      " lambda[12]      4.78     22.49      1.03      0.00      8.08    951.18      1.00\n",
      " lambda[13]      2.77     11.02      0.97      0.00      5.15    770.33      1.00\n",
      " lambda[14]      7.43    109.64      0.94      0.00      5.35   1001.22      1.00\n",
      " lambda[15]      3.60     14.20      1.03      0.00      5.59    651.42      1.00\n",
      " lambda[16]      3.62     10.42      0.98      0.00      7.41    772.73      1.00\n",
      " lambda[17]      4.60     34.45      1.04      0.00      5.72    832.13      1.00\n",
      " lambda[18]      3.08      8.20      0.95      0.00      6.34    576.08      1.00\n",
      " lambda[19]      3.28     12.43      0.93      0.01      5.87    863.14      1.00\n",
      " lambda[20]      2.42      6.51      0.97      0.01      5.16    777.82      1.00\n",
      " lambda[21]      2.83      8.18      0.97      0.00      5.97    796.39      1.00\n",
      " lambda[22]      2.51      5.45      1.01      0.00      5.36    672.12      1.00\n",
      " lambda[23]      3.09      8.23      1.00      0.00      5.88    731.64      1.00\n",
      " lambda[24]      3.96     21.28      1.06      0.00      5.69    919.59      1.00\n",
      " lambda[25]      3.13     12.56      0.99      0.00      5.47    600.93      1.00\n",
      " lambda[26]      3.37     15.04      0.99      0.00      5.23    744.92      1.00\n",
      " lambda[27]      2.92      8.24      1.01      0.00      5.43    567.21      1.00\n",
      " lambda[28]      3.00     10.42      0.99      0.00      5.78    579.15      1.00\n",
      " lambda[29]      3.27     11.45      0.94      0.00      6.35    458.08      1.00\n",
      " lambda[30]      3.81     14.83      0.99      0.01      5.56    645.38      1.00\n",
      " lambda[31]      3.45     14.54      0.96      0.00      5.92    576.15      1.00\n",
      " lambda[32]      3.27     13.44      0.97      0.00      5.99    604.03      1.00\n",
      " lambda[33]      3.22     11.87      0.95      0.00      5.42    788.64      1.00\n",
      " lambda[34]      4.39     22.43      0.97      0.00      5.90    460.22      1.00\n",
      " lambda[35]      2.57      7.25      0.96      0.00      4.80    925.51      1.00\n",
      " lambda[36]      3.65     16.05      1.06      0.00      5.97    818.19      1.00\n",
      " lambda[37]      2.81      8.02      1.01      0.00      5.53   1009.84      1.00\n",
      " lambda[38]      3.11      8.92      0.97      0.00      5.88    738.63      1.00\n",
      " lambda[39]      3.33      9.52      0.99      0.00      5.91    701.66      1.00\n",
      " lambda[40]      3.73     16.95      0.91      0.00      6.17    953.79      1.00\n",
      " lambda[41]     45.14    406.98      0.97      0.00     10.20    180.29      1.01\n",
      " lambda[42]      2.91      6.38      0.96      0.00      5.92    524.98      1.00\n",
      " lambda[43]      3.83     29.11      0.94      0.00      5.94    972.26      1.00\n",
      " lambda[44]      3.26     18.07      1.00      0.00      5.88    586.64      1.00\n",
      " lambda[45]      2.47      5.69      0.97      0.00      5.02    625.05      1.00\n",
      " lambda[46]      2.43      5.35      1.05      0.01      5.07    818.21      1.00\n",
      " lambda[47]      2.71      6.25      0.91      0.01      6.05    610.24      1.00\n",
      " lambda[48]      2.55      7.30      1.01      0.00      5.01    838.94      1.00\n",
      " lambda[49]      3.21      9.68      0.94      0.00      6.05    703.11      1.00\n",
      " lambda[50]      3.04      9.01      1.05      0.00      5.75    621.50      1.00\n",
      " lambda[51]      4.63     15.63      1.00      0.00      9.16    735.89      1.00\n",
      " lambda[52]      2.93      7.99      0.96      0.00      5.85    574.72      1.00\n",
      " lambda[53]      2.95      8.66      0.93      0.01      5.72    868.70      1.00\n",
      " lambda[54]      2.19      4.22      0.89      0.00      5.21    651.07      1.00\n",
      " lambda[55]      2.99     13.07      0.97      0.00      5.36    840.11      1.00\n",
      " lambda[56]      2.86      7.75      0.98      0.00      5.56    501.01      1.00\n",
      " lambda[57]     59.42    937.27      1.04      0.00      7.60    364.58      1.00\n",
      " lambda[58]      2.34      6.11      0.96      0.00      4.79    802.24      1.00\n",
      " lambda[59]      9.57    161.51      0.96      0.00      6.33    706.28      1.00\n",
      " lambda[60]      4.28     22.86      0.95      0.00      6.38    639.20      1.00\n",
      " lambda[61]      2.79      7.84      1.00      0.00      6.25    802.01      1.00\n",
      " lambda[62]   7611.37  99762.66    342.30      0.00   3922.75    764.90      1.00\n",
      " lambda[63]      2.23      5.94      0.96      0.01      4.87    842.10      1.00\n",
      " lambda[64]      2.94      7.97      0.97      0.00      5.90    791.77      1.00\n",
      " lambda[65]      3.57     14.93      0.98      0.00      6.32    690.96      1.00\n",
      " lambda[66]      8.34    118.67      1.00      0.00      6.72    492.12      1.00\n",
      " lambda[67]      2.66      6.44      0.93      0.00      5.97    709.62      1.00\n",
      " lambda[68]      5.96     53.67      0.96      0.00      6.24    414.67      1.00\n",
      " lambda[69]      4.84     25.89      0.95      0.00      6.76    644.51      1.00\n",
      " lambda[70]      2.74      7.04      1.01      0.00      5.17    440.01      1.00\n",
      " lambda[71]      3.63     19.33      0.98      0.00      5.87    760.90      1.00\n",
      " lambda[72]      2.74      7.63      0.96      0.01      5.24    732.64      1.00\n",
      " lambda[73]      2.93     12.61      1.04      0.00      5.24   1000.02      1.00\n",
      " lambda[74]      2.70      7.57      0.98      0.01      5.58    525.14      1.00\n",
      " lambda[75]      5.08     25.60      1.00      0.00      7.12    774.01      1.01\n",
      " lambda[76]      2.66      6.82      0.95      0.00      5.12    771.52      1.00\n",
      " lambda[77]     68.36   1893.25      1.12      0.00      7.33    965.97      1.00\n",
      " lambda[78]      3.70     16.70      1.10      0.00      6.49    838.11      1.00\n",
      " lambda[79]      2.91      7.52      1.05      0.00      6.21    721.35      1.01\n",
      " lambda[80]      3.60     14.59      1.00      0.01      7.03    881.97      1.00\n",
      " lambda[81]      2.26      4.37      0.88      0.00      5.29    827.37      1.00\n",
      " lambda[82]      2.60     12.62      0.93      0.00      4.76    569.45      1.00\n",
      " lambda[83]      2.78      9.00      0.93      0.00      4.76    667.57      1.00\n",
      " lambda[84]      4.47     30.93      1.00      0.00      5.37    829.56      1.00\n",
      " lambda[85]      2.61      7.21      0.95      0.00      5.18    449.14      1.00\n",
      " lambda[86]      5.02     63.94      0.99      0.01      5.72    885.30      1.00\n",
      " lambda[87]      3.42     14.41      0.98      0.00      6.31    715.76      1.00\n",
      " lambda[88]      2.54      6.10      0.91      0.00      5.51    876.19      1.00\n",
      " lambda[89]    394.06   4505.83      1.12      0.00     74.47    631.78      1.00\n",
      " lambda[90]      2.22      4.14      1.00      0.00      4.74    548.02      1.00\n",
      " lambda[91]      2.64      6.40      0.99      0.01      5.41    655.81      1.00\n",
      " lambda[92]      2.52      5.64      0.99      0.00      4.92    727.37      1.00\n",
      " lambda[93]      2.51      5.66      1.04      0.00      5.51    679.97      1.00\n",
      " lambda[94]      2.30      6.29      0.95      0.00      4.34    904.31      1.00\n",
      " lambda[95]      2.82      7.98      1.01      0.00      5.47    616.82      1.00\n",
      " lambda[96]      2.97      9.27      0.99      0.00      5.16    452.55      1.00\n",
      " lambda[97]      6.00     67.42      1.02      0.00      5.63    514.07      1.00\n",
      " lambda[98]     26.20    297.48      0.99      0.00      5.71    392.49      1.00\n",
      " lambda[99]      2.37      6.47      0.94      0.00      4.70    781.22      1.00\n",
      "lambda[100]      2.43      5.66      0.92      0.00      5.66    686.55      1.00\n",
      "lambda[101]      2.92      8.67      0.90      0.00      5.73    655.87      1.00\n",
      "lambda[102]      2.63      6.67      0.89      0.00      5.24    741.58      1.00\n",
      "lambda[103]      2.44      5.66      0.99      0.00      5.24    697.13      1.00\n",
      "lambda[104]      3.21     11.12      1.01      0.00      6.14    402.66      1.00\n",
      "lambda[105]      3.91     10.81      1.01      0.00      8.36    684.04      1.00\n",
      "lambda[106]      2.49      5.06      1.01      0.01      5.90    730.48      1.00\n",
      "lambda[107]      7.23     52.99      1.01      0.00      5.76    723.14      1.00\n",
      "lambda[108]      2.46     10.63      0.99      0.00      4.55    710.51      1.00\n",
      "lambda[109]      3.66     23.58      0.95      0.00      5.99    959.02      1.00\n",
      "lambda[110]      4.22     16.15      1.00      0.00      6.36    693.16      1.00\n",
      "lambda[111]      8.53    103.62      0.99      0.00      6.40    502.27      1.00\n",
      "lambda[112]      2.49      5.62      0.94      0.00      5.65   1016.53      1.00\n",
      "lambda[113]      3.38     11.77      1.00      0.00      6.02    641.03      1.00\n",
      "lambda[114]      4.57     16.42      1.03      0.00      6.99    785.77      1.00\n",
      "lambda[115]      4.53     21.44      0.90      0.00      6.14    863.49      1.00\n",
      "lambda[116]     14.35    182.64      1.05      0.00      5.70    615.57      1.00\n",
      "lambda[117]      3.16     11.59      0.98      0.00      6.31    849.66      1.00\n",
      "lambda[118]      3.04     10.06      0.95      0.00      6.08    966.39      1.00\n",
      "lambda[119]      2.78     10.23      1.00      0.00      5.65   1011.03      1.00\n",
      "lambda[120]      4.10     24.37      0.94      0.00      5.86    559.11      1.00\n",
      "lambda[121]      3.22     16.30      0.91      0.00      5.78    937.47      1.00\n",
      "lambda[122]      6.82     79.75      0.92      0.00      6.85    900.61      1.00\n",
      "lambda[123]      2.67      6.66      0.91      0.00      6.07    756.56      1.00\n",
      "lambda[124]      2.59      5.59      1.01      0.00      5.97    849.46      1.00\n",
      "lambda[125]      2.75      7.98      0.93      0.00      5.70    663.07      1.00\n",
      "lambda[126]      3.03      9.97      0.98      0.00      5.28    792.96      1.00\n",
      "lambda[127]      4.85     32.19      0.99      0.00      6.57    725.56      1.00\n",
      "lambda[128]      3.45     17.93      0.96      0.00      4.72    367.79      1.00\n",
      "lambda[129]      4.25     24.58      1.00      0.00      7.15    984.31      1.00\n",
      "lambda[130]      3.28      8.89      0.90      0.00      6.30    624.97      1.00\n",
      "lambda[131]      2.87      7.66      0.95      0.00      5.41    696.14      1.00\n",
      "lambda[132]      2.73      6.20      1.04      0.00      5.88    451.72      1.00\n",
      "lambda[133]      2.83     14.14      1.01      0.00      5.25   1008.73      1.00\n",
      "lambda[134]      4.03     17.09      0.91      0.00      7.70    865.18      1.00\n",
      "lambda[135]      2.53      6.14      0.89      0.00      5.19    533.45      1.00\n",
      "lambda[136]      2.72      7.42      0.97      0.00      5.65    804.18      1.00\n",
      "lambda[137]     21.69    603.90      0.96      0.00      5.15   1002.11      1.00\n",
      "lambda[138]      3.18     13.88      1.00      0.00      5.03    823.97      1.00\n",
      "lambda[139]      3.44     13.75      0.96      0.00      6.54    882.94      1.00\n",
      "lambda[140]      3.47     11.47      0.99      0.00      6.09    874.02      1.00\n",
      "lambda[141]      2.94     12.99      0.90      0.00      5.46    702.04      1.00\n",
      "lambda[142]      6.53     63.00      1.00      0.00      6.22    792.75      1.00\n",
      "lambda[143]      3.11     15.63      0.93      0.00      5.32    488.75      1.00\n",
      "        msq      0.25      0.20      0.21      0.07      0.41    673.02      1.00\n",
      "      sigma      5.03      7.45      1.74      0.00     14.36   1195.82      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    446.31      1.00\n",
      "       xisq      1.04      0.53      0.92      0.35      1.67   1616.97      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.41757106781006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t7.02e-05 +- 8.21e-03\n",
      "[dimension 02/145]  inactive:\t9.24e-04 +- 1.94e-02\n",
      "[dimension 03/145]  inactive:\t2.12e-03 +- 2.71e-02\n",
      "[dimension 04/145]  inactive:\t2.80e-03 +- 2.46e-02\n",
      "[dimension 05/145]  inactive:\t8.68e-04 +- 1.92e-02\n",
      "[dimension 06/145]  inactive:\t1.31e-03 +- 2.00e-02\n",
      "[dimension 07/145]  inactive:\t1.48e-03 +- 1.71e-02\n",
      "[dimension 08/145]  inactive:\t2.30e-03 +- 3.11e-02\n",
      "[dimension 09/145]  inactive:\t1.46e-03 +- 2.30e-02\n",
      "[dimension 10/145]  inactive:\t4.33e-04 +- 1.04e-02\n",
      "[dimension 11/145]  inactive:\t4.72e-04 +- 1.45e-02\n",
      "[dimension 12/145]  inactive:\t5.57e-04 +- 1.38e-02\n",
      "[dimension 13/145]  inactive:\t3.27e-03 +- 3.18e-02\n",
      "[dimension 14/145]  inactive:\t8.32e-04 +- 1.90e-02\n",
      "[dimension 15/145]  inactive:\t2.34e-03 +- 3.29e-02\n",
      "[dimension 16/145]  inactive:\t1.14e-03 +- 1.70e-02\n",
      "[dimension 17/145]  inactive:\t2.77e-03 +- 3.34e-02\n",
      "[dimension 18/145]  inactive:\t2.70e-03 +- 3.32e-02\n",
      "[dimension 19/145]  inactive:\t-3.86e-04 +- 1.31e-02\n",
      "[dimension 20/145]  inactive:\t3.55e-04 +- 1.60e-02\n",
      "[dimension 21/145]  inactive:\t-1.22e-04 +- 1.08e-02\n",
      "[dimension 22/145]  inactive:\t3.84e-04 +- 1.20e-02\n",
      "[dimension 23/145]  inactive:\t5.44e-04 +- 1.63e-02\n",
      "[dimension 24/145]  inactive:\t1.72e-03 +- 2.21e-02\n",
      "[dimension 25/145]  inactive:\t2.16e-03 +- 1.80e-02\n",
      "[dimension 26/145]  inactive:\t9.67e-04 +- 2.39e-02\n",
      "[dimension 27/145]  inactive:\t2.27e-03 +- 2.73e-02\n",
      "[dimension 28/145]  inactive:\t9.11e-04 +- 1.34e-02\n",
      "[dimension 29/145]  inactive:\t1.93e-03 +- 2.52e-02\n",
      "[dimension 30/145]  inactive:\t2.73e-03 +- 3.17e-02\n",
      "[dimension 31/145]  inactive:\t4.16e-03 +- 3.87e-02\n",
      "[dimension 32/145]  inactive:\t3.83e-04 +- 1.40e-02\n",
      "[dimension 33/145]  inactive:\t1.29e-03 +- 1.95e-02\n",
      "[dimension 34/145]  inactive:\t8.68e-04 +- 1.50e-02\n",
      "[dimension 35/145]  inactive:\t3.98e-03 +- 4.30e-02\n",
      "[dimension 36/145]  inactive:\t1.66e-03 +- 2.20e-02\n",
      "[dimension 37/145]  inactive:\t2.43e-03 +- 1.95e-02\n",
      "[dimension 38/145]  inactive:\t9.20e-04 +- 2.14e-02\n",
      "[dimension 39/145]  inactive:\t1.91e-03 +- 2.18e-02\n",
      "[dimension 40/145]  inactive:\t3.18e-03 +- 2.84e-02\n",
      "[dimension 41/145]  inactive:\t1.31e-03 +- 2.82e-02\n",
      "[dimension 42/145]  inactive:\t2.05e-02 +- 1.18e-01\n",
      "[dimension 43/145]  inactive:\t1.09e-03 +- 1.67e-02\n",
      "[dimension 44/145]  inactive:\t6.12e-04 +- 1.67e-02\n",
      "[dimension 45/145]  inactive:\t1.15e-03 +- 1.87e-02\n",
      "[dimension 46/145]  inactive:\t4.77e-04 +- 9.84e-03\n",
      "[dimension 47/145]  inactive:\t2.41e-04 +- 1.72e-02\n",
      "[dimension 48/145]  inactive:\t9.17e-04 +- 1.60e-02\n",
      "[dimension 49/145]  inactive:\t1.33e-03 +- 1.88e-02\n",
      "[dimension 50/145]  inactive:\t5.00e-04 +- 1.99e-02\n",
      "[dimension 51/145]  inactive:\t3.24e-03 +- 3.50e-02\n",
      "[dimension 52/145]  inactive:\t4.37e-03 +- 2.23e-02\n",
      "[dimension 53/145]  inactive:\t2.46e-05 +- 1.55e-02\n",
      "[dimension 54/145]  inactive:\t8.05e-04 +- 1.46e-02\n",
      "[dimension 55/145]  inactive:\t4.21e-04 +- 1.01e-02\n",
      "[dimension 56/145]  inactive:\t-6.93e-04 +- 1.58e-02\n",
      "[dimension 57/145]  inactive:\t1.54e-03 +- 2.24e-02\n",
      "[dimension 58/145]  inactive:\t1.77e-02 +- 9.69e-02\n",
      "[dimension 59/145]  inactive:\t3.09e-05 +- 1.09e-02\n",
      "[dimension 60/145]  inactive:\t2.54e-03 +- 3.04e-02\n",
      "[dimension 61/145]  inactive:\t2.99e-03 +- 2.59e-02\n",
      "[dimension 62/145]  inactive:\t1.71e-04 +- 1.18e-02\n",
      "[dimension 63/145]  active:\t5.91e-01 +- 4.25e-01\n",
      "[dimension 64/145]  inactive:\t-6.41e-04 +- 1.26e-02\n",
      "[dimension 65/145]  inactive:\t8.00e-04 +- 1.66e-02\n",
      "[dimension 66/145]  inactive:\t1.72e-03 +- 2.25e-02\n",
      "[dimension 67/145]  inactive:\t1.84e-03 +- 2.47e-02\n",
      "[dimension 68/145]  inactive:\t3.73e-04 +- 1.44e-02\n",
      "[dimension 69/145]  inactive:\t3.70e-03 +- 3.99e-02\n",
      "[dimension 70/145]  inactive:\t4.05e-03 +- 2.77e-02\n",
      "[dimension 71/145]  inactive:\t5.96e-04 +- 1.66e-02\n",
      "[dimension 72/145]  inactive:\t1.63e-03 +- 2.24e-02\n",
      "[dimension 73/145]  inactive:\t4.19e-04 +- 9.85e-03\n",
      "[dimension 74/145]  inactive:\t1.23e-03 +- 2.27e-02\n",
      "[dimension 75/145]  inactive:\t2.46e-03 +- 3.18e-02\n",
      "[dimension 76/145]  inactive:\t5.28e-03 +- 3.68e-02\n",
      "[dimension 77/145]  inactive:\t3.85e-04 +- 1.84e-02\n",
      "[dimension 78/145]  inactive:\t1.06e-02 +- 8.00e-02\n",
      "[dimension 79/145]  inactive:\t3.68e-03 +- 2.60e-02\n",
      "[dimension 80/145]  inactive:\t1.09e-03 +- 1.88e-02\n",
      "[dimension 81/145]  inactive:\t2.26e-03 +- 2.42e-02\n",
      "[dimension 82/145]  inactive:\t3.03e-04 +- 9.44e-03\n",
      "[dimension 83/145]  inactive:\t-2.62e-04 +- 9.65e-03\n",
      "[dimension 84/145]  inactive:\t2.76e-04 +- 1.89e-02\n",
      "[dimension 85/145]  inactive:\t3.34e-03 +- 3.40e-02\n",
      "[dimension 86/145]  inactive:\t-1.21e-05 +- 1.23e-02\n",
      "[dimension 87/145]  inactive:\t2.52e-03 +- 3.46e-02\n",
      "[dimension 88/145]  inactive:\t2.25e-03 +- 2.11e-02\n",
      "[dimension 89/145]  inactive:\t1.33e-04 +- 1.31e-02\n",
      "[dimension 90/145]  inactive:\t8.20e-02 +- 2.41e-01\n",
      "[dimension 91/145]  inactive:\t1.21e-04 +- 9.48e-03\n",
      "[dimension 92/145]  inactive:\t-2.12e-06 +- 1.18e-02\n",
      "[dimension 93/145]  inactive:\t3.79e-04 +- 1.71e-02\n",
      "[dimension 94/145]  inactive:\t1.09e-03 +- 1.76e-02\n",
      "[dimension 95/145]  inactive:\t1.41e-04 +- 1.23e-02\n",
      "[dimension 96/145]  inactive:\t1.21e-03 +- 2.37e-02\n",
      "[dimension 97/145]  inactive:\t1.69e-03 +- 1.66e-02\n",
      "[dimension 98/145]  inactive:\t8.57e-04 +- 2.05e-02\n",
      "[dimension 99/145]  inactive:\t1.21e-02 +- 8.59e-02\n",
      "[dimension 100/145]  inactive:\t3.93e-05 +- 8.89e-03\n",
      "[dimension 101/145]  inactive:\t-5.24e-04 +- 1.12e-02\n",
      "[dimension 102/145]  inactive:\t4.44e-04 +- 1.61e-02\n",
      "[dimension 103/145]  inactive:\t9.29e-04 +- 1.61e-02\n",
      "[dimension 104/145]  inactive:\t-8.03e-05 +- 1.08e-02\n",
      "[dimension 105/145]  inactive:\t6.79e-04 +- 2.00e-02\n",
      "[dimension 106/145]  inactive:\t5.11e-03 +- 3.37e-02\n",
      "[dimension 107/145]  inactive:\t-1.64e-04 +- 1.25e-02\n",
      "[dimension 108/145]  inactive:\t1.31e-02 +- 8.39e-02\n",
      "[dimension 109/145]  inactive:\t1.86e-04 +- 1.02e-02\n",
      "[dimension 110/145]  inactive:\t8.88e-04 +- 2.05e-02\n",
      "[dimension 111/145]  inactive:\t3.47e-03 +- 3.55e-02\n",
      "[dimension 112/145]  inactive:\t5.58e-03 +- 4.86e-02\n",
      "[dimension 113/145]  inactive:\t5.50e-05 +- 1.43e-02\n",
      "[dimension 114/145]  inactive:\t1.70e-03 +- 2.67e-02\n",
      "[dimension 115/145]  inactive:\t2.45e-03 +- 2.10e-02\n",
      "[dimension 116/145]  inactive:\t5.40e-03 +- 5.44e-02\n",
      "[dimension 117/145]  inactive:\t9.32e-03 +- 7.16e-02\n",
      "[dimension 118/145]  inactive:\t1.43e-03 +- 1.41e-02\n",
      "[dimension 119/145]  inactive:\t3.87e-04 +- 1.59e-02\n",
      "[dimension 120/145]  inactive:\t6.23e-04 +- 1.67e-02\n",
      "[dimension 121/145]  inactive:\t2.96e-03 +- 3.07e-02\n",
      "[dimension 122/145]  inactive:\t8.33e-05 +- 1.87e-02\n",
      "[dimension 123/145]  inactive:\t4.80e-03 +- 5.05e-02\n",
      "[dimension 124/145]  inactive:\t2.61e-04 +- 1.20e-02\n",
      "[dimension 125/145]  inactive:\t1.51e-04 +- 1.41e-02\n",
      "[dimension 126/145]  inactive:\t2.27e-04 +- 1.16e-02\n",
      "[dimension 127/145]  inactive:\t5.49e-04 +- 1.13e-02\n",
      "[dimension 128/145]  inactive:\t2.59e-03 +- 3.65e-02\n",
      "[dimension 129/145]  inactive:\t1.33e-03 +- 2.08e-02\n",
      "[dimension 130/145]  inactive:\t2.53e-03 +- 2.31e-02\n",
      "[dimension 131/145]  inactive:\t8.46e-04 +- 2.02e-02\n",
      "[dimension 132/145]  inactive:\t2.09e-03 +- 2.49e-02\n",
      "[dimension 133/145]  inactive:\t1.78e-03 +- 1.65e-02\n",
      "[dimension 134/145]  inactive:\t7.57e-04 +- 1.96e-02\n",
      "[dimension 135/145]  inactive:\t2.15e-03 +- 2.62e-02\n",
      "[dimension 136/145]  inactive:\t1.05e-03 +- 1.32e-02\n",
      "[dimension 137/145]  inactive:\t1.38e-03 +- 2.26e-02\n",
      "[dimension 138/145]  inactive:\t1.34e-03 +- 2.06e-02\n",
      "[dimension 139/145]  inactive:\t9.97e-04 +- 1.58e-02\n",
      "[dimension 140/145]  inactive:\t1.19e-03 +- 2.62e-02\n",
      "[dimension 141/145]  inactive:\t1.70e-03 +- 2.38e-02\n",
      "[dimension 142/145]  inactive:\t1.29e-03 +- 1.25e-02\n",
      "[dimension 143/145]  inactive:\t3.28e-03 +- 3.40e-02\n",
      "[dimension 144/145]  inactive:\t1.97e-03 +- 2.41e-02\n",
      "[dimension 145/145]  inactive:\t-2.68e-10 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8022175]\n",
      "cov_act[[0.0195892]]\n",
      "Active_dimensions: [62]\n",
      "60, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 53.54it/s, 31 steps of size 1.88e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    553.31      1.00\n",
      "  lambda[0]      2.34      6.37      0.92      0.00      4.69    647.21      1.00\n",
      "  lambda[1]      2.60      7.25      0.96      0.00      4.71    945.72      1.00\n",
      "  lambda[2]      2.54      5.96      1.01      0.00      5.05    620.70      1.00\n",
      "  lambda[3]      7.45    104.06      0.95      0.00      7.15    997.70      1.00\n",
      "  lambda[4]      2.98     11.33      1.07      0.00      5.94    849.43      1.00\n",
      "  lambda[5]      3.42     11.14      0.97      0.00      5.87    717.90      1.00\n",
      "  lambda[6]      2.82      8.47      0.95      0.00      5.06    735.36      1.00\n",
      "  lambda[7]      3.17      8.87      1.01      0.00      6.03    532.63      1.00\n",
      "  lambda[8]      2.33      4.05      1.06      0.01      5.33    822.27      1.00\n",
      "  lambda[9]      2.40      6.76      0.98      0.00      4.67   1023.13      1.00\n",
      " lambda[10]      3.04      8.80      1.07      0.00      5.64    664.28      1.00\n",
      " lambda[11]      2.91      9.86      0.97      0.00      6.05    672.06      1.00\n",
      " lambda[12]      4.55     16.87      0.99      0.00      6.59    372.86      1.01\n",
      " lambda[13]      2.64      7.22      0.99      0.00      5.76    558.86      1.00\n",
      " lambda[14]      2.76      8.01      0.95      0.00      5.40    763.87      1.00\n",
      " lambda[15]      2.96      7.85      0.99      0.00      5.76    937.70      1.00\n",
      " lambda[16]      3.09      8.72      1.05      0.00      6.09    909.14      1.00\n",
      " lambda[17]      2.99     13.47      1.01      0.00      5.76    528.82      1.00\n",
      " lambda[18]      2.67      5.45      1.00      0.00      6.12    856.89      1.00\n",
      " lambda[19]      3.44     11.79      0.92      0.00      6.29    847.89      1.00\n",
      " lambda[20]      2.61      8.00      0.94      0.00      4.94    844.24      1.00\n",
      " lambda[21]      2.78      6.29      0.97      0.00      5.95    638.77      1.00\n",
      " lambda[22]      2.37      4.51      1.03      0.00      5.47    685.66      1.00\n",
      " lambda[23]      3.03      8.20      0.96      0.00      6.44    873.13      1.00\n",
      " lambda[24]      3.82     14.38      1.03      0.00      6.98    910.65      1.00\n",
      " lambda[25]      2.45      6.30      1.00      0.00      5.08    448.18      1.00\n",
      " lambda[26]      2.55      5.83      1.00      0.00      5.53    887.63      1.00\n",
      " lambda[27]      2.52      5.58      0.94      0.00      5.35    453.28      1.00\n",
      " lambda[28]      2.56      6.74      1.01      0.00      5.35    858.54      1.00\n",
      " lambda[29]      3.24     12.04      0.92      0.00      5.43    586.45      1.00\n",
      " lambda[30]      3.60     14.60      0.98      0.01      7.07    865.84      1.00\n",
      " lambda[31]      3.58     15.89      0.96      0.00      5.32    565.01      1.00\n",
      " lambda[32]      3.44     12.67      0.99      0.00      6.49    725.64      1.00\n",
      " lambda[33]      2.50      6.18      0.96      0.01      5.74    765.53      1.00\n",
      " lambda[34]      3.17      9.85      1.02      0.00      6.33    640.78      1.00\n",
      " lambda[35]      2.43      6.53      0.99      0.00      4.73   1015.05      1.00\n",
      " lambda[36]      3.23     11.34      0.95      0.00      6.05    825.35      1.00\n",
      " lambda[37]      3.91     14.69      1.01      0.00      6.55    717.40      1.00\n",
      " lambda[38]      3.48     10.58      0.97      0.00      7.00    881.11      1.01\n",
      " lambda[39]      3.17      9.62      0.97      0.00      5.66    744.25      1.00\n",
      " lambda[40]      3.21     11.11      0.98      0.00      5.88    790.79      1.00\n",
      " lambda[41]     16.06    252.76      0.93      0.00      8.66    734.68      1.00\n",
      " lambda[42]      2.42      4.91      1.01      0.00      4.99    582.08      1.01\n",
      " lambda[43]      3.20     15.14      0.99      0.00      5.98    943.16      1.00\n",
      " lambda[44]      3.50     14.15      0.97      0.00      6.70    537.14      1.00\n",
      " lambda[45]      2.64      6.12      0.95      0.00      5.28    605.80      1.00\n",
      " lambda[46]      3.00     10.08      1.02      0.00      5.08    523.29      1.00\n",
      " lambda[47]      2.31      4.46      0.96      0.00      4.97    775.18      1.00\n",
      " lambda[48]      2.97      8.71      0.93      0.00      5.85    557.26      1.00\n",
      " lambda[49]      3.04      9.22      0.97      0.00      5.78    762.94      1.00\n",
      " lambda[50]      2.47      5.38      0.84      0.00      5.44    624.58      1.00\n",
      " lambda[51]      3.06      8.04      0.99      0.00      5.98    714.03      1.00\n",
      " lambda[52]      2.63      7.83      0.92      0.00      5.38    982.39      1.00\n",
      " lambda[53]      2.65      6.69      0.98      0.00      5.21    892.90      1.00\n",
      " lambda[54]      2.45      6.33      0.94      0.00      5.44    647.92      1.00\n",
      " lambda[55]      3.65     23.24      0.94      0.00      5.63    870.87      1.00\n",
      " lambda[56]      2.80      7.26      0.99      0.00      5.31    768.89      1.00\n",
      " lambda[57]      6.07     29.34      0.97      0.00     10.17    355.85      1.00\n",
      " lambda[58]      2.55      6.92      0.90      0.01      4.80    636.59      1.00\n",
      " lambda[59]      2.65      8.95      1.00      0.00      5.20    912.43      1.00\n",
      " lambda[60]      3.31     13.53      0.94      0.00      5.89    650.73      1.00\n",
      " lambda[61]      3.26     18.53      0.97      0.01      5.32    764.92      1.00\n",
      " lambda[62]   1402.44  14802.69    158.16      0.00   1126.66    642.36      1.00\n",
      " lambda[63]      2.30      5.12      1.05      0.00      4.23    759.38      1.00\n",
      " lambda[64]      2.77      7.97      1.00      0.00      5.30    643.15      1.01\n",
      " lambda[65]      2.42      5.13      1.04      0.00      5.39    910.30      1.00\n",
      " lambda[66]      7.19     91.06      0.97      0.00      6.59    557.41      1.00\n",
      " lambda[67]      2.68      7.53      0.90      0.00      5.27    741.44      1.00\n",
      " lambda[68]      4.12     34.10      0.94      0.00      6.19    958.74      1.00\n",
      " lambda[69]      3.35     10.63      0.94      0.00      6.13    767.42      1.00\n",
      " lambda[70]      2.71      7.32      0.94      0.01      5.65    717.50      1.00\n",
      " lambda[71]      3.56     14.84      0.95      0.00      5.63    404.62      1.00\n",
      " lambda[72]      2.43      6.48      0.95      0.00      4.59    531.64      1.00\n",
      " lambda[73]      2.90      8.07      1.10      0.00      6.02    796.14      1.00\n",
      " lambda[74]      2.60      5.40      1.00      0.00      5.94    790.96      1.00\n",
      " lambda[75]      4.30     23.66      1.00      0.00      6.39    928.91      1.00\n",
      " lambda[76]      2.91      7.67      0.94      0.00      5.51    700.53      1.00\n",
      " lambda[77]      4.61     21.51      1.01      0.00      7.22    580.34      1.00\n",
      " lambda[78]      4.87     41.90      1.01      0.00      6.06    696.28      1.00\n",
      " lambda[79]      3.13     15.31      0.98      0.00      5.35    974.70      1.00\n",
      " lambda[80]      3.09      9.98      1.02      0.00      5.96    557.31      1.00\n",
      " lambda[81]      2.64      6.14      0.95      0.00      5.74    860.16      1.00\n",
      " lambda[82]      3.21     13.60      0.96      0.00      5.53    723.67      1.00\n",
      " lambda[83]      2.84      7.83      0.96      0.00      6.14    691.24      1.00\n",
      " lambda[84]      4.33     16.15      1.03      0.00      7.09    445.02      1.00\n",
      " lambda[85]      2.44      5.21      0.93      0.00      5.63    548.17      1.00\n",
      " lambda[86]      2.78      7.95      0.95      0.00      6.21    758.42      1.00\n",
      " lambda[87]      2.94      6.44      0.99      0.00      6.67    861.20      1.00\n",
      " lambda[88]      2.68      5.67      1.02      0.00      6.39    948.76      1.00\n",
      " lambda[89]     86.58    449.97      1.46      0.00    172.25    379.64      1.00\n",
      " lambda[90]      2.87      9.88      1.01      0.00      5.02    693.69      1.00\n",
      " lambda[91]      2.88      8.26      0.95      0.00      5.36    570.02      1.00\n",
      " lambda[92]      2.56      6.42      1.03      0.00      5.29    935.17      1.00\n",
      " lambda[93]      2.93      6.53      1.05      0.00      6.57    470.78      1.00\n",
      " lambda[94]      2.60      6.25      0.97      0.00      4.84    851.41      1.00\n",
      " lambda[95]      2.95      7.37      0.92      0.00      6.15    750.85      1.00\n",
      " lambda[96]      2.58      6.69      0.96      0.00      5.14   1019.64      1.00\n",
      " lambda[97]      3.18      9.06      1.00      0.00      5.76    575.68      1.00\n",
      " lambda[98]      4.36     29.34      0.95      0.00      6.24    887.18      1.00\n",
      " lambda[99]      2.73      7.65      0.90      0.00      4.78    662.33      1.00\n",
      "lambda[100]      3.02     12.95      0.96      0.00      6.15    921.50      1.00\n",
      "lambda[101]      3.01      6.76      0.97      0.00      6.07    614.84      1.00\n",
      "lambda[102]      2.88      9.06      0.98      0.00      5.26    684.22      1.00\n",
      "lambda[103]      2.85      9.82      0.99      0.00      5.45    578.08      1.00\n",
      "lambda[104]      2.99      7.72      0.96      0.00      6.63    670.47      1.00\n",
      "lambda[105]      3.64     11.74      1.07      0.00      7.15    517.42      1.00\n",
      "lambda[106]      2.70      5.95      1.01      0.00      6.43    942.74      1.00\n",
      "lambda[107]      4.07     19.09      0.94      0.00      5.22    539.52      1.00\n",
      "lambda[108]      2.23      5.47      0.96      0.00      4.73    527.00      1.00\n",
      "lambda[109]      5.39     63.53      1.00      0.00      6.31   1008.31      1.00\n",
      "lambda[110]      3.58     18.23      1.02      0.00      6.98    944.34      1.00\n",
      "lambda[111]      3.34     12.20      0.93      0.00      5.85    886.83      1.00\n",
      "lambda[112]      2.35      4.87      0.94      0.01      5.46    654.63      1.00\n",
      "lambda[113]      3.47     11.71      0.99      0.00      5.66    678.99      1.00\n",
      "lambda[114]      2.99     11.24      1.02      0.00      5.27    743.19      1.00\n",
      "lambda[115]      3.65     12.90      0.95      0.00      6.24    576.75      1.00\n",
      "lambda[116]      3.06     11.89      1.02      0.00      5.53    641.57      1.00\n",
      "lambda[117]      3.70     15.16      0.98      0.00      6.22    616.68      1.00\n",
      "lambda[118]      3.26      9.71      0.99      0.00      6.02    820.29      1.00\n",
      "lambda[119]      3.26     10.69      0.92      0.00      5.78    717.88      1.00\n",
      "lambda[120]      4.51     23.75      1.04      0.00      7.29    854.98      1.00\n",
      "lambda[121]      3.44     12.68      1.00      0.00      6.56    890.13      1.00\n",
      "lambda[122]      2.95      8.47      1.01      0.00      5.70    820.77      1.00\n",
      "lambda[123]      2.66      6.61      0.94      0.00      5.15    814.02      1.00\n",
      "lambda[124]      3.09      7.28      1.02      0.00      7.17    818.98      1.00\n",
      "lambda[125]      2.94     10.08      0.97      0.00      5.97    917.18      1.00\n",
      "lambda[126]      2.61      7.73      0.91      0.00      5.18    927.01      1.00\n",
      "lambda[127]      3.15      8.96      0.99      0.00      6.04    531.32      1.00\n",
      "lambda[128]      2.56      5.92      0.92      0.01      5.50    837.03      1.00\n",
      "lambda[129]      4.02     17.74      0.99      0.00      6.71    723.00      1.00\n",
      "lambda[130]      3.19      7.61      1.02      0.00      6.67    697.36      1.00\n",
      "lambda[131]      2.94      8.83      1.02      0.00      5.50    896.37      1.00\n",
      "lambda[132]      2.78      7.39      1.01      0.00      5.74    764.01      1.00\n",
      "lambda[133]      2.87     10.82      0.95      0.00      5.46    996.20      1.00\n",
      "lambda[134]      3.20     10.58      0.95      0.00      6.47    943.05      1.00\n",
      "lambda[135]      2.59      7.36      0.97      0.01      5.37    980.64      1.00\n",
      "lambda[136]      2.60      6.05      0.90      0.00      5.84    855.59      1.01\n",
      "lambda[137]      2.69      7.43      0.92      0.00      5.07    637.48      1.00\n",
      "lambda[138]      2.87      8.60      1.02      0.00      6.18    651.26      1.00\n",
      "lambda[139]      3.17      9.69      1.09      0.00      5.60    540.09      1.01\n",
      "lambda[140]      3.12      9.28      0.96      0.00      5.66    752.84      1.00\n",
      "lambda[141]      2.70      5.81      0.90      0.00      6.55    804.71      1.01\n",
      "lambda[142]      4.63     38.03      0.96      0.00      6.13    655.07      1.00\n",
      "lambda[143]      2.60      8.98      1.01      0.01      5.17    939.06      1.00\n",
      "        msq   7473.76 104613.95     18.73      0.20    796.96    926.82      1.00\n",
      "      sigma      3.13      3.98      1.68      0.01      8.38   1162.85      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11   1059.30      1.00\n",
      "       xisq    407.32   5753.31     12.59      0.58    157.12    885.23      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.60789728164673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.72e-04 +- 1.59e-02\n",
      "[dimension 02/145]  inactive:\t3.96e-04 +- 2.27e-02\n",
      "[dimension 03/145]  inactive:\t-3.64e-05 +- 2.17e-02\n",
      "[dimension 04/145]  inactive:\t7.01e-03 +- 4.62e-02\n",
      "[dimension 05/145]  inactive:\t-3.38e-04 +- 2.48e-02\n",
      "[dimension 06/145]  inactive:\t2.75e-03 +- 3.94e-02\n",
      "[dimension 07/145]  inactive:\t3.61e-04 +- 1.78e-02\n",
      "[dimension 08/145]  inactive:\t9.24e-04 +- 2.71e-02\n",
      "[dimension 09/145]  inactive:\t1.15e-04 +- 2.02e-02\n",
      "[dimension 10/145]  inactive:\t3.29e-04 +- 1.62e-02\n",
      "[dimension 11/145]  inactive:\t-2.71e-04 +- 2.48e-02\n",
      "[dimension 12/145]  inactive:\t1.65e-04 +- 2.56e-02\n",
      "[dimension 13/145]  inactive:\t4.94e-03 +- 3.90e-02\n",
      "[dimension 14/145]  inactive:\t-6.46e-04 +- 2.59e-02\n",
      "[dimension 15/145]  inactive:\t7.79e-04 +- 2.79e-02\n",
      "[dimension 16/145]  inactive:\t9.37e-04 +- 2.07e-02\n",
      "[dimension 17/145]  inactive:\t1.63e-04 +- 2.75e-02\n",
      "[dimension 18/145]  inactive:\t-2.28e-04 +- 2.90e-02\n",
      "[dimension 19/145]  inactive:\t-2.15e-03 +- 1.94e-02\n",
      "[dimension 20/145]  inactive:\t-1.72e-03 +- 2.87e-02\n",
      "[dimension 21/145]  inactive:\t-1.95e-03 +- 2.47e-02\n",
      "[dimension 22/145]  inactive:\t-1.20e-06 +- 2.18e-02\n",
      "[dimension 23/145]  inactive:\t-2.69e-04 +- 1.99e-02\n",
      "[dimension 24/145]  inactive:\t1.35e-03 +- 2.75e-02\n",
      "[dimension 25/145]  inactive:\t3.36e-03 +- 2.33e-02\n",
      "[dimension 26/145]  inactive:\t-3.05e-04 +- 2.52e-02\n",
      "[dimension 27/145]  inactive:\t3.98e-04 +- 2.08e-02\n",
      "[dimension 28/145]  inactive:\t5.71e-04 +- 1.90e-02\n",
      "[dimension 29/145]  inactive:\t5.50e-04 +- 2.61e-02\n",
      "[dimension 30/145]  inactive:\t2.39e-03 +- 3.55e-02\n",
      "[dimension 31/145]  inactive:\t5.17e-03 +- 3.92e-02\n",
      "[dimension 32/145]  inactive:\t-1.33e-03 +- 2.22e-02\n",
      "[dimension 33/145]  inactive:\t2.34e-03 +- 3.67e-02\n",
      "[dimension 34/145]  inactive:\t6.49e-04 +- 1.64e-02\n",
      "[dimension 35/145]  inactive:\t4.64e-04 +- 2.44e-02\n",
      "[dimension 36/145]  inactive:\t7.04e-04 +- 2.33e-02\n",
      "[dimension 37/145]  inactive:\t4.75e-03 +- 2.96e-02\n",
      "[dimension 38/145]  inactive:\t-2.36e-03 +- 3.38e-02\n",
      "[dimension 39/145]  inactive:\t1.03e-03 +- 2.96e-02\n",
      "[dimension 40/145]  inactive:\t4.48e-03 +- 3.68e-02\n",
      "[dimension 41/145]  inactive:\t-1.07e-03 +- 3.43e-02\n",
      "[dimension 42/145]  inactive:\t1.00e-02 +- 7.67e-02\n",
      "[dimension 43/145]  inactive:\t-2.31e-04 +- 1.70e-02\n",
      "[dimension 44/145]  inactive:\t-9.35e-04 +- 2.67e-02\n",
      "[dimension 45/145]  inactive:\t-4.97e-04 +- 2.37e-02\n",
      "[dimension 46/145]  inactive:\t8.75e-04 +- 1.49e-02\n",
      "[dimension 47/145]  inactive:\t-1.92e-03 +- 2.90e-02\n",
      "[dimension 48/145]  inactive:\t7.89e-04 +- 1.95e-02\n",
      "[dimension 49/145]  inactive:\t2.74e-03 +- 2.42e-02\n",
      "[dimension 50/145]  inactive:\t-1.76e-03 +- 2.62e-02\n",
      "[dimension 51/145]  inactive:\t2.24e-03 +- 2.63e-02\n",
      "[dimension 52/145]  inactive:\t4.53e-03 +- 2.18e-02\n",
      "[dimension 53/145]  inactive:\t-1.51e-03 +- 2.52e-02\n",
      "[dimension 54/145]  inactive:\t-2.66e-04 +- 1.94e-02\n",
      "[dimension 55/145]  inactive:\t4.06e-04 +- 1.50e-02\n",
      "[dimension 56/145]  inactive:\t-3.31e-03 +- 2.53e-02\n",
      "[dimension 57/145]  inactive:\t1.59e-03 +- 3.60e-02\n",
      "[dimension 58/145]  inactive:\t1.55e-02 +- 7.70e-02\n",
      "[dimension 59/145]  inactive:\t-1.02e-03 +- 1.84e-02\n",
      "[dimension 60/145]  inactive:\t5.13e-04 +- 2.19e-02\n",
      "[dimension 61/145]  inactive:\t2.41e-03 +- 2.35e-02\n",
      "[dimension 62/145]  inactive:\t-1.41e-03 +- 2.51e-02\n",
      "[dimension 63/145]  active:\t6.54e-01 +- 4.46e-01\n",
      "[dimension 64/145]  inactive:\t-2.60e-03 +- 2.55e-02\n",
      "[dimension 65/145]  inactive:\t-3.33e-04 +- 2.17e-02\n",
      "[dimension 66/145]  inactive:\t2.83e-04 +- 1.89e-02\n",
      "[dimension 67/145]  inactive:\t2.11e-03 +- 2.96e-02\n",
      "[dimension 68/145]  inactive:\t-6.04e-04 +- 3.14e-02\n",
      "[dimension 69/145]  inactive:\t2.43e-03 +- 3.03e-02\n",
      "[dimension 70/145]  inactive:\t3.44e-03 +- 2.28e-02\n",
      "[dimension 71/145]  inactive:\t7.48e-05 +- 2.73e-02\n",
      "[dimension 72/145]  inactive:\t1.78e-04 +- 2.37e-02\n",
      "[dimension 73/145]  inactive:\t5.26e-04 +- 1.62e-02\n",
      "[dimension 74/145]  inactive:\t-1.05e-03 +- 3.19e-02\n",
      "[dimension 75/145]  inactive:\t3.16e-04 +- 2.01e-02\n",
      "[dimension 76/145]  inactive:\t5.50e-03 +- 3.77e-02\n",
      "[dimension 77/145]  inactive:\t-1.53e-03 +- 2.81e-02\n",
      "[dimension 78/145]  inactive:\t7.54e-03 +- 6.54e-02\n",
      "[dimension 79/145]  inactive:\t6.59e-03 +- 3.42e-02\n",
      "[dimension 80/145]  inactive:\t5.30e-05 +- 3.04e-02\n",
      "[dimension 81/145]  inactive:\t2.56e-03 +- 3.67e-02\n",
      "[dimension 82/145]  inactive:\t1.53e-04 +- 1.76e-02\n",
      "[dimension 83/145]  inactive:\t-1.94e-03 +- 1.84e-02\n",
      "[dimension 84/145]  inactive:\t-2.00e-03 +- 2.73e-02\n",
      "[dimension 85/145]  inactive:\t3.56e-03 +- 3.37e-02\n",
      "[dimension 86/145]  inactive:\t-7.49e-04 +- 2.08e-02\n",
      "[dimension 87/145]  inactive:\t1.71e-03 +- 3.47e-02\n",
      "[dimension 88/145]  inactive:\t2.65e-03 +- 2.42e-02\n",
      "[dimension 89/145]  inactive:\t-1.25e-03 +- 2.23e-02\n",
      "[dimension 90/145]  inactive:\t1.86e-01 +- 3.62e-01\n",
      "[dimension 91/145]  inactive:\t-2.02e-04 +- 1.81e-02\n",
      "[dimension 92/145]  inactive:\t-1.73e-03 +- 2.61e-02\n",
      "[dimension 93/145]  inactive:\t-8.13e-04 +- 2.37e-02\n",
      "[dimension 94/145]  inactive:\t1.85e-03 +- 2.61e-02\n",
      "[dimension 95/145]  inactive:\t-3.20e-04 +- 2.04e-02\n",
      "[dimension 96/145]  inactive:\t5.17e-04 +- 3.38e-02\n",
      "[dimension 97/145]  inactive:\t1.53e-03 +- 1.95e-02\n",
      "[dimension 98/145]  inactive:\t-8.20e-04 +- 2.65e-02\n",
      "[dimension 99/145]  inactive:\t4.68e-03 +- 5.61e-02\n",
      "[dimension 100/145]  inactive:\t-6.45e-04 +- 1.60e-02\n",
      "[dimension 101/145]  inactive:\t-2.85e-03 +- 2.29e-02\n",
      "[dimension 102/145]  inactive:\t-9.61e-04 +- 2.57e-02\n",
      "[dimension 103/145]  inactive:\t6.98e-04 +- 2.18e-02\n",
      "[dimension 104/145]  inactive:\t-1.39e-03 +- 1.77e-02\n",
      "[dimension 105/145]  inactive:\t-6.53e-04 +- 2.58e-02\n",
      "[dimension 106/145]  inactive:\t4.36e-03 +- 3.02e-02\n",
      "[dimension 107/145]  inactive:\t-1.15e-03 +- 2.14e-02\n",
      "[dimension 108/145]  inactive:\t6.57e-03 +- 6.63e-02\n",
      "[dimension 109/145]  inactive:\t-3.64e-04 +- 1.56e-02\n",
      "[dimension 110/145]  inactive:\t-6.61e-04 +- 3.03e-02\n",
      "[dimension 111/145]  inactive:\t2.15e-03 +- 3.08e-02\n",
      "[dimension 112/145]  inactive:\t3.35e-03 +- 3.08e-02\n",
      "[dimension 113/145]  inactive:\t-1.49e-03 +- 1.96e-02\n",
      "[dimension 114/145]  inactive:\t2.11e-03 +- 4.35e-02\n",
      "[dimension 115/145]  inactive:\t1.54e-03 +- 1.81e-02\n",
      "[dimension 116/145]  inactive:\t5.46e-04 +- 2.98e-02\n",
      "[dimension 117/145]  inactive:\t3.23e-03 +- 3.71e-02\n",
      "[dimension 118/145]  inactive:\t3.00e-03 +- 2.42e-02\n",
      "[dimension 119/145]  inactive:\t-2.34e-03 +- 2.95e-02\n",
      "[dimension 120/145]  inactive:\t4.28e-04 +- 3.32e-02\n",
      "[dimension 121/145]  inactive:\t5.11e-03 +- 4.03e-02\n",
      "[dimension 122/145]  inactive:\t-2.25e-03 +- 2.89e-02\n",
      "[dimension 123/145]  inactive:\t9.65e-04 +- 2.85e-02\n",
      "[dimension 124/145]  inactive:\t-1.63e-03 +- 2.01e-02\n",
      "[dimension 125/145]  inactive:\t-1.59e-03 +- 2.27e-02\n",
      "[dimension 126/145]  inactive:\t-1.43e-03 +- 2.55e-02\n",
      "[dimension 127/145]  inactive:\t9.74e-05 +- 1.69e-02\n",
      "[dimension 128/145]  inactive:\t-1.07e-03 +- 2.83e-02\n",
      "[dimension 129/145]  inactive:\t-9.58e-05 +- 2.35e-02\n",
      "[dimension 130/145]  inactive:\t3.49e-03 +- 2.70e-02\n",
      "[dimension 131/145]  inactive:\t-2.13e-04 +- 2.89e-02\n",
      "[dimension 132/145]  inactive:\t2.28e-03 +- 2.76e-02\n",
      "[dimension 133/145]  inactive:\t2.03e-03 +- 1.86e-02\n",
      "[dimension 134/145]  inactive:\t-8.00e-04 +- 2.60e-02\n",
      "[dimension 135/145]  inactive:\t2.62e-04 +- 2.36e-02\n",
      "[dimension 136/145]  inactive:\t8.55e-04 +- 1.73e-02\n",
      "[dimension 137/145]  inactive:\t-1.64e-04 +- 2.76e-02\n",
      "[dimension 138/145]  inactive:\t5.08e-04 +- 2.15e-02\n",
      "[dimension 139/145]  inactive:\t3.66e-04 +- 2.03e-02\n",
      "[dimension 140/145]  inactive:\t-1.19e-03 +- 3.12e-02\n",
      "[dimension 141/145]  inactive:\t8.02e-04 +- 2.48e-02\n",
      "[dimension 142/145]  inactive:\t1.35e-03 +- 1.92e-02\n",
      "[dimension 143/145]  inactive:\t1.52e-03 +- 3.36e-02\n",
      "[dimension 144/145]  inactive:\t2.56e-04 +- 1.91e-02\n",
      "[dimension 145/145]  inactive:\t2.38e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9200958]\n",
      "cov_act[[0.01212369]]\n",
      "Active_dimensions: [62]\n",
      "61, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:23<00:00, 63.32it/s, 15 steps of size 2.12e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    381.85      1.01\n",
      "  lambda[0]      2.96     12.18      0.95      0.00      5.27    967.98      1.00\n",
      "  lambda[1]      3.37     16.79      0.97      0.00      6.87    605.53      1.00\n",
      "  lambda[2]      3.30      8.87      1.08      0.01      6.55    433.25      1.00\n",
      "  lambda[3]      4.15     21.52      1.08      0.00      6.51    477.50      1.00\n",
      "  lambda[4]      2.57      5.75      1.00      0.00      6.03    888.37      1.00\n",
      "  lambda[5]      3.39     15.43      1.01      0.00      6.14    941.50      1.00\n",
      "  lambda[6]      4.85     14.54      1.02      0.00     10.10    400.14      1.00\n",
      "  lambda[7]      2.68      5.58      0.93      0.00      6.28    584.57      1.00\n",
      "  lambda[8]      2.76      7.67      0.95      0.00      5.93    738.17      1.00\n",
      "  lambda[9]      3.30     10.59      0.99      0.00      6.12    516.29      1.00\n",
      " lambda[10]      3.29      8.90      1.02      0.00      6.20    498.88      1.00\n",
      " lambda[11]      2.65      6.94      0.92      0.01      5.54    681.08      1.01\n",
      " lambda[12]      5.06     24.78      1.01      0.01      7.80    535.41      1.01\n",
      " lambda[13]      2.72      9.23      0.95      0.00      5.06    589.39      1.01\n",
      " lambda[14]      3.27      9.23      1.04      0.00      6.31    690.67      1.00\n",
      " lambda[15]      3.90      9.77      1.08      0.00      8.94    721.63      1.00\n",
      " lambda[16]      2.45      5.44      0.95      0.00      5.12    858.68      1.00\n",
      " lambda[17]      3.07      9.40      1.03      0.00      5.98    744.52      1.00\n",
      " lambda[18]      3.05      9.17      0.97      0.00      6.02    790.76      1.00\n",
      " lambda[19]      2.89      7.40      1.00      0.00      6.27    817.49      1.00\n",
      " lambda[20]      2.86      6.68      1.05      0.00      6.28    640.58      1.00\n",
      " lambda[21]      2.68      5.90      1.01      0.01      6.21    327.21      1.00\n",
      " lambda[22]      2.61      7.08      1.04      0.00      5.63    893.78      1.00\n",
      " lambda[23]      3.15     19.98      1.05      0.00      5.55    972.06      1.00\n",
      " lambda[24]      3.20      8.16      1.05      0.00      6.48    588.10      1.00\n",
      " lambda[25]      2.17      5.00      0.91      0.01      4.77    663.18      1.00\n",
      " lambda[26]      2.56      6.22      0.96      0.00      5.21    986.90      1.00\n",
      " lambda[27]      2.87      7.26      0.96      0.00      6.30    525.74      1.00\n",
      " lambda[28]      2.55      5.30      0.98      0.00      5.83    585.65      1.00\n",
      " lambda[29]      3.03     13.00      0.95      0.00      5.86    936.03      1.00\n",
      " lambda[30]      2.54      5.14      0.92      0.00      6.00    741.51      1.00\n",
      " lambda[31]      2.86      8.09      0.99      0.00      5.18    849.26      1.00\n",
      " lambda[32]      2.73      8.35      1.05      0.00      5.63    925.12      1.00\n",
      " lambda[33]      3.14      7.86      0.96      0.00      6.01    654.88      1.00\n",
      " lambda[34]      3.34     18.08      1.00      0.00      5.72    761.64      1.00\n",
      " lambda[35]      2.88      8.48      0.98      0.00      5.90    682.58      1.00\n",
      " lambda[36]      4.03     32.54      1.03      0.00      5.95    841.93      1.00\n",
      " lambda[37]      3.23     10.24      1.01      0.01      6.43    801.37      1.00\n",
      " lambda[38]      2.83      7.54      0.96      0.00      5.99    735.98      1.00\n",
      " lambda[39]      3.04     11.27      0.96      0.00      6.29    974.03      1.00\n",
      " lambda[40]      3.39      9.37      0.99      0.00      6.66    637.98      1.00\n",
      " lambda[41]      3.39     11.57      0.99      0.00      6.98    815.65      1.00\n",
      " lambda[42]      2.41      5.78      1.00      0.00      5.33    965.13      1.00\n",
      " lambda[43]      2.91      9.35      1.00      0.00      5.38    620.69      1.00\n",
      " lambda[44]      2.78      7.33      0.99      0.01      5.96    711.92      1.00\n",
      " lambda[45]      2.39      5.73      0.99      0.00      4.97    865.70      1.00\n",
      " lambda[46]      2.39      5.72      0.95      0.00      4.67    829.73      1.00\n",
      " lambda[47]      2.35      4.32      1.04      0.00      5.93    714.79      1.00\n",
      " lambda[48]      2.80      5.90      0.97      0.00      6.70    727.70      1.00\n",
      " lambda[49]      2.88      7.16      1.06      0.00      6.31    688.26      1.00\n",
      " lambda[50]      3.08     11.57      0.94      0.00      5.59    885.94      1.00\n",
      " lambda[51]      4.12     22.83      1.07      0.00      7.83    835.49      1.00\n",
      " lambda[52]      2.65      8.11      0.96      0.00      4.63    804.49      1.00\n",
      " lambda[53]      2.79      6.14      0.96      0.00      5.89    632.08      1.00\n",
      " lambda[54]      2.27      4.96      0.94      0.00      4.84    734.36      1.00\n",
      " lambda[55]      2.91     14.88      0.89      0.00      5.54    987.58      1.00\n",
      " lambda[56]      2.47      7.84      0.96      0.00      4.93    920.46      1.00\n",
      " lambda[57]      3.24      8.71      0.91      0.00      6.68    671.57      1.00\n",
      " lambda[58]      2.30      5.29      0.93      0.00      4.77    765.69      1.00\n",
      " lambda[59]      2.58      5.98      1.03      0.00      5.65    801.41      1.00\n",
      " lambda[60]      4.19     13.33      1.07      0.00      8.14    508.83      1.00\n",
      " lambda[61]      2.54      6.45      0.98      0.00      5.46    639.47      1.00\n",
      " lambda[62]  23366.76 398046.38   1307.39      0.03  11623.96    587.66      1.00\n",
      " lambda[63]      3.10     14.02      0.93      0.01      4.95    425.14      1.00\n",
      " lambda[64]      2.84      7.66      0.97      0.00      5.56    735.07      1.00\n",
      " lambda[65]      2.61      8.07      0.98      0.00      4.87    834.18      1.00\n",
      " lambda[66]      2.90      7.28      0.92      0.00      6.01    801.98      1.00\n",
      " lambda[67]      2.76      7.15      1.01      0.00      5.62    805.62      1.00\n",
      " lambda[68]      2.83      7.29      1.03      0.01      5.88    927.13      1.00\n",
      " lambda[69]      5.22     37.80      1.04      0.00      6.80    688.11      1.00\n",
      " lambda[70]      2.76      8.82      0.94      0.00      5.10    769.68      1.00\n",
      " lambda[71]      3.15     10.65      1.09      0.01      5.44    622.18      1.00\n",
      " lambda[72]      2.27      5.61      1.00      0.00      4.36    725.97      1.00\n",
      " lambda[73]      3.53     18.71      1.04      0.00      6.16    910.16      1.00\n",
      " lambda[74]      2.65      5.87      0.99      0.00      6.09    735.43      1.00\n",
      " lambda[75]      3.79     12.25      1.02      0.00      6.95    781.09      1.00\n",
      " lambda[76]      2.74      6.18      1.01      0.00      5.82    566.23      1.00\n",
      " lambda[77]      5.68     57.44      0.97      0.00      5.31    403.67      1.00\n",
      " lambda[78]      2.55      5.86      1.01      0.01      5.09    787.23      1.00\n",
      " lambda[79]      2.74     10.23      0.89      0.00      4.78    772.87      1.00\n",
      " lambda[80]      3.01      7.36      0.96      0.00      6.31    699.47      1.00\n",
      " lambda[81]      2.64      5.77      1.00      0.00      5.90    644.79      1.00\n",
      " lambda[82]      2.46      5.75      0.93      0.00      5.11    685.22      1.00\n",
      " lambda[83]      3.11      8.51      1.01      0.00      6.02    720.02      1.00\n",
      " lambda[84]      4.98     46.91      1.00      0.00      6.60    815.39      1.00\n",
      " lambda[85]      2.75      6.69      1.00      0.00      6.04    724.61      1.00\n",
      " lambda[86]      3.45     17.04      0.93      0.00      5.45    867.19      1.00\n",
      " lambda[87]      3.00     11.26      0.98      0.00      5.44    836.35      1.00\n",
      " lambda[88]      2.63      7.00      0.95      0.00      5.37    682.60      1.00\n",
      " lambda[89]    147.94   2406.60      1.06      0.00      9.39    372.88      1.00\n",
      " lambda[90]      2.51      6.05      0.98      0.00      5.23    848.74      1.00\n",
      " lambda[91]      2.88      8.72      1.00      0.00      5.49    503.45      1.00\n",
      " lambda[92]      2.77      6.72      0.98      0.00      6.35    670.49      1.00\n",
      " lambda[93]      2.65      7.24      0.97      0.00      4.78    587.52      1.00\n",
      " lambda[94]      3.72     12.87      1.00      0.00      6.46    609.52      1.01\n",
      " lambda[95]      3.37     10.28      0.94      0.00      5.81    714.51      1.00\n",
      " lambda[96]      3.07      9.31      0.98      0.00      5.68    406.57      1.00\n",
      " lambda[97]      2.63      6.29      0.96      0.00      5.30    678.94      1.00\n",
      " lambda[98]      2.79      7.75      1.00      0.00      5.68    690.68      1.00\n",
      " lambda[99]      2.51      6.10      0.93      0.00      6.24    881.48      1.00\n",
      "lambda[100]      3.05     10.64      1.00      0.00      6.33    776.19      1.00\n",
      "lambda[101]      3.47     14.20      1.03      0.00      6.12    452.32      1.00\n",
      "lambda[102]      2.49      6.56      0.93      0.00      4.91    676.83      1.00\n",
      "lambda[103]      3.42     18.13      0.94      0.00      5.91    406.95      1.00\n",
      "lambda[104]      2.77     11.41      0.95      0.00      4.41    426.35      1.00\n",
      "lambda[105]      2.92      9.01      0.95      0.00      6.22    883.45      1.00\n",
      "lambda[106]      2.87     11.92      0.94      0.00      4.77    462.52      1.00\n",
      "lambda[107]      2.36      5.08      0.95      0.00      4.73    613.88      1.00\n",
      "lambda[108]      2.64      6.76      0.94      0.00      5.70    589.10      1.00\n",
      "lambda[109]      3.61     13.82      1.02      0.00      6.90    838.71      1.00\n",
      "lambda[110]      2.87      7.34      1.00      0.00      6.22    625.45      1.00\n",
      "lambda[111]      4.14     13.70      1.05      0.00      7.54    354.97      1.00\n",
      "lambda[112]      2.20      4.38      0.98      0.01      4.67    752.56      1.00\n",
      "lambda[113]      3.40      9.89      1.01      0.00      5.81    549.56      1.00\n",
      "lambda[114]      5.17     60.20      0.95      0.00      6.03    994.83      1.00\n",
      "lambda[115]      4.53     29.57      1.04      0.00      6.40    589.57      1.00\n",
      "lambda[116]      2.85     15.77      0.99      0.01      5.32   1002.22      1.00\n",
      "lambda[117]      3.30     12.76      0.94      0.00      6.44    516.30      1.00\n",
      "lambda[118]      2.84      9.35      0.95      0.00      5.45    555.53      1.00\n",
      "lambda[119]      3.93     17.09      0.97      0.01      6.78    904.16      1.00\n",
      "lambda[120]      3.47     13.05      0.95      0.00      5.98    894.08      1.00\n",
      "lambda[121]      2.95     10.82      0.96      0.00      5.40    771.74      1.00\n",
      "lambda[122]      3.15     11.57      1.00      0.01      5.74    668.53      1.00\n",
      "lambda[123]      2.77      7.53      0.89      0.00      6.13    836.51      1.00\n",
      "lambda[124]      2.60      5.93      0.96      0.00      5.47    870.48      1.00\n",
      "lambda[125]      2.79      7.88      0.94      0.00      6.22    754.71      1.00\n",
      "lambda[126]      2.35      7.10      0.94      0.00      5.07    953.05      1.00\n",
      "lambda[127]      3.21     13.04      0.94      0.00      5.47    919.98      1.00\n",
      "lambda[128]      3.17      8.89      0.99      0.00      6.84    756.46      1.00\n",
      "lambda[129]      2.56      8.08      0.84      0.00      4.74    606.97      1.00\n",
      "lambda[130]      3.41     12.56      0.95      0.00      6.41    888.63      1.01\n",
      "lambda[131]      3.37     16.37      0.97      0.00      5.59    777.86      1.00\n",
      "lambda[132]      3.14      8.52      1.00      0.00      5.80    830.78      1.00\n",
      "lambda[133]      2.49      5.35      1.01      0.00      5.78    904.95      1.00\n",
      "lambda[134]      3.11      8.08      1.01      0.00      6.62    847.19      1.00\n",
      "lambda[135]      2.46      5.77      0.95      0.00      4.93    658.21      1.00\n",
      "lambda[136]      2.82      8.36      0.93      0.00      5.18    867.36      1.00\n",
      "lambda[137]      3.13      8.95      1.02      0.00      6.14    539.60      1.00\n",
      "lambda[138]      2.83      7.03      0.97      0.00      5.81    450.14      1.00\n",
      "lambda[139]      2.64      5.90      0.90      0.01      5.76    502.02      1.00\n",
      "lambda[140]      2.82      9.38      0.97      0.00      5.85    926.26      1.00\n",
      "lambda[141]      2.98      8.20      0.97      0.00      6.62    590.23      1.00\n",
      "lambda[142]      3.36     11.35      0.95      0.00      5.80    656.24      1.00\n",
      "lambda[143]      2.36      6.10      0.97      0.00      4.97    789.04      1.00\n",
      "        msq      0.28      0.20      0.24      0.08      0.48    447.95      1.00\n",
      "      sigma      2.44      3.75      0.75      0.00      6.96    809.29      1.00\n",
      "    var_obs      0.08      0.02      0.08      0.06      0.11    768.09      1.00\n",
      "       xisq     14.80     38.71      5.90      0.86     27.36    375.89      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 27.94170904159546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.60e-04 +- 6.66e-03\n",
      "[dimension 02/145]  inactive:\t4.10e-04 +- 1.18e-02\n",
      "[dimension 03/145]  inactive:\t2.87e-04 +- 9.99e-03\n",
      "[dimension 04/145]  inactive:\t1.23e-03 +- 1.53e-02\n",
      "[dimension 05/145]  inactive:\t7.27e-05 +- 6.70e-03\n",
      "[dimension 06/145]  inactive:\t8.06e-04 +- 1.49e-02\n",
      "[dimension 07/145]  inactive:\t5.33e-04 +- 9.12e-03\n",
      "[dimension 08/145]  inactive:\t5.06e-04 +- 1.10e-02\n",
      "[dimension 09/145]  inactive:\t2.78e-04 +- 8.72e-03\n",
      "[dimension 10/145]  inactive:\t3.25e-04 +- 8.11e-03\n",
      "[dimension 11/145]  inactive:\t9.73e-05 +- 7.71e-03\n",
      "[dimension 12/145]  inactive:\t1.92e-04 +- 9.29e-03\n",
      "[dimension 13/145]  inactive:\t2.12e-03 +- 2.59e-02\n",
      "[dimension 14/145]  inactive:\t4.16e-05 +- 6.89e-03\n",
      "[dimension 15/145]  inactive:\t4.62e-04 +- 1.35e-02\n",
      "[dimension 16/145]  inactive:\t3.30e-04 +- 1.01e-02\n",
      "[dimension 17/145]  inactive:\t5.45e-04 +- 1.30e-02\n",
      "[dimension 18/145]  inactive:\t3.66e-04 +- 1.27e-02\n",
      "[dimension 19/145]  inactive:\t-4.48e-05 +- 6.26e-03\n",
      "[dimension 20/145]  inactive:\t1.96e-04 +- 8.41e-03\n",
      "[dimension 21/145]  inactive:\t-7.17e-06 +- 6.44e-03\n",
      "[dimension 22/145]  inactive:\t1.41e-04 +- 7.00e-03\n",
      "[dimension 23/145]  inactive:\t3.09e-04 +- 1.07e-02\n",
      "[dimension 24/145]  inactive:\t4.82e-04 +- 1.13e-02\n",
      "[dimension 25/145]  inactive:\t5.85e-04 +- 8.02e-03\n",
      "[dimension 26/145]  inactive:\t1.64e-04 +- 8.09e-03\n",
      "[dimension 27/145]  inactive:\t7.66e-05 +- 7.55e-03\n",
      "[dimension 28/145]  inactive:\t2.75e-04 +- 6.50e-03\n",
      "[dimension 29/145]  inactive:\t2.06e-04 +- 8.41e-03\n",
      "[dimension 30/145]  inactive:\t6.19e-04 +- 1.21e-02\n",
      "[dimension 31/145]  inactive:\t4.34e-04 +- 7.80e-03\n",
      "[dimension 32/145]  inactive:\t4.96e-05 +- 7.97e-03\n",
      "[dimension 33/145]  inactive:\t3.42e-04 +- 1.05e-02\n",
      "[dimension 34/145]  inactive:\t3.28e-04 +- 8.43e-03\n",
      "[dimension 35/145]  inactive:\t8.93e-04 +- 2.45e-02\n",
      "[dimension 36/145]  inactive:\t2.41e-04 +- 7.29e-03\n",
      "[dimension 37/145]  inactive:\t6.73e-04 +- 8.26e-03\n",
      "[dimension 38/145]  inactive:\t-9.31e-05 +- 9.63e-03\n",
      "[dimension 39/145]  inactive:\t4.99e-04 +- 1.08e-02\n",
      "[dimension 40/145]  inactive:\t6.20e-04 +- 9.16e-03\n",
      "[dimension 41/145]  inactive:\t1.63e-04 +- 1.03e-02\n",
      "[dimension 42/145]  inactive:\t7.17e-04 +- 1.28e-02\n",
      "[dimension 43/145]  inactive:\t7.93e-05 +- 6.61e-03\n",
      "[dimension 44/145]  inactive:\t2.12e-04 +- 9.43e-03\n",
      "[dimension 45/145]  inactive:\t1.58e-04 +- 1.01e-02\n",
      "[dimension 46/145]  inactive:\t1.71e-04 +- 5.13e-03\n",
      "[dimension 47/145]  inactive:\t5.71e-06 +- 8.05e-03\n",
      "[dimension 48/145]  inactive:\t1.25e-04 +- 6.73e-03\n",
      "[dimension 49/145]  inactive:\t3.91e-04 +- 9.02e-03\n",
      "[dimension 50/145]  inactive:\t1.80e-05 +- 1.06e-02\n",
      "[dimension 51/145]  inactive:\t7.12e-04 +- 1.64e-02\n",
      "[dimension 52/145]  inactive:\t1.63e-03 +- 1.21e-02\n",
      "[dimension 53/145]  inactive:\t-3.12e-05 +- 8.22e-03\n",
      "[dimension 54/145]  inactive:\t4.40e-04 +- 9.74e-03\n",
      "[dimension 55/145]  inactive:\t1.75e-04 +- 6.57e-03\n",
      "[dimension 56/145]  inactive:\t-3.01e-04 +- 6.98e-03\n",
      "[dimension 57/145]  inactive:\t4.86e-04 +- 1.20e-02\n",
      "[dimension 58/145]  inactive:\t8.05e-04 +- 1.08e-02\n",
      "[dimension 59/145]  inactive:\t-9.70e-05 +- 6.88e-03\n",
      "[dimension 60/145]  inactive:\t7.94e-05 +- 6.16e-03\n",
      "[dimension 61/145]  inactive:\t9.80e-04 +- 1.37e-02\n",
      "[dimension 62/145]  inactive:\t1.79e-05 +- 7.27e-03\n",
      "[dimension 63/145]  active:\t8.81e-01 +- 2.31e-01\n",
      "[dimension 64/145]  inactive:\t-1.72e-04 +- 6.97e-03\n",
      "[dimension 65/145]  inactive:\t8.26e-05 +- 9.00e-03\n",
      "[dimension 66/145]  inactive:\t1.48e-04 +- 7.15e-03\n",
      "[dimension 67/145]  inactive:\t2.83e-04 +- 8.84e-03\n",
      "[dimension 68/145]  inactive:\t1.10e-04 +- 1.12e-02\n",
      "[dimension 69/145]  inactive:\t9.07e-04 +- 1.60e-02\n",
      "[dimension 70/145]  inactive:\t1.30e-03 +- 1.19e-02\n",
      "[dimension 71/145]  inactive:\t2.48e-04 +- 1.08e-02\n",
      "[dimension 72/145]  inactive:\t3.64e-04 +- 8.79e-03\n",
      "[dimension 73/145]  inactive:\t1.11e-04 +- 5.43e-03\n",
      "[dimension 74/145]  inactive:\t-3.75e-05 +- 9.99e-03\n",
      "[dimension 75/145]  inactive:\t1.07e-04 +- 6.50e-03\n",
      "[dimension 76/145]  inactive:\t1.12e-03 +- 1.41e-02\n",
      "[dimension 77/145]  inactive:\t5.73e-05 +- 1.07e-02\n",
      "[dimension 78/145]  inactive:\t2.91e-03 +- 3.38e-02\n",
      "[dimension 79/145]  inactive:\t1.26e-03 +- 1.35e-02\n",
      "[dimension 80/145]  inactive:\t2.63e-04 +- 1.02e-02\n",
      "[dimension 81/145]  inactive:\t4.71e-04 +- 1.22e-02\n",
      "[dimension 82/145]  inactive:\t1.54e-04 +- 6.83e-03\n",
      "[dimension 83/145]  inactive:\t-2.19e-04 +- 6.27e-03\n",
      "[dimension 84/145]  inactive:\t-6.60e-05 +- 8.35e-03\n",
      "[dimension 85/145]  inactive:\t6.02e-04 +- 1.15e-02\n",
      "[dimension 86/145]  inactive:\t-8.14e-05 +- 8.14e-03\n",
      "[dimension 87/145]  inactive:\t4.26e-04 +- 1.18e-02\n",
      "[dimension 88/145]  inactive:\t5.83e-04 +- 9.66e-03\n",
      "[dimension 89/145]  inactive:\t-8.99e-05 +- 6.77e-03\n",
      "[dimension 90/145]  inactive:\t3.34e-02 +- 1.67e-01\n",
      "[dimension 91/145]  inactive:\t1.01e-04 +- 6.31e-03\n",
      "[dimension 92/145]  inactive:\t-2.69e-05 +- 7.97e-03\n",
      "[dimension 93/145]  inactive:\t5.80e-05 +- 9.23e-03\n",
      "[dimension 94/145]  inactive:\t3.66e-04 +- 9.89e-03\n",
      "[dimension 95/145]  inactive:\t2.17e-04 +- 1.18e-02\n",
      "[dimension 96/145]  inactive:\t2.56e-04 +- 1.34e-02\n",
      "[dimension 97/145]  inactive:\t5.68e-04 +- 9.38e-03\n",
      "[dimension 98/145]  inactive:\t-8.54e-05 +- 7.67e-03\n",
      "[dimension 99/145]  inactive:\t3.00e-04 +- 9.89e-03\n",
      "[dimension 100/145]  inactive:\t-7.37e-06 +- 6.04e-03\n",
      "[dimension 101/145]  inactive:\t-2.87e-04 +- 6.12e-03\n",
      "[dimension 102/145]  inactive:\t-2.88e-05 +- 8.59e-03\n",
      "[dimension 103/145]  inactive:\t2.84e-04 +- 9.35e-03\n",
      "[dimension 104/145]  inactive:\t-1.42e-04 +- 5.73e-03\n",
      "[dimension 105/145]  inactive:\t9.41e-06 +- 6.44e-03\n",
      "[dimension 106/145]  inactive:\t9.23e-04 +- 1.18e-02\n",
      "[dimension 107/145]  inactive:\t-1.56e-04 +- 6.95e-03\n",
      "[dimension 108/145]  inactive:\t1.16e-04 +- 6.46e-03\n",
      "[dimension 109/145]  inactive:\t1.02e-04 +- 5.69e-03\n",
      "[dimension 110/145]  inactive:\t3.25e-04 +- 1.23e-02\n",
      "[dimension 111/145]  inactive:\t3.79e-04 +- 1.10e-02\n",
      "[dimension 112/145]  inactive:\t1.36e-03 +- 1.92e-02\n",
      "[dimension 113/145]  inactive:\t4.27e-07 +- 5.87e-03\n",
      "[dimension 114/145]  inactive:\t4.31e-04 +- 1.26e-02\n",
      "[dimension 115/145]  inactive:\t8.81e-04 +- 1.17e-02\n",
      "[dimension 116/145]  inactive:\t5.67e-04 +- 1.59e-02\n",
      "[dimension 117/145]  inactive:\t9.41e-04 +- 2.05e-02\n",
      "[dimension 118/145]  inactive:\t7.48e-04 +- 1.01e-02\n",
      "[dimension 119/145]  inactive:\t2.73e-04 +- 1.16e-02\n",
      "[dimension 120/145]  inactive:\t4.99e-04 +- 1.64e-02\n",
      "[dimension 121/145]  inactive:\t1.42e-03 +- 1.78e-02\n",
      "[dimension 122/145]  inactive:\t1.98e-06 +- 1.10e-02\n",
      "[dimension 123/145]  inactive:\t4.02e-04 +- 1.23e-02\n",
      "[dimension 124/145]  inactive:\t-1.01e-04 +- 6.15e-03\n",
      "[dimension 125/145]  inactive:\t-1.25e-05 +- 6.47e-03\n",
      "[dimension 126/145]  inactive:\t3.55e-06 +- 7.49e-03\n",
      "[dimension 127/145]  inactive:\t1.93e-04 +- 5.94e-03\n",
      "[dimension 128/145]  inactive:\t2.46e-04 +- 1.21e-02\n",
      "[dimension 129/145]  inactive:\t-1.79e-06 +- 1.03e-02\n",
      "[dimension 130/145]  inactive:\t5.92e-04 +- 1.11e-02\n",
      "[dimension 131/145]  inactive:\t1.49e-04 +- 1.03e-02\n",
      "[dimension 132/145]  inactive:\t1.44e-03 +- 2.74e-02\n",
      "[dimension 133/145]  inactive:\t6.37e-04 +- 8.92e-03\n",
      "[dimension 134/145]  inactive:\t9.30e-05 +- 7.22e-03\n",
      "[dimension 135/145]  inactive:\t2.15e-04 +- 1.05e-02\n",
      "[dimension 136/145]  inactive:\t2.92e-04 +- 7.30e-03\n",
      "[dimension 137/145]  inactive:\t1.58e-04 +- 8.70e-03\n",
      "[dimension 138/145]  inactive:\t2.59e-04 +- 7.94e-03\n",
      "[dimension 139/145]  inactive:\t2.61e-04 +- 9.45e-03\n",
      "[dimension 140/145]  inactive:\t1.19e-04 +- 7.71e-03\n",
      "[dimension 141/145]  inactive:\t4.24e-04 +- 1.19e-02\n",
      "[dimension 142/145]  inactive:\t6.40e-04 +- 9.39e-03\n",
      "[dimension 143/145]  inactive:\t5.12e-04 +- 1.29e-02\n",
      "[dimension 144/145]  inactive:\t2.54e-04 +- 8.13e-03\n",
      "[dimension 145/145]  inactive:\t5.28e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[5.23217e-06]\n",
      "cov_act[[8.6054206e-07]]\n",
      "Active_dimensions: [62]\n",
      "62, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:24<00:00, 60.54it/s, 15 steps of size 2.31e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    230.36      1.00\n",
      "  lambda[0]      2.48     11.00      0.97      0.00      5.22   1018.75      1.00\n",
      "  lambda[1]      3.60     21.16      0.94      0.01      5.87    414.18      1.00\n",
      "  lambda[2]      2.72      6.10      0.99      0.01      5.84    325.32      1.00\n",
      "  lambda[3]      3.89     16.71      1.00      0.00      6.94    748.32      1.00\n",
      "  lambda[4]      3.20      9.25      0.99      0.00      6.34    587.08      1.00\n",
      "  lambda[5]      3.48     12.61      0.99      0.00      6.34    671.82      1.00\n",
      "  lambda[6]      3.85     35.22      0.98      0.00      5.31    870.54      1.00\n",
      "  lambda[7]      2.95      8.37      0.92      0.00      5.95    711.54      1.00\n",
      "  lambda[8]      2.66      6.95      0.96      0.00      5.71    795.26      1.00\n",
      "  lambda[9]      3.10      9.52      1.06      0.00      5.44    692.90      1.00\n",
      " lambda[10]      3.26     10.22      1.01      0.00      6.12    807.44      1.00\n",
      " lambda[11]      2.71      7.33      0.96      0.01      5.59    695.20      1.01\n",
      " lambda[12]      4.52     21.05      1.01      0.00      6.63    498.02      1.00\n",
      " lambda[13]      2.54      6.00      0.93      0.00      5.09    753.83      1.00\n",
      " lambda[14]      5.19     38.27      1.06      0.00      7.12    562.36      1.00\n",
      " lambda[15]      2.68      6.54      1.03      0.00      5.50    598.30      1.00\n",
      " lambda[16]      2.58      6.50      0.99      0.00      5.80   1029.09      1.00\n",
      " lambda[17]      2.88      7.74      1.04      0.00      5.40    714.63      1.00\n",
      " lambda[18]      2.99     10.86      0.94      0.00      5.42    748.52      1.00\n",
      " lambda[19]      2.70      6.73      1.01      0.00      5.54    958.72      1.00\n",
      " lambda[20]      3.28      9.19      1.06      0.01      7.11    516.61      1.00\n",
      " lambda[21]      2.60      5.87      1.00      0.00      5.91    531.05      1.00\n",
      " lambda[22]      2.52      7.58      0.99      0.00      5.13   1108.06      1.00\n",
      " lambda[23]      3.16     13.18      1.03      0.00      5.03    877.95      1.00\n",
      " lambda[24]      3.59     13.03      1.02      0.00      6.77    713.72      1.00\n",
      " lambda[25]      2.35      6.73      0.95      0.00      5.05    649.63      1.00\n",
      " lambda[26]      3.12     11.56      1.00      0.00      5.26    657.83      1.00\n",
      " lambda[27]      2.56      6.17      0.90      0.00      5.62   1047.24      1.00\n",
      " lambda[28]      2.45      5.32      0.98      0.00      5.55    775.74      1.00\n",
      " lambda[29]      3.32     20.92      0.91      0.01      5.94    945.10      1.00\n",
      " lambda[30]      3.22     11.80      0.94      0.01      6.65    675.96      1.00\n",
      " lambda[31]      3.09     11.04      0.98      0.00      5.57    959.18      1.00\n",
      " lambda[32]      2.95      9.24      1.05      0.00      6.09    960.45      1.00\n",
      " lambda[33]      2.43      5.19      0.92      0.00      5.12    612.31      1.00\n",
      " lambda[34]      2.82     12.91      0.99      0.00      5.10    485.13      1.00\n",
      " lambda[35]      2.95      7.26      1.02      0.00      6.19    644.13      1.00\n",
      " lambda[36]      3.11     10.74      1.00      0.00      5.95    950.06      1.00\n",
      " lambda[37]      3.15     12.82      0.97      0.00      5.28    995.41      1.00\n",
      " lambda[38]      4.12     27.71      1.02      0.00      6.29    966.18      1.00\n",
      " lambda[39]      3.30     15.97      0.98      0.00      6.15    946.99      1.00\n",
      " lambda[40]      2.94      8.44      0.98      0.00      5.99    751.00      1.00\n",
      " lambda[41]     13.03    103.80      1.02      0.00      9.04    175.43      1.00\n",
      " lambda[42]      2.50      5.50      0.95      0.00      5.41    989.68      1.00\n",
      " lambda[43]      4.65     44.08      0.94      0.00      5.44    622.97      1.00\n",
      " lambda[44]      2.55      5.40      0.96      0.00      5.61    513.95      1.00\n",
      " lambda[45]      2.68      9.45      0.95      0.01      5.47    878.74      1.00\n",
      " lambda[46]      2.70      8.93      0.91      0.00      4.39    865.91      1.00\n",
      " lambda[47]      2.33      4.19      1.05      0.00      5.24    896.54      1.00\n",
      " lambda[48]      3.36      8.33      1.00      0.00      7.39    727.37      1.00\n",
      " lambda[49]      3.53     10.08      1.05      0.00      6.25    663.23      1.00\n",
      " lambda[50]      5.16     72.84      0.97      0.00      5.55    962.77      1.00\n",
      " lambda[51]      4.39     21.55      1.05      0.00      7.90    585.54      1.00\n",
      " lambda[52]      2.95     12.71      0.96      0.00      4.59    985.02      1.00\n",
      " lambda[53]      3.20     10.90      0.98      0.00      5.57    687.36      1.00\n",
      " lambda[54]      2.25      5.19      0.92      0.00      4.59    838.60      1.00\n",
      " lambda[55]      3.29     17.30      0.91      0.00      5.31    945.29      1.00\n",
      " lambda[56]      2.57      7.34      0.96      0.01      4.67   1009.89      1.00\n",
      " lambda[57]      9.96     66.77      1.12      0.00     12.35    390.73      1.00\n",
      " lambda[58]      2.36      5.21      0.99      0.00      5.15    522.39      1.00\n",
      " lambda[59]      3.00      7.89      0.98      0.00      5.99    792.51      1.00\n",
      " lambda[60]      2.97     10.71      0.97      0.00      5.30    824.88      1.00\n",
      " lambda[61]      2.37      5.22      0.97      0.00      5.25    780.87      1.00\n",
      " lambda[62]    909.00   4101.76    166.66      0.02   1624.66    316.99      1.00\n",
      " lambda[63]      2.61      6.25      0.99      0.00      5.32    784.63      1.00\n",
      " lambda[64]      2.49      6.54      0.98      0.00      5.05    885.01      1.00\n",
      " lambda[65]      3.02      9.97      0.98      0.00      5.89    807.96      1.00\n",
      " lambda[66]      2.84      7.23      0.96      0.00      5.78    792.60      1.00\n",
      " lambda[67]      3.02      9.70      1.03      0.00      5.83    957.55      1.00\n",
      " lambda[68]      3.32     10.56      1.02      0.00      6.36    992.40      1.00\n",
      " lambda[69]      4.15     17.18      0.97      0.00      6.64    618.90      1.00\n",
      " lambda[70]      2.63      7.19      0.96      0.00      4.72    706.13      1.00\n",
      " lambda[71]      3.12      9.54      1.06      0.00      6.09    440.73      1.00\n",
      " lambda[72]      2.57      6.46      0.96      0.01      5.08    597.36      1.00\n",
      " lambda[73]      2.90      8.44      1.01      0.00      5.84    670.95      1.01\n",
      " lambda[74]      2.56      6.14      0.96      0.01      5.71    800.44      1.00\n",
      " lambda[75]      5.12     25.83      1.05      0.00      7.01    595.86      1.00\n",
      " lambda[76]      2.66      6.61      0.95      0.00      5.62    567.67      1.00\n",
      " lambda[77]      8.14     62.22      1.00      0.00      6.92    184.53      1.00\n",
      " lambda[78]      2.89      8.02      1.00      0.01      5.63    645.77      1.00\n",
      " lambda[79]      2.49      7.43      0.91      0.00      4.47    755.75      1.00\n",
      " lambda[80]      3.05      7.23      1.01      0.00      6.94    754.74      1.00\n",
      " lambda[81]      2.49      5.34      1.04      0.00      5.56    459.71      1.00\n",
      " lambda[82]      2.71      7.35      0.96      0.00      5.44    692.79      1.00\n",
      " lambda[83]      3.50     10.42      1.03      0.00      6.64    704.94      1.00\n",
      " lambda[84]      3.69     18.68      1.00      0.00      6.27    820.03      1.00\n",
      " lambda[85]      2.88      9.78      0.93      0.00      5.74    587.56      1.00\n",
      " lambda[86]      3.63     12.85      1.00      0.00      6.04    862.80      1.00\n",
      " lambda[87]      3.05     11.92      0.92      0.01      5.44    776.27      1.00\n",
      " lambda[88]      2.84      7.24      1.00      0.01      6.19    582.06      1.00\n",
      " lambda[89]    159.86   2122.83      1.33      0.00    123.91    410.02      1.00\n",
      " lambda[90]      2.51      7.34      0.93      0.00      4.95    646.75      1.00\n",
      " lambda[91]      2.76      8.80      1.01      0.00      4.93    445.79      1.00\n",
      " lambda[92]      2.82      7.03      0.97      0.00      5.75    738.60      1.00\n",
      " lambda[93]      2.78      9.51      1.01      0.00      5.30    578.52      1.00\n",
      " lambda[94]      3.25      9.00      0.99      0.00      5.85    808.07      1.00\n",
      " lambda[95]      3.32     12.50      0.98      0.00      6.35   1036.83      1.00\n",
      " lambda[96]      2.98      7.79      0.95      0.00      6.27    675.50      1.00\n",
      " lambda[97]      2.40      5.29      1.01      0.00      4.75   1056.94      1.00\n",
      " lambda[98]      3.81     24.27      1.03      0.00      5.90    775.62      1.00\n",
      " lambda[99]      2.41      6.16      0.92      0.00      5.21    784.78      1.00\n",
      "lambda[100]      3.04      7.93      1.01      0.00      6.61    682.72      1.00\n",
      "lambda[101]      3.65     12.77      1.08      0.00      6.16    550.42      1.00\n",
      "lambda[102]      2.63      7.11      0.97      0.00      5.50    958.66      1.00\n",
      "lambda[103]      3.66     21.29      0.91      0.00      5.85    355.02      1.00\n",
      "lambda[104]      2.76      8.00      0.98      0.00      4.82    538.08      1.00\n",
      "lambda[105]      3.40     13.83      0.98      0.00      6.45    819.70      1.00\n",
      "lambda[106]      3.07     11.50      0.95      0.00      5.78    871.01      1.00\n",
      "lambda[107]      3.47     11.57      0.98      0.01      5.14    436.28      1.00\n",
      "lambda[108]      2.20      4.89      0.96      0.00      4.76    966.65      1.00\n",
      "lambda[109]      5.76     44.96      0.99      0.00      7.19    524.68      1.00\n",
      "lambda[110]      3.56     14.06      1.04      0.00      6.07    774.12      1.00\n",
      "lambda[111]      4.32     15.12      1.06      0.00      6.67    624.19      1.01\n",
      "lambda[112]      2.18      5.26      0.97      0.01      4.58    596.99      1.00\n",
      "lambda[113]      3.46     10.95      1.01      0.00      5.75    683.84      1.00\n",
      "lambda[114]      2.50      5.52      0.96      0.01      5.24    733.10      1.00\n",
      "lambda[115]      4.01     34.13      0.99      0.00      5.56    980.61      1.00\n",
      "lambda[116]      3.25     17.74      1.03      0.00      5.29    968.63      1.00\n",
      "lambda[117]      3.30     12.83      0.93      0.00      5.52    764.06      1.00\n",
      "lambda[118]      3.62     35.38      0.94      0.00      4.78    965.30      1.00\n",
      "lambda[119]      3.84     12.25      0.97      0.01      6.67    718.69      1.00\n",
      "lambda[120]      3.25      9.34      0.96      0.00      6.33    792.97      1.00\n",
      "lambda[121]      3.43     13.97      0.96      0.00      6.42    848.13      1.00\n",
      "lambda[122]      3.19     11.70      0.97      0.00      6.16    704.96      1.00\n",
      "lambda[123]      2.78      7.05      0.88      0.00      6.62    771.77      1.00\n",
      "lambda[124]      3.03      7.66      1.00      0.01      6.75    773.13      1.00\n",
      "lambda[125]      2.76      7.63      0.92      0.00      6.13    726.56      1.00\n",
      "lambda[126]      2.42      7.27      0.92      0.00      4.57    959.76      1.00\n",
      "lambda[127]      3.41     18.93      0.99      0.00      5.33    983.65      1.00\n",
      "lambda[128]      4.47     28.69      0.99      0.00      6.31    415.18      1.00\n",
      "lambda[129]      3.52     20.48      0.88      0.00      5.53    852.40      1.00\n",
      "lambda[130]      2.85      9.33      0.98      0.00      5.85    807.33      1.00\n",
      "lambda[131]      7.45     78.37      1.02      0.00      5.43    348.64      1.00\n",
      "lambda[132]      2.87      7.60      1.04      0.00      5.87    712.76      1.00\n",
      "lambda[133]      2.49      6.76      0.96      0.00      4.76    969.24      1.00\n",
      "lambda[134]      3.25      8.77      0.96      0.00      6.40    729.72      1.00\n",
      "lambda[135]      2.35      5.78      0.96      0.00      4.69    780.14      1.00\n",
      "lambda[136]      2.91      8.69      0.95      0.00      5.14    863.17      1.00\n",
      "lambda[137]      2.79      8.98      1.02      0.00      5.02    804.96      1.00\n",
      "lambda[138]      3.17     10.06      0.97      0.00      6.03    703.67      1.00\n",
      "lambda[139]      2.42      5.23      0.93      0.00      5.31    689.04      1.00\n",
      "lambda[140]      3.33     12.53      0.99      0.00      5.92    716.21      1.00\n",
      "lambda[141]      2.74      6.16      0.94      0.00      6.35    663.15      1.00\n",
      "lambda[142]      3.30      9.53      1.01      0.00      6.21    887.60      1.00\n",
      "lambda[143]      2.85     15.02      0.92      0.00      4.72    993.50      1.00\n",
      "        msq   2268.74  39297.26      6.78      0.13    139.91    785.07      1.00\n",
      "      sigma      3.30      4.07      1.68      0.00      8.56    967.69      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    485.10      1.01\n",
      "       xisq      1.23      0.65      1.08      0.43      2.10    846.23      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 28.387794017791748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.74e-04 +- 1.75e-02\n",
      "[dimension 02/145]  inactive:\t-4.84e-04 +- 2.75e-02\n",
      "[dimension 03/145]  inactive:\t1.70e-06 +- 2.37e-02\n",
      "[dimension 04/145]  inactive:\t5.51e-03 +- 3.80e-02\n",
      "[dimension 05/145]  inactive:\t-1.17e-03 +- 2.54e-02\n",
      "[dimension 06/145]  inactive:\t3.14e-03 +- 3.95e-02\n",
      "[dimension 07/145]  inactive:\t5.78e-04 +- 1.79e-02\n",
      "[dimension 08/145]  inactive:\t1.32e-03 +- 2.74e-02\n",
      "[dimension 09/145]  inactive:\t2.94e-04 +- 2.21e-02\n",
      "[dimension 10/145]  inactive:\t4.04e-04 +- 1.90e-02\n",
      "[dimension 11/145]  inactive:\t-6.94e-04 +- 2.75e-02\n",
      "[dimension 12/145]  inactive:\t-3.28e-04 +- 2.42e-02\n",
      "[dimension 13/145]  inactive:\t4.88e-03 +- 3.93e-02\n",
      "[dimension 14/145]  inactive:\t-1.20e-03 +- 2.57e-02\n",
      "[dimension 15/145]  inactive:\t5.02e-04 +- 3.37e-02\n",
      "[dimension 16/145]  inactive:\t6.41e-04 +- 1.97e-02\n",
      "[dimension 17/145]  inactive:\t1.26e-04 +- 2.63e-02\n",
      "[dimension 18/145]  inactive:\t-3.89e-04 +- 2.96e-02\n",
      "[dimension 19/145]  inactive:\t-1.87e-03 +- 1.82e-02\n",
      "[dimension 20/145]  inactive:\t-1.09e-03 +- 2.68e-02\n",
      "[dimension 21/145]  inactive:\t-1.43e-03 +- 2.21e-02\n",
      "[dimension 22/145]  inactive:\t-7.36e-06 +- 2.19e-02\n",
      "[dimension 23/145]  inactive:\t-4.90e-04 +- 2.22e-02\n",
      "[dimension 24/145]  inactive:\t1.34e-03 +- 2.44e-02\n",
      "[dimension 25/145]  inactive:\t3.37e-03 +- 2.35e-02\n",
      "[dimension 26/145]  inactive:\t-2.26e-04 +- 2.47e-02\n",
      "[dimension 27/145]  inactive:\t6.16e-04 +- 2.49e-02\n",
      "[dimension 28/145]  inactive:\t8.89e-04 +- 1.82e-02\n",
      "[dimension 29/145]  inactive:\t-1.28e-04 +- 2.46e-02\n",
      "[dimension 30/145]  inactive:\t1.49e-03 +- 2.72e-02\n",
      "[dimension 31/145]  inactive:\t4.27e-03 +- 3.25e-02\n",
      "[dimension 32/145]  inactive:\t-1.20e-03 +- 2.63e-02\n",
      "[dimension 33/145]  inactive:\t2.71e-03 +- 3.82e-02\n",
      "[dimension 34/145]  inactive:\t8.79e-04 +- 1.91e-02\n",
      "[dimension 35/145]  inactive:\t6.80e-04 +- 2.58e-02\n",
      "[dimension 36/145]  inactive:\t1.04e-03 +- 2.46e-02\n",
      "[dimension 37/145]  inactive:\t4.50e-03 +- 3.08e-02\n",
      "[dimension 38/145]  inactive:\t-1.70e-03 +- 2.88e-02\n",
      "[dimension 39/145]  inactive:\t2.15e-03 +- 3.68e-02\n",
      "[dimension 40/145]  inactive:\t3.47e-03 +- 2.95e-02\n",
      "[dimension 41/145]  inactive:\t-1.55e-03 +- 2.61e-02\n",
      "[dimension 42/145]  inactive:\t1.92e-02 +- 1.20e-01\n",
      "[dimension 43/145]  inactive:\t-3.70e-04 +- 1.91e-02\n",
      "[dimension 44/145]  inactive:\t-5.24e-05 +- 3.64e-02\n",
      "[dimension 45/145]  inactive:\t-3.23e-04 +- 2.33e-02\n",
      "[dimension 46/145]  inactive:\t1.02e-03 +- 1.56e-02\n",
      "[dimension 47/145]  inactive:\t-2.30e-03 +- 3.33e-02\n",
      "[dimension 48/145]  inactive:\t1.02e-03 +- 2.14e-02\n",
      "[dimension 49/145]  inactive:\t4.02e-03 +- 3.09e-02\n",
      "[dimension 50/145]  inactive:\t-1.70e-03 +- 2.79e-02\n",
      "[dimension 51/145]  inactive:\t2.78e-03 +- 2.96e-02\n",
      "[dimension 52/145]  inactive:\t6.11e-03 +- 2.57e-02\n",
      "[dimension 53/145]  inactive:\t-9.10e-04 +- 2.44e-02\n",
      "[dimension 54/145]  inactive:\t3.08e-04 +- 2.19e-02\n",
      "[dimension 55/145]  inactive:\t4.92e-04 +- 1.63e-02\n",
      "[dimension 56/145]  inactive:\t-2.36e-03 +- 2.72e-02\n",
      "[dimension 57/145]  inactive:\t1.49e-03 +- 3.23e-02\n",
      "[dimension 58/145]  inactive:\t2.27e-02 +- 9.79e-02\n",
      "[dimension 59/145]  inactive:\t-7.84e-04 +- 1.77e-02\n",
      "[dimension 60/145]  inactive:\t9.47e-05 +- 2.66e-02\n",
      "[dimension 61/145]  inactive:\t2.13e-03 +- 2.19e-02\n",
      "[dimension 62/145]  inactive:\t-4.91e-04 +- 2.25e-02\n",
      "[dimension 63/145]  active:\t6.71e-01 +- 4.44e-01\n",
      "[dimension 64/145]  inactive:\t-3.79e-03 +- 3.38e-02\n",
      "[dimension 65/145]  inactive:\t-5.55e-04 +- 2.07e-02\n",
      "[dimension 66/145]  inactive:\t-7.61e-05 +- 2.36e-02\n",
      "[dimension 67/145]  inactive:\t8.57e-04 +- 2.62e-02\n",
      "[dimension 68/145]  inactive:\t-1.27e-03 +- 3.49e-02\n",
      "[dimension 69/145]  inactive:\t4.12e-03 +- 4.16e-02\n",
      "[dimension 70/145]  inactive:\t4.20e-03 +- 2.57e-02\n",
      "[dimension 71/145]  inactive:\t4.39e-04 +- 2.87e-02\n",
      "[dimension 72/145]  inactive:\t8.19e-04 +- 2.38e-02\n",
      "[dimension 73/145]  inactive:\t3.67e-04 +- 1.70e-02\n",
      "[dimension 74/145]  inactive:\t-2.10e-03 +- 3.07e-02\n",
      "[dimension 75/145]  inactive:\t3.52e-04 +- 2.31e-02\n",
      "[dimension 76/145]  inactive:\t5.69e-03 +- 3.67e-02\n",
      "[dimension 77/145]  inactive:\t-1.70e-03 +- 2.89e-02\n",
      "[dimension 78/145]  inactive:\t1.37e-02 +- 9.51e-02\n",
      "[dimension 79/145]  inactive:\t5.63e-03 +- 3.19e-02\n",
      "[dimension 80/145]  inactive:\t4.14e-04 +- 3.28e-02\n",
      "[dimension 81/145]  inactive:\t5.22e-04 +- 2.85e-02\n",
      "[dimension 82/145]  inactive:\t6.09e-05 +- 1.62e-02\n",
      "[dimension 83/145]  inactive:\t-1.97e-03 +- 2.40e-02\n",
      "[dimension 84/145]  inactive:\t-2.46e-03 +- 3.19e-02\n",
      "[dimension 85/145]  inactive:\t3.35e-03 +- 3.54e-02\n",
      "[dimension 86/145]  inactive:\t-9.00e-04 +- 2.04e-02\n",
      "[dimension 87/145]  inactive:\t3.16e-03 +- 4.91e-02\n",
      "[dimension 88/145]  inactive:\t2.44e-03 +- 2.29e-02\n",
      "[dimension 89/145]  inactive:\t-1.01e-03 +- 2.37e-02\n",
      "[dimension 90/145]  inactive:\t1.42e-01 +- 3.24e-01\n",
      "[dimension 91/145]  inactive:\t9.39e-05 +- 1.82e-02\n",
      "[dimension 92/145]  inactive:\t-1.31e-03 +- 2.18e-02\n",
      "[dimension 93/145]  inactive:\t-6.54e-04 +- 2.46e-02\n",
      "[dimension 94/145]  inactive:\t1.18e-03 +- 2.26e-02\n",
      "[dimension 95/145]  inactive:\t-8.36e-04 +- 2.75e-02\n",
      "[dimension 96/145]  inactive:\t1.71e-04 +- 3.68e-02\n",
      "[dimension 97/145]  inactive:\t2.41e-03 +- 2.21e-02\n",
      "[dimension 98/145]  inactive:\t-6.65e-04 +- 2.32e-02\n",
      "[dimension 99/145]  inactive:\t1.85e-03 +- 2.99e-02\n",
      "[dimension 100/145]  inactive:\t-6.23e-04 +- 1.70e-02\n",
      "[dimension 101/145]  inactive:\t-2.58e-03 +- 2.09e-02\n",
      "[dimension 102/145]  inactive:\t-6.55e-04 +- 2.69e-02\n",
      "[dimension 103/145]  inactive:\t7.66e-04 +- 2.30e-02\n",
      "[dimension 104/145]  inactive:\t-1.17e-03 +- 1.78e-02\n",
      "[dimension 105/145]  inactive:\t-4.99e-04 +- 2.13e-02\n",
      "[dimension 106/145]  inactive:\t3.96e-03 +- 2.82e-02\n",
      "[dimension 107/145]  inactive:\t-1.44e-03 +- 2.07e-02\n",
      "[dimension 108/145]  inactive:\t4.17e-03 +- 5.61e-02\n",
      "[dimension 109/145]  inactive:\t-3.73e-04 +- 1.55e-02\n",
      "[dimension 110/145]  inactive:\t-1.50e-03 +- 3.55e-02\n",
      "[dimension 111/145]  inactive:\t2.52e-03 +- 3.38e-02\n",
      "[dimension 112/145]  inactive:\t7.60e-03 +- 5.37e-02\n",
      "[dimension 113/145]  inactive:\t-9.39e-04 +- 1.66e-02\n",
      "[dimension 114/145]  inactive:\t1.63e-03 +- 3.94e-02\n",
      "[dimension 115/145]  inactive:\t1.63e-03 +- 1.94e-02\n",
      "[dimension 116/145]  inactive:\t5.40e-04 +- 3.30e-02\n",
      "[dimension 117/145]  inactive:\t2.64e-03 +- 3.43e-02\n",
      "[dimension 118/145]  inactive:\t2.84e-03 +- 2.46e-02\n",
      "[dimension 119/145]  inactive:\t-1.71e-03 +- 2.80e-02\n",
      "[dimension 120/145]  inactive:\t1.02e-03 +- 4.54e-02\n",
      "[dimension 121/145]  inactive:\t3.67e-03 +- 3.50e-02\n",
      "[dimension 122/145]  inactive:\t-2.48e-03 +- 3.00e-02\n",
      "[dimension 123/145]  inactive:\t1.19e-03 +- 3.40e-02\n",
      "[dimension 124/145]  inactive:\t-1.59e-03 +- 1.89e-02\n",
      "[dimension 125/145]  inactive:\t-1.81e-03 +- 2.76e-02\n",
      "[dimension 126/145]  inactive:\t-1.21e-03 +- 2.26e-02\n",
      "[dimension 127/145]  inactive:\t-5.53e-06 +- 1.58e-02\n",
      "[dimension 128/145]  inactive:\t-1.03e-03 +- 2.97e-02\n",
      "[dimension 129/145]  inactive:\t3.64e-04 +- 2.84e-02\n",
      "[dimension 130/145]  inactive:\t4.04e-03 +- 3.09e-02\n",
      "[dimension 131/145]  inactive:\t-7.71e-04 +- 2.68e-02\n",
      "[dimension 132/145]  inactive:\t6.19e-03 +- 5.74e-02\n",
      "[dimension 133/145]  inactive:\t2.21e-03 +- 2.11e-02\n",
      "[dimension 134/145]  inactive:\t-4.96e-04 +- 2.12e-02\n",
      "[dimension 135/145]  inactive:\t8.29e-07 +- 2.51e-02\n",
      "[dimension 136/145]  inactive:\t9.08e-04 +- 1.87e-02\n",
      "[dimension 137/145]  inactive:\t-4.32e-04 +- 2.71e-02\n",
      "[dimension 138/145]  inactive:\t3.23e-04 +- 2.21e-02\n",
      "[dimension 139/145]  inactive:\t-3.01e-05 +- 2.69e-02\n",
      "[dimension 140/145]  inactive:\t-6.34e-04 +- 2.73e-02\n",
      "[dimension 141/145]  inactive:\t1.17e-03 +- 2.96e-02\n",
      "[dimension 142/145]  inactive:\t1.51e-03 +- 1.97e-02\n",
      "[dimension 143/145]  inactive:\t1.40e-03 +- 3.40e-02\n",
      "[dimension 144/145]  inactive:\t2.66e-04 +- 2.09e-02\n",
      "[dimension 145/145]  inactive:\t2.83e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00014275]\n",
      "cov_act[[1.2751669e-05]]\n",
      "Active_dimensions: [62]\n",
      "63, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:26<00:00, 57.31it/s, 31 steps of size 2.02e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    419.67      1.00\n",
      "  lambda[0]      2.43      8.28      0.95      0.00      5.04   1009.36      1.00\n",
      "  lambda[1]      2.54      7.04      0.92      0.00      5.38    626.85      1.01\n",
      "  lambda[2]      3.14      8.12      1.00      0.00      6.03    458.17      1.00\n",
      "  lambda[3]      3.31      9.67      0.99      0.00      6.93    630.79      1.00\n",
      "  lambda[4]      2.72      8.38      0.99      0.00      5.73    933.12      1.00\n",
      "  lambda[5]      7.75    134.54      1.01      0.00      5.55    989.41      1.00\n",
      "  lambda[6]      4.67     19.50      1.02      0.00      9.23    715.99      1.00\n",
      "  lambda[7]      3.01     12.61      0.98      0.00      6.45    795.56      1.00\n",
      "  lambda[8]      2.67      6.61      1.01      0.00      5.55    782.10      1.00\n",
      "  lambda[9]      3.17     12.13      0.99      0.00      5.22    631.84      1.00\n",
      " lambda[10]      3.03      7.97      0.99      0.00      6.23    699.99      1.00\n",
      " lambda[11]      2.74      6.93      1.01      0.01      6.01    804.27      1.00\n",
      " lambda[12]      4.60     26.51      1.00      0.00      7.31    839.46      1.00\n",
      " lambda[13]      3.00      8.33      1.02      0.00      5.73    521.94      1.00\n",
      " lambda[14]      3.18      9.48      0.98      0.00      6.30    892.66      1.00\n",
      " lambda[15]      3.55     10.92      1.05      0.00      6.61    762.83      1.00\n",
      " lambda[16]      4.39     42.60      1.07      0.00      6.72    679.95      1.00\n",
      " lambda[17]      2.85      7.86      1.04      0.00      5.46    785.46      1.00\n",
      " lambda[18]      2.45      5.22      0.97      0.00      4.99    914.86      1.00\n",
      " lambda[19]      2.87      7.34      1.00      0.01      6.09    647.36      1.00\n",
      " lambda[20]      2.82      7.22      0.96      0.00      6.32    630.93      1.00\n",
      " lambda[21]      2.73      7.97      1.03      0.00      6.09    903.95      1.00\n",
      " lambda[22]      2.61      6.23      1.00      0.00      5.67    722.64      1.00\n",
      " lambda[23]      3.49     34.37      1.01      0.00      4.99    989.71      1.00\n",
      " lambda[24]      3.89     17.35      1.02      0.00      6.92    735.42      1.00\n",
      " lambda[25]      2.28      4.12      1.08      0.01      5.33    466.76      1.00\n",
      " lambda[26]      2.95      7.45      0.99      0.00      6.54    670.75      1.00\n",
      " lambda[27]      3.01     10.99      0.96      0.00      4.99    715.84      1.00\n",
      " lambda[28]      3.10     10.32      1.05      0.01      5.70    645.29      1.00\n",
      " lambda[29]      4.63     32.47      0.96      0.00      6.23    804.51      1.00\n",
      " lambda[30]      4.69     25.42      0.98      0.00      7.00    616.80      1.00\n",
      " lambda[31]      3.07      9.79      0.98      0.00      5.31    738.73      1.00\n",
      " lambda[32]      8.85    116.09      1.04      0.00      5.84    534.94      1.00\n",
      " lambda[33]      3.07     10.93      0.94      0.01      5.61    936.07      1.00\n",
      " lambda[34]      3.25     16.34      1.01      0.00      5.71    987.62      1.00\n",
      " lambda[35]      3.16      7.86      1.06      0.00      6.95    551.70      1.00\n",
      " lambda[36]      3.01      8.72      1.01      0.00      6.09    621.84      1.00\n",
      " lambda[37]      3.40     14.66      1.03      0.00      5.97    969.38      1.00\n",
      " lambda[38]      3.27      7.53      1.02      0.00      7.12    619.24      1.01\n",
      " lambda[39]      3.44     14.63      0.96      0.00      5.91    564.61      1.00\n",
      " lambda[40]      3.74     16.47      1.01      0.00      6.17    946.91      1.00\n",
      " lambda[41]    130.41   3128.08      0.98      0.00      9.05    754.32      1.00\n",
      " lambda[42]      2.65      6.25      0.98      0.00      5.55    667.24      1.00\n",
      " lambda[43]      2.96      7.04      1.03      0.00      6.25    782.49      1.00\n",
      " lambda[44]      2.83      8.24      0.94      0.01      5.24    905.63      1.00\n",
      " lambda[45]      2.41      6.07      0.96      0.00      4.53    729.07      1.00\n",
      " lambda[46]      2.52      7.45      0.91      0.00      4.97    927.59      1.00\n",
      " lambda[47]      2.42      4.51      0.93      0.00      6.25    525.13      1.00\n",
      " lambda[48]      2.92     10.18      1.00      0.00      5.90    524.49      1.00\n",
      " lambda[49]      3.41     14.94      1.03      0.00      5.86    638.63      1.00\n",
      " lambda[50]      3.31     11.27      0.95      0.01      6.14    785.50      1.00\n",
      " lambda[51]      4.63     19.50      1.06      0.00      8.00    941.81      1.00\n",
      " lambda[52]      2.69      8.44      0.99      0.00      4.78    815.41      1.00\n",
      " lambda[53]      2.85      7.17      0.95      0.00      5.92    617.92      1.00\n",
      " lambda[54]      2.24      4.62      0.90      0.00      4.79    619.48      1.00\n",
      " lambda[55]      3.34     21.78      0.98      0.00      5.32    782.00      1.00\n",
      " lambda[56]      2.53      5.82      0.99      0.01      5.30    897.01      1.00\n",
      " lambda[57]     12.18     99.66      0.93      0.00      8.73    249.03      1.01\n",
      " lambda[58]      2.34      5.23      0.94      0.00      4.86    890.91      1.00\n",
      " lambda[59]      2.88      6.64      0.94      0.00      6.00    520.34      1.00\n",
      " lambda[60]      4.78     19.59      1.05      0.00      7.33    539.67      1.00\n",
      " lambda[61]      2.43      5.90      0.96      0.00      5.50    822.72      1.00\n",
      " lambda[62]  13758.51 178110.55    605.24      0.03   5013.93    830.59      1.00\n",
      " lambda[63]      2.54      6.98      0.95      0.00      4.81    580.96      1.00\n",
      " lambda[64]      3.11      8.23      1.04      0.00      6.03    525.05      1.00\n",
      " lambda[65]      2.36      4.82      0.99      0.00      5.49    682.44      1.00\n",
      " lambda[66]      2.77      7.17      1.00      0.00      5.73    753.82      1.00\n",
      " lambda[67]      2.96      8.71      1.00      0.00      5.95    776.27      1.00\n",
      " lambda[68]      2.85      7.15      0.92      0.00      5.71    928.12      1.00\n",
      " lambda[69]      4.63     20.11      0.97      0.00      6.22    668.42      1.00\n",
      " lambda[70]      2.67      6.41      0.97      0.00      5.63    711.35      1.00\n",
      " lambda[71]      3.02      7.23      0.99      0.00      5.84    477.00      1.00\n",
      " lambda[72]      2.44      6.86      0.98      0.01      4.74    869.86      1.00\n",
      " lambda[73]      3.05      7.40      1.04      0.00      5.77    521.65      1.01\n",
      " lambda[74]      2.31      4.27      0.94      0.01      5.66    894.71      1.00\n",
      " lambda[75]      3.91     14.80      1.03      0.00      7.27    683.86      1.00\n",
      " lambda[76]      3.05      9.20      1.00      0.00      5.80    594.85      1.00\n",
      " lambda[77]     21.90    213.07      1.06      0.01      8.65    379.94      1.00\n",
      " lambda[78]      3.23      9.64      0.99      0.01      6.45    395.27      1.00\n",
      " lambda[79]      3.17     12.52      0.92      0.01      5.24    658.98      1.00\n",
      " lambda[80]      6.76     99.55      0.95      0.01      5.81    828.09      1.00\n",
      " lambda[81]      2.44      6.94      1.01      0.00      5.06    878.43      1.00\n",
      " lambda[82]      2.41      4.99      0.96      0.01      5.35    726.01      1.00\n",
      " lambda[83]      3.18      9.46      1.11      0.00      6.31    917.27      1.00\n",
      " lambda[84]      3.91     18.40      0.98      0.00      5.89    509.71      1.01\n",
      " lambda[85]      2.63      6.59      0.94      0.00      5.13    829.08      1.00\n",
      " lambda[86]      2.62      7.29      0.99      0.00      5.46    980.21      1.00\n",
      " lambda[87]      3.54     25.48      0.96      0.00      5.70    974.03      1.00\n",
      " lambda[88]      2.42      4.86      0.96      0.00      5.23    638.87      1.00\n",
      " lambda[89]    492.01  10529.52      1.13      0.00      9.69    859.01      1.00\n",
      " lambda[90]      2.55      8.35      0.91      0.00      4.89    505.69      1.00\n",
      " lambda[91]      2.91      7.17      1.00      0.00      6.11    639.53      1.00\n",
      " lambda[92]      3.07     10.16      0.95      0.00      5.32    664.54      1.00\n",
      " lambda[93]      3.36     18.11      1.04      0.00      5.94    617.91      1.00\n",
      " lambda[94]      3.05      8.72      1.01      0.00      6.29    629.64      1.00\n",
      " lambda[95]      3.42     11.65      0.96      0.00      5.92    588.50      1.00\n",
      " lambda[96]      3.55     17.84      0.97      0.00      6.36    635.74      1.00\n",
      " lambda[97]      2.75      6.57      0.96      0.01      5.85    471.89      1.00\n",
      " lambda[98]      7.45     60.17      1.03      0.00      6.21    271.25      1.00\n",
      " lambda[99]      2.54      6.15      0.92      0.00      5.34    797.38      1.00\n",
      "lambda[100]      2.32      5.55      0.96      0.00      4.86    754.15      1.00\n",
      "lambda[101]      3.31      8.80      0.99      0.00      6.47    470.72      1.00\n",
      "lambda[102]      2.37      5.09      0.95      0.00      5.16    647.59      1.00\n",
      "lambda[103]      2.57     10.57      0.96      0.00      5.06    803.44      1.00\n",
      "lambda[104]      2.17      4.74      0.92      0.00      4.28   1125.60      1.00\n",
      "lambda[105]      3.57     10.60      0.98      0.00      6.18    596.28      1.00\n",
      "lambda[106]      2.80      7.64      0.92      0.00      6.26    520.13      1.00\n",
      "lambda[107]      3.51     20.64      0.97      0.00      4.89    516.95      1.00\n",
      "lambda[108]      2.49      5.70      0.98      0.01      5.71    870.97      1.00\n",
      "lambda[109]      8.27    157.13      0.97      0.00      5.78   1004.60      1.00\n",
      "lambda[110]      3.34     11.41      1.09      0.00      6.18    654.84      1.00\n",
      "lambda[111]      5.48     26.05      0.99      0.00      8.49    704.52      1.00\n",
      "lambda[112]      2.19      4.06      1.01      0.02      4.96    928.09      1.00\n",
      "lambda[113]      3.76     11.95      0.96      0.00      6.57    610.15      1.00\n",
      "lambda[114]      7.07     68.63      1.02      0.00      6.84    900.77      1.00\n",
      "lambda[115]      3.80     16.34      1.00      0.00      5.90    831.24      1.00\n",
      "lambda[116]      4.50     28.14      0.98      0.01      6.42    624.55      1.00\n",
      "lambda[117]      3.45     15.04      0.92      0.00      5.92   1019.76      1.00\n",
      "lambda[118]      2.50      5.25      0.94      0.00      5.52    611.85      1.00\n",
      "lambda[119]      2.68      6.60      0.94      0.00      5.65    614.79      1.00\n",
      "lambda[120]      4.20     15.71      0.99      0.00      7.58    721.81      1.00\n",
      "lambda[121]      3.81     19.40      1.03      0.00      5.97    774.10      1.00\n",
      "lambda[122]      2.67      7.00      0.98      0.00      5.45    980.44      1.00\n",
      "lambda[123]      2.55      6.03      0.93      0.00      5.44    682.31      1.01\n",
      "lambda[124]      2.86      7.99      1.05      0.01      5.59    562.59      1.00\n",
      "lambda[125]      2.95      8.41      0.97      0.00      6.15    500.70      1.00\n",
      "lambda[126]      2.78      9.15      0.99      0.00      5.04    871.57      1.00\n",
      "lambda[127]      3.57     15.31      1.01      0.00      6.08    898.15      1.00\n",
      "lambda[128]      3.11     13.63      0.99      0.00      5.01    614.62      1.00\n",
      "lambda[129]      3.78     29.18      0.96      0.00      5.81    967.05      1.00\n",
      "lambda[130]      3.31     12.35      0.99      0.00      5.76    645.89      1.00\n",
      "lambda[131]     19.15    319.60      0.97      0.00      5.56    508.20      1.00\n",
      "lambda[132]      2.61      6.15      0.99      0.00      5.38    904.49      1.00\n",
      "lambda[133]      2.89      9.32      0.95      0.00      5.58    796.40      1.00\n",
      "lambda[134]      3.03      7.04      0.87      0.00      6.97    616.27      1.00\n",
      "lambda[135]      2.65      6.32      0.95      0.00      5.38    828.99      1.00\n",
      "lambda[136]      2.92     11.44      0.92      0.00      5.35    876.04      1.00\n",
      "lambda[137]      2.80      9.79      0.97      0.01      5.50    889.30      1.00\n",
      "lambda[138]      2.74      6.83      0.96      0.00      5.56    632.53      1.00\n",
      "lambda[139]      3.04      7.64      0.94      0.00      6.76    753.96      1.00\n",
      "lambda[140]      2.98      9.05      0.98      0.00      5.52    934.91      1.00\n",
      "lambda[141]      3.35     11.10      0.89      0.00      6.50    777.35      1.00\n",
      "lambda[142]      7.88     87.56      0.92      0.00      6.64    748.08      1.00\n",
      "lambda[143]      2.57      9.35      0.89      0.00      4.68    624.64      1.00\n",
      "        msq      0.25      0.15      0.21      0.08      0.42    720.28      1.00\n",
      "      sigma      2.68      3.89      1.07      0.01      7.13    935.77      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    672.99      1.00\n",
      "       xisq      1.09      0.55      0.96      0.39      1.78    819.76      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 29.776647806167603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t6.00e-05 +- 1.01e-02\n",
      "[dimension 02/145]  inactive:\t5.06e-04 +- 1.38e-02\n",
      "[dimension 03/145]  inactive:\t4.64e-04 +- 1.48e-02\n",
      "[dimension 04/145]  inactive:\t2.44e-03 +- 2.48e-02\n",
      "[dimension 05/145]  inactive:\t4.56e-04 +- 1.55e-02\n",
      "[dimension 06/145]  inactive:\t1.77e-03 +- 2.52e-02\n",
      "[dimension 07/145]  inactive:\t1.31e-03 +- 1.54e-02\n",
      "[dimension 08/145]  inactive:\t1.14e-03 +- 1.89e-02\n",
      "[dimension 09/145]  inactive:\t4.74e-04 +- 1.25e-02\n",
      "[dimension 10/145]  inactive:\t5.70e-04 +- 1.16e-02\n",
      "[dimension 11/145]  inactive:\t1.31e-04 +- 1.20e-02\n",
      "[dimension 12/145]  inactive:\t5.90e-04 +- 1.61e-02\n",
      "[dimension 13/145]  inactive:\t2.84e-03 +- 2.86e-02\n",
      "[dimension 14/145]  inactive:\t4.69e-04 +- 1.90e-02\n",
      "[dimension 15/145]  inactive:\t7.62e-04 +- 1.89e-02\n",
      "[dimension 16/145]  inactive:\t8.31e-04 +- 1.43e-02\n",
      "[dimension 17/145]  inactive:\t1.68e-03 +- 2.69e-02\n",
      "[dimension 18/145]  inactive:\t6.45e-04 +- 1.78e-02\n",
      "[dimension 19/145]  inactive:\t-2.77e-04 +- 9.78e-03\n",
      "[dimension 20/145]  inactive:\t5.70e-05 +- 1.18e-02\n",
      "[dimension 21/145]  inactive:\t-1.30e-04 +- 1.07e-02\n",
      "[dimension 22/145]  inactive:\t3.99e-04 +- 1.19e-02\n",
      "[dimension 23/145]  inactive:\t4.10e-04 +- 1.47e-02\n",
      "[dimension 24/145]  inactive:\t8.03e-04 +- 1.66e-02\n",
      "[dimension 25/145]  inactive:\t2.21e-03 +- 1.89e-02\n",
      "[dimension 26/145]  inactive:\t2.37e-04 +- 1.16e-02\n",
      "[dimension 27/145]  inactive:\t5.64e-04 +- 1.25e-02\n",
      "[dimension 28/145]  inactive:\t7.58e-04 +- 1.26e-02\n",
      "[dimension 29/145]  inactive:\t6.90e-04 +- 1.61e-02\n",
      "[dimension 30/145]  inactive:\t2.42e-03 +- 2.88e-02\n",
      "[dimension 31/145]  inactive:\t2.72e-03 +- 2.88e-02\n",
      "[dimension 32/145]  inactive:\t4.45e-04 +- 1.77e-02\n",
      "[dimension 33/145]  inactive:\t3.87e-03 +- 4.27e-02\n",
      "[dimension 34/145]  inactive:\t7.69e-04 +- 1.27e-02\n",
      "[dimension 35/145]  inactive:\t1.36e-03 +- 2.40e-02\n",
      "[dimension 36/145]  inactive:\t7.34e-04 +- 1.35e-02\n",
      "[dimension 37/145]  inactive:\t2.07e-03 +- 1.72e-02\n",
      "[dimension 38/145]  inactive:\t5.56e-04 +- 1.98e-02\n",
      "[dimension 39/145]  inactive:\t1.45e-03 +- 1.91e-02\n",
      "[dimension 40/145]  inactive:\t2.63e-03 +- 2.75e-02\n",
      "[dimension 41/145]  inactive:\t7.63e-04 +- 2.40e-02\n",
      "[dimension 42/145]  inactive:\t2.16e-02 +- 1.20e-01\n",
      "[dimension 43/145]  inactive:\t5.65e-04 +- 1.29e-02\n",
      "[dimension 44/145]  inactive:\t2.79e-04 +- 1.34e-02\n",
      "[dimension 45/145]  inactive:\t5.73e-04 +- 1.48e-02\n",
      "[dimension 46/145]  inactive:\t3.27e-04 +- 8.11e-03\n",
      "[dimension 47/145]  inactive:\t-1.14e-04 +- 1.25e-02\n",
      "[dimension 48/145]  inactive:\t4.47e-04 +- 1.15e-02\n",
      "[dimension 49/145]  inactive:\t7.49e-04 +- 1.14e-02\n",
      "[dimension 50/145]  inactive:\t-5.33e-05 +- 1.88e-02\n",
      "[dimension 51/145]  inactive:\t1.32e-03 +- 2.03e-02\n",
      "[dimension 52/145]  inactive:\t3.69e-03 +- 2.04e-02\n",
      "[dimension 53/145]  inactive:\t1.76e-04 +- 1.46e-02\n",
      "[dimension 54/145]  inactive:\t3.99e-04 +- 1.29e-02\n",
      "[dimension 55/145]  inactive:\t3.69e-04 +- 9.55e-03\n",
      "[dimension 56/145]  inactive:\t-3.62e-04 +- 9.35e-03\n",
      "[dimension 57/145]  inactive:\t9.48e-04 +- 1.66e-02\n",
      "[dimension 58/145]  inactive:\t9.53e-03 +- 6.23e-02\n",
      "[dimension 59/145]  inactive:\t-9.50e-05 +- 1.09e-02\n",
      "[dimension 60/145]  inactive:\t9.15e-04 +- 1.56e-02\n",
      "[dimension 61/145]  inactive:\t2.70e-03 +- 2.40e-02\n",
      "[dimension 62/145]  inactive:\t1.39e-04 +- 1.07e-02\n",
      "[dimension 63/145]  active:\t7.35e-01 +- 3.60e-01\n",
      "[dimension 64/145]  inactive:\t-6.26e-04 +- 1.18e-02\n",
      "[dimension 65/145]  inactive:\t6.88e-04 +- 1.73e-02\n",
      "[dimension 66/145]  inactive:\t3.24e-04 +- 1.02e-02\n",
      "[dimension 67/145]  inactive:\t5.49e-04 +- 1.26e-02\n",
      "[dimension 68/145]  inactive:\t2.76e-04 +- 1.74e-02\n",
      "[dimension 69/145]  inactive:\t1.20e-03 +- 1.83e-02\n",
      "[dimension 70/145]  inactive:\t2.88e-03 +- 1.93e-02\n",
      "[dimension 71/145]  inactive:\t9.11e-04 +- 1.60e-02\n",
      "[dimension 72/145]  inactive:\t9.40e-04 +- 1.71e-02\n",
      "[dimension 73/145]  inactive:\t3.34e-04 +- 1.02e-02\n",
      "[dimension 74/145]  inactive:\t4.22e-04 +- 2.05e-02\n",
      "[dimension 75/145]  inactive:\t3.03e-04 +- 1.05e-02\n",
      "[dimension 76/145]  inactive:\t2.86e-03 +- 2.65e-02\n",
      "[dimension 77/145]  inactive:\t1.25e-04 +- 1.67e-02\n",
      "[dimension 78/145]  inactive:\t1.49e-02 +- 9.60e-02\n",
      "[dimension 79/145]  inactive:\t3.79e-03 +- 2.57e-02\n",
      "[dimension 80/145]  inactive:\t7.43e-04 +- 1.76e-02\n",
      "[dimension 81/145]  inactive:\t2.51e-03 +- 3.24e-02\n",
      "[dimension 82/145]  inactive:\t1.99e-04 +- 8.28e-03\n",
      "[dimension 83/145]  inactive:\t-2.72e-04 +- 9.36e-03\n",
      "[dimension 84/145]  inactive:\t1.49e-04 +- 1.55e-02\n",
      "[dimension 85/145]  inactive:\t1.60e-03 +- 2.18e-02\n",
      "[dimension 86/145]  inactive:\t-1.72e-04 +- 1.12e-02\n",
      "[dimension 87/145]  inactive:\t1.13e-03 +- 1.96e-02\n",
      "[dimension 88/145]  inactive:\t1.38e-03 +- 1.54e-02\n",
      "[dimension 89/145]  inactive:\t3.75e-05 +- 1.08e-02\n",
      "[dimension 90/145]  inactive:\t3.83e-02 +- 1.69e-01\n",
      "[dimension 91/145]  inactive:\t1.76e-04 +- 9.15e-03\n",
      "[dimension 92/145]  inactive:\t-2.91e-05 +- 1.35e-02\n",
      "[dimension 93/145]  inactive:\t3.29e-04 +- 1.42e-02\n",
      "[dimension 94/145]  inactive:\t1.56e-03 +- 2.50e-02\n",
      "[dimension 95/145]  inactive:\t5.05e-04 +- 1.46e-02\n",
      "[dimension 96/145]  inactive:\t7.09e-04 +- 2.07e-02\n",
      "[dimension 97/145]  inactive:\t1.80e-03 +- 1.70e-02\n",
      "[dimension 98/145]  inactive:\t1.53e-04 +- 1.13e-02\n",
      "[dimension 99/145]  inactive:\t6.45e-03 +- 5.78e-02\n",
      "[dimension 100/145]  inactive:\t-6.33e-05 +- 9.56e-03\n",
      "[dimension 101/145]  inactive:\t-5.10e-04 +- 9.97e-03\n",
      "[dimension 102/145]  inactive:\t4.08e-04 +- 1.86e-02\n",
      "[dimension 103/145]  inactive:\t4.15e-04 +- 1.09e-02\n",
      "[dimension 104/145]  inactive:\t-2.30e-04 +- 9.72e-03\n",
      "[dimension 105/145]  inactive:\t1.93e-04 +- 1.04e-02\n",
      "[dimension 106/145]  inactive:\t2.51e-03 +- 1.94e-02\n",
      "[dimension 107/145]  inactive:\t-1.35e-04 +- 1.19e-02\n",
      "[dimension 108/145]  inactive:\t2.31e-03 +- 3.10e-02\n",
      "[dimension 109/145]  inactive:\t1.40e-04 +- 1.04e-02\n",
      "[dimension 110/145]  inactive:\t1.53e-03 +- 2.63e-02\n",
      "[dimension 111/145]  inactive:\t1.87e-03 +- 2.68e-02\n",
      "[dimension 112/145]  inactive:\t3.86e-03 +- 3.17e-02\n",
      "[dimension 113/145]  inactive:\t3.03e-05 +- 1.32e-02\n",
      "[dimension 114/145]  inactive:\t1.16e-03 +- 2.15e-02\n",
      "[dimension 115/145]  inactive:\t1.54e-03 +- 1.73e-02\n",
      "[dimension 116/145]  inactive:\t2.10e-03 +- 3.57e-02\n",
      "[dimension 117/145]  inactive:\t4.00e-03 +- 3.93e-02\n",
      "[dimension 118/145]  inactive:\t1.52e-03 +- 1.55e-02\n",
      "[dimension 119/145]  inactive:\t-6.19e-05 +- 1.14e-02\n",
      "[dimension 120/145]  inactive:\t5.85e-04 +- 1.75e-02\n",
      "[dimension 121/145]  inactive:\t2.32e-03 +- 2.23e-02\n",
      "[dimension 122/145]  inactive:\t-8.92e-05 +- 1.52e-02\n",
      "[dimension 123/145]  inactive:\t7.93e-04 +- 1.44e-02\n",
      "[dimension 124/145]  inactive:\t-2.12e-04 +- 9.52e-03\n",
      "[dimension 125/145]  inactive:\t-4.21e-05 +- 1.39e-02\n",
      "[dimension 126/145]  inactive:\t7.03e-05 +- 1.34e-02\n",
      "[dimension 127/145]  inactive:\t2.94e-04 +- 1.02e-02\n",
      "[dimension 128/145]  inactive:\t5.41e-04 +- 1.60e-02\n",
      "[dimension 129/145]  inactive:\t6.60e-05 +- 1.44e-02\n",
      "[dimension 130/145]  inactive:\t1.97e-03 +- 2.28e-02\n",
      "[dimension 131/145]  inactive:\t9.29e-04 +- 2.30e-02\n",
      "[dimension 132/145]  inactive:\t7.03e-03 +- 6.17e-02\n",
      "[dimension 133/145]  inactive:\t1.11e-03 +- 1.15e-02\n",
      "[dimension 134/145]  inactive:\t2.18e-04 +- 1.31e-02\n",
      "[dimension 135/145]  inactive:\t5.15e-04 +- 1.56e-02\n",
      "[dimension 136/145]  inactive:\t6.44e-04 +- 1.08e-02\n",
      "[dimension 137/145]  inactive:\t4.69e-04 +- 1.51e-02\n",
      "[dimension 138/145]  inactive:\t6.24e-04 +- 1.46e-02\n",
      "[dimension 139/145]  inactive:\t5.60e-04 +- 1.24e-02\n",
      "[dimension 140/145]  inactive:\t4.03e-04 +- 1.83e-02\n",
      "[dimension 141/145]  inactive:\t6.58e-04 +- 1.33e-02\n",
      "[dimension 142/145]  inactive:\t1.56e-03 +- 1.47e-02\n",
      "[dimension 143/145]  inactive:\t4.56e-03 +- 5.08e-02\n",
      "[dimension 144/145]  inactive:\t5.81e-04 +- 1.27e-02\n",
      "[dimension 145/145]  inactive:\t-1.67e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8612852]\n",
      "cov_act[[0.00955566]]\n",
      "Active_dimensions: [62]\n",
      "64, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:25<00:00, 58.78it/s, 15 steps of size 2.69e-01. acc. prob=0.87] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    298.95      1.01\n",
      "  lambda[0]      2.48      8.11      0.98      0.00      5.11    999.87      1.00\n",
      "  lambda[1]      3.33     19.04      0.96      0.00      4.79    590.79      1.00\n",
      "  lambda[2]      2.91      7.48      0.94      0.01      6.09    576.12      1.00\n",
      "  lambda[3]      3.31      9.31      1.06      0.00      6.82    956.65      1.00\n",
      "  lambda[4]      3.19      9.49      0.97      0.00      6.06    501.69      1.00\n",
      "  lambda[5]      4.12     21.83      0.98      0.00      6.20    701.84      1.00\n",
      "  lambda[6]      3.14     13.43      0.95      0.00      5.74    691.79      1.00\n",
      "  lambda[7]      2.82      7.11      0.93      0.00      6.19    825.58      1.00\n",
      "  lambda[8]      2.80      6.58      0.96      0.00      6.05    696.80      1.00\n",
      "  lambda[9]      3.21      8.92      0.99      0.00      6.34    807.85      1.00\n",
      " lambda[10]      3.19     10.67      1.01      0.00      5.83    662.77      1.00\n",
      " lambda[11]      2.82      7.65      0.92      0.01      6.14    882.79      1.00\n",
      " lambda[12]      3.52     12.15      0.97      0.01      6.71    621.63      1.00\n",
      " lambda[13]      2.67      7.13      0.91      0.00      5.49    660.07      1.00\n",
      " lambda[14]      4.88     30.95      1.04      0.00      5.67    602.09      1.00\n",
      " lambda[15]      3.24     10.62      1.04      0.00      5.44    897.91      1.00\n",
      " lambda[16]      2.84      6.73      0.96      0.01      5.90    608.31      1.00\n",
      " lambda[17]      2.64      6.55      0.99      0.00      5.20    828.65      1.00\n",
      " lambda[18]      2.67      8.05      0.94      0.00      5.30    833.18      1.00\n",
      " lambda[19]      3.25      9.75      1.13      0.00      6.68    418.33      1.00\n",
      " lambda[20]      3.38      9.38      1.06      0.00      7.63    581.95      1.00\n",
      " lambda[21]      2.44      4.73      0.98      0.00      5.99    817.73      1.00\n",
      " lambda[22]      2.68      6.50      1.01      0.00      5.85    842.92      1.00\n",
      " lambda[23]      4.89     52.53      1.01      0.00      5.70    993.12      1.00\n",
      " lambda[24]      3.79     12.01      1.02      0.00      7.32    846.67      1.00\n",
      " lambda[25]      2.84      7.24      1.01      0.00      6.42    415.89      1.00\n",
      " lambda[26]      2.66      6.51      0.93      0.00      5.76    792.23      1.00\n",
      " lambda[27]      2.85      7.68      0.90      0.00      5.59    863.12      1.00\n",
      " lambda[28]      2.29      5.30      0.96      0.00      4.86    870.84      1.00\n",
      " lambda[29]      4.13     40.46      0.99      0.00      6.11    976.51      1.00\n",
      " lambda[30]      2.74      7.62      0.94      0.01      5.43    786.26      1.00\n",
      " lambda[31]      3.29     12.04      0.95      0.00      5.31    540.66      1.00\n",
      " lambda[32]      3.02      7.17      0.96      0.00      6.78    751.18      1.00\n",
      " lambda[33]      2.49      5.70      0.94      0.00      5.38    859.22      1.00\n",
      " lambda[34]      2.94      9.93      1.08      0.00      5.00    729.98      1.00\n",
      " lambda[35]      2.73      6.50      0.96      0.00      5.61    844.41      1.00\n",
      " lambda[36]      2.68      7.10      0.99      0.00      5.82    868.89      1.00\n",
      " lambda[37]      3.51     18.70      1.00      0.00      6.32    947.84      1.00\n",
      " lambda[38]      5.78     92.92      1.00      0.00      5.50    985.45      1.00\n",
      " lambda[39]      3.12      9.22      0.97      0.00      5.83    745.67      1.00\n",
      " lambda[40]      3.24     11.83      0.99      0.00      5.67    708.04      1.00\n",
      " lambda[41]      5.55     36.48      1.01      0.00      7.24    428.24      1.00\n",
      " lambda[42]      2.55      6.26      0.95      0.00      5.39    802.68      1.00\n",
      " lambda[43]      3.24     12.41      0.93      0.00      6.10    724.36      1.00\n",
      " lambda[44]      2.42      4.95      0.94      0.00      5.86    933.57      1.00\n",
      " lambda[45]      2.98     15.98      0.99      0.00      4.90    979.52      1.00\n",
      " lambda[46]      2.42      6.11      0.91      0.00      4.74    791.66      1.00\n",
      " lambda[47]      2.79      9.34      1.03      0.00      5.57    776.79      1.00\n",
      " lambda[48]      3.08      8.81      1.01      0.00      6.09    573.92      1.00\n",
      " lambda[49]      3.33     10.02      1.07      0.00      6.36    957.99      1.00\n",
      " lambda[50]      3.29     12.00      0.99      0.00      6.28    722.07      1.00\n",
      " lambda[51]      4.04     12.75      1.02      0.00      6.52    346.86      1.00\n",
      " lambda[52]      2.92     10.04      0.99      0.00      5.00    698.13      1.00\n",
      " lambda[53]      2.77      7.14      0.98      0.00      5.53    710.05      1.00\n",
      " lambda[54]      2.49      5.48      0.97      0.00      5.07    521.60      1.00\n",
      " lambda[55]      3.20     19.77      0.89      0.00      5.30    995.03      1.00\n",
      " lambda[56]      2.38      5.43      0.94      0.01      4.75    846.07      1.00\n",
      " lambda[57]      6.34     27.06      1.03      0.01     10.13    555.33      1.00\n",
      " lambda[58]      2.41      5.42      0.93      0.00      5.27    723.17      1.00\n",
      " lambda[59]      3.33      9.86      1.02      0.00      6.70    781.93      1.00\n",
      " lambda[60]      3.43     11.99      1.01      0.00      5.96    460.76      1.00\n",
      " lambda[61]      2.70      7.71      0.98      0.00      5.72    661.56      1.00\n",
      " lambda[62]   1649.81  13945.34    225.05      0.01   1505.74    207.68      1.00\n",
      " lambda[63]      2.56      6.44      1.00      0.00      5.22    895.38      1.00\n",
      " lambda[64]      2.66      7.05      0.97      0.00      5.65    719.68      1.00\n",
      " lambda[65]      3.27     14.03      0.98      0.00      5.79    932.43      1.00\n",
      " lambda[66]      3.71     16.40      0.92      0.00      6.15    777.82      1.00\n",
      " lambda[67]      3.90     20.46      0.96      0.00      6.89    890.86      1.00\n",
      " lambda[68]      3.41     12.02      1.01      0.00      5.86    990.32      1.00\n",
      " lambda[69]      4.14     18.51      1.04      0.00      7.71    992.18      1.00\n",
      " lambda[70]      2.73      8.06      0.93      0.00      5.52    788.26      1.00\n",
      " lambda[71]      3.49     15.19      1.01      0.00      5.67    547.67      1.00\n",
      " lambda[72]      2.41      7.77      0.97      0.00      4.61    705.78      1.00\n",
      " lambda[73]      2.92     14.52      0.97      0.00      5.22    977.44      1.00\n",
      " lambda[74]      2.51      5.77      0.97      0.01      5.14    762.98      1.00\n",
      " lambda[75]      5.14     33.77      1.02      0.00      6.93    888.40      1.00\n",
      " lambda[76]      2.98      7.26      1.06      0.00      5.77    702.58      1.00\n",
      " lambda[77]      5.03     43.00      0.97      0.00      5.73    731.04      1.00\n",
      " lambda[78]      2.91      7.66      1.02      0.00      5.88    613.15      1.00\n",
      " lambda[79]      2.69      9.19      0.93      0.00      5.29    720.52      1.00\n",
      " lambda[80]      3.40      9.44      0.96      0.00      7.39    535.88      1.00\n",
      " lambda[81]      2.51      4.95      1.03      0.00      5.65    440.15      1.00\n",
      " lambda[82]      2.69      7.07      0.99      0.00      5.43    646.55      1.00\n",
      " lambda[83]      3.83     14.99      0.97      0.00      7.34    849.09      1.00\n",
      " lambda[84]      2.60      7.04      0.96      0.00      5.33    822.32      1.00\n",
      " lambda[85]      2.54      6.86      0.96      0.00      5.33    878.76      1.00\n",
      " lambda[86]      3.12     11.03      0.95      0.00      5.56   1014.46      1.00\n",
      " lambda[87]      2.44      4.80      0.95      0.00      5.89    801.02      1.00\n",
      " lambda[88]      2.90      7.46      1.02      0.01      6.35    671.26      1.00\n",
      " lambda[89]     39.65    204.79      1.22      0.00     56.50    161.57      1.01\n",
      " lambda[90]      2.73      7.42      0.95      0.00      5.77    910.49      1.00\n",
      " lambda[91]      2.88      8.79      0.99      0.00      5.74    570.80      1.00\n",
      " lambda[92]      2.98      7.69      0.96      0.00      5.74    723.78      1.00\n",
      " lambda[93]      2.66      8.79      1.03      0.00      4.40    721.25      1.00\n",
      " lambda[94]      3.29      8.77      1.00      0.00      6.50    717.38      1.00\n",
      " lambda[95]      3.36     11.30      0.98      0.00      6.38    713.33      1.00\n",
      " lambda[96]      2.99      7.66      0.97      0.00      6.36    639.97      1.00\n",
      " lambda[97]      2.69      6.15      0.98      0.00      5.69    782.53      1.00\n",
      " lambda[98]      4.24     28.01      0.96      0.00      4.93    670.74      1.00\n",
      " lambda[99]      2.61      7.97      0.93      0.00      5.10   1040.26      1.00\n",
      "lambda[100]      2.89      7.03      0.98      0.00      6.32    655.31      1.00\n",
      "lambda[101]      3.46     14.24      0.95      0.00      5.77    518.14      1.00\n",
      "lambda[102]      2.82      7.78      0.99      0.00      5.84    889.42      1.00\n",
      "lambda[103]      2.87     16.97      0.93      0.00      5.55    796.42      1.00\n",
      "lambda[104]      2.65      8.01      0.96      0.00      4.87    737.17      1.00\n",
      "lambda[105]      3.64     13.62      1.03      0.00      6.19    756.04      1.00\n",
      "lambda[106]      4.50     29.34      0.94      0.00      5.56    281.19      1.00\n",
      "lambda[107]      2.74      7.53      0.97      0.00      5.60    886.34      1.00\n",
      "lambda[108]      2.59      7.60      0.91      0.00      5.71    740.88      1.00\n",
      "lambda[109]      4.97     21.45      1.01      0.00      7.23    763.78      1.00\n",
      "lambda[110]      3.11     13.73      1.01      0.00      5.92    932.36      1.00\n",
      "lambda[111]      3.73     13.40      0.99      0.00      6.53    643.47      1.01\n",
      "lambda[112]      2.28      5.92      0.97      0.01      4.25    603.25      1.00\n",
      "lambda[113]      3.06      9.43      0.95      0.00      5.40    957.05      1.00\n",
      "lambda[114]      2.60      6.60      0.99      0.00      5.37    904.83      1.00\n",
      "lambda[115]      3.60     17.09      1.03      0.00      6.46    982.44      1.00\n",
      "lambda[116]      3.44     19.16      1.02      0.00      5.57    876.01      1.00\n",
      "lambda[117]      3.24     11.20      0.90      0.00      6.08    784.24      1.00\n",
      "lambda[118]      3.60     36.85      0.94      0.00      4.80    997.42      1.00\n",
      "lambda[119]      3.87     12.18      0.97      0.00      6.92    617.37      1.00\n",
      "lambda[120]      3.97     14.43      0.98      0.00      7.56    596.33      1.00\n",
      "lambda[121]      2.97      8.54      1.01      0.00      5.17    597.42      1.00\n",
      "lambda[122]      3.39     12.81      1.00      0.00      6.46    645.15      1.00\n",
      "lambda[123]      2.62      5.87      0.93      0.00      5.63    690.93      1.00\n",
      "lambda[124]      2.96      8.01      0.97      0.01      6.23    912.31      1.00\n",
      "lambda[125]      2.86      6.81      0.98      0.01      5.73    526.40      1.00\n",
      "lambda[126]      2.33      6.03      0.97      0.00      4.86    983.28      1.00\n",
      "lambda[127]      3.86     20.39      0.95      0.00      5.80    759.35      1.00\n",
      "lambda[128]      4.37     38.08      0.94      0.00      5.75    500.71      1.00\n",
      "lambda[129]      3.57     13.35      0.91      0.00      6.17    580.56      1.00\n",
      "lambda[130]      2.83      6.58      0.99      0.01      6.15    659.55      1.01\n",
      "lambda[131]      4.20     34.44      0.98      0.00      5.25    503.99      1.00\n",
      "lambda[132]      2.94      9.82      1.00      0.00      5.88    641.80      1.00\n",
      "lambda[133]      2.56      7.62      0.96      0.00      4.69    930.61      1.00\n",
      "lambda[134]      3.59     12.14      0.95      0.00      6.89    614.04      1.00\n",
      "lambda[135]      2.36      6.16      0.96      0.00      4.67    944.20      1.00\n",
      "lambda[136]      2.80      7.27      0.93      0.00      5.83    847.77      1.00\n",
      "lambda[137]      2.77      8.83      1.02      0.00      4.83    946.73      1.00\n",
      "lambda[138]      3.36     10.09      0.99      0.00      6.23    693.22      1.00\n",
      "lambda[139]      2.82      6.24      0.94      0.00      5.89    689.17      1.00\n",
      "lambda[140]      3.71     18.01      0.93      0.00      6.11    943.55      1.00\n",
      "lambda[141]      2.68      6.26      0.97      0.00      5.92    656.03      1.01\n",
      "lambda[142]      3.35     10.36      1.00      0.00      5.98    760.96      1.00\n",
      "lambda[143]      2.48      7.24      0.95      0.00      4.97    980.77      1.00\n",
      "        msq  91941.52 2303036.00     21.97      0.12    864.96    946.24      1.00\n",
      "      sigma      4.63      6.33      1.86      0.01     13.90   1097.70      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    995.94      1.00\n",
      "       xisq    146.73   1173.16     14.50      0.82    158.09    935.23      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 29.61156725883484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-5.74e-05 +- 1.61e-02\n",
      "[dimension 02/145]  inactive:\t-3.49e-04 +- 2.42e-02\n",
      "[dimension 03/145]  inactive:\t7.30e-05 +- 2.17e-02\n",
      "[dimension 04/145]  inactive:\t4.91e-03 +- 3.64e-02\n",
      "[dimension 05/145]  inactive:\t-1.06e-03 +- 2.33e-02\n",
      "[dimension 06/145]  inactive:\t3.63e-03 +- 4.61e-02\n",
      "[dimension 07/145]  inactive:\t5.21e-04 +- 1.65e-02\n",
      "[dimension 08/145]  inactive:\t5.66e-04 +- 2.24e-02\n",
      "[dimension 09/145]  inactive:\t4.36e-04 +- 2.06e-02\n",
      "[dimension 10/145]  inactive:\t3.55e-04 +- 2.18e-02\n",
      "[dimension 11/145]  inactive:\t-9.49e-04 +- 2.53e-02\n",
      "[dimension 12/145]  inactive:\t-6.57e-04 +- 2.22e-02\n",
      "[dimension 13/145]  inactive:\t4.16e-03 +- 3.49e-02\n",
      "[dimension 14/145]  inactive:\t-1.48e-03 +- 2.02e-02\n",
      "[dimension 15/145]  inactive:\t1.86e-04 +- 3.18e-02\n",
      "[dimension 16/145]  inactive:\t7.75e-04 +- 1.94e-02\n",
      "[dimension 17/145]  inactive:\t-3.63e-04 +- 2.52e-02\n",
      "[dimension 18/145]  inactive:\t-5.43e-04 +- 2.45e-02\n",
      "[dimension 19/145]  inactive:\t-1.51e-03 +- 1.78e-02\n",
      "[dimension 20/145]  inactive:\t-1.17e-03 +- 2.70e-02\n",
      "[dimension 21/145]  inactive:\t-1.37e-03 +- 2.25e-02\n",
      "[dimension 22/145]  inactive:\t9.80e-05 +- 1.90e-02\n",
      "[dimension 23/145]  inactive:\t-5.65e-04 +- 2.44e-02\n",
      "[dimension 24/145]  inactive:\t1.44e-03 +- 2.38e-02\n",
      "[dimension 25/145]  inactive:\t3.41e-03 +- 2.33e-02\n",
      "[dimension 26/145]  inactive:\t-8.75e-04 +- 2.66e-02\n",
      "[dimension 27/145]  inactive:\t7.32e-04 +- 2.31e-02\n",
      "[dimension 28/145]  inactive:\t6.24e-04 +- 1.70e-02\n",
      "[dimension 29/145]  inactive:\t-2.88e-04 +- 2.08e-02\n",
      "[dimension 30/145]  inactive:\t2.21e-03 +- 3.72e-02\n",
      "[dimension 31/145]  inactive:\t2.90e-03 +- 2.67e-02\n",
      "[dimension 32/145]  inactive:\t-1.19e-03 +- 2.66e-02\n",
      "[dimension 33/145]  inactive:\t2.20e-03 +- 3.67e-02\n",
      "[dimension 34/145]  inactive:\t6.01e-04 +- 1.67e-02\n",
      "[dimension 35/145]  inactive:\t4.11e-05 +- 2.29e-02\n",
      "[dimension 36/145]  inactive:\t6.22e-04 +- 2.11e-02\n",
      "[dimension 37/145]  inactive:\t3.31e-03 +- 2.30e-02\n",
      "[dimension 38/145]  inactive:\t-1.91e-03 +- 2.76e-02\n",
      "[dimension 39/145]  inactive:\t1.39e-03 +- 3.28e-02\n",
      "[dimension 40/145]  inactive:\t2.90e-03 +- 2.46e-02\n",
      "[dimension 41/145]  inactive:\t-1.60e-03 +- 2.55e-02\n",
      "[dimension 42/145]  inactive:\t8.27e-03 +- 6.83e-02\n",
      "[dimension 43/145]  inactive:\t-3.86e-04 +- 1.77e-02\n",
      "[dimension 44/145]  inactive:\t-1.15e-03 +- 2.88e-02\n",
      "[dimension 45/145]  inactive:\t-4.49e-04 +- 2.12e-02\n",
      "[dimension 46/145]  inactive:\t1.04e-03 +- 1.55e-02\n",
      "[dimension 47/145]  inactive:\t-1.21e-03 +- 2.44e-02\n",
      "[dimension 48/145]  inactive:\t8.24e-04 +- 2.18e-02\n",
      "[dimension 49/145]  inactive:\t3.14e-03 +- 2.68e-02\n",
      "[dimension 50/145]  inactive:\t-1.50e-03 +- 2.48e-02\n",
      "[dimension 51/145]  inactive:\t2.11e-03 +- 2.54e-02\n",
      "[dimension 52/145]  inactive:\t5.23e-03 +- 2.31e-02\n",
      "[dimension 53/145]  inactive:\t-1.25e-03 +- 2.27e-02\n",
      "[dimension 54/145]  inactive:\t1.31e-04 +- 1.83e-02\n",
      "[dimension 55/145]  inactive:\t4.06e-04 +- 1.51e-02\n",
      "[dimension 56/145]  inactive:\t-1.80e-03 +- 1.94e-02\n",
      "[dimension 57/145]  inactive:\t7.78e-04 +- 2.64e-02\n",
      "[dimension 58/145]  inactive:\t1.48e-02 +- 7.52e-02\n",
      "[dimension 59/145]  inactive:\t-5.27e-04 +- 1.67e-02\n",
      "[dimension 60/145]  inactive:\t4.84e-04 +- 2.52e-02\n",
      "[dimension 61/145]  inactive:\t2.43e-03 +- 2.21e-02\n",
      "[dimension 62/145]  inactive:\t-4.56e-04 +- 2.00e-02\n",
      "[dimension 63/145]  active:\t7.79e-01 +- 3.75e-01\n",
      "[dimension 64/145]  inactive:\t-1.96e-03 +- 1.94e-02\n",
      "[dimension 65/145]  inactive:\t-6.36e-04 +- 2.06e-02\n",
      "[dimension 66/145]  inactive:\t1.39e-04 +- 2.18e-02\n",
      "[dimension 67/145]  inactive:\t1.51e-03 +- 2.28e-02\n",
      "[dimension 68/145]  inactive:\t-5.44e-04 +- 3.66e-02\n",
      "[dimension 69/145]  inactive:\t3.78e-03 +- 4.14e-02\n",
      "[dimension 70/145]  inactive:\t3.88e-03 +- 2.38e-02\n",
      "[dimension 71/145]  inactive:\t6.58e-04 +- 2.91e-02\n",
      "[dimension 72/145]  inactive:\t2.12e-04 +- 2.14e-02\n",
      "[dimension 73/145]  inactive:\t1.35e-04 +- 1.42e-02\n",
      "[dimension 74/145]  inactive:\t-1.56e-03 +- 2.47e-02\n",
      "[dimension 75/145]  inactive:\t-7.30e-07 +- 2.09e-02\n",
      "[dimension 76/145]  inactive:\t4.72e-03 +- 3.38e-02\n",
      "[dimension 77/145]  inactive:\t-1.53e-03 +- 2.69e-02\n",
      "[dimension 78/145]  inactive:\t5.24e-03 +- 5.18e-02\n",
      "[dimension 79/145]  inactive:\t4.52e-03 +- 2.74e-02\n",
      "[dimension 80/145]  inactive:\t-8.19e-04 +- 2.60e-02\n",
      "[dimension 81/145]  inactive:\t1.60e-03 +- 3.51e-02\n",
      "[dimension 82/145]  inactive:\t2.13e-04 +- 1.65e-02\n",
      "[dimension 83/145]  inactive:\t-1.61e-03 +- 1.73e-02\n",
      "[dimension 84/145]  inactive:\t-2.42e-03 +- 2.90e-02\n",
      "[dimension 85/145]  inactive:\t2.14e-03 +- 2.60e-02\n",
      "[dimension 86/145]  inactive:\t-6.67e-04 +- 1.79e-02\n",
      "[dimension 87/145]  inactive:\t1.50e-03 +- 3.07e-02\n",
      "[dimension 88/145]  inactive:\t1.95e-03 +- 1.91e-02\n",
      "[dimension 89/145]  inactive:\t-9.84e-04 +- 1.94e-02\n",
      "[dimension 90/145]  inactive:\t8.73e-02 +- 2.64e-01\n",
      "[dimension 91/145]  inactive:\t-1.94e-05 +- 1.85e-02\n",
      "[dimension 92/145]  inactive:\t-1.19e-03 +- 1.92e-02\n",
      "[dimension 93/145]  inactive:\t-5.44e-04 +- 2.16e-02\n",
      "[dimension 94/145]  inactive:\t1.03e-03 +- 1.99e-02\n",
      "[dimension 95/145]  inactive:\t-4.65e-04 +- 2.49e-02\n",
      "[dimension 96/145]  inactive:\t2.25e-04 +- 3.66e-02\n",
      "[dimension 97/145]  inactive:\t2.11e-03 +- 2.15e-02\n",
      "[dimension 98/145]  inactive:\t-3.29e-04 +- 2.20e-02\n",
      "[dimension 99/145]  inactive:\t1.72e-03 +- 3.06e-02\n",
      "[dimension 100/145]  inactive:\t-6.29e-04 +- 1.62e-02\n",
      "[dimension 101/145]  inactive:\t-1.84e-03 +- 1.74e-02\n",
      "[dimension 102/145]  inactive:\t-5.27e-04 +- 2.90e-02\n",
      "[dimension 103/145]  inactive:\t7.88e-04 +- 2.75e-02\n",
      "[dimension 104/145]  inactive:\t-8.55e-04 +- 1.56e-02\n",
      "[dimension 105/145]  inactive:\t-2.35e-04 +- 1.86e-02\n",
      "[dimension 106/145]  inactive:\t4.41e-03 +- 3.04e-02\n",
      "[dimension 107/145]  inactive:\t-1.43e-03 +- 1.85e-02\n",
      "[dimension 108/145]  inactive:\t-2.36e-04 +- 2.71e-02\n",
      "[dimension 109/145]  inactive:\t-2.22e-04 +- 1.45e-02\n",
      "[dimension 110/145]  inactive:\t-1.24e-03 +- 3.35e-02\n",
      "[dimension 111/145]  inactive:\t1.02e-03 +- 2.62e-02\n",
      "[dimension 112/145]  inactive:\t5.16e-03 +- 4.15e-02\n",
      "[dimension 113/145]  inactive:\t-9.26e-04 +- 1.60e-02\n",
      "[dimension 114/145]  inactive:\t5.90e-04 +- 3.11e-02\n",
      "[dimension 115/145]  inactive:\t1.73e-03 +- 1.95e-02\n",
      "[dimension 116/145]  inactive:\t3.57e-04 +- 2.79e-02\n",
      "[dimension 117/145]  inactive:\t2.89e-03 +- 4.36e-02\n",
      "[dimension 118/145]  inactive:\t2.94e-03 +- 2.62e-02\n",
      "[dimension 119/145]  inactive:\t-1.74e-03 +- 2.40e-02\n",
      "[dimension 120/145]  inactive:\t-4.61e-04 +- 3.57e-02\n",
      "[dimension 121/145]  inactive:\t3.67e-03 +- 3.18e-02\n",
      "[dimension 122/145]  inactive:\t-1.40e-03 +- 2.19e-02\n",
      "[dimension 123/145]  inactive:\t1.67e-03 +- 3.20e-02\n",
      "[dimension 124/145]  inactive:\t-1.29e-03 +- 1.62e-02\n",
      "[dimension 125/145]  inactive:\t-1.76e-03 +- 2.64e-02\n",
      "[dimension 126/145]  inactive:\t-9.87e-04 +- 2.29e-02\n",
      "[dimension 127/145]  inactive:\t7.05e-05 +- 1.47e-02\n",
      "[dimension 128/145]  inactive:\t-1.15e-03 +- 2.66e-02\n",
      "[dimension 129/145]  inactive:\t-6.06e-05 +- 2.15e-02\n",
      "[dimension 130/145]  inactive:\t3.82e-03 +- 2.97e-02\n",
      "[dimension 131/145]  inactive:\t-8.24e-04 +- 2.25e-02\n",
      "[dimension 132/145]  inactive:\t3.02e-03 +- 3.25e-02\n",
      "[dimension 133/145]  inactive:\t2.18e-03 +- 1.88e-02\n",
      "[dimension 134/145]  inactive:\t-2.24e-04 +- 2.15e-02\n",
      "[dimension 135/145]  inactive:\t2.32e-04 +- 2.35e-02\n",
      "[dimension 136/145]  inactive:\t6.71e-04 +- 1.64e-02\n",
      "[dimension 137/145]  inactive:\t-1.36e-04 +- 3.11e-02\n",
      "[dimension 138/145]  inactive:\t5.85e-05 +- 1.98e-02\n",
      "[dimension 139/145]  inactive:\t-5.46e-04 +- 2.83e-02\n",
      "[dimension 140/145]  inactive:\t-9.67e-04 +- 2.50e-02\n",
      "[dimension 141/145]  inactive:\t1.71e-03 +- 3.08e-02\n",
      "[dimension 142/145]  inactive:\t1.17e-03 +- 1.57e-02\n",
      "[dimension 143/145]  inactive:\t9.79e-04 +- 3.47e-02\n",
      "[dimension 144/145]  inactive:\t4.06e-04 +- 1.97e-02\n",
      "[dimension 145/145]  inactive:\t-2.89e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00012875]\n",
      "cov_act[[1.0840595e-05]]\n",
      "Active_dimensions: [62]\n",
      "65, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:27<00:00, 55.51it/s, 15 steps of size 2.22e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    270.82      1.02\n",
      "  lambda[0]      2.74      9.18      0.97      0.00      5.54    857.15      1.00\n",
      "  lambda[1]      4.45     41.23      0.96      0.01      4.90    395.79      1.00\n",
      "  lambda[2]      2.73      5.99      1.04      0.01      5.76    547.67      1.00\n",
      "  lambda[3]      3.46     12.21      1.07      0.00      6.56    686.33      1.00\n",
      "  lambda[4]      2.55      5.50      0.96      0.00      5.68    680.96      1.00\n",
      "  lambda[5]      3.41     16.19      0.99      0.00      5.20    550.62      1.00\n",
      "  lambda[6]      4.70     15.54      1.02      0.00      8.75    642.38      1.00\n",
      "  lambda[7]      3.00      7.50      0.93      0.00      6.59    650.03      1.00\n",
      "  lambda[8]      2.71      6.25      0.99      0.00      5.82    648.48      1.00\n",
      "  lambda[9]      3.20      9.34      1.08      0.00      6.00    383.10      1.00\n",
      " lambda[10]      3.31      8.54      1.05      0.00      6.76    652.98      1.00\n",
      " lambda[11]      2.76      9.70      0.94      0.01      5.18    892.08      1.00\n",
      " lambda[12]      4.59     23.67      0.96      0.00      7.30    734.69      1.01\n",
      " lambda[13]      2.34      5.21      0.94      0.00      4.55    611.62      1.00\n",
      " lambda[14]      3.22      9.33      1.02      0.00      6.56    639.48      1.00\n",
      " lambda[15]      4.23     15.88      1.11      0.00      8.00    906.55      1.00\n",
      " lambda[16]      2.58      6.69      0.97      0.00      5.90    935.12      1.00\n",
      " lambda[17]      6.29     92.10      1.05      0.00      5.73    899.81      1.00\n",
      " lambda[18]      2.88      9.70      0.97      0.00      5.26    789.63      1.00\n",
      " lambda[19]      2.83      7.10      0.98      0.00      5.84    902.97      1.00\n",
      " lambda[20]      2.90      7.68      0.99      0.00      5.81    727.44      1.00\n",
      " lambda[21]      2.50      5.62      0.95      0.00      5.89    478.30      1.00\n",
      " lambda[22]      2.68      6.46      1.03      0.00      5.48    827.36      1.00\n",
      " lambda[23]      3.41     20.31      1.01      0.00      5.17    980.34      1.00\n",
      " lambda[24]      3.68     12.94      1.02      0.00      7.23    747.54      1.00\n",
      " lambda[25]      2.37      6.01      0.94      0.01      5.32    647.68      1.00\n",
      " lambda[26]      3.11     13.13      0.94      0.00      6.03    635.99      1.00\n",
      " lambda[27]      2.54      5.56      0.88      0.00      5.74   1007.68      1.00\n",
      " lambda[28]      2.59      6.11      0.95      0.00      5.60    496.95      1.00\n",
      " lambda[29]      3.35     16.43      0.92      0.01      5.88    870.33      1.00\n",
      " lambda[30]      2.52      6.14      0.94      0.01      5.85    602.69      1.00\n",
      " lambda[31]      2.93      9.58      0.94      0.00      5.13    767.66      1.00\n",
      " lambda[32]      2.73      7.29      0.99      0.00      6.62    868.01      1.00\n",
      " lambda[33]      3.16      8.31      1.01      0.00      6.21    494.64      1.00\n",
      " lambda[34]      3.46     19.99      1.01      0.00      5.42    702.63      1.00\n",
      " lambda[35]      2.83      6.99      0.99      0.00      6.13    766.88      1.00\n",
      " lambda[36]      2.95     10.87      0.95      0.00      5.44    916.60      1.00\n",
      " lambda[37]      3.30     12.50      0.98      0.00      5.81    859.86      1.00\n",
      " lambda[38]      9.26    102.66      1.00      0.00      6.23    326.10      1.00\n",
      " lambda[39]      3.47     16.64      0.92      0.00      6.55    958.89      1.00\n",
      " lambda[40]      2.52      5.68      0.96      0.00      5.78    790.66      1.00\n",
      " lambda[41]      4.45     22.78      1.00      0.00      7.40    889.19      1.00\n",
      " lambda[42]      2.37      6.20      0.95      0.00      4.61    922.54      1.00\n",
      " lambda[43]      3.16     13.65      0.97      0.00      5.24    515.28      1.00\n",
      " lambda[44]      2.78      7.64      0.97      0.00      5.94    887.12      1.00\n",
      " lambda[45]      2.63      9.48      0.95      0.00      4.94   1012.17      1.00\n",
      " lambda[46]      2.26      5.45      0.92      0.00      4.35    995.76      1.00\n",
      " lambda[47]      2.46      4.65      1.04      0.00      5.66    612.26      1.00\n",
      " lambda[48]      2.87      6.87      0.97      0.00      5.99    644.66      1.00\n",
      " lambda[49]      3.01      8.08      1.03      0.00      6.30    832.03      1.00\n",
      " lambda[50]      3.00      9.31      0.96      0.01      6.20    744.46      1.00\n",
      " lambda[51]      4.79     18.41      1.08      0.00      9.42    579.89      1.00\n",
      " lambda[52]      2.45      6.28      0.95      0.00      4.72    865.53      1.00\n",
      " lambda[53]      2.70      7.62      0.99      0.00      5.24    474.33      1.00\n",
      " lambda[54]      2.20      4.75      0.94      0.00      4.41    824.68      1.00\n",
      " lambda[55]      2.86     13.47      0.90      0.00      5.19    981.76      1.00\n",
      " lambda[56]      2.39      6.62      0.98      0.00      4.65   1013.86      1.00\n",
      " lambda[57]      2.92      7.40      0.99      0.00      5.64    638.91      1.00\n",
      " lambda[58]      2.46      5.32      0.96      0.00      5.31    648.50      1.00\n",
      " lambda[59]      2.63      5.99      1.02      0.00      5.67    818.80      1.00\n",
      " lambda[60]      3.54      9.01      1.10      0.00      7.85    656.86      1.00\n",
      " lambda[61]      2.60      6.10      0.99      0.00      5.70    663.06      1.00\n",
      " lambda[62]   8051.49  74843.34   1165.70      0.01  11873.56    842.43      1.00\n",
      " lambda[63]      2.75      9.14      0.90      0.00      4.99    464.15      1.00\n",
      " lambda[64]      2.71      6.48      0.98      0.00      5.47    667.29      1.00\n",
      " lambda[65]      2.93      9.80      0.97      0.00      5.47    773.33      1.00\n",
      " lambda[66]      2.90      7.69      0.96      0.00      5.96    731.59      1.00\n",
      " lambda[67]      2.93      7.79      1.08      0.00      5.83    727.57      1.00\n",
      " lambda[68]      3.10      8.56      1.00      0.00      5.75    821.72      1.00\n",
      " lambda[69]      4.88     29.07      1.03      0.00      6.55    708.27      1.00\n",
      " lambda[70]      2.48      7.55      0.91      0.00      4.44    875.50      1.00\n",
      " lambda[71]      3.29     13.09      1.04      0.00      5.54    664.47      1.00\n",
      " lambda[72]      2.23      5.59      0.98      0.01      4.42    925.35      1.00\n",
      " lambda[73]      2.74      6.66      0.97      0.00      5.78    604.05      1.01\n",
      " lambda[74]      2.57      6.23      0.96      0.01      5.79    737.43      1.00\n",
      " lambda[75]      3.71     13.09      1.04      0.00      6.87    820.91      1.00\n",
      " lambda[76]      2.43      4.82      1.00      0.00      5.57    639.98      1.00\n",
      " lambda[77]      7.92    104.33      0.99      0.00      5.80    421.18      1.00\n",
      " lambda[78]      2.78      7.82      0.99      0.00      4.77    388.16      1.00\n",
      " lambda[79]      2.63      7.84      0.96      0.00      5.01    723.03      1.00\n",
      " lambda[80]      2.97      7.51      0.95      0.00      6.50    764.60      1.00\n",
      " lambda[81]      2.77      6.41      1.02      0.00      6.38    591.82      1.00\n",
      " lambda[82]      2.44      6.14      0.93      0.00      4.84    679.78      1.00\n",
      " lambda[83]      3.28      8.87      1.04      0.00      6.30    689.99      1.00\n",
      " lambda[84]      3.14     14.00      0.99      0.00      4.56    706.93      1.00\n",
      " lambda[85]      2.60      5.91      0.98      0.00      5.37    552.89      1.00\n",
      " lambda[86]      3.45     15.86      0.96      0.00      5.42    925.99      1.00\n",
      " lambda[87]      3.02     11.60      0.93      0.00      5.68    699.09      1.00\n",
      " lambda[88]      2.86      7.26      0.99      0.00      6.05    510.78      1.00\n",
      " lambda[89]    300.21   1696.33      1.16      0.00     96.49     46.00      1.03\n",
      " lambda[90]      2.28      5.21      0.95      0.00      4.63    920.01      1.00\n",
      " lambda[91]      2.66      6.92      0.98      0.00      5.03    669.36      1.00\n",
      " lambda[92]      2.70      5.85      0.99      0.00      6.00    679.75      1.00\n",
      " lambda[93]      2.61      8.32      1.00      0.00      4.92    666.14      1.00\n",
      " lambda[94]      3.61     11.21      0.99      0.00      6.77    714.32      1.01\n",
      " lambda[95]      3.28     11.49      1.02      0.00      6.51    906.95      1.00\n",
      " lambda[96]      2.97      7.54      0.97      0.00      6.39    493.52      1.00\n",
      " lambda[97]      2.49      5.92      1.01      0.00      5.03    862.59      1.00\n",
      " lambda[98]      3.18     16.86      1.04      0.00      5.40    936.99      1.00\n",
      " lambda[99]      2.50      6.51      0.94      0.00      5.58    954.55      1.00\n",
      "lambda[100]      3.29     11.89      1.00      0.00      6.51    741.36      1.00\n",
      "lambda[101]      3.12      8.60      1.00      0.00      5.65    654.11      1.00\n",
      "lambda[102]      2.65      6.81      0.90      0.00      5.15    973.91      1.00\n",
      "lambda[103]      4.42     31.47      0.91      0.00      6.11    406.06      1.00\n",
      "lambda[104]      3.05     14.02      0.99      0.00      4.68    443.17      1.00\n",
      "lambda[105]      3.57     10.51      1.00      0.00      6.32    739.96      1.00\n",
      "lambda[106]      2.91     10.35      0.97      0.00      5.25    686.45      1.00\n",
      "lambda[107]      4.61     56.21      0.97      0.01      4.53    816.50      1.00\n",
      "lambda[108]      2.35      5.93      0.99      0.00      5.22    978.71      1.00\n",
      "lambda[109]      4.15     15.13      1.00      0.00      6.70    772.36      1.00\n",
      "lambda[110]      3.29     11.41      1.04      0.00      5.83    675.08      1.00\n",
      "lambda[111]      4.23     14.24      1.10      0.00      7.13    586.59      1.00\n",
      "lambda[112]      2.19      4.78      1.00      0.01      4.76    648.70      1.00\n",
      "lambda[113]      3.27      9.55      0.95      0.00      5.99    498.55      1.00\n",
      "lambda[114]      2.88      7.81      1.03      0.00      5.81    694.86      1.00\n",
      "lambda[115]      3.75     21.74      1.00      0.00      6.40    949.30      1.00\n",
      "lambda[116]      2.80     13.49      0.97      0.01      5.23    954.80      1.00\n",
      "lambda[117]      3.25     11.47      0.91      0.00      6.08    557.74      1.00\n",
      "lambda[118]      3.14     14.05      0.97      0.00      5.37    761.37      1.00\n",
      "lambda[119]      3.88     15.13      0.97      0.00      7.00    857.50      1.00\n",
      "lambda[120]      3.93     21.56      0.98      0.00      6.24    929.17      1.00\n",
      "lambda[121]      3.19      9.89      1.01      0.00      6.58    714.67      1.00\n",
      "lambda[122]      3.17     12.15      0.94      0.00      5.41    498.59      1.00\n",
      "lambda[123]      2.63      6.62      0.93      0.00      5.67    776.74      1.00\n",
      "lambda[124]      2.83      7.73      1.00      0.01      5.77    650.72      1.00\n",
      "lambda[125]      2.74      7.36      0.94      0.00      5.34    510.05      1.00\n",
      "lambda[126]      2.55      8.91      0.98      0.00      5.34    989.97      1.00\n",
      "lambda[127]      3.15     15.72      0.94      0.00      5.02    976.45      1.00\n",
      "lambda[128]      3.76     19.12      1.02      0.00      5.94    355.75      1.00\n",
      "lambda[129]      3.33     18.84      0.86      0.00      5.45    833.01      1.00\n",
      "lambda[130]      2.75      6.11      0.99      0.01      6.31    677.90      1.00\n",
      "lambda[131]      3.56     16.01      0.98      0.00      5.77    587.75      1.00\n",
      "lambda[132]      3.06      8.99      1.00      0.00      5.77    667.24      1.00\n",
      "lambda[133]      2.56      6.51      0.94      0.00      4.77    812.64      1.00\n",
      "lambda[134]      2.95      7.80      1.01      0.00      6.30    836.86      1.00\n",
      "lambda[135]      2.27      5.37      0.93      0.00      4.43    861.38      1.00\n",
      "lambda[136]      2.89      8.92      0.97      0.00      5.82    930.75      1.00\n",
      "lambda[137]      2.66      7.41      1.03      0.00      5.10    984.47      1.00\n",
      "lambda[138]      3.08      9.98      0.95      0.00      6.06    630.46      1.00\n",
      "lambda[139]      2.71      6.82      0.96      0.00      5.52    703.51      1.00\n",
      "lambda[140]      2.83      9.17      0.97      0.00      5.65    809.76      1.00\n",
      "lambda[141]      3.00      8.45      0.97      0.00      6.79    632.32      1.00\n",
      "lambda[142]      3.90     14.74      1.01      0.00      6.39    444.61      1.00\n",
      "lambda[143]      2.73     11.69      0.98      0.00      5.20    985.56      1.00\n",
      "        msq      0.28      0.20      0.24      0.09      0.49    489.36      1.00\n",
      "      sigma      3.47      5.38      0.96      0.00     10.79    918.86      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    591.35      1.00\n",
      "       xisq     15.98     45.50      5.78      0.86     26.72    317.92      1.01\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.67645502090454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.32e-04 +- 6.99e-03\n",
      "[dimension 02/145]  inactive:\t6.54e-04 +- 1.45e-02\n",
      "[dimension 03/145]  inactive:\t2.13e-04 +- 8.62e-03\n",
      "[dimension 04/145]  inactive:\t1.14e-03 +- 1.49e-02\n",
      "[dimension 05/145]  inactive:\t1.68e-04 +- 9.25e-03\n",
      "[dimension 06/145]  inactive:\t1.02e-03 +- 1.88e-02\n",
      "[dimension 07/145]  inactive:\t6.14e-04 +- 1.00e-02\n",
      "[dimension 08/145]  inactive:\t7.71e-04 +- 1.43e-02\n",
      "[dimension 09/145]  inactive:\t2.92e-04 +- 8.23e-03\n",
      "[dimension 10/145]  inactive:\t3.33e-04 +- 8.18e-03\n",
      "[dimension 11/145]  inactive:\t1.38e-04 +- 8.01e-03\n",
      "[dimension 12/145]  inactive:\t6.88e-04 +- 2.13e-02\n",
      "[dimension 13/145]  inactive:\t1.66e-03 +- 2.36e-02\n",
      "[dimension 14/145]  inactive:\t1.24e-04 +- 7.86e-03\n",
      "[dimension 15/145]  inactive:\t2.74e-04 +- 9.92e-03\n",
      "[dimension 16/145]  inactive:\t2.47e-04 +- 1.02e-02\n",
      "[dimension 17/145]  inactive:\t3.51e-04 +- 1.03e-02\n",
      "[dimension 18/145]  inactive:\t1.09e-03 +- 2.02e-02\n",
      "[dimension 19/145]  inactive:\t-1.11e-04 +- 6.66e-03\n",
      "[dimension 20/145]  inactive:\t1.55e-04 +- 9.32e-03\n",
      "[dimension 21/145]  inactive:\t3.65e-05 +- 7.04e-03\n",
      "[dimension 22/145]  inactive:\t1.43e-04 +- 7.77e-03\n",
      "[dimension 23/145]  inactive:\t2.99e-04 +- 1.05e-02\n",
      "[dimension 24/145]  inactive:\t6.23e-04 +- 1.25e-02\n",
      "[dimension 25/145]  inactive:\t8.08e-04 +- 9.73e-03\n",
      "[dimension 26/145]  inactive:\t1.95e-04 +- 9.04e-03\n",
      "[dimension 27/145]  inactive:\t4.08e-04 +- 1.05e-02\n",
      "[dimension 28/145]  inactive:\t3.53e-04 +- 7.55e-03\n",
      "[dimension 29/145]  inactive:\t3.28e-04 +- 9.42e-03\n",
      "[dimension 30/145]  inactive:\t5.08e-04 +- 1.08e-02\n",
      "[dimension 31/145]  inactive:\t8.49e-04 +- 1.34e-02\n",
      "[dimension 32/145]  inactive:\t1.32e-04 +- 8.62e-03\n",
      "[dimension 33/145]  inactive:\t8.22e-04 +- 1.57e-02\n",
      "[dimension 34/145]  inactive:\t3.19e-04 +- 8.80e-03\n",
      "[dimension 35/145]  inactive:\t1.17e-03 +- 2.98e-02\n",
      "[dimension 36/145]  inactive:\t6.06e-04 +- 1.46e-02\n",
      "[dimension 37/145]  inactive:\t9.75e-04 +- 1.07e-02\n",
      "[dimension 38/145]  inactive:\t1.60e-05 +- 8.68e-03\n",
      "[dimension 39/145]  inactive:\t3.31e-03 +- 4.65e-02\n",
      "[dimension 40/145]  inactive:\t9.31e-04 +- 1.37e-02\n",
      "[dimension 41/145]  inactive:\t8.14e-05 +- 8.06e-03\n",
      "[dimension 42/145]  inactive:\t8.59e-04 +- 1.47e-02\n",
      "[dimension 43/145]  inactive:\t1.41e-04 +- 7.16e-03\n",
      "[dimension 44/145]  inactive:\t1.81e-04 +- 1.07e-02\n",
      "[dimension 45/145]  inactive:\t2.78e-04 +- 1.14e-02\n",
      "[dimension 46/145]  inactive:\t1.80e-04 +- 5.59e-03\n",
      "[dimension 47/145]  inactive:\t1.03e-05 +- 8.32e-03\n",
      "[dimension 48/145]  inactive:\t1.38e-04 +- 7.30e-03\n",
      "[dimension 49/145]  inactive:\t5.48e-04 +- 1.06e-02\n",
      "[dimension 50/145]  inactive:\t7.55e-05 +- 1.16e-02\n",
      "[dimension 51/145]  inactive:\t4.06e-04 +- 1.21e-02\n",
      "[dimension 52/145]  inactive:\t2.11e-03 +- 1.42e-02\n",
      "[dimension 53/145]  inactive:\t-1.50e-05 +- 8.60e-03\n",
      "[dimension 54/145]  inactive:\t1.84e-04 +- 7.52e-03\n",
      "[dimension 55/145]  inactive:\t1.72e-04 +- 6.41e-03\n",
      "[dimension 56/145]  inactive:\t-3.15e-04 +- 7.26e-03\n",
      "[dimension 57/145]  inactive:\t3.41e-04 +- 1.03e-02\n",
      "[dimension 58/145]  inactive:\t8.70e-04 +- 1.19e-02\n",
      "[dimension 59/145]  inactive:\t-1.31e-04 +- 8.15e-03\n",
      "[dimension 60/145]  inactive:\t1.78e-04 +- 7.39e-03\n",
      "[dimension 61/145]  inactive:\t8.25e-04 +- 1.24e-02\n",
      "[dimension 62/145]  inactive:\t4.35e-05 +- 7.75e-03\n",
      "[dimension 63/145]  active:\t8.09e-01 +- 3.28e-01\n",
      "[dimension 64/145]  inactive:\t-2.10e-04 +- 7.08e-03\n",
      "[dimension 65/145]  inactive:\t8.28e-05 +- 1.00e-02\n",
      "[dimension 66/145]  inactive:\t1.83e-04 +- 7.87e-03\n",
      "[dimension 67/145]  inactive:\t3.05e-04 +- 9.49e-03\n",
      "[dimension 68/145]  inactive:\t2.74e-04 +- 1.49e-02\n",
      "[dimension 69/145]  inactive:\t2.22e-03 +- 2.85e-02\n",
      "[dimension 70/145]  inactive:\t1.23e-03 +- 1.17e-02\n",
      "[dimension 71/145]  inactive:\t1.40e-04 +- 8.43e-03\n",
      "[dimension 72/145]  inactive:\t3.41e-04 +- 8.40e-03\n",
      "[dimension 73/145]  inactive:\t1.34e-04 +- 5.27e-03\n",
      "[dimension 74/145]  inactive:\t2.91e-05 +- 9.15e-03\n",
      "[dimension 75/145]  inactive:\t2.88e-04 +- 9.38e-03\n",
      "[dimension 76/145]  inactive:\t1.33e-03 +- 1.71e-02\n",
      "[dimension 77/145]  inactive:\t7.92e-05 +- 1.01e-02\n",
      "[dimension 78/145]  inactive:\t3.27e-03 +- 3.80e-02\n",
      "[dimension 79/145]  inactive:\t1.83e-03 +- 1.95e-02\n",
      "[dimension 80/145]  inactive:\t2.20e-04 +- 9.15e-03\n",
      "[dimension 81/145]  inactive:\t4.65e-04 +- 1.10e-02\n",
      "[dimension 82/145]  inactive:\t1.58e-04 +- 6.86e-03\n",
      "[dimension 83/145]  inactive:\t-3.50e-04 +- 1.01e-02\n",
      "[dimension 84/145]  inactive:\t-8.27e-05 +- 9.10e-03\n",
      "[dimension 85/145]  inactive:\t1.40e-03 +- 2.32e-02\n",
      "[dimension 86/145]  inactive:\t-6.12e-05 +- 6.86e-03\n",
      "[dimension 87/145]  inactive:\t5.37e-04 +- 1.49e-02\n",
      "[dimension 88/145]  inactive:\t6.92e-04 +- 1.05e-02\n",
      "[dimension 89/145]  inactive:\t-2.16e-04 +- 9.23e-03\n",
      "[dimension 90/145]  inactive:\t8.61e-02 +- 2.62e-01\n",
      "[dimension 91/145]  inactive:\t6.76e-05 +- 6.92e-03\n",
      "[dimension 92/145]  inactive:\t-6.71e-05 +- 7.21e-03\n",
      "[dimension 93/145]  inactive:\t8.80e-05 +- 8.23e-03\n",
      "[dimension 94/145]  inactive:\t2.26e-04 +- 7.04e-03\n",
      "[dimension 95/145]  inactive:\t2.33e-04 +- 1.16e-02\n",
      "[dimension 96/145]  inactive:\t2.52e-04 +- 1.00e-02\n",
      "[dimension 97/145]  inactive:\t6.27e-04 +- 9.24e-03\n",
      "[dimension 98/145]  inactive:\t6.55e-05 +- 7.62e-03\n",
      "[dimension 99/145]  inactive:\t3.12e-04 +- 9.83e-03\n",
      "[dimension 100/145]  inactive:\t-4.52e-06 +- 6.28e-03\n",
      "[dimension 101/145]  inactive:\t-4.74e-04 +- 7.80e-03\n",
      "[dimension 102/145]  inactive:\t1.83e-05 +- 7.46e-03\n",
      "[dimension 103/145]  inactive:\t4.12e-04 +- 1.05e-02\n",
      "[dimension 104/145]  inactive:\t-1.56e-04 +- 5.83e-03\n",
      "[dimension 105/145]  inactive:\t5.91e-05 +- 9.47e-03\n",
      "[dimension 106/145]  inactive:\t1.31e-03 +- 1.48e-02\n",
      "[dimension 107/145]  inactive:\t-8.27e-05 +- 8.08e-03\n",
      "[dimension 108/145]  inactive:\t1.53e-03 +- 3.08e-02\n",
      "[dimension 109/145]  inactive:\t8.57e-05 +- 5.69e-03\n",
      "[dimension 110/145]  inactive:\t2.63e-04 +- 1.12e-02\n",
      "[dimension 111/145]  inactive:\t7.94e-04 +- 1.63e-02\n",
      "[dimension 112/145]  inactive:\t2.10e-03 +- 2.42e-02\n",
      "[dimension 113/145]  inactive:\t-1.45e-08 +- 5.64e-03\n",
      "[dimension 114/145]  inactive:\t7.78e-04 +- 1.78e-02\n",
      "[dimension 115/145]  inactive:\t4.65e-04 +- 8.03e-03\n",
      "[dimension 116/145]  inactive:\t3.49e-04 +- 1.12e-02\n",
      "[dimension 117/145]  inactive:\t1.47e-03 +- 2.76e-02\n",
      "[dimension 118/145]  inactive:\t8.11e-04 +- 1.04e-02\n",
      "[dimension 119/145]  inactive:\t4.77e-04 +- 1.53e-02\n",
      "[dimension 120/145]  inactive:\t5.54e-04 +- 1.68e-02\n",
      "[dimension 121/145]  inactive:\t1.41e-03 +- 1.79e-02\n",
      "[dimension 122/145]  inactive:\t-9.87e-06 +- 9.32e-03\n",
      "[dimension 123/145]  inactive:\t4.37e-04 +- 1.07e-02\n",
      "[dimension 124/145]  inactive:\t-6.53e-05 +- 6.16e-03\n",
      "[dimension 125/145]  inactive:\t-1.79e-05 +- 7.83e-03\n",
      "[dimension 126/145]  inactive:\t1.06e-04 +- 8.39e-03\n",
      "[dimension 127/145]  inactive:\t1.55e-04 +- 6.49e-03\n",
      "[dimension 128/145]  inactive:\t3.39e-04 +- 1.20e-02\n",
      "[dimension 129/145]  inactive:\t9.27e-05 +- 1.15e-02\n",
      "[dimension 130/145]  inactive:\t7.15e-04 +- 1.12e-02\n",
      "[dimension 131/145]  inactive:\t1.44e-04 +- 1.03e-02\n",
      "[dimension 132/145]  inactive:\t7.27e-04 +- 1.21e-02\n",
      "[dimension 133/145]  inactive:\t8.73e-04 +- 1.19e-02\n",
      "[dimension 134/145]  inactive:\t1.26e-04 +- 7.83e-03\n",
      "[dimension 135/145]  inactive:\t1.51e-04 +- 8.91e-03\n",
      "[dimension 136/145]  inactive:\t3.07e-04 +- 7.19e-03\n",
      "[dimension 137/145]  inactive:\t2.18e-04 +- 8.18e-03\n",
      "[dimension 138/145]  inactive:\t1.99e-04 +- 7.81e-03\n",
      "[dimension 139/145]  inactive:\t5.14e-04 +- 1.26e-02\n",
      "[dimension 140/145]  inactive:\t1.62e-04 +- 8.90e-03\n",
      "[dimension 141/145]  inactive:\t3.93e-04 +- 1.05e-02\n",
      "[dimension 142/145]  inactive:\t7.61e-04 +- 9.91e-03\n",
      "[dimension 143/145]  inactive:\t2.80e-03 +- 3.89e-02\n",
      "[dimension 144/145]  inactive:\t3.50e-04 +- 8.67e-03\n",
      "[dimension 145/145]  inactive:\t6.56e-10 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.4379621e-05]\n",
      "cov_act[[1.3113022e-06]]\n",
      "Active_dimensions: [62]\n",
      "66, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:35<00:00, 42.79it/s, 31 steps of size 1.45e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    805.13      1.00\n",
      "  lambda[0]      2.55      6.84      0.96      0.00      5.00    872.46      1.00\n",
      "  lambda[1]      3.18      9.49      1.01      0.00      5.67    630.55      1.01\n",
      "  lambda[2]      2.90     11.48      1.02      0.00      5.12    559.41      1.00\n",
      "  lambda[3]      4.44     22.20      1.00      0.00      7.38    586.28      1.00\n",
      "  lambda[4]      2.67      6.99      1.07      0.00      5.57    612.61      1.00\n",
      "  lambda[5]      3.56     11.35      0.99      0.00      6.08    758.00      1.00\n",
      "  lambda[6]      3.37     14.84      0.93      0.00      6.14    777.37      1.00\n",
      "  lambda[7]      3.93     12.79      0.98      0.00      6.72    585.79      1.01\n",
      "  lambda[8]      2.26      4.67      0.97      0.00      5.12   1172.49      1.00\n",
      "  lambda[9]      2.37      7.36      0.94      0.00      4.33    723.79      1.00\n",
      " lambda[10]      3.69     15.00      1.08      0.00      5.49    353.96      1.00\n",
      " lambda[11]      2.84      7.13      1.04      0.01      5.57    846.40      1.00\n",
      " lambda[12]      4.31     13.51      0.97      0.00      8.40    705.39      1.00\n",
      " lambda[13]      2.52      5.91      0.95      0.00      5.29    919.08      1.00\n",
      " lambda[14]      3.76     17.00      0.96      0.00      5.40    777.83      1.00\n",
      " lambda[15]      3.05     10.28      0.98      0.00      4.92    603.69      1.00\n",
      " lambda[16]      3.61     10.19      0.94      0.00      8.29    663.05      1.00\n",
      " lambda[17]      3.61     22.50      0.99      0.00      5.09    615.29      1.00\n",
      " lambda[18]      2.64      6.21      0.96      0.00      6.03    943.57      1.00\n",
      " lambda[19]      3.50     16.02      0.94      0.00      6.10    756.75      1.00\n",
      " lambda[20]      2.77      6.67      0.99      0.00      5.66    818.58      1.00\n",
      " lambda[21]      3.00      8.75      0.97      0.00      5.97    625.97      1.00\n",
      " lambda[22]      2.83     10.51      0.99      0.00      5.14    423.84      1.00\n",
      " lambda[23]      3.04      7.88      1.01      0.00      6.08    745.37      1.00\n",
      " lambda[24]      3.94     18.73      1.01      0.00      6.21    584.96      1.00\n",
      " lambda[25]      3.10      8.93      0.97      0.01      6.05    577.75      1.00\n",
      " lambda[26]      2.91      8.31      0.99      0.00      5.48    570.01      1.00\n",
      " lambda[27]      3.12      8.77      1.01      0.00      5.74    569.64      1.00\n",
      " lambda[28]      2.68      6.90      1.02      0.00      5.64    565.01      1.00\n",
      " lambda[29]      3.06      9.52      0.94      0.00      6.05    759.48      1.00\n",
      " lambda[30]      4.04     19.40      1.02      0.01      7.35    761.42      1.00\n",
      " lambda[31]      4.07     15.74      1.01      0.00      6.62    652.06      1.00\n",
      " lambda[32]      3.04     10.68      0.93      0.00      5.54   1014.14      1.00\n",
      " lambda[33]      2.81      8.63      0.95      0.00      5.32    842.04      1.00\n",
      " lambda[34]      2.76      9.84      0.97      0.00      5.01    612.15      1.00\n",
      " lambda[35]      2.38      5.43      1.05      0.00      4.82    974.34      1.00\n",
      " lambda[36]      3.36     13.26      1.02      0.00      5.99    870.46      1.00\n",
      " lambda[37]      3.16      8.30      0.99      0.00      6.44    590.74      1.00\n",
      " lambda[38]      2.72      6.68      0.95      0.00      5.41    871.80      1.00\n",
      " lambda[39]      3.55     11.24      1.03      0.00      6.32    521.72      1.00\n",
      " lambda[40]      4.16     19.81      0.93      0.00      5.78   1032.26      1.00\n",
      " lambda[41]     13.28    123.13      0.93      0.00     11.08    487.99      1.00\n",
      " lambda[42]      2.62      6.50      0.99      0.00      5.54    730.19      1.00\n",
      " lambda[43]      2.84     15.77      1.02      0.00      5.64   1015.18      1.00\n",
      " lambda[44]      2.63      9.35      0.98      0.00      4.74    961.60      1.00\n",
      " lambda[45]      2.36      4.87      0.97      0.00      5.48    912.61      1.00\n",
      " lambda[46]      2.47      6.68      0.94      0.00      4.77    845.66      1.00\n",
      " lambda[47]      2.49      4.92      0.96      0.00      5.89    654.90      1.00\n",
      " lambda[48]      2.95     10.47      1.02      0.00      5.10    790.30      1.00\n",
      " lambda[49]      2.98      8.37      0.96      0.00      5.90    746.37      1.00\n",
      " lambda[50]      2.92      9.17      0.99      0.00      5.38    753.04      1.00\n",
      " lambda[51]      4.21     15.73      1.05      0.00      6.85    853.90      1.00\n",
      " lambda[52]      2.89      7.94      0.89      0.00      5.70    610.98      1.00\n",
      " lambda[53]      2.87      8.34      0.94      0.00      5.47    911.27      1.00\n",
      " lambda[54]      2.11      4.13      0.97      0.00      4.32    669.12      1.00\n",
      " lambda[55]      3.72     17.88      0.99      0.00      6.12    632.53      1.00\n",
      " lambda[56]      2.47      5.56      0.99      0.00      4.87    834.81      1.00\n",
      " lambda[57]      4.30     17.95      1.00      0.00      6.64    513.81      1.00\n",
      " lambda[58]      2.36      5.21      0.98      0.00      4.92    628.12      1.00\n",
      " lambda[59]      2.81      7.82      0.94      0.00      5.10    753.75      1.00\n",
      " lambda[60]      2.96      8.96      0.96      0.00      5.65    538.91      1.00\n",
      " lambda[61]      2.99     10.27      1.03      0.00      5.80    930.72      1.00\n",
      " lambda[62]   1248.20  18315.37    215.31      0.00   1300.44    907.71      1.00\n",
      " lambda[63]      2.47      7.14      0.96      0.00      5.55    654.25      1.00\n",
      " lambda[64]      3.48     11.69      0.93      0.00      6.03    667.80      1.00\n",
      " lambda[65]      3.30     11.60      0.99      0.00      5.86    816.39      1.00\n",
      " lambda[66]      2.96      7.06      1.01      0.00      6.50    761.44      1.00\n",
      " lambda[67]      2.62      6.20      0.93      0.00      5.22    866.43      1.00\n",
      " lambda[68]      3.43     20.71      0.99      0.00      5.77    761.97      1.00\n",
      " lambda[69]      3.96     13.70      0.94      0.00      7.10    818.10      1.00\n",
      " lambda[70]      2.63      6.67      1.06      0.01      5.68    605.88      1.00\n",
      " lambda[71]      3.03     14.13      0.98      0.00      5.22    773.35      1.00\n",
      " lambda[72]      2.69      7.26      0.94      0.01      5.40    858.16      1.00\n",
      " lambda[73]      2.78      9.98      0.99      0.00      5.51    554.11      1.00\n",
      " lambda[74]      2.27      4.25      1.02      0.01      5.65    888.05      1.00\n",
      " lambda[75]      4.05     13.46      1.00      0.00      7.05    730.47      1.00\n",
      " lambda[76]      2.91      7.19      0.99      0.00      6.01    853.14      1.00\n",
      " lambda[77]      8.59     82.52      1.09      0.00      6.07    280.89      1.00\n",
      " lambda[78]      3.37     11.00      1.07      0.00      6.61    883.51      1.00\n",
      " lambda[79]      3.06     10.60      0.99      0.00      5.27    738.78      1.00\n",
      " lambda[80]      4.48     31.16      1.03      0.00      6.04    781.36      1.00\n",
      " lambda[81]      2.66     11.58      0.97      0.00      4.64    850.02      1.00\n",
      " lambda[82]      2.75     12.84      0.91      0.00      4.97    701.82      1.00\n",
      " lambda[83]      2.51      7.10      0.92      0.00      5.30   1063.41      1.00\n",
      " lambda[84]      5.00     62.21      0.96      0.00      5.94    969.43      1.00\n",
      " lambda[85]      2.78      9.82      0.95      0.00      5.59    629.85      1.00\n",
      " lambda[86]      3.25     11.24      0.96      0.01      5.31    825.98      1.00\n",
      " lambda[87]      3.33      9.84      0.99      0.00      6.37    625.35      1.00\n",
      " lambda[88]      3.00     11.52      0.93      0.00      5.32   1027.37      1.00\n",
      " lambda[89]     38.14    190.91      1.13      0.00     23.17    288.37      1.01\n",
      " lambda[90]      2.78     13.75      1.00      0.00      5.26    981.26      1.00\n",
      " lambda[91]      2.58      6.67      0.95      0.00      5.45    679.61      1.00\n",
      " lambda[92]      2.48      6.02      1.02      0.01      4.98    840.71      1.00\n",
      " lambda[93]      2.47      5.84      0.98      0.00      4.95    690.50      1.00\n",
      " lambda[94]      2.48      7.02      0.98      0.00      5.04    642.40      1.00\n",
      " lambda[95]      3.19      9.41      0.99      0.00      6.95    610.46      1.00\n",
      " lambda[96]      2.89     10.98      0.96      0.00      5.08    536.28      1.00\n",
      " lambda[97]      3.32     13.92      0.99      0.00      5.44    556.68      1.01\n",
      " lambda[98]      3.37     13.77      0.98      0.00      5.23    747.91      1.00\n",
      " lambda[99]      2.51      6.66      0.98      0.00      4.52    913.34      1.00\n",
      "lambda[100]      2.93     13.42      0.90      0.00      5.75    830.59      1.00\n",
      "lambda[101]      2.75      9.34      0.99      0.00      5.31    628.35      1.00\n",
      "lambda[102]      2.61      6.72      0.87      0.00      5.30    907.10      1.00\n",
      "lambda[103]      2.30      4.15      0.99      0.00      5.36    713.72      1.00\n",
      "lambda[104]      2.88      9.41      1.00      0.00      6.02    650.28      1.00\n",
      "lambda[105]      3.47     11.72      1.04      0.00      6.81    695.97      1.00\n",
      "lambda[106]      2.62      5.83      1.01      0.00      5.47    707.61      1.00\n",
      "lambda[107]      3.79     14.51      0.99      0.00      5.88    532.37      1.00\n",
      "lambda[108]      2.36      6.31      0.92      0.00      4.61    613.91      1.00\n",
      "lambda[109]      2.76      6.30      0.99      0.00      5.80    752.42      1.00\n",
      "lambda[110]      3.39     13.14      1.02      0.00      5.87    817.73      1.00\n",
      "lambda[111]      3.73     11.34      0.93      0.00      6.50    694.18      1.00\n",
      "lambda[112]      3.00     13.81      0.99      0.00      5.67    807.24      1.00\n",
      "lambda[113]      4.66     26.74      0.99      0.00      6.59    618.18      1.00\n",
      "lambda[114]      3.40     10.01      0.99      0.00      6.95    748.49      1.00\n",
      "lambda[115]      4.08     19.44      0.96      0.00      6.12    838.99      1.00\n",
      "lambda[116]      4.17     20.80      0.98      0.00      5.79    388.96      1.00\n",
      "lambda[117]      3.12     10.16      0.95      0.00      5.85    878.57      1.00\n",
      "lambda[118]      3.18     10.03      0.98      0.00      5.80    899.18      1.00\n",
      "lambda[119]      2.55      6.08      0.99      0.00      5.27    840.35      1.00\n",
      "lambda[120]      3.88     15.97      0.97      0.00      6.18    766.25      1.00\n",
      "lambda[121]      3.28     15.74      0.91      0.00      5.27    960.50      1.00\n",
      "lambda[122]      3.62     15.68      0.98      0.00      6.26    685.44      1.00\n",
      "lambda[123]      2.77      6.00      0.93      0.00      6.30    562.28      1.01\n",
      "lambda[124]      2.75      6.86      1.00      0.00      5.71    607.39      1.00\n",
      "lambda[125]      2.79      7.58      0.99      0.01      6.06    593.69      1.00\n",
      "lambda[126]      2.16      4.61      0.89      0.00      4.49    848.90      1.00\n",
      "lambda[127]      4.81     24.98      0.98      0.00      6.14    539.43      1.00\n",
      "lambda[128]      3.12     14.25      1.00      0.00      5.43    706.05      1.00\n",
      "lambda[129]      3.85     16.03      1.00      0.00      6.33    964.98      1.00\n",
      "lambda[130]      3.29      9.24      0.94      0.00      6.47    603.78      1.00\n",
      "lambda[131]      3.60     15.40      0.98      0.00      6.66    592.22      1.00\n",
      "lambda[132]      2.90      6.99      0.94      0.00      6.48    895.68      1.00\n",
      "lambda[133]      2.76      7.70      1.02      0.00      5.16    721.44      1.00\n",
      "lambda[134]      3.33      8.35      0.93      0.00      7.35    690.28      1.00\n",
      "lambda[135]      2.82     10.84      0.96      0.00      4.98    711.61      1.00\n",
      "lambda[136]      2.55      5.97      0.95      0.00      5.07    849.07      1.00\n",
      "lambda[137]      2.54      6.61      0.99      0.00      5.57    768.89      1.00\n",
      "lambda[138]      3.18     12.10      1.00      0.00      4.87    675.73      1.00\n",
      "lambda[139]      3.58     12.73      0.99      0.00      6.00    707.15      1.00\n",
      "lambda[140]      2.97      8.24      0.98      0.00      5.60    957.35      1.00\n",
      "lambda[141]      2.45      6.18      0.88      0.00      5.03    782.58      1.00\n",
      "lambda[142]      4.21     25.00      0.95      0.01      5.50    718.84      1.00\n",
      "lambda[143]      2.56      6.32      0.99      0.01      4.98    476.23      1.00\n",
      "        msq    334.12   2528.08      5.92      0.15    197.52    523.04      1.00\n",
      "      sigma      4.31      5.88      1.98      0.01     12.18   1250.73      1.00\n",
      "    var_obs      0.09      0.01      0.09      0.07      0.11    959.38      1.00\n",
      "       xisq      1.21      0.68      1.02      0.41      2.03   1310.52      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 38.789265871047974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.80e-04 +- 2.00e-02\n",
      "[dimension 02/145]  inactive:\t-8.53e-04 +- 2.56e-02\n",
      "[dimension 03/145]  inactive:\t-1.01e-04 +- 2.46e-02\n",
      "[dimension 04/145]  inactive:\t6.45e-03 +- 4.35e-02\n",
      "[dimension 05/145]  inactive:\t-7.63e-04 +- 2.10e-02\n",
      "[dimension 06/145]  inactive:\t1.40e-03 +- 3.72e-02\n",
      "[dimension 07/145]  inactive:\t6.06e-04 +- 1.80e-02\n",
      "[dimension 08/145]  inactive:\t1.01e-03 +- 3.14e-02\n",
      "[dimension 09/145]  inactive:\t-5.89e-05 +- 2.03e-02\n",
      "[dimension 10/145]  inactive:\t3.44e-04 +- 1.53e-02\n",
      "[dimension 11/145]  inactive:\t-1.10e-03 +- 2.65e-02\n",
      "[dimension 12/145]  inactive:\t-4.30e-04 +- 2.83e-02\n",
      "[dimension 13/145]  inactive:\t5.64e-03 +- 4.31e-02\n",
      "[dimension 14/145]  inactive:\t-1.24e-03 +- 2.21e-02\n",
      "[dimension 15/145]  inactive:\t7.27e-04 +- 3.17e-02\n",
      "[dimension 16/145]  inactive:\t8.13e-04 +- 1.92e-02\n",
      "[dimension 17/145]  inactive:\t-8.60e-04 +- 2.86e-02\n",
      "[dimension 18/145]  inactive:\t-3.15e-04 +- 2.46e-02\n",
      "[dimension 19/145]  inactive:\t-2.18e-03 +- 2.03e-02\n",
      "[dimension 20/145]  inactive:\t-1.29e-03 +- 2.75e-02\n",
      "[dimension 21/145]  inactive:\t-1.44e-03 +- 2.22e-02\n",
      "[dimension 22/145]  inactive:\t-4.37e-05 +- 2.44e-02\n",
      "[dimension 23/145]  inactive:\t-8.77e-04 +- 2.60e-02\n",
      "[dimension 24/145]  inactive:\t1.64e-03 +- 2.68e-02\n",
      "[dimension 25/145]  inactive:\t3.37e-03 +- 2.32e-02\n",
      "[dimension 26/145]  inactive:\t-9.19e-04 +- 2.35e-02\n",
      "[dimension 27/145]  inactive:\t7.74e-04 +- 2.19e-02\n",
      "[dimension 28/145]  inactive:\t1.05e-03 +- 2.29e-02\n",
      "[dimension 29/145]  inactive:\t-4.15e-04 +- 2.61e-02\n",
      "[dimension 30/145]  inactive:\t1.01e-03 +- 2.88e-02\n",
      "[dimension 31/145]  inactive:\t6.08e-03 +- 4.15e-02\n",
      "[dimension 32/145]  inactive:\t-1.78e-03 +- 3.55e-02\n",
      "[dimension 33/145]  inactive:\t1.44e-03 +- 3.35e-02\n",
      "[dimension 34/145]  inactive:\t6.44e-04 +- 1.86e-02\n",
      "[dimension 35/145]  inactive:\t1.05e-04 +- 2.26e-02\n",
      "[dimension 36/145]  inactive:\t6.25e-04 +- 2.16e-02\n",
      "[dimension 37/145]  inactive:\t3.86e-03 +- 2.58e-02\n",
      "[dimension 38/145]  inactive:\t-1.99e-03 +- 2.88e-02\n",
      "[dimension 39/145]  inactive:\t6.07e-04 +- 2.81e-02\n",
      "[dimension 40/145]  inactive:\t4.81e-03 +- 3.81e-02\n",
      "[dimension 41/145]  inactive:\t-1.96e-03 +- 3.24e-02\n",
      "[dimension 42/145]  inactive:\t1.90e-02 +- 1.13e-01\n",
      "[dimension 43/145]  inactive:\t-6.80e-04 +- 1.97e-02\n",
      "[dimension 44/145]  inactive:\t-3.03e-04 +- 2.48e-02\n",
      "[dimension 45/145]  inactive:\t-3.20e-04 +- 1.96e-02\n",
      "[dimension 46/145]  inactive:\t1.28e-03 +- 1.65e-02\n",
      "[dimension 47/145]  inactive:\t-1.61e-03 +- 2.44e-02\n",
      "[dimension 48/145]  inactive:\t1.47e-03 +- 2.51e-02\n",
      "[dimension 49/145]  inactive:\t2.87e-03 +- 2.33e-02\n",
      "[dimension 50/145]  inactive:\t-1.94e-03 +- 2.94e-02\n",
      "[dimension 51/145]  inactive:\t1.71e-03 +- 2.40e-02\n",
      "[dimension 52/145]  inactive:\t6.10e-03 +- 2.64e-02\n",
      "[dimension 53/145]  inactive:\t-9.18e-04 +- 2.56e-02\n",
      "[dimension 54/145]  inactive:\t1.50e-06 +- 2.02e-02\n",
      "[dimension 55/145]  inactive:\t4.33e-04 +- 1.44e-02\n",
      "[dimension 56/145]  inactive:\t-2.52e-03 +- 2.21e-02\n",
      "[dimension 57/145]  inactive:\t5.04e-04 +- 2.50e-02\n",
      "[dimension 58/145]  inactive:\t1.18e-02 +- 6.81e-02\n",
      "[dimension 59/145]  inactive:\t-5.75e-04 +- 1.57e-02\n",
      "[dimension 60/145]  inactive:\t2.30e-04 +- 2.89e-02\n",
      "[dimension 61/145]  inactive:\t1.99e-03 +- 2.41e-02\n",
      "[dimension 62/145]  inactive:\t-9.82e-04 +- 2.14e-02\n",
      "[dimension 63/145]  active:\t7.66e-01 +- 3.85e-01\n",
      "[dimension 64/145]  inactive:\t-3.41e-03 +- 2.89e-02\n",
      "[dimension 65/145]  inactive:\t-7.53e-04 +- 2.84e-02\n",
      "[dimension 66/145]  inactive:\t6.13e-04 +- 2.56e-02\n",
      "[dimension 67/145]  inactive:\t1.24e-03 +- 2.51e-02\n",
      "[dimension 68/145]  inactive:\t-4.79e-04 +- 2.50e-02\n",
      "[dimension 69/145]  inactive:\t2.30e-03 +- 3.28e-02\n",
      "[dimension 70/145]  inactive:\t3.82e-03 +- 2.40e-02\n",
      "[dimension 71/145]  inactive:\t-1.75e-04 +- 2.12e-02\n",
      "[dimension 72/145]  inactive:\t1.34e-04 +- 1.98e-02\n",
      "[dimension 73/145]  inactive:\t-3.53e-05 +- 1.74e-02\n",
      "[dimension 74/145]  inactive:\t-1.59e-03 +- 3.25e-02\n",
      "[dimension 75/145]  inactive:\t-1.99e-04 +- 2.09e-02\n",
      "[dimension 76/145]  inactive:\t6.24e-03 +- 4.15e-02\n",
      "[dimension 77/145]  inactive:\t-1.49e-03 +- 2.87e-02\n",
      "[dimension 78/145]  inactive:\t1.14e-02 +- 8.71e-02\n",
      "[dimension 79/145]  inactive:\t5.77e-03 +- 3.19e-02\n",
      "[dimension 80/145]  inactive:\t-2.99e-04 +- 3.09e-02\n",
      "[dimension 81/145]  inactive:\t4.35e-04 +- 3.21e-02\n",
      "[dimension 82/145]  inactive:\t2.54e-04 +- 1.45e-02\n",
      "[dimension 83/145]  inactive:\t-1.48e-03 +- 1.60e-02\n",
      "[dimension 84/145]  inactive:\t-9.30e-04 +- 2.02e-02\n",
      "[dimension 85/145]  inactive:\t2.35e-03 +- 3.12e-02\n",
      "[dimension 86/145]  inactive:\t-2.89e-04 +- 1.89e-02\n",
      "[dimension 87/145]  inactive:\t2.14e-03 +- 3.58e-02\n",
      "[dimension 88/145]  inactive:\t3.03e-03 +- 2.54e-02\n",
      "[dimension 89/145]  inactive:\t-6.73e-04 +- 1.99e-02\n",
      "[dimension 90/145]  inactive:\t7.58e-02 +- 2.48e-01\n",
      "[dimension 91/145]  inactive:\t5.29e-05 +- 1.69e-02\n",
      "[dimension 92/145]  inactive:\t-1.47e-03 +- 2.44e-02\n",
      "[dimension 93/145]  inactive:\t-4.64e-04 +- 2.47e-02\n",
      "[dimension 94/145]  inactive:\t1.35e-03 +- 2.45e-02\n",
      "[dimension 95/145]  inactive:\t-1.19e-04 +- 2.05e-02\n",
      "[dimension 96/145]  inactive:\t1.51e-04 +- 2.97e-02\n",
      "[dimension 97/145]  inactive:\t2.44e-03 +- 2.31e-02\n",
      "[dimension 98/145]  inactive:\t-9.27e-04 +- 2.43e-02\n",
      "[dimension 99/145]  inactive:\t1.73e-03 +- 3.31e-02\n",
      "[dimension 100/145]  inactive:\t-4.66e-04 +- 1.56e-02\n",
      "[dimension 101/145]  inactive:\t-1.90e-03 +- 1.91e-02\n",
      "[dimension 102/145]  inactive:\t-8.78e-04 +- 2.21e-02\n",
      "[dimension 103/145]  inactive:\t5.28e-04 +- 2.02e-02\n",
      "[dimension 104/145]  inactive:\t-8.71e-04 +- 2.00e-02\n",
      "[dimension 105/145]  inactive:\t-1.27e-04 +- 2.67e-02\n",
      "[dimension 106/145]  inactive:\t4.29e-03 +- 2.85e-02\n",
      "[dimension 107/145]  inactive:\t-1.44e-03 +- 1.92e-02\n",
      "[dimension 108/145]  inactive:\t7.25e-03 +- 7.60e-02\n",
      "[dimension 109/145]  inactive:\t-5.89e-04 +- 1.98e-02\n",
      "[dimension 110/145]  inactive:\t-1.42e-03 +- 2.70e-02\n",
      "[dimension 111/145]  inactive:\t1.29e-03 +- 3.07e-02\n",
      "[dimension 112/145]  inactive:\t5.37e-03 +- 4.17e-02\n",
      "[dimension 113/145]  inactive:\t-1.53e-03 +- 2.25e-02\n",
      "[dimension 114/145]  inactive:\t2.21e-04 +- 3.60e-02\n",
      "[dimension 115/145]  inactive:\t2.46e-03 +- 2.40e-02\n",
      "[dimension 116/145]  inactive:\t4.26e-04 +- 3.88e-02\n",
      "[dimension 117/145]  inactive:\t6.00e-03 +- 5.73e-02\n",
      "[dimension 118/145]  inactive:\t2.73e-03 +- 2.26e-02\n",
      "[dimension 119/145]  inactive:\t-2.46e-03 +- 3.28e-02\n",
      "[dimension 120/145]  inactive:\t-4.17e-04 +- 2.41e-02\n",
      "[dimension 121/145]  inactive:\t4.31e-03 +- 3.61e-02\n",
      "[dimension 122/145]  inactive:\t-2.75e-03 +- 2.97e-02\n",
      "[dimension 123/145]  inactive:\t3.15e-03 +- 4.83e-02\n",
      "[dimension 124/145]  inactive:\t-1.71e-03 +- 1.91e-02\n",
      "[dimension 125/145]  inactive:\t-1.65e-03 +- 2.71e-02\n",
      "[dimension 126/145]  inactive:\t-1.06e-03 +- 2.21e-02\n",
      "[dimension 127/145]  inactive:\t-8.66e-05 +- 1.52e-02\n",
      "[dimension 128/145]  inactive:\t-1.70e-03 +- 3.37e-02\n",
      "[dimension 129/145]  inactive:\t-1.18e-04 +- 2.26e-02\n",
      "[dimension 130/145]  inactive:\t3.41e-03 +- 2.72e-02\n",
      "[dimension 131/145]  inactive:\t-1.78e-03 +- 3.14e-02\n",
      "[dimension 132/145]  inactive:\t3.24e-03 +- 3.43e-02\n",
      "[dimension 133/145]  inactive:\t2.60e-03 +- 2.10e-02\n",
      "[dimension 134/145]  inactive:\t-5.76e-04 +- 2.56e-02\n",
      "[dimension 135/145]  inactive:\t-1.33e-04 +- 2.74e-02\n",
      "[dimension 136/145]  inactive:\t1.17e-03 +- 1.99e-02\n",
      "[dimension 137/145]  inactive:\t-5.44e-04 +- 2.71e-02\n",
      "[dimension 138/145]  inactive:\t2.98e-04 +- 1.75e-02\n",
      "[dimension 139/145]  inactive:\t6.09e-04 +- 2.20e-02\n",
      "[dimension 140/145]  inactive:\t-1.55e-03 +- 2.87e-02\n",
      "[dimension 141/145]  inactive:\t1.39e-03 +- 2.62e-02\n",
      "[dimension 142/145]  inactive:\t1.06e-03 +- 1.56e-02\n",
      "[dimension 143/145]  inactive:\t1.04e-03 +- 3.41e-02\n",
      "[dimension 144/145]  inactive:\t3.72e-05 +- 2.17e-02\n",
      "[dimension 145/145]  inactive:\t6.29e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8258133]\n",
      "cov_act[[0.03726262]]\n",
      "Active_dimensions: [62]\n",
      "67, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:26<00:00, 55.73it/s, 15 steps of size 2.02e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    208.10      1.02\n",
      "  lambda[0]      2.50     11.31      0.94      0.00      5.32    978.00      1.00\n",
      "  lambda[1]      7.28    101.44      0.97      0.00      5.76   1007.21      1.00\n",
      "  lambda[2]      3.20      8.30      1.07      0.00      6.24    470.30      1.00\n",
      "  lambda[3]      5.41     40.27      1.08      0.00      6.36    381.16      1.00\n",
      "  lambda[4]      2.61      6.42      1.05      0.00      5.89   1042.60      1.00\n",
      "  lambda[5]      3.64     15.85      1.01      0.00      7.03    749.30      1.00\n",
      "  lambda[6]      7.21     85.58      1.01      0.00      7.77    841.70      1.00\n",
      "  lambda[7]      3.06      7.45      1.00      0.00      6.55    688.26      1.00\n",
      "  lambda[8]      2.55      5.45      1.02      0.01      6.03    948.82      1.00\n",
      "  lambda[9]      2.76      7.27      1.05      0.00      4.89    657.34      1.00\n",
      " lambda[10]      3.40     10.98      0.94      0.00      5.91    837.11      1.00\n",
      " lambda[11]      3.17      9.27      0.96      0.00      6.26    777.79      1.00\n",
      " lambda[12]      5.70     31.53      1.06      0.01      7.58    503.91      1.00\n",
      " lambda[13]      2.89      8.15      0.99      0.00      5.32    573.08      1.00\n",
      " lambda[14]      3.75     13.69      0.95      0.01      6.04    707.09      1.00\n",
      " lambda[15]      3.49     13.06      1.02      0.00      6.08    779.63      1.00\n",
      " lambda[16]      3.25     10.45      0.96      0.00      5.55    596.78      1.00\n",
      " lambda[17]      2.67      6.73      0.96      0.00      5.12    696.24      1.00\n",
      " lambda[18]      2.74      7.13      0.93      0.00      5.36    817.71      1.00\n",
      " lambda[19]      2.55      5.80      0.94      0.00      5.49   1009.23      1.00\n",
      " lambda[20]      2.94      8.28      0.96      0.00      5.62    483.29      1.00\n",
      " lambda[21]      2.61      5.44      0.97      0.00      5.68    668.84      1.00\n",
      " lambda[22]      2.55      6.09      0.99      0.00      5.52    602.43      1.00\n",
      " lambda[23]      2.92      8.96      1.02      0.00      5.19    740.90      1.00\n",
      " lambda[24]      4.08     15.43      1.04      0.00      7.19    504.08      1.00\n",
      " lambda[25]      3.08      9.65      0.98      0.00      6.21    564.16      1.00\n",
      " lambda[26]      3.40     11.96      0.98      0.00      6.04    602.96      1.00\n",
      " lambda[27]      2.72      6.49      0.95      0.00      5.50    470.47      1.00\n",
      " lambda[28]      4.88     61.11      0.93      0.01      5.05    616.48      1.00\n",
      " lambda[29]      3.99     22.82      0.95      0.00      6.47    712.76      1.00\n",
      " lambda[30]      4.49     34.09      0.97      0.00      5.88    534.32      1.00\n",
      " lambda[31]      3.11     11.66      1.00      0.00      5.79   1013.45      1.00\n",
      " lambda[32]      4.39     26.95      1.02      0.00      6.69    854.18      1.00\n",
      " lambda[33]      3.02      7.20      0.95      0.00      6.67    570.79      1.00\n",
      " lambda[34]      3.04     10.86      0.98      0.00      6.08    713.35      1.00\n",
      " lambda[35]      2.94      7.19      0.97      0.00      6.03    765.96      1.00\n",
      " lambda[36]      3.92     19.57      1.02      0.00      5.97    679.97      1.00\n",
      " lambda[37]      3.44     11.64      1.02      0.00      6.29    737.43      1.00\n",
      " lambda[38]      5.06     41.46      0.94      0.00      6.38    948.45      1.00\n",
      " lambda[39]      4.40     21.94      1.00      0.00      7.10    708.53      1.00\n",
      " lambda[40]      2.96      9.25      0.99      0.00      6.18    840.38      1.00\n",
      " lambda[41]     28.91    294.91      0.96      0.00      8.42    346.76      1.00\n",
      " lambda[42]      3.18     11.66      0.95      0.00      6.35    610.20      1.00\n",
      " lambda[43]      3.52     19.73      0.99      0.00      6.15    711.63      1.00\n",
      " lambda[44]      2.90      6.63      1.01      0.00      5.83    749.97      1.00\n",
      " lambda[45]      2.80     10.01      0.91      0.00      4.82    681.68      1.00\n",
      " lambda[46]      2.73     11.68      0.96      0.00      4.73    674.71      1.00\n",
      " lambda[47]      2.40      5.10      0.97      0.01      5.89    646.91      1.00\n",
      " lambda[48]      2.31      4.83      0.98      0.00      5.06    984.54      1.00\n",
      " lambda[49]      2.98      9.01      1.00      0.00      5.41    814.47      1.00\n",
      " lambda[50]      3.83     16.44      0.99      0.00      5.71    551.75      1.00\n",
      " lambda[51]      4.94     24.54      0.99      0.00      7.46    500.17      1.00\n",
      " lambda[52]      2.75      7.33      1.01      0.00      5.36    901.55      1.00\n",
      " lambda[53]      3.17     14.77      0.95      0.01      4.70    431.64      1.00\n",
      " lambda[54]      1.93      3.54      0.97      0.00      4.23    845.56      1.00\n",
      " lambda[55]      3.44     17.29      0.92      0.00      5.31    905.26      1.00\n",
      " lambda[56]      3.36     15.20      0.98      0.00      5.64    673.80      1.00\n",
      " lambda[57]      5.36     26.94      0.98      0.00      8.35    660.05      1.00\n",
      " lambda[58]      2.60      6.74      0.96      0.00      5.99    845.03      1.00\n",
      " lambda[59]      2.71      7.72      1.06      0.00      5.56    927.65      1.00\n",
      " lambda[60]      4.36     19.80      1.02      0.00      7.20    837.31      1.00\n",
      " lambda[61]      3.58     30.17      0.99      0.00      5.74    917.85      1.00\n",
      " lambda[62]   3833.10  36349.04    398.70      0.04   4039.26    559.71      1.00\n",
      " lambda[63]      2.71      7.96      0.94      0.00      5.47    614.95      1.00\n",
      " lambda[64]      2.98      6.89      1.05      0.00      6.37    701.90      1.00\n",
      " lambda[65]      2.91      9.57      0.98      0.00      4.99    635.37      1.00\n",
      " lambda[66]      2.63      6.15      0.92      0.00      5.58    726.86      1.00\n",
      " lambda[67]      3.00      8.19      1.00      0.00      5.89    753.43      1.00\n",
      " lambda[68]      2.68      5.74      1.01      0.00      5.55    941.50      1.00\n",
      " lambda[69]      3.67     11.96      0.94      0.00      6.84    675.57      1.00\n",
      " lambda[70]      3.36     17.85      1.01      0.02      5.12    573.95      1.00\n",
      " lambda[71]      3.22     12.25      1.01      0.00      5.80    506.53      1.00\n",
      " lambda[72]      2.36      6.53      0.98      0.00      4.68    834.21      1.00\n",
      " lambda[73]      3.47     22.01      1.04      0.00      5.88    928.85      1.00\n",
      " lambda[74]      2.80      6.72      0.95      0.01      6.14    734.43      1.00\n",
      " lambda[75]      5.17     41.48      1.03      0.00      7.24    613.49      1.00\n",
      " lambda[76]      3.13     11.44      0.97      0.00      5.64    698.38      1.00\n",
      " lambda[77]     12.40    126.21      0.94      0.00      7.31    489.74      1.00\n",
      " lambda[78]      3.16     10.52      0.95      0.01      5.72    382.62      1.00\n",
      " lambda[79]      2.82     17.75      0.93      0.00      4.85    938.81      1.00\n",
      " lambda[80]      4.20     42.88      0.98      0.00      6.19    825.05      1.00\n",
      " lambda[81]      2.62      6.18      0.96      0.00      5.53    847.56      1.00\n",
      " lambda[82]      2.29      5.53      0.94      0.00      4.66    834.50      1.00\n",
      " lambda[83]      3.11      8.72      0.98      0.00      5.58    712.21      1.00\n",
      " lambda[84]      3.76     20.18      0.99      0.00      5.55    681.80      1.00\n",
      " lambda[85]      2.75      9.25      0.96      0.00      5.29    765.46      1.00\n",
      " lambda[86]      3.21      8.57      0.97      0.00      5.81    637.40      1.00\n",
      " lambda[87]      5.21     44.93      1.00      0.00      6.71    743.77      1.00\n",
      " lambda[88]      2.55      5.09      0.92      0.01      5.78    756.40      1.00\n",
      " lambda[89]    549.52   8245.20      1.27      0.00    236.57    744.95      1.00\n",
      " lambda[90]      2.24      4.13      1.00      0.00      5.26    905.52      1.00\n",
      " lambda[91]      2.76      6.63      1.00      0.01      5.63    475.20      1.00\n",
      " lambda[92]      2.99      9.49      0.99      0.00      5.98    873.24      1.00\n",
      " lambda[93]      2.74      7.60      0.97      0.00      5.08    528.05      1.00\n",
      " lambda[94]      3.01      9.47      1.00      0.00      5.46    683.35      1.00\n",
      " lambda[95]      3.56     10.39      0.97      0.00      7.17    707.55      1.00\n",
      " lambda[96]      3.07     11.64      0.98      0.00      5.98    552.17      1.00\n",
      " lambda[97]      2.61      5.84      1.00      0.00      5.24    542.02      1.00\n",
      " lambda[98]     14.20    111.76      1.00      0.00      6.72    261.52      1.01\n",
      " lambda[99]      2.22      4.32      0.90      0.00      5.40    621.97      1.00\n",
      "lambda[100]      2.87      6.23      0.95      0.00      6.65    673.42      1.00\n",
      "lambda[101]      2.76      6.56      0.94      0.00      5.53    583.92      1.00\n",
      "lambda[102]      2.36      5.35      0.94      0.00      4.96    718.99      1.00\n",
      "lambda[103]      2.34      5.70      0.90      0.00      5.23    882.95      1.00\n",
      "lambda[104]      3.01     14.79      0.94      0.00      4.81    466.66      1.00\n",
      "lambda[105]      3.64      9.80      1.00      0.00      7.29    732.85      1.00\n",
      "lambda[106]      2.48     10.71      0.86      0.00      4.78    578.39      1.00\n",
      "lambda[107]      3.38     12.44      0.98      0.00      5.39    476.25      1.00\n",
      "lambda[108]      2.45      5.65      0.90      0.00      5.02    767.39      1.00\n",
      "lambda[109]     11.13    194.11      0.93      0.00      6.30    618.81      1.00\n",
      "lambda[110]      7.86    124.68      0.99      0.00      5.81    669.01      1.00\n",
      "lambda[111]      5.13     16.97      1.12      0.00     10.69    627.08      1.00\n",
      "lambda[112]      2.19      4.90      0.88      0.01      4.90    696.32      1.00\n",
      "lambda[113]      4.88     40.33      0.99      0.00      7.26    929.12      1.00\n",
      "lambda[114]      3.29     13.29      1.06      0.00      7.12    893.06      1.00\n",
      "lambda[115]      4.70     25.46      1.08      0.00      6.65    706.88      1.00\n",
      "lambda[116]      4.40     27.53      1.01      0.01      6.21    481.78      1.00\n",
      "lambda[117]      3.72     14.94      0.92      0.00      6.05    662.14      1.00\n",
      "lambda[118]      2.93     14.71      0.90      0.00      5.68    928.08      1.00\n",
      "lambda[119]      2.72      6.06      1.01      0.00      6.35    581.37      1.00\n",
      "lambda[120]      4.00     25.17      0.99      0.00      6.64    982.93      1.00\n",
      "lambda[121]      2.73      7.16      0.96      0.00      5.65    832.89      1.00\n",
      "lambda[122]      4.10     19.80      0.93      0.00      5.77    758.17      1.00\n",
      "lambda[123]      2.52      6.15      0.93      0.00      5.48    776.34      1.00\n",
      "lambda[124]      2.57      6.31      0.94      0.01      5.05    743.19      1.00\n",
      "lambda[125]      2.84      7.98      0.97      0.00      5.65    524.93      1.00\n",
      "lambda[126]      2.14      4.42      0.88      0.00      5.27   1003.04      1.00\n",
      "lambda[127]      3.43     13.98      0.97      0.00      5.38    827.04      1.00\n",
      "lambda[128]      3.01      9.70      0.97      0.00      5.38    449.61      1.00\n",
      "lambda[129]      3.19     13.83      0.91      0.01      5.17    839.16      1.00\n",
      "lambda[130]      3.46     11.90      0.97      0.00      6.03    629.42      1.00\n",
      "lambda[131]      4.16     29.88      0.98      0.00      5.59    810.89      1.00\n",
      "lambda[132]      3.15     11.05      1.00      0.00      5.47    685.92      1.00\n",
      "lambda[133]      2.71      7.90      0.98      0.00      5.75    792.30      1.00\n",
      "lambda[134]      2.89      7.29      0.99      0.00      5.71    753.83      1.00\n",
      "lambda[135]      2.34      4.76      0.93      0.00      5.25    768.47      1.01\n",
      "lambda[136]      2.88      8.68      0.82      0.00      6.03    643.81      1.00\n",
      "lambda[137]      2.53      8.56      0.94      0.00      5.14    881.71      1.00\n",
      "lambda[138]      2.85      9.29      0.91      0.00      5.55    625.12      1.00\n",
      "lambda[139]      2.43      5.15      0.95      0.00      5.41    638.97      1.00\n",
      "lambda[140]      3.28     13.79      0.93      0.00      6.60    579.22      1.00\n",
      "lambda[141]      2.82      5.71      1.00      0.00      6.57    744.04      1.00\n",
      "lambda[142]      4.31     16.78      1.01      0.00      6.95    602.02      1.00\n",
      "lambda[143]      2.21      5.79      0.95      0.00      4.70    938.48      1.00\n",
      "        msq      0.25      0.16      0.21      0.07      0.44    567.46      1.00\n",
      "      sigma      3.87      5.94      1.29      0.00     11.69   1083.15      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    558.71      1.00\n",
      "       xisq      1.09      0.56      0.95      0.42      1.81    678.16      1.00\n",
      "\n",
      "Number of divergences: 2\n",
      "\n",
      "MCMC elapsed time: 30.588924884796143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t8.59e-05 +- 1.05e-02\n",
      "[dimension 02/145]  inactive:\t1.30e-03 +- 2.42e-02\n",
      "[dimension 03/145]  inactive:\t5.26e-04 +- 1.37e-02\n",
      "[dimension 04/145]  inactive:\t3.56e-03 +- 3.48e-02\n",
      "[dimension 05/145]  inactive:\t3.26e-04 +- 1.25e-02\n",
      "[dimension 06/145]  inactive:\t2.88e-03 +- 3.41e-02\n",
      "[dimension 07/145]  inactive:\t1.44e-03 +- 1.56e-02\n",
      "[dimension 08/145]  inactive:\t1.63e-03 +- 2.08e-02\n",
      "[dimension 09/145]  inactive:\t9.29e-04 +- 1.63e-02\n",
      "[dimension 10/145]  inactive:\t7.22e-04 +- 1.31e-02\n",
      "[dimension 11/145]  inactive:\t8.76e-04 +- 1.91e-02\n",
      "[dimension 12/145]  inactive:\t1.11e-03 +- 2.18e-02\n",
      "[dimension 13/145]  inactive:\t3.37e-03 +- 3.08e-02\n",
      "[dimension 14/145]  inactive:\t7.60e-04 +- 2.10e-02\n",
      "[dimension 15/145]  inactive:\t1.41e-03 +- 2.44e-02\n",
      "[dimension 16/145]  inactive:\t7.38e-04 +- 1.43e-02\n",
      "[dimension 17/145]  inactive:\t2.68e-03 +- 3.56e-02\n",
      "[dimension 18/145]  inactive:\t8.53e-04 +- 1.68e-02\n",
      "[dimension 19/145]  inactive:\t-1.67e-04 +- 9.89e-03\n",
      "[dimension 20/145]  inactive:\t2.25e-04 +- 1.34e-02\n",
      "[dimension 21/145]  inactive:\t-2.28e-04 +- 1.20e-02\n",
      "[dimension 22/145]  inactive:\t3.60e-04 +- 1.25e-02\n",
      "[dimension 23/145]  inactive:\t2.24e-04 +- 1.28e-02\n",
      "[dimension 24/145]  inactive:\t1.00e-03 +- 1.75e-02\n",
      "[dimension 25/145]  inactive:\t2.39e-03 +- 1.82e-02\n",
      "[dimension 26/145]  inactive:\t4.84e-04 +- 1.71e-02\n",
      "[dimension 27/145]  inactive:\t9.89e-04 +- 1.62e-02\n",
      "[dimension 28/145]  inactive:\t7.13e-04 +- 1.17e-02\n",
      "[dimension 29/145]  inactive:\t1.98e-03 +- 3.07e-02\n",
      "[dimension 30/145]  inactive:\t2.79e-03 +- 2.91e-02\n",
      "[dimension 31/145]  inactive:\t3.85e-03 +- 4.05e-02\n",
      "[dimension 32/145]  inactive:\t9.21e-04 +- 2.08e-02\n",
      "[dimension 33/145]  inactive:\t4.60e-03 +- 4.57e-02\n",
      "[dimension 34/145]  inactive:\t6.16e-04 +- 1.18e-02\n",
      "[dimension 35/145]  inactive:\t1.34e-03 +- 2.01e-02\n",
      "[dimension 36/145]  inactive:\t1.05e-03 +- 1.61e-02\n",
      "[dimension 37/145]  inactive:\t3.10e-03 +- 2.28e-02\n",
      "[dimension 38/145]  inactive:\t1.04e-03 +- 2.74e-02\n",
      "[dimension 39/145]  inactive:\t3.69e-03 +- 3.85e-02\n",
      "[dimension 40/145]  inactive:\t4.70e-03 +- 3.64e-02\n",
      "[dimension 41/145]  inactive:\t1.79e-04 +- 1.38e-02\n",
      "[dimension 42/145]  inactive:\t1.71e-02 +- 1.03e-01\n",
      "[dimension 43/145]  inactive:\t5.86e-04 +- 1.33e-02\n",
      "[dimension 44/145]  inactive:\t1.23e-03 +- 2.50e-02\n",
      "[dimension 45/145]  inactive:\t5.30e-04 +- 1.53e-02\n",
      "[dimension 46/145]  inactive:\t4.32e-04 +- 9.28e-03\n",
      "[dimension 47/145]  inactive:\t7.25e-05 +- 1.76e-02\n",
      "[dimension 48/145]  inactive:\t7.27e-04 +- 1.42e-02\n",
      "[dimension 49/145]  inactive:\t7.04e-04 +- 1.17e-02\n",
      "[dimension 50/145]  inactive:\t1.19e-05 +- 1.48e-02\n",
      "[dimension 51/145]  inactive:\t2.08e-03 +- 2.65e-02\n",
      "[dimension 52/145]  inactive:\t4.16e-03 +- 2.13e-02\n",
      "[dimension 53/145]  inactive:\t-1.52e-04 +- 1.40e-02\n",
      "[dimension 54/145]  inactive:\t7.73e-04 +- 1.37e-02\n",
      "[dimension 55/145]  inactive:\t2.63e-04 +- 8.56e-03\n",
      "[dimension 56/145]  inactive:\t-7.59e-04 +- 1.63e-02\n",
      "[dimension 57/145]  inactive:\t2.36e-03 +- 2.88e-02\n",
      "[dimension 58/145]  inactive:\t6.85e-03 +- 4.80e-02\n",
      "[dimension 59/145]  inactive:\t-2.45e-04 +- 1.17e-02\n",
      "[dimension 60/145]  inactive:\t5.81e-04 +- 1.23e-02\n",
      "[dimension 61/145]  inactive:\t2.81e-03 +- 2.24e-02\n",
      "[dimension 62/145]  inactive:\t5.79e-06 +- 1.26e-02\n",
      "[dimension 63/145]  active:\t6.50e-01 +- 4.11e-01\n",
      "[dimension 64/145]  inactive:\t-6.94e-04 +- 1.32e-02\n",
      "[dimension 65/145]  inactive:\t5.60e-04 +- 1.76e-02\n",
      "[dimension 66/145]  inactive:\t7.04e-04 +- 1.64e-02\n",
      "[dimension 67/145]  inactive:\t8.64e-04 +- 1.56e-02\n",
      "[dimension 68/145]  inactive:\t3.98e-04 +- 2.01e-02\n",
      "[dimension 69/145]  inactive:\t1.40e-03 +- 1.86e-02\n",
      "[dimension 70/145]  inactive:\t3.37e-03 +- 2.21e-02\n",
      "[dimension 71/145]  inactive:\t1.57e-03 +- 2.33e-02\n",
      "[dimension 72/145]  inactive:\t1.25e-03 +- 1.86e-02\n",
      "[dimension 73/145]  inactive:\t2.67e-04 +- 1.10e-02\n",
      "[dimension 74/145]  inactive:\t1.31e-04 +- 1.41e-02\n",
      "[dimension 75/145]  inactive:\t1.21e-03 +- 1.69e-02\n",
      "[dimension 76/145]  inactive:\t5.54e-03 +- 4.43e-02\n",
      "[dimension 77/145]  inactive:\t6.67e-04 +- 2.39e-02\n",
      "[dimension 78/145]  inactive:\t8.37e-03 +- 6.73e-02\n",
      "[dimension 79/145]  inactive:\t3.00e-03 +- 2.21e-02\n",
      "[dimension 80/145]  inactive:\t1.10e-03 +- 2.07e-02\n",
      "[dimension 81/145]  inactive:\t1.72e-03 +- 2.21e-02\n",
      "[dimension 82/145]  inactive:\t4.25e-04 +- 1.12e-02\n",
      "[dimension 83/145]  inactive:\t-3.85e-04 +- 9.18e-03\n",
      "[dimension 84/145]  inactive:\t3.48e-04 +- 1.75e-02\n",
      "[dimension 85/145]  inactive:\t1.50e-03 +- 1.94e-02\n",
      "[dimension 86/145]  inactive:\t-5.95e-05 +- 1.13e-02\n",
      "[dimension 87/145]  inactive:\t2.10e-03 +- 2.78e-02\n",
      "[dimension 88/145]  inactive:\t2.80e-03 +- 2.27e-02\n",
      "[dimension 89/145]  inactive:\t-6.11e-05 +- 1.18e-02\n",
      "[dimension 90/145]  inactive:\t1.04e-01 +- 2.73e-01\n",
      "[dimension 91/145]  inactive:\t1.07e-04 +- 1.08e-02\n",
      "[dimension 92/145]  inactive:\t-9.20e-05 +- 1.52e-02\n",
      "[dimension 93/145]  inactive:\t1.04e-04 +- 1.48e-02\n",
      "[dimension 94/145]  inactive:\t1.18e-03 +- 1.75e-02\n",
      "[dimension 95/145]  inactive:\t5.95e-04 +- 1.79e-02\n",
      "[dimension 96/145]  inactive:\t6.39e-04 +- 1.91e-02\n",
      "[dimension 97/145]  inactive:\t1.71e-03 +- 1.63e-02\n",
      "[dimension 98/145]  inactive:\t3.15e-04 +- 1.33e-02\n",
      "[dimension 99/145]  inactive:\t8.59e-03 +- 6.85e-02\n",
      "[dimension 100/145]  inactive:\t2.12e-05 +- 9.86e-03\n",
      "[dimension 101/145]  inactive:\t-6.37e-04 +- 1.03e-02\n",
      "[dimension 102/145]  inactive:\t3.71e-04 +- 1.42e-02\n",
      "[dimension 103/145]  inactive:\t4.38e-04 +- 1.14e-02\n",
      "[dimension 104/145]  inactive:\t-1.46e-04 +- 9.56e-03\n",
      "[dimension 105/145]  inactive:\t6.03e-04 +- 1.57e-02\n",
      "[dimension 106/145]  inactive:\t3.43e-03 +- 2.42e-02\n",
      "[dimension 107/145]  inactive:\t-1.29e-04 +- 9.89e-03\n",
      "[dimension 108/145]  inactive:\t3.29e-03 +- 3.96e-02\n",
      "[dimension 109/145]  inactive:\t5.57e-05 +- 1.25e-02\n",
      "[dimension 110/145]  inactive:\t2.54e-03 +- 3.47e-02\n",
      "[dimension 111/145]  inactive:\t1.70e-03 +- 2.54e-02\n",
      "[dimension 112/145]  inactive:\t4.55e-03 +- 3.56e-02\n",
      "[dimension 113/145]  inactive:\t-3.44e-05 +- 9.92e-03\n",
      "[dimension 114/145]  inactive:\t2.68e-03 +- 3.84e-02\n",
      "[dimension 115/145]  inactive:\t1.16e-03 +- 1.40e-02\n",
      "[dimension 116/145]  inactive:\t1.55e-03 +- 2.59e-02\n",
      "[dimension 117/145]  inactive:\t4.50e-03 +- 4.66e-02\n",
      "[dimension 118/145]  inactive:\t1.77e-03 +- 1.64e-02\n",
      "[dimension 119/145]  inactive:\t1.80e-04 +- 1.57e-02\n",
      "[dimension 120/145]  inactive:\t8.16e-04 +- 2.00e-02\n",
      "[dimension 121/145]  inactive:\t2.78e-03 +- 2.85e-02\n",
      "[dimension 122/145]  inactive:\t3.82e-04 +- 2.09e-02\n",
      "[dimension 123/145]  inactive:\t2.29e-03 +- 3.09e-02\n",
      "[dimension 124/145]  inactive:\t-2.27e-04 +- 1.08e-02\n",
      "[dimension 125/145]  inactive:\t4.20e-05 +- 1.20e-02\n",
      "[dimension 126/145]  inactive:\t2.06e-04 +- 1.27e-02\n",
      "[dimension 127/145]  inactive:\t2.33e-04 +- 8.70e-03\n",
      "[dimension 128/145]  inactive:\t1.06e-03 +- 2.01e-02\n",
      "[dimension 129/145]  inactive:\t5.55e-04 +- 1.72e-02\n",
      "[dimension 130/145]  inactive:\t1.41e-03 +- 1.56e-02\n",
      "[dimension 131/145]  inactive:\t8.98e-04 +- 2.35e-02\n",
      "[dimension 132/145]  inactive:\t1.55e-03 +- 1.83e-02\n",
      "[dimension 133/145]  inactive:\t1.50e-03 +- 1.40e-02\n",
      "[dimension 134/145]  inactive:\t2.36e-04 +- 1.36e-02\n",
      "[dimension 135/145]  inactive:\t9.84e-04 +- 1.80e-02\n",
      "[dimension 136/145]  inactive:\t6.61e-04 +- 1.10e-02\n",
      "[dimension 137/145]  inactive:\t1.03e-03 +- 1.91e-02\n",
      "[dimension 138/145]  inactive:\t5.27e-04 +- 1.26e-02\n",
      "[dimension 139/145]  inactive:\t8.88e-04 +- 1.70e-02\n",
      "[dimension 140/145]  inactive:\t3.87e-04 +- 1.49e-02\n",
      "[dimension 141/145]  inactive:\t1.65e-03 +- 2.54e-02\n",
      "[dimension 142/145]  inactive:\t1.18e-03 +- 1.18e-02\n",
      "[dimension 143/145]  inactive:\t1.79e-03 +- 2.31e-02\n",
      "[dimension 144/145]  inactive:\t5.19e-04 +- 1.09e-02\n",
      "[dimension 145/145]  inactive:\t-4.95e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.9144479]\n",
      "cov_act[[0.01393717]]\n",
      "Active_dimensions: [62]\n",
      "68, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:32<00:00, 46.51it/s, 15 steps of size 2.09e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    469.58      1.00\n",
      "  lambda[0]      2.61      8.60      0.93      0.00      5.56    921.19      1.00\n",
      "  lambda[1]      4.37     28.39      1.00      0.00      6.30    504.78      1.00\n",
      "  lambda[2]      3.34      9.74      1.03      0.01      6.14    417.92      1.00\n",
      "  lambda[3]      3.50     11.84      1.03      0.00      6.37    743.30      1.00\n",
      "  lambda[4]      2.59      5.57      0.96      0.00      6.29    831.82      1.00\n",
      "  lambda[5]      3.77     22.08      0.98      0.00      6.17    986.96      1.00\n",
      "  lambda[6]      2.80      7.54      1.01      0.00      6.03   1020.47      1.00\n",
      "  lambda[7]      2.44      4.92      0.94      0.00      5.76    940.51      1.00\n",
      "  lambda[8]      2.58      5.83      0.97      0.00      6.09    761.53      1.00\n",
      "  lambda[9]      2.41      5.13      1.02      0.00      5.38    876.90      1.00\n",
      " lambda[10]      3.13      9.31      1.01      0.00      5.68    704.49      1.00\n",
      " lambda[11]      2.85      7.39      0.97      0.01      6.10    713.88      1.00\n",
      " lambda[12]      4.38     18.65      0.98      0.00      7.17    572.05      1.01\n",
      " lambda[13]      2.32      5.02      0.93      0.00      5.68    653.93      1.00\n",
      " lambda[14]      3.39      9.54      1.10      0.00      6.91    751.46      1.00\n",
      " lambda[15]      2.96      8.42      1.00      0.00      5.78    693.43      1.00\n",
      " lambda[16]      2.76      7.17      0.97      0.00      5.69    854.57      1.00\n",
      " lambda[17]      2.88      7.17      0.97      0.00      5.57    736.01      1.00\n",
      " lambda[18]      3.02      9.21      0.94      0.00      5.39    753.36      1.00\n",
      " lambda[19]      2.67      6.91      1.06      0.00      6.02    843.14      1.00\n",
      " lambda[20]      3.25      7.49      1.04      0.00      8.55    550.47      1.00\n",
      " lambda[21]      2.63      5.81      1.00      0.00      6.16    417.52      1.00\n",
      " lambda[22]      2.73      7.93      1.04      0.00      5.49    987.75      1.00\n",
      " lambda[23]      3.16     15.41      0.99      0.00      5.03    988.88      1.00\n",
      " lambda[24]      3.74     12.92      1.00      0.00      8.07    790.39      1.00\n",
      " lambda[25]      2.43      5.00      0.94      0.00      5.95    723.03      1.00\n",
      " lambda[26]      3.30     14.77      1.02      0.00      5.29    837.37      1.00\n",
      " lambda[27]      2.76      6.80      0.96      0.00      5.70    509.49      1.00\n",
      " lambda[28]      2.53      5.59      0.96      0.00      6.14    619.94      1.00\n",
      " lambda[29]      2.74      6.97      0.90      0.00      5.94    765.26      1.00\n",
      " lambda[30]      3.12      8.93      0.96      0.01      6.86    762.70      1.00\n",
      " lambda[31]      2.94      9.40      0.98      0.00      5.43   1043.59      1.00\n",
      " lambda[32]      2.84      9.04      0.99      0.00      5.45    838.93      1.00\n",
      " lambda[33]      2.53      5.85      0.96      0.00      5.09    844.65      1.00\n",
      " lambda[34]      2.75      6.49      0.96      0.00      5.82    668.15      1.00\n",
      " lambda[35]      2.94      8.22      1.02      0.00      5.80    885.75      1.00\n",
      " lambda[36]      3.13      8.79      1.05      0.00      7.15    575.91      1.00\n",
      " lambda[37]      2.94      7.36      1.03      0.01      6.27    727.57      1.00\n",
      " lambda[38]      5.96     95.45      0.99      0.01      5.80    939.32      1.00\n",
      " lambda[39]      3.24     11.91      0.98      0.00      6.88    890.00      1.00\n",
      " lambda[40]      3.58     11.51      0.97      0.00      7.12    734.53      1.00\n",
      " lambda[41]      4.36     16.67      0.94      0.00      6.65    592.18      1.00\n",
      " lambda[42]      2.09      4.05      0.88      0.00      4.88    785.06      1.00\n",
      " lambda[43]      3.62     23.35      0.99      0.00      5.80    499.79      1.00\n",
      " lambda[44]      2.78      7.22      0.95      0.01      5.91    878.50      1.00\n",
      " lambda[45]      2.63      8.63      0.96      0.00      5.25    900.69      1.00\n",
      " lambda[46]      2.72      9.68      0.91      0.00      4.48    865.95      1.00\n",
      " lambda[47]      2.27      4.57      1.02      0.00      5.07    857.07      1.00\n",
      " lambda[48]      3.42      9.61      1.05      0.01      7.36    484.97      1.00\n",
      " lambda[49]      3.02      8.24      1.02      0.00      5.75    685.76      1.00\n",
      " lambda[50]      3.19     13.57      0.94      0.00      5.69    746.07      1.00\n",
      " lambda[51]      3.79     11.82      1.00      0.00      7.51    648.88      1.00\n",
      " lambda[52]      2.88     12.20      0.97      0.00      4.49    940.36      1.00\n",
      " lambda[53]      2.94      8.61      0.97      0.00      5.46    621.02      1.00\n",
      " lambda[54]      2.35      5.59      0.92      0.00      5.00   1004.43      1.00\n",
      " lambda[55]      2.75     10.45      0.92      0.00      5.39    938.25      1.00\n",
      " lambda[56]      2.45      7.60      0.93      0.00      4.60    988.43      1.00\n",
      " lambda[57]      4.83     18.04      1.07      0.01      7.89    864.15      1.00\n",
      " lambda[58]      2.44      6.66      0.90      0.00      5.31    787.01      1.00\n",
      " lambda[59]      2.86      7.53      0.97      0.00      5.70    734.29      1.00\n",
      " lambda[60]      2.89     10.47      0.97      0.00      5.31    863.84      1.00\n",
      " lambda[61]      2.35      6.31      0.98      0.00      5.24    966.50      1.00\n",
      " lambda[62]   1589.22  23590.00    209.82      0.02   1486.21    880.81      1.00\n",
      " lambda[63]      3.13     14.47      0.93      0.00      5.14    859.17      1.00\n",
      " lambda[64]      2.53      5.80      0.99      0.00      5.30    716.60      1.00\n",
      " lambda[65]      2.84     11.08      0.99      0.00      5.47    952.19      1.00\n",
      " lambda[66]      3.04      7.93      1.00      0.00      5.72    706.22      1.00\n",
      " lambda[67]      3.15      9.49      1.05      0.00      5.88    733.79      1.00\n",
      " lambda[68]      3.19      8.88      1.03      0.00      6.39    763.74      1.00\n",
      " lambda[69]      4.08     17.20      1.01      0.00      6.82    663.91      1.00\n",
      " lambda[70]      3.04      9.87      0.99      0.00      5.14    514.60      1.00\n",
      " lambda[71]      2.96      7.90      1.01      0.00      5.62    497.86      1.00\n",
      " lambda[72]      2.47      5.82      0.99      0.00      4.99    682.32      1.00\n",
      " lambda[73]      3.53     17.72      1.02      0.00      6.10    916.97      1.00\n",
      " lambda[74]      2.52      5.30      1.00      0.00      5.60    882.28      1.00\n",
      " lambda[75]      4.47     17.22      1.08      0.00      6.79    679.04      1.00\n",
      " lambda[76]      2.63      5.12      1.01      0.00      6.21    795.14      1.00\n",
      " lambda[77]      3.13     10.14      0.98      0.00      5.36    860.44      1.00\n",
      " lambda[78]      3.14      8.91      1.08      0.00      5.58    684.63      1.00\n",
      " lambda[79]      2.76      8.35      0.93      0.00      4.74    733.25      1.00\n",
      " lambda[80]      3.06      8.76      0.93      0.00      5.84    539.94      1.00\n",
      " lambda[81]      2.64      5.11      1.00      0.00      5.93    809.68      1.00\n",
      " lambda[82]      2.56      7.57      0.96      0.00      4.41    883.26      1.00\n",
      " lambda[83]      3.46      9.61      1.09      0.00      6.31    573.60      1.00\n",
      " lambda[84]      3.85     19.93      1.00      0.00      6.44    918.61      1.00\n",
      " lambda[85]      2.65      9.10      0.93      0.00      5.08    617.12      1.00\n",
      " lambda[86]      3.38     11.96      0.98      0.00      6.01    803.46      1.00\n",
      " lambda[87]      2.53      5.98      0.93      0.00      5.21    970.52      1.00\n",
      " lambda[88]      2.47      4.88      1.00      0.00      5.52    606.12      1.00\n",
      " lambda[89]    158.62   1732.65      1.26      0.00     95.56    213.41      1.00\n",
      " lambda[90]      2.13      4.77      0.90      0.01      4.55    739.35      1.00\n",
      " lambda[91]      2.88      8.56      1.03      0.00      5.94    460.63      1.00\n",
      " lambda[92]      3.39     10.60      1.00      0.00      7.42    525.78      1.00\n",
      " lambda[93]      2.64      8.80      0.94      0.00      5.06    524.27      1.00\n",
      " lambda[94]      3.53     11.38      1.01      0.01      6.10    701.26      1.00\n",
      " lambda[95]      3.26     11.03      1.00      0.00      6.68    785.26      1.00\n",
      " lambda[96]      2.81      7.34      0.97      0.00      5.95    779.21      1.00\n",
      " lambda[97]      2.60      6.14      0.97      0.01      5.39    840.66      1.00\n",
      " lambda[98]      3.53     22.74      1.03      0.00      5.64    968.25      1.00\n",
      " lambda[99]      2.68      7.08      0.92      0.00      5.47    841.14      1.00\n",
      "lambda[100]      3.12      8.63      0.96      0.00      6.85    510.68      1.00\n",
      "lambda[101]      3.69     13.25      1.01      0.01      5.96    489.96      1.00\n",
      "lambda[102]      2.48      6.05      0.91      0.00      4.88    740.78      1.00\n",
      "lambda[103]      2.46      6.90      0.90      0.00      5.48    815.37      1.00\n",
      "lambda[104]      4.54     44.99      0.96      0.00      5.08    516.73      1.00\n",
      "lambda[105]      3.11      9.75      1.03      0.00      6.11    631.38      1.00\n",
      "lambda[106]      3.31     12.91      0.92      0.00      5.81    548.37      1.00\n",
      "lambda[107]      2.99      8.94      0.99      0.01      5.71    490.41      1.00\n",
      "lambda[108]      2.39      5.58      0.93      0.00      5.47    829.14      1.00\n",
      "lambda[109]      3.67     11.66      0.99      0.00      6.10    601.74      1.00\n",
      "lambda[110]      3.38     12.01      1.07      0.00      5.27    762.41      1.00\n",
      "lambda[111]      3.77     12.10      1.06      0.00      7.16    778.98      1.00\n",
      "lambda[112]      2.22      4.83      0.97      0.01      4.69    558.84      1.00\n",
      "lambda[113]      3.37      9.58      0.97      0.00      6.34    683.21      1.00\n",
      "lambda[114]      3.07     18.46      0.96      0.00      5.39    981.67      1.00\n",
      "lambda[115]      3.06     10.25      0.98      0.00      6.15    890.09      1.00\n",
      "lambda[116]      2.85     11.21      0.99      0.01      5.80    950.54      1.00\n",
      "lambda[117]      2.94     10.03      0.90      0.00      5.47    823.72      1.00\n",
      "lambda[118]      2.51      6.53      0.90      0.00      4.98    597.08      1.00\n",
      "lambda[119]      3.00      8.53      0.95      0.00      6.16    741.45      1.00\n",
      "lambda[120]      3.49     12.09      0.97      0.00      6.75    811.01      1.00\n",
      "lambda[121]      3.95     30.57      0.98      0.00      6.00    980.07      1.00\n",
      "lambda[122]      3.41     16.53      0.95      0.00      5.46    473.16      1.00\n",
      "lambda[123]      3.01      7.02      0.93      0.00      7.37    829.24      1.01\n",
      "lambda[124]      2.99     10.00      0.96      0.00      5.05    590.90      1.00\n",
      "lambda[125]      2.76      9.13      1.01      0.00      5.70    664.62      1.00\n",
      "lambda[126]      2.11      5.03      0.94      0.00      4.84    913.25      1.00\n",
      "lambda[127]      2.84      7.55      0.98      0.00      5.66    883.82      1.00\n",
      "lambda[128]      2.80      6.41      1.02      0.00      5.77    850.89      1.00\n",
      "lambda[129]      3.46     22.18      0.91      0.00      5.54    886.79      1.00\n",
      "lambda[130]      3.10     12.14      0.95      0.00      5.93    741.61      1.01\n",
      "lambda[131]      6.82     69.24      1.00      0.00      5.34    423.10      1.00\n",
      "lambda[132]      2.78      6.90      1.00      0.00      5.52    952.34      1.00\n",
      "lambda[133]      2.73      7.44      0.97      0.00      5.51    669.26      1.00\n",
      "lambda[134]      3.37      9.58      0.95      0.00      7.20    749.36      1.00\n",
      "lambda[135]      2.50      6.59      0.93      0.00      5.10    872.52      1.00\n",
      "lambda[136]      3.19     11.11      0.90      0.00      5.41    501.89      1.00\n",
      "lambda[137]      2.87      9.05      1.02      0.00      5.80    802.18      1.00\n",
      "lambda[138]      2.78      7.46      0.96      0.00      6.21    573.07      1.00\n",
      "lambda[139]      2.68      6.47      0.92      0.00      5.63    753.34      1.00\n",
      "lambda[140]      2.70      6.02      0.96      0.00      6.18    697.15      1.00\n",
      "lambda[141]      3.03      9.69      0.91      0.00      6.07    711.07      1.00\n",
      "lambda[142]      3.52     12.37      0.97      0.00      5.92    679.23      1.00\n",
      "lambda[143]      2.34      6.83      0.96      0.00      4.52    889.09      1.00\n",
      "        msq   3418.61  41157.18     21.72      0.16    819.08    833.57      1.00\n",
      "      sigma      5.26      7.57      1.93      0.01     15.30   1007.05      1.00\n",
      "    var_obs      0.09      0.02      0.09      0.06      0.11    802.17      1.00\n",
      "       xisq    156.12    921.89     15.05      0.70    193.64    660.75      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 36.41272783279419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.47e-04 +- 1.72e-02\n",
      "[dimension 02/145]  inactive:\t-6.58e-05 +- 2.67e-02\n",
      "[dimension 03/145]  inactive:\t-1.88e-05 +- 2.41e-02\n",
      "[dimension 04/145]  inactive:\t5.27e-03 +- 3.81e-02\n",
      "[dimension 05/145]  inactive:\t-4.15e-04 +- 2.33e-02\n",
      "[dimension 06/145]  inactive:\t2.46e-03 +- 4.10e-02\n",
      "[dimension 07/145]  inactive:\t4.92e-04 +- 1.77e-02\n",
      "[dimension 08/145]  inactive:\t3.65e-04 +- 2.22e-02\n",
      "[dimension 09/145]  inactive:\t2.03e-04 +- 2.08e-02\n",
      "[dimension 10/145]  inactive:\t1.62e-04 +- 1.62e-02\n",
      "[dimension 11/145]  inactive:\t-1.00e-03 +- 2.41e-02\n",
      "[dimension 12/145]  inactive:\t-4.39e-04 +- 2.63e-02\n",
      "[dimension 13/145]  inactive:\t4.43e-03 +- 3.79e-02\n",
      "[dimension 14/145]  inactive:\t-1.18e-03 +- 1.95e-02\n",
      "[dimension 15/145]  inactive:\t2.73e-04 +- 2.83e-02\n",
      "[dimension 16/145]  inactive:\t8.68e-04 +- 1.95e-02\n",
      "[dimension 17/145]  inactive:\t-4.69e-06 +- 2.69e-02\n",
      "[dimension 18/145]  inactive:\t-4.82e-04 +- 2.54e-02\n",
      "[dimension 19/145]  inactive:\t-1.79e-03 +- 1.88e-02\n",
      "[dimension 20/145]  inactive:\t-1.16e-03 +- 2.63e-02\n",
      "[dimension 21/145]  inactive:\t-1.54e-03 +- 2.38e-02\n",
      "[dimension 22/145]  inactive:\t-1.29e-04 +- 1.95e-02\n",
      "[dimension 23/145]  inactive:\t-6.32e-04 +- 2.22e-02\n",
      "[dimension 24/145]  inactive:\t1.09e-03 +- 2.23e-02\n",
      "[dimension 25/145]  inactive:\t3.52e-03 +- 2.36e-02\n",
      "[dimension 26/145]  inactive:\t-8.03e-04 +- 2.67e-02\n",
      "[dimension 27/145]  inactive:\t5.93e-04 +- 2.43e-02\n",
      "[dimension 28/145]  inactive:\t9.45e-04 +- 1.82e-02\n",
      "[dimension 29/145]  inactive:\t-4.75e-04 +- 2.45e-02\n",
      "[dimension 30/145]  inactive:\t1.06e-03 +- 2.40e-02\n",
      "[dimension 31/145]  inactive:\t4.02e-03 +- 3.23e-02\n",
      "[dimension 32/145]  inactive:\t-1.32e-03 +- 2.50e-02\n",
      "[dimension 33/145]  inactive:\t2.84e-03 +- 4.02e-02\n",
      "[dimension 34/145]  inactive:\t7.04e-04 +- 1.72e-02\n",
      "[dimension 35/145]  inactive:\t3.79e-04 +- 2.06e-02\n",
      "[dimension 36/145]  inactive:\t8.32e-04 +- 2.40e-02\n",
      "[dimension 37/145]  inactive:\t4.09e-03 +- 2.60e-02\n",
      "[dimension 38/145]  inactive:\t-1.71e-03 +- 2.95e-02\n",
      "[dimension 39/145]  inactive:\t1.14e-03 +- 3.22e-02\n",
      "[dimension 40/145]  inactive:\t2.90e-03 +- 2.56e-02\n",
      "[dimension 41/145]  inactive:\t-1.83e-03 +- 2.90e-02\n",
      "[dimension 42/145]  inactive:\t4.40e-03 +- 4.32e-02\n",
      "[dimension 43/145]  inactive:\t-3.08e-04 +- 1.68e-02\n",
      "[dimension 44/145]  inactive:\t-7.15e-04 +- 2.68e-02\n",
      "[dimension 45/145]  inactive:\t-6.22e-04 +- 2.29e-02\n",
      "[dimension 46/145]  inactive:\t8.96e-04 +- 1.37e-02\n",
      "[dimension 47/145]  inactive:\t-1.88e-03 +- 3.11e-02\n",
      "[dimension 48/145]  inactive:\t8.61e-04 +- 1.87e-02\n",
      "[dimension 49/145]  inactive:\t3.16e-03 +- 2.49e-02\n",
      "[dimension 50/145]  inactive:\t-1.60e-03 +- 2.57e-02\n",
      "[dimension 51/145]  inactive:\t2.39e-03 +- 2.87e-02\n",
      "[dimension 52/145]  inactive:\t5.50e-03 +- 2.47e-02\n",
      "[dimension 53/145]  inactive:\t-1.03e-03 +- 2.27e-02\n",
      "[dimension 54/145]  inactive:\t-8.54e-05 +- 2.07e-02\n",
      "[dimension 55/145]  inactive:\t5.10e-04 +- 1.59e-02\n",
      "[dimension 56/145]  inactive:\t-1.72e-03 +- 1.78e-02\n",
      "[dimension 57/145]  inactive:\t8.99e-04 +- 2.51e-02\n",
      "[dimension 58/145]  inactive:\t9.86e-03 +- 6.05e-02\n",
      "[dimension 59/145]  inactive:\t-8.16e-04 +- 1.76e-02\n",
      "[dimension 60/145]  inactive:\t5.57e-04 +- 2.39e-02\n",
      "[dimension 61/145]  inactive:\t1.72e-03 +- 2.10e-02\n",
      "[dimension 62/145]  inactive:\t-5.43e-04 +- 1.99e-02\n",
      "[dimension 63/145]  active:\t7.71e-01 +- 3.78e-01\n",
      "[dimension 64/145]  inactive:\t-2.32e-03 +- 2.38e-02\n",
      "[dimension 65/145]  inactive:\t-5.98e-04 +- 2.13e-02\n",
      "[dimension 66/145]  inactive:\t2.30e-04 +- 2.12e-02\n",
      "[dimension 67/145]  inactive:\t1.65e-03 +- 2.60e-02\n",
      "[dimension 68/145]  inactive:\t-1.23e-03 +- 2.94e-02\n",
      "[dimension 69/145]  inactive:\t3.17e-03 +- 3.83e-02\n",
      "[dimension 70/145]  inactive:\t3.89e-03 +- 2.45e-02\n",
      "[dimension 71/145]  inactive:\t2.22e-04 +- 2.69e-02\n",
      "[dimension 72/145]  inactive:\t1.80e-04 +- 2.08e-02\n",
      "[dimension 73/145]  inactive:\t2.54e-04 +- 1.55e-02\n",
      "[dimension 74/145]  inactive:\t-1.99e-03 +- 2.59e-02\n",
      "[dimension 75/145]  inactive:\t4.47e-05 +- 1.84e-02\n",
      "[dimension 76/145]  inactive:\t5.51e-03 +- 3.81e-02\n",
      "[dimension 77/145]  inactive:\t-1.76e-03 +- 2.96e-02\n",
      "[dimension 78/145]  inactive:\t2.75e-03 +- 3.49e-02\n",
      "[dimension 79/145]  inactive:\t5.79e-03 +- 3.37e-02\n",
      "[dimension 80/145]  inactive:\t-8.31e-04 +- 2.99e-02\n",
      "[dimension 81/145]  inactive:\t-4.97e-05 +- 2.81e-02\n",
      "[dimension 82/145]  inactive:\t3.53e-04 +- 1.73e-02\n",
      "[dimension 83/145]  inactive:\t-1.61e-03 +- 1.83e-02\n",
      "[dimension 84/145]  inactive:\t-2.20e-03 +- 2.85e-02\n",
      "[dimension 85/145]  inactive:\t2.98e-03 +- 3.06e-02\n",
      "[dimension 86/145]  inactive:\t-3.90e-04 +- 1.70e-02\n",
      "[dimension 87/145]  inactive:\t1.16e-03 +- 3.39e-02\n",
      "[dimension 88/145]  inactive:\t2.11e-03 +- 2.12e-02\n",
      "[dimension 89/145]  inactive:\t-7.83e-04 +- 1.84e-02\n",
      "[dimension 90/145]  inactive:\t1.10e-01 +- 2.94e-01\n",
      "[dimension 91/145]  inactive:\t-8.79e-05 +- 1.57e-02\n",
      "[dimension 92/145]  inactive:\t-1.40e-03 +- 2.13e-02\n",
      "[dimension 93/145]  inactive:\t-5.51e-04 +- 2.43e-02\n",
      "[dimension 94/145]  inactive:\t1.17e-03 +- 1.99e-02\n",
      "[dimension 95/145]  inactive:\t-6.02e-04 +- 2.46e-02\n",
      "[dimension 96/145]  inactive:\t2.26e-04 +- 3.47e-02\n",
      "[dimension 97/145]  inactive:\t2.30e-03 +- 2.16e-02\n",
      "[dimension 98/145]  inactive:\t-1.16e-04 +- 2.49e-02\n",
      "[dimension 99/145]  inactive:\t1.52e-03 +- 3.03e-02\n",
      "[dimension 100/145]  inactive:\t-6.17e-04 +- 1.63e-02\n",
      "[dimension 101/145]  inactive:\t-2.40e-03 +- 2.02e-02\n",
      "[dimension 102/145]  inactive:\t-1.06e-03 +- 2.77e-02\n",
      "[dimension 103/145]  inactive:\t7.45e-04 +- 2.12e-02\n",
      "[dimension 104/145]  inactive:\t-9.43e-04 +- 1.61e-02\n",
      "[dimension 105/145]  inactive:\t-8.45e-04 +- 2.26e-02\n",
      "[dimension 106/145]  inactive:\t3.35e-03 +- 2.54e-02\n",
      "[dimension 107/145]  inactive:\t-1.45e-03 +- 1.89e-02\n",
      "[dimension 108/145]  inactive:\t3.03e-03 +- 4.61e-02\n",
      "[dimension 109/145]  inactive:\t-2.06e-04 +- 1.49e-02\n",
      "[dimension 110/145]  inactive:\t-1.32e-03 +- 2.66e-02\n",
      "[dimension 111/145]  inactive:\t2.29e-03 +- 3.57e-02\n",
      "[dimension 112/145]  inactive:\t5.48e-03 +- 4.57e-02\n",
      "[dimension 113/145]  inactive:\t-1.01e-03 +- 1.70e-02\n",
      "[dimension 114/145]  inactive:\t-5.56e-05 +- 2.75e-02\n",
      "[dimension 115/145]  inactive:\t1.62e-03 +- 1.91e-02\n",
      "[dimension 116/145]  inactive:\t7.95e-06 +- 2.86e-02\n",
      "[dimension 117/145]  inactive:\t2.06e-03 +- 3.17e-02\n",
      "[dimension 118/145]  inactive:\t2.36e-03 +- 2.10e-02\n",
      "[dimension 119/145]  inactive:\t-1.77e-03 +- 2.49e-02\n",
      "[dimension 120/145]  inactive:\t-4.82e-04 +- 3.06e-02\n",
      "[dimension 121/145]  inactive:\t3.60e-03 +- 3.21e-02\n",
      "[dimension 122/145]  inactive:\t-2.46e-03 +- 2.93e-02\n",
      "[dimension 123/145]  inactive:\t1.63e-03 +- 3.32e-02\n",
      "[dimension 124/145]  inactive:\t-1.89e-03 +- 2.04e-02\n",
      "[dimension 125/145]  inactive:\t-1.36e-03 +- 2.30e-02\n",
      "[dimension 126/145]  inactive:\t-9.06e-04 +- 2.03e-02\n",
      "[dimension 127/145]  inactive:\t9.36e-05 +- 1.48e-02\n",
      "[dimension 128/145]  inactive:\t-6.49e-04 +- 2.78e-02\n",
      "[dimension 129/145]  inactive:\t-2.69e-04 +- 2.21e-02\n",
      "[dimension 130/145]  inactive:\t3.26e-03 +- 2.76e-02\n",
      "[dimension 131/145]  inactive:\t-1.12e-03 +- 2.41e-02\n",
      "[dimension 132/145]  inactive:\t4.42e-03 +- 4.59e-02\n",
      "[dimension 133/145]  inactive:\t1.99e-03 +- 1.88e-02\n",
      "[dimension 134/145]  inactive:\t-8.26e-04 +- 2.30e-02\n",
      "[dimension 135/145]  inactive:\t-9.04e-05 +- 2.46e-02\n",
      "[dimension 136/145]  inactive:\t7.10e-04 +- 1.65e-02\n",
      "[dimension 137/145]  inactive:\t-5.87e-04 +- 2.72e-02\n",
      "[dimension 138/145]  inactive:\t1.43e-04 +- 2.12e-02\n",
      "[dimension 139/145]  inactive:\t1.45e-04 +- 2.22e-02\n",
      "[dimension 140/145]  inactive:\t-8.78e-04 +- 2.69e-02\n",
      "[dimension 141/145]  inactive:\t6.67e-04 +- 1.94e-02\n",
      "[dimension 142/145]  inactive:\t1.30e-03 +- 1.76e-02\n",
      "[dimension 143/145]  inactive:\t6.54e-04 +- 2.69e-02\n",
      "[dimension 144/145]  inactive:\t1.44e-04 +- 1.90e-02\n",
      "[dimension 145/145]  inactive:\t1.97e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.0371208e-05]\n",
      "cov_act[[1.3113022e-06]]\n",
      "Active_dimensions: [62]\n",
      "69, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:26<00:00, 56.62it/s, 15 steps of size 2.08e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    349.14      1.00\n",
      "  lambda[0]      2.98     16.49      0.96      0.00      4.94    947.87      1.00\n",
      "  lambda[1]      3.22     16.75      0.87      0.00      5.68    470.24      1.00\n",
      "  lambda[2]      2.92      6.88      1.03      0.01      6.07    450.08      1.00\n",
      "  lambda[3]      3.42     11.24      1.05      0.00      6.38    859.56      1.00\n",
      "  lambda[4]      2.52      5.56      0.97      0.00      5.36    934.85      1.00\n",
      "  lambda[5]      3.37     15.11      1.00      0.00      5.84    565.59      1.00\n",
      "  lambda[6]      4.06     11.87      1.06      0.00      8.85    782.80      1.00\n",
      "  lambda[7]      2.77      6.75      0.92      0.00      5.98    905.81      1.00\n",
      "  lambda[8]      3.32      9.35      0.97      0.00      6.54    474.91      1.00\n",
      "  lambda[9]      2.69      6.88      1.03      0.00      5.02    757.88      1.00\n",
      " lambda[10]      3.31      9.91      1.07      0.00      6.32    621.08      1.00\n",
      " lambda[11]      2.94      8.47      0.96      0.01      5.74    818.75      1.00\n",
      " lambda[12]      5.28     25.15      0.98      0.00      6.35    539.57      1.00\n",
      " lambda[13]      2.61      6.97      0.93      0.00      5.25    716.94      1.00\n",
      " lambda[14]      3.61     11.87      1.02      0.00      6.55    795.11      1.00\n",
      " lambda[15]      3.88     11.99      1.11      0.00      7.49    665.45      1.00\n",
      " lambda[16]      2.58      5.79      0.99      0.00      5.26   1011.85      1.00\n",
      " lambda[17]      2.71      7.95      0.92      0.00      5.12    842.89      1.00\n",
      " lambda[18]      2.95      9.56      0.94      0.00      5.60    788.01      1.00\n",
      " lambda[19]      2.76      6.80      1.03      0.00      5.58    795.83      1.00\n",
      " lambda[20]      2.98      8.96      1.00      0.00      6.72    714.33      1.00\n",
      " lambda[21]      2.62      6.57      1.00      0.00      5.87    490.55      1.00\n",
      " lambda[22]      2.49      5.39      1.03      0.01      5.24    908.26      1.00\n",
      " lambda[23]      3.77     26.20      1.04      0.00      5.66    911.55      1.00\n",
      " lambda[24]      3.07      9.71      0.99      0.00      6.69    554.93      1.00\n",
      " lambda[25]      2.35      6.10      0.91      0.00      5.00    676.57      1.00\n",
      " lambda[26]      3.12     13.73      0.99      0.00      5.03    828.64      1.00\n",
      " lambda[27]      2.51      5.83      0.88      0.00      5.67    882.04      1.00\n",
      " lambda[28]      2.51      5.26      0.97      0.01      6.20    700.60      1.00\n",
      " lambda[29]      3.03     15.96      0.97      0.00      5.27    957.23      1.00\n",
      " lambda[30]      2.54      5.95      0.96      0.00      5.79    894.04      1.00\n",
      " lambda[31]      2.96     10.96      0.96      0.00      5.08    984.18      1.00\n",
      " lambda[32]      2.96      8.61      1.05      0.00      6.28    915.27      1.00\n",
      " lambda[33]      2.93      7.96      0.98      0.00      5.41    542.74      1.00\n",
      " lambda[34]      3.72     26.68      1.03      0.00      5.22    519.35      1.00\n",
      " lambda[35]      2.64      6.44      0.96      0.00      5.63    867.69      1.00\n",
      " lambda[36]      3.14     12.37      0.99      0.00      5.75    677.19      1.00\n",
      " lambda[37]      3.20     10.22      1.02      0.01      6.22    902.98      1.00\n",
      " lambda[38]      5.56     58.43      0.97      0.00      6.01    861.05      1.00\n",
      " lambda[39]      4.18     31.93      1.00      0.00      6.59    936.42      1.00\n",
      " lambda[40]      3.70     16.07      0.96      0.00      6.67    677.71      1.00\n",
      " lambda[41]      4.18     18.15      0.92      0.00      7.00    755.46      1.00\n",
      " lambda[42]      2.40      5.85      0.94      0.00      5.09    817.04      1.00\n",
      " lambda[43]      3.80     26.69      0.98      0.00      6.15    603.96      1.00\n",
      " lambda[44]      3.03      8.81      0.98      0.01      6.38    748.55      1.00\n",
      " lambda[45]      2.42      6.41      0.95      0.00      4.88    922.06      1.00\n",
      " lambda[46]      2.61     10.06      0.95      0.00      4.78    708.77      1.00\n",
      " lambda[47]      2.45      4.78      1.03      0.01      5.33    694.51      1.00\n",
      " lambda[48]      2.13      3.54      0.94      0.00      5.12    985.00      1.00\n",
      " lambda[49]      3.18      9.35      1.02      0.00      6.20    759.99      1.00\n",
      " lambda[50]      3.22     13.81      0.90      0.01      6.28    874.24      1.00\n",
      " lambda[51]      3.39      8.97      1.02      0.01      7.32    867.87      1.00\n",
      " lambda[52]      2.89      9.94      0.94      0.00      4.95    410.20      1.00\n",
      " lambda[53]      2.93      7.89      0.94      0.00      5.54    818.80      1.00\n",
      " lambda[54]      2.20      4.76      0.93      0.00      4.25    878.87      1.00\n",
      " lambda[55]      2.63     12.50      0.93      0.00      5.00   1034.58      1.00\n",
      " lambda[56]      2.58      6.95      0.95      0.00      5.15    966.05      1.00\n",
      " lambda[57]      2.88      6.74      1.02      0.01      6.34    670.62      1.00\n",
      " lambda[58]      2.50      5.33      0.95      0.01      5.28    576.66      1.00\n",
      " lambda[59]      3.46     23.00      1.00      0.00      5.66    952.07      1.00\n",
      " lambda[60]      3.42     11.94      1.07      0.00      6.23    810.74      1.00\n",
      " lambda[61]      2.28      4.40      1.01      0.00      5.16   1038.58      1.00\n",
      " lambda[62]  12753.19 135231.19    939.77      0.01  10954.38    643.67      1.00\n",
      " lambda[63]      3.04     12.39      0.94      0.00      5.08    898.44      1.00\n",
      " lambda[64]      3.11     14.41      0.98      0.00      5.57    944.58      1.00\n",
      " lambda[65]      3.03      9.32      0.97      0.00      5.58    702.02      1.00\n",
      " lambda[66]      2.46      5.77      0.91      0.00      5.47    688.22      1.00\n",
      " lambda[67]      2.80      8.04      1.03      0.00      5.74    995.71      1.00\n",
      " lambda[68]      3.58     16.50      0.96      0.00      6.04    463.15      1.00\n",
      " lambda[69]      4.67     31.55      1.01      0.00      7.21    791.87      1.00\n",
      " lambda[70]      2.42      5.26      0.96      0.00      4.89    621.97      1.00\n",
      " lambda[71]      2.72      7.08      1.02      0.01      5.55    380.90      1.00\n",
      " lambda[72]      2.35      6.71      0.97      0.00      4.32    783.68      1.00\n",
      " lambda[73]      3.49     17.32      1.02      0.00      6.19    799.47      1.00\n",
      " lambda[74]      2.68      7.14      0.97      0.01      5.72    846.89      1.00\n",
      " lambda[75]      3.96     13.43      1.06      0.00      6.96    611.66      1.00\n",
      " lambda[76]      3.04      7.40      1.08      0.00      6.89    623.47      1.00\n",
      " lambda[77]    107.12   1117.42      1.05      0.00      9.44    197.28      1.01\n",
      " lambda[78]      2.45      5.69      1.05      0.01      4.78    657.08      1.00\n",
      " lambda[79]      2.76     10.80      0.88      0.00      4.64    705.82      1.00\n",
      " lambda[80]      3.01     10.32      1.00      0.00      5.44    668.46      1.00\n",
      " lambda[81]      2.82      6.91      0.96      0.00      6.23    687.24      1.00\n",
      " lambda[82]      2.53      6.32      0.92      0.00      5.15    618.50      1.00\n",
      " lambda[83]      2.99      7.94      1.03      0.00      6.01    610.24      1.00\n",
      " lambda[84]      3.73     27.10      1.01      0.00      5.41    721.86      1.00\n",
      " lambda[85]      2.62      6.08      0.95      0.00      5.72    654.92      1.00\n",
      " lambda[86]      3.94     26.08      0.96      0.00      6.10    974.05      1.00\n",
      " lambda[87]      3.09     13.58      0.95      0.00      5.75    797.07      1.00\n",
      " lambda[88]      2.53      5.45      0.98      0.00      5.68    748.49      1.00\n",
      " lambda[89]    387.62   3317.69      1.17      0.00    123.80    134.63      1.01\n",
      " lambda[90]      2.24      5.01      0.96      0.00      4.90   1068.06      1.00\n",
      " lambda[91]      2.88      9.72      1.02      0.00      5.12    517.25      1.00\n",
      " lambda[92]      3.28     14.33      1.04      0.00      6.87    587.43      1.00\n",
      " lambda[93]      2.79      9.65      0.98      0.00      5.01    656.58      1.00\n",
      " lambda[94]      3.45     10.78      1.04      0.01      6.55    751.63      1.00\n",
      " lambda[95]      2.96      9.01      0.93      0.00      5.41    910.14      1.00\n",
      " lambda[96]      2.88      6.91      1.02      0.00      5.83    576.94      1.00\n",
      " lambda[97]      2.48      5.46      0.99      0.00      5.45    915.80      1.00\n",
      " lambda[98]      3.29     16.97      0.97      0.00      5.56    907.57      1.00\n",
      " lambda[99]      2.28      5.38      0.88      0.00      5.04    526.69      1.00\n",
      "lambda[100]      2.94      8.57      0.97      0.00      6.13    845.93      1.00\n",
      "lambda[101]      2.99      8.07      0.99      0.00      5.68    563.99      1.00\n",
      "lambda[102]      2.49      6.12      0.95      0.00      5.02    782.40      1.00\n",
      "lambda[103]      2.91     13.65      0.95      0.00      5.99    943.76      1.00\n",
      "lambda[104]      2.46      6.75      0.98      0.00      4.86    769.07      1.00\n",
      "lambda[105]      3.01     10.32      0.93      0.00      5.88    680.97      1.00\n",
      "lambda[106]      3.10     11.44      0.98      0.00      5.44    378.03      1.00\n",
      "lambda[107]      2.43      5.34      0.98      0.01      4.90    728.45      1.00\n",
      "lambda[108]      3.11     13.48      0.93      0.00      5.28    667.69      1.00\n",
      "lambda[109]      4.00     13.88      0.96      0.00      6.50    856.70      1.00\n",
      "lambda[110]      3.08      8.56      1.01      0.00      5.97    757.22      1.00\n",
      "lambda[111]      3.91      9.90      1.02      0.00      8.08    485.76      1.00\n",
      "lambda[112]      2.05      3.80      0.92      0.01      4.72    784.60      1.00\n",
      "lambda[113]     15.21    353.15      1.01      0.00      7.09    909.87      1.00\n",
      "lambda[114]      3.38     11.70      1.01      0.00      6.21    476.70      1.00\n",
      "lambda[115]      3.66     20.36      0.97      0.00      5.97    721.32      1.00\n",
      "lambda[116]      3.23     18.84      0.97      0.01      5.21    598.04      1.00\n",
      "lambda[117]      3.12     10.09      0.92      0.00      5.80    766.91      1.00\n",
      "lambda[118]      3.08      9.24      0.97      0.00      6.08    497.55      1.00\n",
      "lambda[119]      2.63      6.41      0.96      0.00      5.76    976.99      1.00\n",
      "lambda[120]      3.11      9.44      1.00      0.00      5.83    746.08      1.00\n",
      "lambda[121]      3.16     10.98      1.06      0.00      5.85    806.84      1.00\n",
      "lambda[122]      2.89      9.50      0.94      0.00      5.18    866.88      1.00\n",
      "lambda[123]      2.66      6.11      0.92      0.00      5.78    835.35      1.00\n",
      "lambda[124]      3.05     11.37      0.93      0.00      5.50    724.95      1.00\n",
      "lambda[125]      2.87      9.39      0.97      0.00      5.82    599.82      1.00\n",
      "lambda[126]      2.52      7.88      0.98      0.00      5.08    946.65      1.00\n",
      "lambda[127]      3.04      9.39      0.97      0.00      5.68    843.58      1.00\n",
      "lambda[128]      2.38      4.72      0.94      0.00      5.73    716.60      1.00\n",
      "lambda[129]      3.51     15.03      0.94      0.00      5.97    720.71      1.00\n",
      "lambda[130]      3.00     10.21      1.00      0.00      6.49    880.77      1.00\n",
      "lambda[131]      3.65     18.42      0.99      0.00      5.88    534.10      1.00\n",
      "lambda[132]      2.67      6.05      0.99      0.00      5.54    926.69      1.00\n",
      "lambda[133]      2.33      5.15      0.96      0.00      5.15    862.64      1.00\n",
      "lambda[134]      3.09      7.80      0.95      0.00      6.42    554.83      1.00\n",
      "lambda[135]      2.13      4.50      0.89      0.00      4.17    804.46      1.00\n",
      "lambda[136]      2.74      7.45      0.92      0.00      5.75    639.42      1.01\n",
      "lambda[137]      2.97      8.78      1.02      0.00      5.46    690.36      1.00\n",
      "lambda[138]      2.66      6.89      0.98      0.00      5.69    638.98      1.00\n",
      "lambda[139]      2.97      9.59      0.95      0.00      5.52    560.22      1.00\n",
      "lambda[140]      5.96     57.40      1.02      0.00      6.02    392.61      1.00\n",
      "lambda[141]      3.16      9.62      0.99      0.00      6.01    744.80      1.00\n",
      "lambda[142]      3.82     14.06      1.00      0.00      5.75    645.62      1.00\n",
      "lambda[143]      2.39      5.54      0.98      0.00      4.90    676.87      1.00\n",
      "        msq      0.28      0.18      0.24      0.07      0.47    465.06      1.00\n",
      "      sigma      4.25      7.30      1.11      0.00     12.44   1037.48      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    200.71      1.00\n",
      "       xisq     16.28     51.77      5.79      0.82     26.24    371.33      1.01\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 31.103347778320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.24e-04 +- 6.68e-03\n",
      "[dimension 02/145]  inactive:\t4.01e-04 +- 1.11e-02\n",
      "[dimension 03/145]  inactive:\t1.71e-04 +- 7.96e-03\n",
      "[dimension 04/145]  inactive:\t9.66e-04 +- 1.28e-02\n",
      "[dimension 05/145]  inactive:\t6.54e-05 +- 6.24e-03\n",
      "[dimension 06/145]  inactive:\t9.49e-04 +- 2.03e-02\n",
      "[dimension 07/145]  inactive:\t5.27e-04 +- 8.98e-03\n",
      "[dimension 08/145]  inactive:\t6.97e-04 +- 1.36e-02\n",
      "[dimension 09/145]  inactive:\t6.09e-04 +- 1.23e-02\n",
      "[dimension 10/145]  inactive:\t3.98e-04 +- 8.48e-03\n",
      "[dimension 11/145]  inactive:\t9.61e-05 +- 7.33e-03\n",
      "[dimension 12/145]  inactive:\t7.88e-04 +- 2.03e-02\n",
      "[dimension 13/145]  inactive:\t2.24e-03 +- 2.72e-02\n",
      "[dimension 14/145]  inactive:\t2.04e-04 +- 8.44e-03\n",
      "[dimension 15/145]  inactive:\t1.32e-03 +- 2.26e-02\n",
      "[dimension 16/145]  inactive:\t3.09e-04 +- 9.84e-03\n",
      "[dimension 17/145]  inactive:\t3.68e-04 +- 1.08e-02\n",
      "[dimension 18/145]  inactive:\t7.83e-04 +- 1.62e-02\n",
      "[dimension 19/145]  inactive:\t-1.77e-05 +- 6.90e-03\n",
      "[dimension 20/145]  inactive:\t2.57e-04 +- 1.00e-02\n",
      "[dimension 21/145]  inactive:\t-5.55e-05 +- 6.93e-03\n",
      "[dimension 22/145]  inactive:\t1.75e-04 +- 7.46e-03\n",
      "[dimension 23/145]  inactive:\t1.13e-04 +- 6.94e-03\n",
      "[dimension 24/145]  inactive:\t9.51e-04 +- 1.64e-02\n",
      "[dimension 25/145]  inactive:\t6.55e-04 +- 9.07e-03\n",
      "[dimension 26/145]  inactive:\t2.49e-04 +- 1.03e-02\n",
      "[dimension 27/145]  inactive:\t3.84e-04 +- 9.97e-03\n",
      "[dimension 28/145]  inactive:\t3.56e-04 +- 7.61e-03\n",
      "[dimension 29/145]  inactive:\t6.69e-04 +- 1.50e-02\n",
      "[dimension 30/145]  inactive:\t3.68e-04 +- 9.22e-03\n",
      "[dimension 31/145]  inactive:\t4.25e-04 +- 7.55e-03\n",
      "[dimension 32/145]  inactive:\t1.10e-04 +- 8.26e-03\n",
      "[dimension 33/145]  inactive:\t1.01e-03 +- 1.73e-02\n",
      "[dimension 34/145]  inactive:\t3.81e-04 +- 8.98e-03\n",
      "[dimension 35/145]  inactive:\t5.48e-04 +- 1.19e-02\n",
      "[dimension 36/145]  inactive:\t2.28e-04 +- 7.17e-03\n",
      "[dimension 37/145]  inactive:\t9.41e-04 +- 1.02e-02\n",
      "[dimension 38/145]  inactive:\t2.32e-04 +- 1.46e-02\n",
      "[dimension 39/145]  inactive:\t2.14e-03 +- 3.03e-02\n",
      "[dimension 40/145]  inactive:\t1.46e-03 +- 2.23e-02\n",
      "[dimension 41/145]  inactive:\t7.69e-05 +- 1.17e-02\n",
      "[dimension 42/145]  inactive:\t1.28e-03 +- 1.59e-02\n",
      "[dimension 43/145]  inactive:\t2.35e-04 +- 7.03e-03\n",
      "[dimension 44/145]  inactive:\t6.47e-04 +- 1.57e-02\n",
      "[dimension 45/145]  inactive:\t2.47e-04 +- 1.03e-02\n",
      "[dimension 46/145]  inactive:\t1.70e-04 +- 5.76e-03\n",
      "[dimension 47/145]  inactive:\t-7.13e-05 +- 1.08e-02\n",
      "[dimension 48/145]  inactive:\t1.52e-04 +- 7.67e-03\n",
      "[dimension 49/145]  inactive:\t1.90e-04 +- 5.33e-03\n",
      "[dimension 50/145]  inactive:\t1.12e-04 +- 1.25e-02\n",
      "[dimension 51/145]  inactive:\t3.71e-04 +- 9.75e-03\n",
      "[dimension 52/145]  inactive:\t1.71e-03 +- 1.35e-02\n",
      "[dimension 53/145]  inactive:\t2.15e-04 +- 1.31e-02\n",
      "[dimension 54/145]  inactive:\t1.88e-04 +- 7.64e-03\n",
      "[dimension 55/145]  inactive:\t1.81e-04 +- 6.74e-03\n",
      "[dimension 56/145]  inactive:\t-1.50e-04 +- 6.77e-03\n",
      "[dimension 57/145]  inactive:\t9.33e-04 +- 2.08e-02\n",
      "[dimension 58/145]  inactive:\t8.42e-04 +- 1.19e-02\n",
      "[dimension 59/145]  inactive:\t-1.95e-04 +- 8.35e-03\n",
      "[dimension 60/145]  inactive:\t5.77e-04 +- 1.66e-02\n",
      "[dimension 61/145]  inactive:\t8.07e-04 +- 1.12e-02\n",
      "[dimension 62/145]  inactive:\t3.51e-06 +- 6.27e-03\n",
      "[dimension 63/145]  active:\t7.66e-01 +- 3.67e-01\n",
      "[dimension 64/145]  inactive:\t-1.02e-04 +- 6.31e-03\n",
      "[dimension 65/145]  inactive:\t1.03e-04 +- 9.07e-03\n",
      "[dimension 66/145]  inactive:\t3.39e-04 +- 1.10e-02\n",
      "[dimension 67/145]  inactive:\t2.14e-04 +- 7.67e-03\n",
      "[dimension 68/145]  inactive:\t1.04e-04 +- 1.06e-02\n",
      "[dimension 69/145]  inactive:\t3.05e-03 +- 3.68e-02\n",
      "[dimension 70/145]  inactive:\t1.37e-03 +- 1.27e-02\n",
      "[dimension 71/145]  inactive:\t1.68e-04 +- 7.79e-03\n",
      "[dimension 72/145]  inactive:\t4.78e-04 +- 1.18e-02\n",
      "[dimension 73/145]  inactive:\t1.65e-04 +- 6.46e-03\n",
      "[dimension 74/145]  inactive:\t1.42e-04 +- 1.22e-02\n",
      "[dimension 75/145]  inactive:\t4.77e-04 +- 1.12e-02\n",
      "[dimension 76/145]  inactive:\t1.48e-03 +- 1.53e-02\n",
      "[dimension 77/145]  inactive:\t1.10e-04 +- 1.14e-02\n",
      "[dimension 78/145]  inactive:\t3.37e-02 +- 1.58e-01\n",
      "[dimension 79/145]  inactive:\t1.35e-03 +- 1.50e-02\n",
      "[dimension 80/145]  inactive:\t2.60e-04 +- 9.90e-03\n",
      "[dimension 81/145]  inactive:\t6.13e-04 +- 1.11e-02\n",
      "[dimension 82/145]  inactive:\t2.69e-04 +- 8.12e-03\n",
      "[dimension 83/145]  inactive:\t-2.11e-04 +- 6.39e-03\n",
      "[dimension 84/145]  inactive:\t4.79e-05 +- 9.93e-03\n",
      "[dimension 85/145]  inactive:\t1.15e-03 +- 1.80e-02\n",
      "[dimension 86/145]  inactive:\t-1.29e-04 +- 6.82e-03\n",
      "[dimension 87/145]  inactive:\t6.71e-04 +- 1.51e-02\n",
      "[dimension 88/145]  inactive:\t8.43e-04 +- 1.19e-02\n",
      "[dimension 89/145]  inactive:\t-8.24e-05 +- 6.39e-03\n",
      "[dimension 90/145]  inactive:\t9.08e-02 +- 2.67e-01\n",
      "[dimension 91/145]  inactive:\t9.03e-05 +- 6.52e-03\n",
      "[dimension 92/145]  inactive:\t1.18e-05 +- 7.96e-03\n",
      "[dimension 93/145]  inactive:\t1.75e-04 +- 1.07e-02\n",
      "[dimension 94/145]  inactive:\t2.92e-04 +- 8.17e-03\n",
      "[dimension 95/145]  inactive:\t3.26e-04 +- 1.36e-02\n",
      "[dimension 96/145]  inactive:\t9.85e-05 +- 8.22e-03\n",
      "[dimension 97/145]  inactive:\t8.16e-04 +- 1.08e-02\n",
      "[dimension 98/145]  inactive:\t1.33e-05 +- 8.24e-03\n",
      "[dimension 99/145]  inactive:\t4.28e-04 +- 9.53e-03\n",
      "[dimension 100/145]  inactive:\t-4.81e-06 +- 5.60e-03\n",
      "[dimension 101/145]  inactive:\t-4.86e-04 +- 8.08e-03\n",
      "[dimension 102/145]  inactive:\t3.56e-05 +- 7.72e-03\n",
      "[dimension 103/145]  inactive:\t2.06e-04 +- 7.50e-03\n",
      "[dimension 104/145]  inactive:\t-1.31e-04 +- 5.97e-03\n",
      "[dimension 105/145]  inactive:\t1.24e-04 +- 6.88e-03\n",
      "[dimension 106/145]  inactive:\t8.97e-04 +- 1.20e-02\n",
      "[dimension 107/145]  inactive:\t-1.01e-04 +- 6.77e-03\n",
      "[dimension 108/145]  inactive:\t1.39e-04 +- 6.87e-03\n",
      "[dimension 109/145]  inactive:\t1.60e-04 +- 7.35e-03\n",
      "[dimension 110/145]  inactive:\t4.27e-04 +- 1.28e-02\n",
      "[dimension 111/145]  inactive:\t5.96e-04 +- 1.39e-02\n",
      "[dimension 112/145]  inactive:\t1.75e-03 +- 2.16e-02\n",
      "[dimension 113/145]  inactive:\t4.21e-06 +- 5.62e-03\n",
      "[dimension 114/145]  inactive:\t2.75e-03 +- 4.59e-02\n",
      "[dimension 115/145]  inactive:\t6.81e-04 +- 9.57e-03\n",
      "[dimension 116/145]  inactive:\t5.44e-04 +- 1.41e-02\n",
      "[dimension 117/145]  inactive:\t6.51e-04 +- 1.44e-02\n",
      "[dimension 118/145]  inactive:\t8.48e-04 +- 1.12e-02\n",
      "[dimension 119/145]  inactive:\t7.24e-04 +- 1.79e-02\n",
      "[dimension 120/145]  inactive:\t1.42e-04 +- 1.15e-02\n",
      "[dimension 121/145]  inactive:\t1.10e-03 +- 1.63e-02\n",
      "[dimension 122/145]  inactive:\t5.16e-05 +- 1.03e-02\n",
      "[dimension 123/145]  inactive:\t4.81e-04 +- 1.16e-02\n",
      "[dimension 124/145]  inactive:\t-6.56e-05 +- 6.65e-03\n",
      "[dimension 125/145]  inactive:\t-1.33e-05 +- 7.32e-03\n",
      "[dimension 126/145]  inactive:\t7.36e-05 +- 7.63e-03\n",
      "[dimension 127/145]  inactive:\t1.98e-04 +- 6.29e-03\n",
      "[dimension 128/145]  inactive:\t3.76e-04 +- 1.22e-02\n",
      "[dimension 129/145]  inactive:\t8.25e-05 +- 7.75e-03\n",
      "[dimension 130/145]  inactive:\t1.05e-03 +- 1.33e-02\n",
      "[dimension 131/145]  inactive:\t6.57e-04 +- 1.86e-02\n",
      "[dimension 132/145]  inactive:\t2.69e-04 +- 6.85e-03\n",
      "[dimension 133/145]  inactive:\t5.06e-04 +- 7.82e-03\n",
      "[dimension 134/145]  inactive:\t1.39e-04 +- 9.00e-03\n",
      "[dimension 135/145]  inactive:\t2.31e-04 +- 1.03e-02\n",
      "[dimension 136/145]  inactive:\t2.30e-04 +- 5.73e-03\n",
      "[dimension 137/145]  inactive:\t3.26e-04 +- 9.53e-03\n",
      "[dimension 138/145]  inactive:\t5.41e-04 +- 1.23e-02\n",
      "[dimension 139/145]  inactive:\t3.20e-04 +- 1.03e-02\n",
      "[dimension 140/145]  inactive:\t2.60e-04 +- 1.15e-02\n",
      "[dimension 141/145]  inactive:\t3.18e-03 +- 4.21e-02\n",
      "[dimension 142/145]  inactive:\t8.63e-04 +- 1.06e-02\n",
      "[dimension 143/145]  inactive:\t6.77e-04 +- 1.39e-02\n",
      "[dimension 144/145]  inactive:\t3.10e-04 +- 9.22e-03\n",
      "[dimension 145/145]  inactive:\t3.31e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[8.538365e-06]\n",
      "cov_act[[1.244247e-06]]\n",
      "Active_dimensions: [62]\n",
      "70, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:32<00:00, 46.49it/s, 31 steps of size 1.65e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    380.46      1.00\n",
      "  lambda[0]      2.42      5.63      0.95      0.00      5.45    627.78      1.00\n",
      "  lambda[1]      3.11     10.48      1.02      0.00      5.93    635.16      1.01\n",
      "  lambda[2]      2.97      8.32      0.98      0.00      5.68    604.83      1.00\n",
      "  lambda[3]      3.54     13.01      1.00      0.00      6.83    599.58      1.01\n",
      "  lambda[4]      2.58      5.91      0.95      0.00      5.13    796.52      1.00\n",
      "  lambda[5]      2.86      9.51      0.96      0.00      5.60    683.45      1.00\n",
      "  lambda[6]      3.57     11.30      0.98      0.00      6.42    605.33      1.00\n",
      "  lambda[7]      2.84      7.49      1.02      0.00      5.80    717.31      1.00\n",
      "  lambda[8]      2.34      4.32      0.99      0.00      5.30    872.16      1.00\n",
      "  lambda[9]      2.40      8.13      0.98      0.00      4.42    773.11      1.00\n",
      " lambda[10]      3.62     12.41      1.04      0.00      6.93    918.59      1.00\n",
      " lambda[11]      2.74      7.06      1.01      0.01      5.59    778.30      1.00\n",
      " lambda[12]      3.71      9.56      1.05      0.00      6.81    380.65      1.01\n",
      " lambda[13]      2.59      6.18      0.89      0.00      5.53    750.29      1.00\n",
      " lambda[14]      3.39     18.82      0.96      0.00      4.98    713.60      1.00\n",
      " lambda[15]      2.65      7.66      1.02      0.00      4.80    672.41      1.00\n",
      " lambda[16]      3.65     10.65      0.94      0.00      7.51    690.17      1.00\n",
      " lambda[17]      2.68      7.34      0.97      0.00      5.51    691.68      1.00\n",
      " lambda[18]      3.15      8.14      0.94      0.00      6.70    473.54      1.00\n",
      " lambda[19]      2.93      8.02      0.99      0.00      6.03    656.21      1.00\n",
      " lambda[20]      2.76      5.66      1.00      0.01      6.12    655.08      1.00\n",
      " lambda[21]      3.12     10.30      0.98      0.00      6.23    870.40      1.00\n",
      " lambda[22]      2.57      5.54      0.98      0.00      5.45    595.20      1.00\n",
      " lambda[23]      3.00      9.98      0.97      0.00      5.69    686.63      1.00\n",
      " lambda[24]      3.07     10.24      1.02      0.00      5.87    775.09      1.00\n",
      " lambda[25]      3.11      7.82      0.99      0.01      6.10    375.14      1.01\n",
      " lambda[26]      2.88      9.64      1.02      0.00      5.23    465.88      1.00\n",
      " lambda[27]      3.06      8.19      0.99      0.00      6.20    608.36      1.00\n",
      " lambda[28]      2.73      7.10      0.99      0.00      5.45    707.91      1.00\n",
      " lambda[29]      2.58      6.91      0.93      0.00      5.23    567.38      1.00\n",
      " lambda[30]      4.03     18.33      1.04      0.01      6.88    717.86      1.00\n",
      " lambda[31]      3.68     15.25      0.97      0.00      6.47    664.19      1.00\n",
      " lambda[32]      2.82      7.20      0.93      0.00      6.46    424.05      1.00\n",
      " lambda[33]      2.97     10.70      0.97      0.00      5.19    852.37      1.00\n",
      " lambda[34]      3.01     13.25      0.96      0.00      5.36    651.88      1.00\n",
      " lambda[35]      2.45      5.67      1.05      0.00      5.06    846.67      1.00\n",
      " lambda[36]      4.04     17.14      0.98      0.00      7.16    646.73      1.00\n",
      " lambda[37]      2.99      7.80      1.00      0.00      5.78    595.05      1.00\n",
      " lambda[38]      3.28      8.76      0.96      0.00      5.98    731.69      1.01\n",
      " lambda[39]      3.60     13.66      0.97      0.00      5.79    531.69      1.00\n",
      " lambda[40]      4.30     19.78      0.95      0.00      6.31    569.21      1.00\n",
      " lambda[41]      6.05     34.61      0.98      0.00      7.22    524.80      1.01\n",
      " lambda[42]      2.76     11.75      0.98      0.00      4.97    930.86      1.00\n",
      " lambda[43]      3.81     29.00      0.99      0.00      5.52    935.33      1.00\n",
      " lambda[44]      2.75      6.12      1.00      0.01      5.28    582.40      1.00\n",
      " lambda[45]      2.73      7.52      0.92      0.00      4.98    856.23      1.00\n",
      " lambda[46]      2.93      8.47      1.00      0.00      5.61    808.41      1.00\n",
      " lambda[47]      2.56      5.55      0.93      0.01      5.87    555.39      1.00\n",
      " lambda[48]      2.65      7.43      1.01      0.01      5.28    847.26      1.00\n",
      " lambda[49]      2.66      6.98      0.92      0.00      5.27    676.44      1.00\n",
      " lambda[50]      3.20     10.76      0.99      0.00      5.13    586.63      1.00\n",
      " lambda[51]      3.66     12.50      1.08      0.00      6.87    682.69      1.00\n",
      " lambda[52]      3.24     20.10      0.90      0.00      5.71    869.33      1.00\n",
      " lambda[53]      3.18     10.63      0.99      0.00      5.95    920.08      1.00\n",
      " lambda[54]      2.05      3.92      0.96      0.00      4.47    498.99      1.00\n",
      " lambda[55]      3.18     12.97      1.04      0.00      5.82    802.46      1.00\n",
      " lambda[56]      2.59      5.45      0.95      0.00      5.62    754.58      1.00\n",
      " lambda[57]      4.45     32.08      1.00      0.00      6.56    992.39      1.00\n",
      " lambda[58]      2.27      4.87      0.97      0.00      5.04    580.32      1.00\n",
      " lambda[59]      3.15      7.75      0.94      0.00      6.67    399.81      1.00\n",
      " lambda[60]      3.08     15.66      0.95      0.00      4.95    979.46      1.00\n",
      " lambda[61]      2.69      6.21      1.01      0.00      5.85    718.30      1.00\n",
      " lambda[62]   1555.40  16700.49    213.89      0.03   1370.97    921.99      1.00\n",
      " lambda[63]      2.55      5.83      1.03      0.00      6.10    688.74      1.00\n",
      " lambda[64]      2.96      9.04      1.01      0.01      4.99    543.24      1.01\n",
      " lambda[65]      3.36     10.40      0.96      0.00      6.22    639.64      1.00\n",
      " lambda[66]      3.02      6.66      1.00      0.00      7.10    749.64      1.00\n",
      " lambda[67]      2.70      6.36      0.93      0.00      5.88    764.38      1.00\n",
      " lambda[68]      4.05     35.05      0.95      0.00      5.71    721.45      1.00\n",
      " lambda[69]      3.60     15.20      0.94      0.00      5.94    937.88      1.00\n",
      " lambda[70]      2.42      5.41      0.96      0.00      4.95    646.74      1.00\n",
      " lambda[71]      2.37      6.93      0.97      0.00      4.44    534.99      1.00\n",
      " lambda[72]      2.63      6.82      0.97      0.01      5.22    717.70      1.00\n",
      " lambda[73]      2.89      9.37      1.06      0.00      5.18    664.79      1.00\n",
      " lambda[74]      2.35      4.23      1.03      0.01      5.50    722.74      1.00\n",
      " lambda[75]      4.22     18.31      0.97      0.00      7.33    711.17      1.00\n",
      " lambda[76]      3.22      9.57      0.99      0.00      6.31    750.72      1.00\n",
      " lambda[77]      2.73      6.38      1.05      0.00      5.77    709.22      1.00\n",
      " lambda[78]      3.08      8.21      1.09      0.01      6.35    965.27      1.00\n",
      " lambda[79]      3.29      9.82      1.01      0.00      6.59    578.61      1.00\n",
      " lambda[80]      4.28     23.33      1.02      0.00      6.39    742.06      1.00\n",
      " lambda[81]      2.35      5.12      0.90      0.00      5.27   1088.34      1.00\n",
      " lambda[82]      2.96     11.14      0.94      0.00      4.68    702.66      1.00\n",
      " lambda[83]      3.32     11.13      1.00      0.00      5.97    695.91      1.00\n",
      " lambda[84]      3.80     20.25      0.97      0.00      6.28    802.51      1.00\n",
      " lambda[85]      2.67      7.47      0.95      0.00      6.31    864.27      1.00\n",
      " lambda[86]      3.24      9.78      1.01      0.00      5.60    681.50      1.00\n",
      " lambda[87]      3.75     27.02      1.02      0.01      5.84    795.42      1.00\n",
      " lambda[88]      2.57      5.22      0.94      0.00      6.04    775.81      1.00\n",
      " lambda[89]     68.55    430.11      1.31      0.00    120.50    329.27      1.00\n",
      " lambda[90]      2.90      8.06      0.96      0.00      5.80    590.36      1.00\n",
      " lambda[91]      2.41      6.13      0.93      0.01      4.69    740.25      1.00\n",
      " lambda[92]      3.41     17.75      1.00      0.00      5.22    489.02      1.00\n",
      " lambda[93]      2.82      8.39      1.03      0.00      4.85    489.75      1.00\n",
      " lambda[94]      2.66      7.95      0.93      0.00      5.30    668.44      1.00\n",
      " lambda[95]      3.01      9.77      0.98      0.00      5.98    845.03      1.00\n",
      " lambda[96]      2.32      4.70      0.93      0.00      4.96    905.76      1.00\n",
      " lambda[97]      3.45     12.86      1.05      0.00      6.16    625.68      1.00\n",
      " lambda[98]      5.18     49.37      1.02      0.00      5.78    525.83      1.00\n",
      " lambda[99]      2.42      7.52      0.97      0.00      4.62    857.91      1.00\n",
      "lambda[100]      2.62      7.73      0.89      0.00      5.47    609.29      1.00\n",
      "lambda[101]      2.84      8.56      0.94      0.00      5.70    723.09      1.00\n",
      "lambda[102]      2.65      6.93      0.89      0.00      5.30    742.14      1.00\n",
      "lambda[103]      2.28      4.37      0.96      0.00      4.86    692.27      1.00\n",
      "lambda[104]      3.08     10.95      0.95      0.00      6.33    463.74      1.00\n",
      "lambda[105]      3.37      9.17      1.00      0.00      6.95    618.20      1.00\n",
      "lambda[106]      2.49      5.07      1.04      0.01      5.41    706.63      1.00\n",
      "lambda[107]      4.18     17.78      0.98      0.00      5.84    570.48      1.00\n",
      "lambda[108]      2.43      5.99      0.98      0.00      5.10    636.35      1.00\n",
      "lambda[109]      4.43     24.74      0.96      0.00      7.14    908.25      1.00\n",
      "lambda[110]      3.48      9.56      0.94      0.00      6.76    639.94      1.00\n",
      "lambda[111]      4.62     21.35      0.91      0.00      5.68    460.00      1.00\n",
      "lambda[112]      3.00      9.98      0.96      0.00      6.05    963.80      1.00\n",
      "lambda[113]      2.88      7.24      1.04      0.00      5.72    735.55      1.00\n",
      "lambda[114]      3.31      9.99      0.96      0.00      6.35    786.69      1.00\n",
      "lambda[115]      3.56     14.48      0.96      0.00      6.39    913.20      1.00\n",
      "lambda[116]      3.07     10.36      0.97      0.00      5.40    633.71      1.00\n",
      "lambda[117]      3.63     12.98      1.00      0.00      6.10    776.49      1.00\n",
      "lambda[118]      3.16     10.20      0.94      0.00      6.11    899.74      1.00\n",
      "lambda[119]      3.04     16.03      0.98      0.00      5.61    932.88      1.00\n",
      "lambda[120]      3.84     15.31      0.95      0.00      6.81    924.55      1.00\n",
      "lambda[121]      3.10     11.22      0.97      0.00      5.76    817.82      1.00\n",
      "lambda[122]      2.94      7.15      1.01      0.00      5.99    814.21      1.00\n",
      "lambda[123]      2.62      7.65      0.96      0.00      5.04    628.70      1.00\n",
      "lambda[124]      2.78      5.99      1.01      0.00      6.40    701.80      1.00\n",
      "lambda[125]      3.32     11.34      0.91      0.00      6.17    470.98      1.00\n",
      "lambda[126]      2.42      5.66      0.92      0.00      5.23    722.61      1.00\n",
      "lambda[127]      4.12     15.83      1.00      0.00      7.56    759.62      1.00\n",
      "lambda[128]      3.19     13.72      0.99      0.00      5.02    471.31      1.00\n",
      "lambda[129]      3.61     16.30      0.98      0.00      6.54    901.71      1.00\n",
      "lambda[130]      3.00      6.94      0.95      0.00      6.32    508.13      1.01\n",
      "lambda[131]      2.92      7.13      0.96      0.01      5.96    788.10      1.00\n",
      "lambda[132]      3.34     10.07      0.94      0.00      6.69    625.37      1.00\n",
      "lambda[133]      2.45      4.77      0.94      0.00      5.57    772.66      1.00\n",
      "lambda[134]      3.40      9.19      0.88      0.00      7.44    639.40      1.00\n",
      "lambda[135]      3.11     13.54      0.87      0.00      5.26    829.04      1.00\n",
      "lambda[136]      2.93      7.52      0.96      0.00      5.81    486.06      1.00\n",
      "lambda[137]      2.71      7.30      1.02      0.00      5.59    609.38      1.00\n",
      "lambda[138]      3.20     11.77      1.01      0.00      5.70    755.96      1.00\n",
      "lambda[139]      3.75     14.02      1.02      0.00      6.65    824.73      1.00\n",
      "lambda[140]      2.91      8.22      0.94      0.00      5.78    708.24      1.00\n",
      "lambda[141]      2.67      6.98      0.92      0.00      5.64    717.96      1.01\n",
      "lambda[142]      3.79     14.22      0.97      0.00      6.69    614.65      1.00\n",
      "lambda[143]      2.16      4.24      0.94      0.00      4.57    749.89      1.00\n",
      "        msq   2418.24  37424.71      6.07      0.20    160.53    945.03      1.00\n",
      "      sigma      5.49      7.68      2.24      0.02     15.45   1533.78      1.00\n",
      "    var_obs      0.09      0.01      0.09      0.06      0.11   1471.43      1.00\n",
      "       xisq      1.18      0.63      1.03      0.40      1.95   1371.56      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 36.05062007904053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.68e-05 +- 1.89e-02\n",
      "[dimension 02/145]  inactive:\t-8.40e-04 +- 2.50e-02\n",
      "[dimension 03/145]  inactive:\t4.32e-04 +- 2.60e-02\n",
      "[dimension 04/145]  inactive:\t5.04e-03 +- 3.74e-02\n",
      "[dimension 05/145]  inactive:\t-8.18e-04 +- 2.56e-02\n",
      "[dimension 06/145]  inactive:\t1.43e-03 +- 2.67e-02\n",
      "[dimension 07/145]  inactive:\t8.86e-04 +- 1.89e-02\n",
      "[dimension 08/145]  inactive:\t7.61e-04 +- 2.56e-02\n",
      "[dimension 09/145]  inactive:\t1.54e-04 +- 2.12e-02\n",
      "[dimension 10/145]  inactive:\t2.68e-04 +- 1.75e-02\n",
      "[dimension 11/145]  inactive:\t-1.56e-03 +- 2.27e-02\n",
      "[dimension 12/145]  inactive:\t-7.33e-04 +- 2.58e-02\n",
      "[dimension 13/145]  inactive:\t3.58e-03 +- 3.25e-02\n",
      "[dimension 14/145]  inactive:\t-1.39e-03 +- 2.22e-02\n",
      "[dimension 15/145]  inactive:\t1.28e-04 +- 2.45e-02\n",
      "[dimension 16/145]  inactive:\t6.11e-04 +- 1.83e-02\n",
      "[dimension 17/145]  inactive:\t4.07e-04 +- 3.63e-02\n",
      "[dimension 18/145]  inactive:\t5.37e-04 +- 3.14e-02\n",
      "[dimension 19/145]  inactive:\t-3.07e-03 +- 2.54e-02\n",
      "[dimension 20/145]  inactive:\t-1.45e-03 +- 2.71e-02\n",
      "[dimension 21/145]  inactive:\t-2.33e-03 +- 2.81e-02\n",
      "[dimension 22/145]  inactive:\t-1.09e-04 +- 2.41e-02\n",
      "[dimension 23/145]  inactive:\t-5.62e-04 +- 2.23e-02\n",
      "[dimension 24/145]  inactive:\t1.44e-03 +- 2.39e-02\n",
      "[dimension 25/145]  inactive:\t3.23e-03 +- 2.28e-02\n",
      "[dimension 26/145]  inactive:\t-9.06e-04 +- 2.51e-02\n",
      "[dimension 27/145]  inactive:\t6.52e-04 +- 2.05e-02\n",
      "[dimension 28/145]  inactive:\t9.56e-04 +- 1.95e-02\n",
      "[dimension 29/145]  inactive:\t-5.91e-04 +- 2.51e-02\n",
      "[dimension 30/145]  inactive:\t3.67e-04 +- 2.20e-02\n",
      "[dimension 31/145]  inactive:\t6.24e-03 +- 4.20e-02\n",
      "[dimension 32/145]  inactive:\t-1.49e-03 +- 2.98e-02\n",
      "[dimension 33/145]  inactive:\t1.12e-03 +- 2.84e-02\n",
      "[dimension 34/145]  inactive:\t7.49e-04 +- 1.90e-02\n",
      "[dimension 35/145]  inactive:\t-8.94e-05 +- 2.32e-02\n",
      "[dimension 36/145]  inactive:\t5.58e-04 +- 2.21e-02\n",
      "[dimension 37/145]  inactive:\t5.41e-03 +- 3.17e-02\n",
      "[dimension 38/145]  inactive:\t-1.67e-03 +- 2.84e-02\n",
      "[dimension 39/145]  inactive:\t9.80e-04 +- 3.09e-02\n",
      "[dimension 40/145]  inactive:\t5.40e-03 +- 4.00e-02\n",
      "[dimension 41/145]  inactive:\t-1.94e-03 +- 3.23e-02\n",
      "[dimension 42/145]  inactive:\t7.00e-03 +- 6.29e-02\n",
      "[dimension 43/145]  inactive:\t-5.88e-04 +- 1.80e-02\n",
      "[dimension 44/145]  inactive:\t-7.84e-04 +- 2.63e-02\n",
      "[dimension 45/145]  inactive:\t-2.05e-04 +- 2.22e-02\n",
      "[dimension 46/145]  inactive:\t1.30e-03 +- 1.66e-02\n",
      "[dimension 47/145]  inactive:\t-2.41e-03 +- 3.08e-02\n",
      "[dimension 48/145]  inactive:\t1.37e-03 +- 2.48e-02\n",
      "[dimension 49/145]  inactive:\t2.47e-03 +- 2.12e-02\n",
      "[dimension 50/145]  inactive:\t-1.55e-03 +- 2.61e-02\n",
      "[dimension 51/145]  inactive:\t4.26e-03 +- 3.98e-02\n",
      "[dimension 52/145]  inactive:\t5.81e-03 +- 2.56e-02\n",
      "[dimension 53/145]  inactive:\t-1.52e-03 +- 2.73e-02\n",
      "[dimension 54/145]  inactive:\t-3.82e-04 +- 2.06e-02\n",
      "[dimension 55/145]  inactive:\t3.59e-04 +- 1.39e-02\n",
      "[dimension 56/145]  inactive:\t-3.00e-03 +- 2.44e-02\n",
      "[dimension 57/145]  inactive:\t-4.47e-05 +- 2.30e-02\n",
      "[dimension 58/145]  inactive:\t8.84e-03 +- 5.78e-02\n",
      "[dimension 59/145]  inactive:\t-8.37e-04 +- 1.64e-02\n",
      "[dimension 60/145]  inactive:\t8.46e-04 +- 3.16e-02\n",
      "[dimension 61/145]  inactive:\t2.63e-03 +- 2.61e-02\n",
      "[dimension 62/145]  inactive:\t-9.89e-04 +- 2.12e-02\n",
      "[dimension 63/145]  active:\t7.50e-01 +- 4.01e-01\n",
      "[dimension 64/145]  inactive:\t-2.93e-03 +- 2.70e-02\n",
      "[dimension 65/145]  inactive:\t-8.45e-04 +- 2.56e-02\n",
      "[dimension 66/145]  inactive:\t1.15e-03 +- 2.61e-02\n",
      "[dimension 67/145]  inactive:\t1.70e-03 +- 2.54e-02\n",
      "[dimension 68/145]  inactive:\t-7.64e-04 +- 2.44e-02\n",
      "[dimension 69/145]  inactive:\t2.74e-03 +- 3.57e-02\n",
      "[dimension 70/145]  inactive:\t3.50e-03 +- 2.34e-02\n",
      "[dimension 71/145]  inactive:\t-1.61e-04 +- 2.22e-02\n",
      "[dimension 72/145]  inactive:\t-3.83e-05 +- 1.68e-02\n",
      "[dimension 73/145]  inactive:\t1.61e-04 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-1.19e-03 +- 3.06e-02\n",
      "[dimension 75/145]  inactive:\t2.80e-05 +- 1.92e-02\n",
      "[dimension 76/145]  inactive:\t5.29e-03 +- 3.74e-02\n",
      "[dimension 77/145]  inactive:\t-2.03e-03 +- 3.16e-02\n",
      "[dimension 78/145]  inactive:\t1.30e-03 +- 2.40e-02\n",
      "[dimension 79/145]  inactive:\t5.70e-03 +- 3.21e-02\n",
      "[dimension 80/145]  inactive:\t-1.04e-03 +- 3.24e-02\n",
      "[dimension 81/145]  inactive:\t1.22e-03 +- 3.34e-02\n",
      "[dimension 82/145]  inactive:\t2.32e-04 +- 1.52e-02\n",
      "[dimension 83/145]  inactive:\t-1.97e-03 +- 1.85e-02\n",
      "[dimension 84/145]  inactive:\t-1.53e-03 +- 2.76e-02\n",
      "[dimension 85/145]  inactive:\t2.49e-03 +- 2.95e-02\n",
      "[dimension 86/145]  inactive:\t-8.89e-04 +- 1.96e-02\n",
      "[dimension 87/145]  inactive:\t1.84e-03 +- 3.64e-02\n",
      "[dimension 88/145]  inactive:\t2.41e-03 +- 2.39e-02\n",
      "[dimension 89/145]  inactive:\t-8.59e-04 +- 1.91e-02\n",
      "[dimension 90/145]  inactive:\t1.25e-01 +- 3.09e-01\n",
      "[dimension 91/145]  inactive:\t-1.50e-04 +- 1.92e-02\n",
      "[dimension 92/145]  inactive:\t-1.21e-03 +- 2.16e-02\n",
      "[dimension 93/145]  inactive:\t-8.32e-04 +- 3.07e-02\n",
      "[dimension 94/145]  inactive:\t1.84e-03 +- 2.54e-02\n",
      "[dimension 95/145]  inactive:\t-4.57e-04 +- 1.95e-02\n",
      "[dimension 96/145]  inactive:\t-2.76e-04 +- 3.08e-02\n",
      "[dimension 97/145]  inactive:\t1.81e-03 +- 2.07e-02\n",
      "[dimension 98/145]  inactive:\t-9.26e-04 +- 2.28e-02\n",
      "[dimension 99/145]  inactive:\t1.79e-03 +- 3.27e-02\n",
      "[dimension 100/145]  inactive:\t-4.67e-04 +- 1.38e-02\n",
      "[dimension 101/145]  inactive:\t-2.29e-03 +- 2.09e-02\n",
      "[dimension 102/145]  inactive:\t-1.01e-03 +- 2.47e-02\n",
      "[dimension 103/145]  inactive:\t7.80e-04 +- 2.17e-02\n",
      "[dimension 104/145]  inactive:\t-9.67e-04 +- 1.64e-02\n",
      "[dimension 105/145]  inactive:\t-4.74e-04 +- 2.68e-02\n",
      "[dimension 106/145]  inactive:\t4.65e-03 +- 3.14e-02\n",
      "[dimension 107/145]  inactive:\t-1.25e-03 +- 1.97e-02\n",
      "[dimension 108/145]  inactive:\t6.61e-03 +- 7.09e-02\n",
      "[dimension 109/145]  inactive:\t-5.07e-04 +- 1.87e-02\n",
      "[dimension 110/145]  inactive:\t-1.60e-03 +- 3.40e-02\n",
      "[dimension 111/145]  inactive:\t1.45e-03 +- 2.94e-02\n",
      "[dimension 112/145]  inactive:\t5.30e-03 +- 4.38e-02\n",
      "[dimension 113/145]  inactive:\t-1.62e-03 +- 2.29e-02\n",
      "[dimension 114/145]  inactive:\t1.65e-04 +- 2.40e-02\n",
      "[dimension 115/145]  inactive:\t2.08e-03 +- 2.28e-02\n",
      "[dimension 116/145]  inactive:\t3.28e-04 +- 3.36e-02\n",
      "[dimension 117/145]  inactive:\t3.08e-03 +- 3.73e-02\n",
      "[dimension 118/145]  inactive:\t3.91e-03 +- 2.96e-02\n",
      "[dimension 119/145]  inactive:\t-2.45e-03 +- 3.30e-02\n",
      "[dimension 120/145]  inactive:\t-2.16e-04 +- 2.39e-02\n",
      "[dimension 121/145]  inactive:\t4.55e-03 +- 3.51e-02\n",
      "[dimension 122/145]  inactive:\t-2.34e-03 +- 2.74e-02\n",
      "[dimension 123/145]  inactive:\t7.31e-04 +- 2.79e-02\n",
      "[dimension 124/145]  inactive:\t-1.10e-03 +- 1.58e-02\n",
      "[dimension 125/145]  inactive:\t-1.59e-03 +- 2.45e-02\n",
      "[dimension 126/145]  inactive:\t-1.17e-03 +- 2.29e-02\n",
      "[dimension 127/145]  inactive:\t-7.05e-05 +- 1.76e-02\n",
      "[dimension 128/145]  inactive:\t-1.94e-03 +- 3.18e-02\n",
      "[dimension 129/145]  inactive:\t-1.29e-04 +- 2.46e-02\n",
      "[dimension 130/145]  inactive:\t3.56e-03 +- 2.70e-02\n",
      "[dimension 131/145]  inactive:\t-1.16e-03 +- 2.60e-02\n",
      "[dimension 132/145]  inactive:\t2.63e-03 +- 3.22e-02\n",
      "[dimension 133/145]  inactive:\t2.60e-03 +- 2.03e-02\n",
      "[dimension 134/145]  inactive:\t-8.50e-04 +- 2.54e-02\n",
      "[dimension 135/145]  inactive:\t1.36e-04 +- 2.95e-02\n",
      "[dimension 136/145]  inactive:\t1.32e-03 +- 1.90e-02\n",
      "[dimension 137/145]  inactive:\t-2.37e-04 +- 3.17e-02\n",
      "[dimension 138/145]  inactive:\t5.80e-04 +- 2.37e-02\n",
      "[dimension 139/145]  inactive:\t5.78e-04 +- 2.08e-02\n",
      "[dimension 140/145]  inactive:\t-1.14e-03 +- 2.96e-02\n",
      "[dimension 141/145]  inactive:\t8.57e-04 +- 2.64e-02\n",
      "[dimension 142/145]  inactive:\t1.48e-03 +- 1.86e-02\n",
      "[dimension 143/145]  inactive:\t7.83e-04 +- 3.13e-02\n",
      "[dimension 144/145]  inactive:\t1.05e-04 +- 1.59e-02\n",
      "[dimension 145/145]  inactive:\t-8.88e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8771008]\n",
      "cov_act[[0.02460122]]\n",
      "Active_dimensions: [62]\n",
      "71, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:31<00:00, 48.29it/s, 31 steps of size 1.78e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    248.40      1.00\n",
      "  lambda[0]      2.01      3.73      0.92      0.00      4.46    997.34      1.00\n",
      "  lambda[1]      2.81      7.69      1.02      0.00      5.56    682.91      1.00\n",
      "  lambda[2]      2.99      8.87      0.96      0.00      5.49    602.08      1.00\n",
      "  lambda[3]      6.63     65.05      0.98      0.00      6.92    772.84      1.00\n",
      "  lambda[4]      2.99     12.36      1.03      0.00      5.54    533.92      1.00\n",
      "  lambda[5]      3.37     11.58      0.99      0.00      6.29    814.05      1.00\n",
      "  lambda[6]      6.78     81.48      1.01      0.00      7.28    938.76      1.00\n",
      "  lambda[7]      2.83      6.97      0.96      0.00      5.93    819.77      1.00\n",
      "  lambda[8]      2.64      6.02      0.97      0.00      5.56    531.48      1.00\n",
      "  lambda[9]      2.42      5.97      0.95      0.00      4.46    767.23      1.00\n",
      " lambda[10]      3.04      9.62      1.08      0.00      5.66    941.77      1.00\n",
      " lambda[11]      3.43     12.33      1.03      0.00      6.50    221.65      1.00\n",
      " lambda[12]      3.72     11.60      0.99      0.00      7.19    409.60      1.00\n",
      " lambda[13]      2.51      6.09      0.96      0.00      5.46    707.17      1.00\n",
      " lambda[14]     10.41     97.67      0.91      0.00      5.10    337.92      1.00\n",
      " lambda[15]      3.39     12.18      1.08      0.00      5.86    782.73      1.00\n",
      " lambda[16]      4.62     24.38      0.97      0.00      8.51    739.80      1.00\n",
      " lambda[17]      4.13     40.07      1.01      0.00      6.07    876.46      1.00\n",
      " lambda[18]      2.58      5.31      0.96      0.00      5.92    665.48      1.00\n",
      " lambda[19]      3.45     16.63      0.99      0.00      6.41    654.06      1.00\n",
      " lambda[20]      2.49      6.01      0.96      0.00      5.34    898.20      1.00\n",
      " lambda[21]      2.33      4.28      0.98      0.01      5.43   1004.67      1.00\n",
      " lambda[22]      2.81      7.72      0.96      0.00      5.35    493.44      1.00\n",
      " lambda[23]      3.05      9.70      0.94      0.00      5.59    883.90      1.00\n",
      " lambda[24]      4.42     31.06      1.06      0.00      5.93    847.63      1.00\n",
      " lambda[25]      3.01     10.95      1.00      0.00      5.41    399.94      1.00\n",
      " lambda[26]      2.79      8.70      0.97      0.00      4.75    926.02      1.00\n",
      " lambda[27]      2.24      4.47      0.95      0.00      5.15    821.58      1.00\n",
      " lambda[28]      2.86     11.04      1.00      0.00      5.67    509.96      1.00\n",
      " lambda[29]      3.82     19.25      0.97      0.00      6.32    413.72      1.00\n",
      " lambda[30]      3.41     11.21      1.01      0.01      5.83    672.10      1.00\n",
      " lambda[31]      3.36     13.89      0.98      0.00      5.29    405.92      1.00\n",
      " lambda[32]      3.59     15.02      0.98      0.00      6.46    790.46      1.00\n",
      " lambda[33]      3.22      8.19      0.94      0.00      6.94    526.22      1.00\n",
      " lambda[34]      3.09     14.34      0.98      0.00      5.51    879.29      1.00\n",
      " lambda[35]      2.69      8.94      0.96      0.00      4.75    423.97      1.00\n",
      " lambda[36]      3.53     15.57      0.99      0.00      6.25    630.22      1.00\n",
      " lambda[37]      3.48     17.21      1.02      0.00      6.30    547.68      1.00\n",
      " lambda[38]      3.53     12.47      0.95      0.00      5.96    866.33      1.00\n",
      " lambda[39]      3.63     13.17      1.00      0.00      5.89    494.36      1.00\n",
      " lambda[40]      3.73     15.56      0.98      0.00      5.72   1042.98      1.00\n",
      " lambda[41]     44.15    543.01      0.92      0.00      8.93    222.18      1.00\n",
      " lambda[42]      2.40      4.68      0.91      0.00      5.52    705.32      1.00\n",
      " lambda[43]      4.27     50.05      0.90      0.00      5.90   1011.85      1.00\n",
      " lambda[44]      3.60     13.07      0.98      0.00      6.15    689.36      1.00\n",
      " lambda[45]      2.19      4.35      0.98      0.00      4.69    712.59      1.00\n",
      " lambda[46]      2.53      6.68      1.03      0.01      4.96    592.44      1.00\n",
      " lambda[47]      2.80      7.44      0.92      0.00      5.93    683.26      1.00\n",
      " lambda[48]      2.85      9.45      0.97      0.00      5.23    779.66      1.00\n",
      " lambda[49]      2.89      7.82      0.98      0.00      5.85    801.66      1.00\n",
      " lambda[50]      2.99      9.17      0.96      0.00      5.56    768.17      1.00\n",
      " lambda[51]      8.04     54.44      1.03      0.00      8.85    499.27      1.00\n",
      " lambda[52]      2.77      7.45      0.98      0.00      5.53    862.39      1.00\n",
      " lambda[53]      6.62     91.07      0.98      0.01      5.26    504.45      1.00\n",
      " lambda[54]      2.28      5.91      0.92      0.00      4.40    594.03      1.00\n",
      " lambda[55]      3.24     21.00      1.03      0.00      5.60    831.95      1.00\n",
      " lambda[56]      2.75      6.69      0.98      0.00      5.70    634.88      1.00\n",
      " lambda[57]      9.77    132.65      0.97      0.00      6.84    969.58      1.00\n",
      " lambda[58]      2.29      4.61      0.95      0.01      5.34    670.04      1.00\n",
      " lambda[59]      2.70      6.07      1.00      0.00      6.23    611.99      1.00\n",
      " lambda[60]      5.48     26.51      1.06      0.00      7.46    847.72      1.00\n",
      " lambda[61]      3.19     14.62      1.02      0.00      6.10    773.21      1.00\n",
      " lambda[62]   6999.43 107615.31    420.44      0.02   3627.66    644.26      1.00\n",
      " lambda[63]      2.48      6.32      1.00      0.00      4.73    772.01      1.00\n",
      " lambda[64]      2.66      6.63      0.97      0.00      5.08    760.63      1.00\n",
      " lambda[65]      3.07     17.60      1.02      0.00      5.50    944.58      1.00\n",
      " lambda[66]      2.95      8.49      1.03      0.00      5.89    690.61      1.00\n",
      " lambda[67]      2.67      7.38      0.94      0.00      5.52    666.73      1.00\n",
      " lambda[68]      4.87     58.58      0.92      0.00      5.11    643.89      1.00\n",
      " lambda[69]      5.13     27.66      0.92      0.00      6.37    724.04      1.00\n",
      " lambda[70]      2.42      8.22      0.94      0.01      4.65    973.07      1.00\n",
      " lambda[71]      2.98      8.96      0.95      0.00      6.17    282.09      1.00\n",
      " lambda[72]      2.35      6.91      0.95      0.01      4.35    504.77      1.00\n",
      " lambda[73]      3.13     17.25      1.02      0.00      5.56   1001.25      1.00\n",
      " lambda[74]      3.97     40.19      1.04      0.01      5.14    605.93      1.00\n",
      " lambda[75]      4.51     18.82      0.96      0.00      8.22    647.38      1.00\n",
      " lambda[76]      2.97      7.24      0.94      0.00      6.26    781.14      1.00\n",
      " lambda[77]     17.28    171.80      1.11      0.00      7.26    269.71      1.01\n",
      " lambda[78]      5.24     44.05      0.99      0.00      6.23    944.42      1.00\n",
      " lambda[79]      3.33     21.86      0.98      0.00      5.41    984.74      1.00\n",
      " lambda[80]     11.39    237.74      0.98      0.00      6.85   1002.52      1.00\n",
      " lambda[81]      2.19      4.22      0.90      0.00      5.25   1003.78      1.00\n",
      " lambda[82]      2.37      5.33      0.95      0.00      4.72    894.64      1.00\n",
      " lambda[83]      2.80      8.00      0.94      0.00      5.96    725.36      1.00\n",
      " lambda[84]      4.76     36.11      1.01      0.00      6.82    714.97      1.00\n",
      " lambda[85]      2.33      5.43      0.94      0.00      5.21    765.61      1.00\n",
      " lambda[86]      2.39      5.05      0.97      0.00      5.22    883.63      1.00\n",
      " lambda[87]      3.13      8.15      1.00      0.00      6.55    710.79      1.00\n",
      " lambda[88]      2.68      6.16      0.99      0.00      6.57    772.13      1.00\n",
      " lambda[89]    315.84   3804.98      1.13      0.00     57.01    753.00      1.00\n",
      " lambda[90]      2.95      9.54      0.92      0.00      5.33    481.44      1.00\n",
      " lambda[91]      2.52      5.74      0.98      0.01      5.22    700.06      1.00\n",
      " lambda[92]      3.74     30.35      1.06      0.01      5.44    992.34      1.00\n",
      " lambda[93]      2.97      9.02      1.02      0.00      5.50    485.41      1.00\n",
      " lambda[94]      2.31      5.65      0.97      0.00      4.67    841.08      1.00\n",
      " lambda[95]      2.74      7.25      0.94      0.00      5.72    992.68      1.00\n",
      " lambda[96]      3.36     15.55      0.94      0.00      5.74    357.69      1.00\n",
      " lambda[97]      3.70     14.71      1.07      0.00      5.87    603.08      1.00\n",
      " lambda[98]     26.64    390.47      0.95      0.00      6.06    388.69      1.00\n",
      " lambda[99]      2.59      7.37      0.93      0.00      5.02    817.87      1.00\n",
      "lambda[100]      2.66      9.55      0.93      0.00      4.92    720.23      1.00\n",
      "lambda[101]      3.02     10.37      0.99      0.00      5.62    550.42      1.00\n",
      "lambda[102]      2.74      8.83      0.90      0.00      4.99    595.62      1.00\n",
      "lambda[103]      2.28      4.62      0.93      0.00      5.00    796.54      1.00\n",
      "lambda[104]      2.43      4.71      0.98      0.00      5.70   1020.36      1.00\n",
      "lambda[105]      4.43     23.06      1.07      0.00      7.81    808.39      1.00\n",
      "lambda[106]      2.30      4.22      1.06      0.00      5.09    765.96      1.00\n",
      "lambda[107]      7.94     66.79      1.03      0.00      5.54    480.44      1.00\n",
      "lambda[108]      2.28      4.54      1.00      0.01      4.93    456.53      1.00\n",
      "lambda[109]      6.03     82.94      0.96      0.00      5.62    986.11      1.00\n",
      "lambda[110]      4.23     19.51      0.97      0.00      8.17    823.95      1.00\n",
      "lambda[111]      9.84    118.20      1.05      0.00     10.06    602.58      1.00\n",
      "lambda[112]      2.50      5.64      0.94      0.01      5.57    890.77      1.00\n",
      "lambda[113]      3.15      9.05      0.98      0.00      6.27    655.81      1.00\n",
      "lambda[114]      4.51     21.22      1.01      0.00      7.57    763.52      1.00\n",
      "lambda[115]      4.49     29.29      0.95      0.00      5.52    550.43      1.00\n",
      "lambda[116]     12.52    173.24      0.95      0.00      5.63    390.47      1.00\n",
      "lambda[117]      3.18     10.71      1.02      0.00      5.69    642.05      1.00\n",
      "lambda[118]      4.17     26.45      0.96      0.00      6.52    591.30      1.00\n",
      "lambda[119]      3.15     21.54      0.98      0.00      5.77   1018.34      1.00\n",
      "lambda[120]      4.18     17.26      1.05      0.00      6.97    632.02      1.01\n",
      "lambda[121]      3.08     14.61      0.96      0.00      5.70    885.65      1.00\n",
      "lambda[122]      4.12     33.71      1.01      0.00      6.24    887.91      1.00\n",
      "lambda[123]      2.38      5.35      0.89      0.00      4.89    784.21      1.00\n",
      "lambda[124]      2.60      5.44      1.03      0.01      6.15    897.40      1.00\n",
      "lambda[125]      3.18      9.35      0.95      0.00      5.86    366.77      1.00\n",
      "lambda[126]      2.84      8.68      0.94      0.00      5.73    801.64      1.00\n",
      "lambda[127]      3.17      9.71      1.00      0.00      5.63    672.30      1.00\n",
      "lambda[128]      3.47     19.25      1.01      0.00      4.92    387.14      1.00\n",
      "lambda[129]      5.98     79.38      1.05      0.00      6.10   1006.68      1.00\n",
      "lambda[130]      3.36      9.03      0.95      0.00      6.43    582.85      1.00\n",
      "lambda[131]      2.44      5.57      0.99      0.00      4.99    770.05      1.00\n",
      "lambda[132]      2.65      5.58      1.04      0.00      6.36    860.96      1.00\n",
      "lambda[133]      2.94     10.27      0.96      0.00      5.52    559.54      1.00\n",
      "lambda[134]      2.94      7.79      0.95      0.00      6.59    812.85      1.00\n",
      "lambda[135]      2.49      6.41      0.86      0.00      4.95    592.76      1.00\n",
      "lambda[136]      3.21      9.17      1.00      0.00      6.69    586.36      1.01\n",
      "lambda[137]      2.52      7.32      0.95      0.00      4.70    677.58      1.00\n",
      "lambda[138]      3.00     11.58      1.01      0.00      5.56    688.89      1.00\n",
      "lambda[139]      2.72      8.36      1.01      0.00      5.29    888.92      1.00\n",
      "lambda[140]      2.49      5.84      0.97      0.00      5.43    854.69      1.00\n",
      "lambda[141]      2.52      6.41      0.85      0.00      5.26    756.32      1.00\n",
      "lambda[142]      5.34     27.53      0.97      0.01      7.15    488.05      1.00\n",
      "lambda[143]      2.61     10.20      0.94      0.00      5.19    585.51      1.00\n",
      "        msq      0.25      0.16      0.21      0.08      0.42    778.85      1.00\n",
      "      sigma      4.88      7.27      1.76      0.01     13.59   1407.22      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    401.49      1.00\n",
      "       xisq      1.04      0.49      0.93      0.41      1.68   1131.51      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.81212902069092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t6.30e-05 +- 8.66e-03\n",
      "[dimension 02/145]  inactive:\t4.92e-04 +- 1.46e-02\n",
      "[dimension 03/145]  inactive:\t1.23e-03 +- 2.02e-02\n",
      "[dimension 04/145]  inactive:\t4.08e-03 +- 3.27e-02\n",
      "[dimension 05/145]  inactive:\t8.90e-04 +- 1.85e-02\n",
      "[dimension 06/145]  inactive:\t1.10e-03 +- 1.94e-02\n",
      "[dimension 07/145]  inactive:\t1.38e-03 +- 1.59e-02\n",
      "[dimension 08/145]  inactive:\t1.84e-03 +- 2.25e-02\n",
      "[dimension 09/145]  inactive:\t1.26e-03 +- 1.76e-02\n",
      "[dimension 10/145]  inactive:\t6.10e-04 +- 1.14e-02\n",
      "[dimension 11/145]  inactive:\t6.37e-04 +- 1.79e-02\n",
      "[dimension 12/145]  inactive:\t1.68e-03 +- 2.57e-02\n",
      "[dimension 13/145]  inactive:\t2.60e-03 +- 2.45e-02\n",
      "[dimension 14/145]  inactive:\t4.30e-04 +- 1.54e-02\n",
      "[dimension 15/145]  inactive:\t4.30e-03 +- 4.51e-02\n",
      "[dimension 16/145]  inactive:\t7.70e-04 +- 1.55e-02\n",
      "[dimension 17/145]  inactive:\t3.36e-03 +- 4.05e-02\n",
      "[dimension 18/145]  inactive:\t2.31e-03 +- 2.89e-02\n",
      "[dimension 19/145]  inactive:\t-4.56e-04 +- 1.14e-02\n",
      "[dimension 20/145]  inactive:\t3.47e-04 +- 1.79e-02\n",
      "[dimension 21/145]  inactive:\t-2.10e-04 +- 1.33e-02\n",
      "[dimension 22/145]  inactive:\t2.96e-04 +- 1.25e-02\n",
      "[dimension 23/145]  inactive:\t3.12e-04 +- 1.63e-02\n",
      "[dimension 24/145]  inactive:\t1.27e-03 +- 2.06e-02\n",
      "[dimension 25/145]  inactive:\t2.81e-03 +- 2.47e-02\n",
      "[dimension 26/145]  inactive:\t3.57e-04 +- 1.70e-02\n",
      "[dimension 27/145]  inactive:\t7.53e-04 +- 1.65e-02\n",
      "[dimension 28/145]  inactive:\t5.31e-04 +- 9.80e-03\n",
      "[dimension 29/145]  inactive:\t1.86e-03 +- 2.70e-02\n",
      "[dimension 30/145]  inactive:\t2.95e-03 +- 3.59e-02\n",
      "[dimension 31/145]  inactive:\t3.43e-03 +- 3.03e-02\n",
      "[dimension 32/145]  inactive:\t5.52e-04 +- 1.71e-02\n",
      "[dimension 33/145]  inactive:\t2.57e-03 +- 2.97e-02\n",
      "[dimension 34/145]  inactive:\t7.02e-04 +- 1.29e-02\n",
      "[dimension 35/145]  inactive:\t2.40e-03 +- 3.11e-02\n",
      "[dimension 36/145]  inactive:\t1.38e-03 +- 1.99e-02\n",
      "[dimension 37/145]  inactive:\t2.39e-03 +- 2.01e-02\n",
      "[dimension 38/145]  inactive:\t7.30e-04 +- 2.02e-02\n",
      "[dimension 39/145]  inactive:\t1.56e-03 +- 2.11e-02\n",
      "[dimension 40/145]  inactive:\t4.41e-03 +- 3.57e-02\n",
      "[dimension 41/145]  inactive:\t4.18e-04 +- 1.86e-02\n",
      "[dimension 42/145]  inactive:\t1.49e-02 +- 9.93e-02\n",
      "[dimension 43/145]  inactive:\t3.48e-04 +- 1.13e-02\n",
      "[dimension 44/145]  inactive:\t4.87e-04 +- 1.75e-02\n",
      "[dimension 45/145]  inactive:\t6.31e-04 +- 1.83e-02\n",
      "[dimension 46/145]  inactive:\t3.76e-04 +- 8.56e-03\n",
      "[dimension 47/145]  inactive:\t-6.59e-05 +- 1.29e-02\n",
      "[dimension 48/145]  inactive:\t1.01e-03 +- 1.74e-02\n",
      "[dimension 49/145]  inactive:\t1.01e-03 +- 1.59e-02\n",
      "[dimension 50/145]  inactive:\t-7.29e-05 +- 1.75e-02\n",
      "[dimension 51/145]  inactive:\t1.63e-03 +- 2.13e-02\n",
      "[dimension 52/145]  inactive:\t5.03e-03 +- 2.37e-02\n",
      "[dimension 53/145]  inactive:\t-6.94e-05 +- 1.24e-02\n",
      "[dimension 54/145]  inactive:\t9.23e-04 +- 1.70e-02\n",
      "[dimension 55/145]  inactive:\t3.24e-04 +- 8.73e-03\n",
      "[dimension 56/145]  inactive:\t-6.03e-04 +- 1.32e-02\n",
      "[dimension 57/145]  inactive:\t1.03e-03 +- 1.80e-02\n",
      "[dimension 58/145]  inactive:\t8.76e-03 +- 5.89e-02\n",
      "[dimension 59/145]  inactive:\t-5.49e-05 +- 9.84e-03\n",
      "[dimension 60/145]  inactive:\t8.16e-04 +- 1.55e-02\n",
      "[dimension 61/145]  inactive:\t3.85e-03 +- 2.93e-02\n",
      "[dimension 62/145]  inactive:\t1.68e-04 +- 1.46e-02\n",
      "[dimension 63/145]  active:\t6.54e-01 +- 4.07e-01\n",
      "[dimension 64/145]  inactive:\t-6.15e-04 +- 1.16e-02\n",
      "[dimension 65/145]  inactive:\t5.30e-04 +- 1.57e-02\n",
      "[dimension 66/145]  inactive:\t6.47e-04 +- 1.40e-02\n",
      "[dimension 67/145]  inactive:\t8.94e-04 +- 1.80e-02\n",
      "[dimension 68/145]  inactive:\t3.14e-04 +- 1.46e-02\n",
      "[dimension 69/145]  inactive:\t2.16e-03 +- 3.21e-02\n",
      "[dimension 70/145]  inactive:\t3.52e-03 +- 2.42e-02\n",
      "[dimension 71/145]  inactive:\t5.51e-04 +- 1.44e-02\n",
      "[dimension 72/145]  inactive:\t8.11e-04 +- 1.41e-02\n",
      "[dimension 73/145]  inactive:\t3.42e-04 +- 9.57e-03\n",
      "[dimension 74/145]  inactive:\t6.05e-04 +- 2.03e-02\n",
      "[dimension 75/145]  inactive:\t1.39e-03 +- 2.50e-02\n",
      "[dimension 76/145]  inactive:\t3.92e-03 +- 2.99e-02\n",
      "[dimension 77/145]  inactive:\t2.42e-04 +- 1.85e-02\n",
      "[dimension 78/145]  inactive:\t1.52e-02 +- 9.99e-02\n",
      "[dimension 79/145]  inactive:\t4.90e-03 +- 3.39e-02\n",
      "[dimension 80/145]  inactive:\t1.32e-03 +- 2.47e-02\n",
      "[dimension 81/145]  inactive:\t3.21e-03 +- 3.32e-02\n",
      "[dimension 82/145]  inactive:\t3.14e-04 +- 9.00e-03\n",
      "[dimension 83/145]  inactive:\t-4.66e-04 +- 1.07e-02\n",
      "[dimension 84/145]  inactive:\t-2.10e-04 +- 1.69e-02\n",
      "[dimension 85/145]  inactive:\t3.02e-03 +- 3.20e-02\n",
      "[dimension 86/145]  inactive:\t-1.49e-04 +- 9.90e-03\n",
      "[dimension 87/145]  inactive:\t1.33e-03 +- 2.08e-02\n",
      "[dimension 88/145]  inactive:\t1.90e-03 +- 1.83e-02\n",
      "[dimension 89/145]  inactive:\t5.03e-05 +- 1.29e-02\n",
      "[dimension 90/145]  inactive:\t7.59e-02 +- 2.31e-01\n",
      "[dimension 91/145]  inactive:\t2.60e-04 +- 1.09e-02\n",
      "[dimension 92/145]  inactive:\t-8.64e-06 +- 1.19e-02\n",
      "[dimension 93/145]  inactive:\t4.41e-04 +- 1.98e-02\n",
      "[dimension 94/145]  inactive:\t1.29e-03 +- 1.84e-02\n",
      "[dimension 95/145]  inactive:\t5.00e-04 +- 1.62e-02\n",
      "[dimension 96/145]  inactive:\t9.74e-04 +- 2.20e-02\n",
      "[dimension 97/145]  inactive:\t1.95e-03 +- 1.77e-02\n",
      "[dimension 98/145]  inactive:\t4.25e-05 +- 1.70e-02\n",
      "[dimension 99/145]  inactive:\t9.36e-03 +- 7.60e-02\n",
      "[dimension 100/145]  inactive:\t2.03e-05 +- 9.53e-03\n",
      "[dimension 101/145]  inactive:\t-5.92e-04 +- 1.09e-02\n",
      "[dimension 102/145]  inactive:\t6.53e-04 +- 1.88e-02\n",
      "[dimension 103/145]  inactive:\t7.91e-04 +- 1.51e-02\n",
      "[dimension 104/145]  inactive:\t-1.57e-04 +- 9.73e-03\n",
      "[dimension 105/145]  inactive:\t4.61e-04 +- 1.45e-02\n",
      "[dimension 106/145]  inactive:\t4.49e-03 +- 3.08e-02\n",
      "[dimension 107/145]  inactive:\t-1.71e-04 +- 1.16e-02\n",
      "[dimension 108/145]  inactive:\t9.27e-03 +- 7.78e-02\n",
      "[dimension 109/145]  inactive:\t7.22e-05 +- 1.05e-02\n",
      "[dimension 110/145]  inactive:\t1.79e-03 +- 2.62e-02\n",
      "[dimension 111/145]  inactive:\t3.13e-03 +- 3.27e-02\n",
      "[dimension 112/145]  inactive:\t7.62e-03 +- 6.07e-02\n",
      "[dimension 113/145]  inactive:\t8.54e-05 +- 1.36e-02\n",
      "[dimension 114/145]  inactive:\t1.89e-03 +- 2.69e-02\n",
      "[dimension 115/145]  inactive:\t1.77e-03 +- 1.74e-02\n",
      "[dimension 116/145]  inactive:\t1.87e-03 +- 2.91e-02\n",
      "[dimension 117/145]  inactive:\t6.33e-03 +- 5.93e-02\n",
      "[dimension 118/145]  inactive:\t1.51e-03 +- 1.43e-02\n",
      "[dimension 119/145]  inactive:\t2.81e-04 +- 1.78e-02\n",
      "[dimension 120/145]  inactive:\t7.23e-04 +- 1.68e-02\n",
      "[dimension 121/145]  inactive:\t3.02e-03 +- 2.66e-02\n",
      "[dimension 122/145]  inactive:\t-2.52e-05 +- 1.69e-02\n",
      "[dimension 123/145]  inactive:\t2.36e-03 +- 3.21e-02\n",
      "[dimension 124/145]  inactive:\t-9.59e-05 +- 9.46e-03\n",
      "[dimension 125/145]  inactive:\t6.64e-05 +- 1.50e-02\n",
      "[dimension 126/145]  inactive:\t1.37e-04 +- 1.34e-02\n",
      "[dimension 127/145]  inactive:\t4.49e-04 +- 1.16e-02\n",
      "[dimension 128/145]  inactive:\t7.16e-04 +- 1.64e-02\n",
      "[dimension 129/145]  inactive:\t1.23e-03 +- 2.11e-02\n",
      "[dimension 130/145]  inactive:\t1.97e-03 +- 1.88e-02\n",
      "[dimension 131/145]  inactive:\t9.27e-04 +- 2.41e-02\n",
      "[dimension 132/145]  inactive:\t1.70e-03 +- 2.11e-02\n",
      "[dimension 133/145]  inactive:\t1.28e-03 +- 1.23e-02\n",
      "[dimension 134/145]  inactive:\t5.27e-04 +- 1.81e-02\n",
      "[dimension 135/145]  inactive:\t6.67e-04 +- 1.37e-02\n",
      "[dimension 136/145]  inactive:\t8.88e-04 +- 1.19e-02\n",
      "[dimension 137/145]  inactive:\t1.33e-03 +- 2.23e-02\n",
      "[dimension 138/145]  inactive:\t5.88e-04 +- 1.41e-02\n",
      "[dimension 139/145]  inactive:\t1.10e-03 +- 1.83e-02\n",
      "[dimension 140/145]  inactive:\t6.92e-04 +- 1.90e-02\n",
      "[dimension 141/145]  inactive:\t7.41e-04 +- 1.46e-02\n",
      "[dimension 142/145]  inactive:\t1.38e-03 +- 1.38e-02\n",
      "[dimension 143/145]  inactive:\t3.46e-03 +- 3.73e-02\n",
      "[dimension 144/145]  inactive:\t9.54e-04 +- 1.63e-02\n",
      "[dimension 145/145]  inactive:\t-1.28e-09 +- 7.11e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8349016]\n",
      "cov_act[[0.0127405]]\n",
      "Active_dimensions: [62]\n",
      "72, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 51.55it/s, 15 steps of size 2.23e-01. acc. prob=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    441.54      1.00\n",
      "  lambda[0]      2.67      8.69      0.93      0.00      5.03    945.69      1.00\n",
      "  lambda[1]      3.75     18.20      0.95      0.00      6.04    357.44      1.00\n",
      "  lambda[2]      3.07      8.11      1.05      0.01      5.93    380.11      1.00\n",
      "  lambda[3]      3.09      8.12      1.06      0.00      6.40    718.90      1.00\n",
      "  lambda[4]      2.66      5.99      0.95      0.00      6.09    965.44      1.00\n",
      "  lambda[5]      5.43     50.69      0.97      0.00      6.15    530.14      1.00\n",
      "  lambda[6]      2.82      6.83      0.94      0.00      6.16    745.31      1.00\n",
      "  lambda[7]      2.73      6.77      0.91      0.00      6.10    721.80      1.00\n",
      "  lambda[8]      3.19      9.30      0.98      0.01      6.38    661.39      1.00\n",
      "  lambda[9]      3.13      9.35      1.05      0.00      5.82    719.55      1.00\n",
      " lambda[10]      3.21      8.69      1.04      0.00      6.19    549.77      1.00\n",
      " lambda[11]      2.69      7.02      1.00      0.01      5.72    778.76      1.00\n",
      " lambda[12]      4.46     20.02      0.93      0.00      7.33    493.91      1.01\n",
      " lambda[13]      3.41     22.72      0.95      0.00      5.58    605.87      1.00\n",
      " lambda[14]      4.21     24.98      1.03      0.00      6.77    920.33      1.00\n",
      " lambda[15]      2.63      7.16      0.96      0.00      4.95    835.01      1.00\n",
      " lambda[16]      2.91      9.38      0.96      0.00      5.50    682.54      1.00\n",
      " lambda[17]      2.93      7.52      1.05      0.00      6.01    747.46      1.00\n",
      " lambda[18]      2.88      9.68      0.97      0.00      5.02    734.57      1.00\n",
      " lambda[19]      2.76      6.89      1.07      0.00      5.80    893.79      1.00\n",
      " lambda[20]      3.23     10.20      1.00      0.00      6.08    629.73      1.00\n",
      " lambda[21]      2.70      7.03      0.96      0.00      5.76    321.77      1.00\n",
      " lambda[22]      2.81      8.94      1.02      0.00      5.26    922.63      1.00\n",
      " lambda[23]      3.40     19.12      1.05      0.00      5.18    887.49      1.00\n",
      " lambda[24]      3.63     15.07      1.01      0.00      6.55    578.39      1.00\n",
      " lambda[25]      2.36      5.69      0.92      0.01      5.32    873.19      1.00\n",
      " lambda[26]      3.34     11.38      0.97      0.00      5.75    476.97      1.00\n",
      " lambda[27]      2.70      6.36      0.89      0.00      5.78    917.82      1.00\n",
      " lambda[28]      2.54      5.34      0.98      0.00      6.26    606.30      1.00\n",
      " lambda[29]      3.08     12.49      0.95      0.00      5.37    866.34      1.00\n",
      " lambda[30]      3.17     10.29      0.97      0.00      6.66    695.97      1.00\n",
      " lambda[31]      3.05      9.49      0.98      0.00      5.36    703.45      1.00\n",
      " lambda[32]      3.15     11.47      1.01      0.00      6.34    994.39      1.00\n",
      " lambda[33]      2.53      6.34      0.94      0.00      5.03    703.89      1.00\n",
      " lambda[34]      2.92      9.62      1.00      0.00      5.99    459.37      1.00\n",
      " lambda[35]      2.85      7.37      0.99      0.00      5.69    849.04      1.00\n",
      " lambda[36]      3.22      8.45      1.04      0.00      6.47    693.77      1.00\n",
      " lambda[37]      3.60     14.33      1.02      0.01      6.42    860.26      1.00\n",
      " lambda[38]      4.50     26.82      1.00      0.00      6.63    773.15      1.00\n",
      " lambda[39]      3.71     18.20      0.97      0.00      6.34    855.87      1.00\n",
      " lambda[40]      3.31      9.48      1.04      0.00      6.55    692.64      1.00\n",
      " lambda[41]     11.48    123.92      1.00      0.00      8.23    390.48      1.00\n",
      " lambda[42]      2.32      6.16      0.95      0.00      4.76    933.02      1.00\n",
      " lambda[43]      3.41     16.04      0.98      0.00      6.27    620.64      1.00\n",
      " lambda[44]      2.76      6.86      0.94      0.01      5.98    663.01      1.00\n",
      " lambda[45]      2.66      9.08      0.95      0.01      4.76    920.11      1.00\n",
      " lambda[46]      2.53      7.60      0.96      0.00      4.54    748.60      1.00\n",
      " lambda[47]      2.57      5.28      1.01      0.00      5.62    794.93      1.00\n",
      " lambda[48]      3.28      8.61      1.01      0.00      6.47    695.09      1.00\n",
      " lambda[49]      2.99      7.87      1.02      0.00      5.81    631.90      1.00\n",
      " lambda[50]      3.44     14.80      0.98      0.00      6.06    644.90      1.00\n",
      " lambda[51]      3.60      9.33      1.02      0.00      7.00    630.23      1.00\n",
      " lambda[52]      3.35     18.91      0.94      0.00      4.67    674.59      1.00\n",
      " lambda[53]      3.26     13.17      0.92      0.00      5.22    389.84      1.00\n",
      " lambda[54]      2.26      5.76      0.96      0.00      4.49    757.30      1.00\n",
      " lambda[55]      3.28     19.43      0.86      0.00      5.17    954.35      1.00\n",
      " lambda[56]      2.47      6.16      0.99      0.00      4.94    762.33      1.00\n",
      " lambda[57]      6.93     32.75      1.05      0.01      8.53    383.69      1.00\n",
      " lambda[58]      2.49      5.87      0.94      0.00      5.28    665.80      1.00\n",
      " lambda[59]      3.35     10.82      1.04      0.00      6.42    653.42      1.00\n",
      " lambda[60]      3.25     16.57      1.04      0.00      5.59    871.78      1.00\n",
      " lambda[61]      2.43      5.77      1.02      0.00      5.04    679.66      1.00\n",
      " lambda[62]    451.71   1260.00    156.93      0.01    877.41    366.31      1.00\n",
      " lambda[63]      2.48      5.38      0.92      0.00      5.41    974.63      1.00\n",
      " lambda[64]      2.41      5.75      0.91      0.00      5.03    747.52      1.00\n",
      " lambda[65]      2.94      9.90      1.01      0.00      5.25    811.26      1.00\n",
      " lambda[66]      2.81      6.74      0.95      0.00      6.21    694.58      1.00\n",
      " lambda[67]      2.96      8.18      1.03      0.00      5.71    887.62      1.00\n",
      " lambda[68]      3.56     12.00      1.00      0.01      6.43    828.23      1.00\n",
      " lambda[69]      3.29     10.88      0.98      0.00      5.91    668.63      1.00\n",
      " lambda[70]      2.72      7.77      0.93      0.00      5.26    852.39      1.00\n",
      " lambda[71]      2.91      8.75      1.00      0.00      5.38    761.68      1.00\n",
      " lambda[72]      2.32      5.50      0.99      0.01      5.06    755.67      1.00\n",
      " lambda[73]      2.88      8.23      0.95      0.00      5.33    644.15      1.00\n",
      " lambda[74]      4.42     41.54      0.97      0.01      6.14    938.16      1.00\n",
      " lambda[75]      4.78     22.42      1.06      0.00      7.16    810.94      1.00\n",
      " lambda[76]      2.59      5.42      1.01      0.00      5.56    639.97      1.00\n",
      " lambda[77]      5.45     43.38      0.97      0.00      5.93    413.01      1.00\n",
      " lambda[78]      2.70      7.24      0.98      0.00      5.31    645.38      1.00\n",
      " lambda[79]      2.50      6.94      0.90      0.00      5.16    972.23      1.00\n",
      " lambda[80]      3.18      8.12      0.98      0.00      6.72    569.44      1.00\n",
      " lambda[81]      2.84      6.88      1.01      0.00      6.22    519.66      1.00\n",
      " lambda[82]      2.58      8.01      0.94      0.00      4.84    745.85      1.00\n",
      " lambda[83]      3.62     11.76      1.05      0.00      6.19    639.38      1.00\n",
      " lambda[84]      3.58     15.54      0.97      0.00      5.42    595.29      1.00\n",
      " lambda[85]      2.70      7.11      0.96      0.00      5.68    481.47      1.00\n",
      " lambda[86]      3.69     13.33      0.95      0.00      6.18    617.58      1.00\n",
      " lambda[87]      2.73      7.49      0.90      0.00      5.69    891.88      1.00\n",
      " lambda[88]      3.06      8.96      0.99      0.01      6.13    462.10      1.00\n",
      " lambda[89]    362.25   5640.72      1.25      0.00     74.10    343.46      1.00\n",
      " lambda[90]      2.39      5.48      0.95      0.00      4.74    771.84      1.00\n",
      " lambda[91]      2.63      6.84      1.01      0.00      5.15    502.96      1.00\n",
      " lambda[92]      2.84      8.95      0.99      0.00      5.24    955.84      1.00\n",
      " lambda[93]      2.61      8.31      0.99      0.00      4.82    619.27      1.00\n",
      " lambda[94]      3.38      9.64      0.98      0.00      6.36    495.80      1.00\n",
      " lambda[95]      3.79     13.44      0.97      0.00      6.87    705.76      1.00\n",
      " lambda[96]      3.64     10.58      1.00      0.00      6.74    517.43      1.00\n",
      " lambda[97]      2.58      6.80      0.96      0.00      4.87    659.07      1.00\n",
      " lambda[98]      4.14     24.05      1.00      0.00      5.33    557.12      1.00\n",
      " lambda[99]      2.59      7.85      0.95      0.00      5.43    994.80      1.00\n",
      "lambda[100]      2.77      6.71      0.97      0.00      6.25    731.09      1.00\n",
      "lambda[101]      3.25      9.37      1.00      0.00      6.72    549.17      1.00\n",
      "lambda[102]      3.15     16.83      0.94      0.00      5.42    793.64      1.00\n",
      "lambda[103]      3.11     12.54      0.92      0.00      6.11    463.88      1.00\n",
      "lambda[104]      2.74      7.85      0.96      0.00      5.20    758.74      1.00\n",
      "lambda[105]      3.28     10.94      0.96      0.00      6.00    544.46      1.00\n",
      "lambda[106]      2.99     11.44      0.93      0.00      5.18    804.76      1.00\n",
      "lambda[107]      3.09      7.88      0.96      0.01      5.74    494.63      1.00\n",
      "lambda[108]      2.61      7.95      0.95      0.00      5.72    888.80      1.00\n",
      "lambda[109]      4.90     25.48      0.99      0.00      7.20    578.05      1.00\n",
      "lambda[110]      3.56     12.51      1.01      0.00      6.19    637.87      1.00\n",
      "lambda[111]     14.51    158.73      1.08      0.00      7.24    231.03      1.00\n",
      "lambda[112]      2.34      5.83      0.96      0.01      4.86    627.54      1.00\n",
      "lambda[113]      3.75     14.25      0.99      0.00      5.96    456.91      1.00\n",
      "lambda[114]      2.64      7.49      0.95      0.00      5.01    609.38      1.00\n",
      "lambda[115]      4.09     30.08      1.00      0.00      6.05    957.76      1.00\n",
      "lambda[116]      2.51      7.06      0.99      0.00      5.15    708.33      1.00\n",
      "lambda[117]      3.36     12.31      0.94      0.00      5.83    681.69      1.00\n",
      "lambda[118]      3.83     24.13      0.96      0.00      5.62    515.35      1.00\n",
      "lambda[119]      3.84     12.56      1.00      0.01      6.55    790.97      1.00\n",
      "lambda[120]      4.54     37.43      0.92      0.00      7.10    999.63      1.00\n",
      "lambda[121]      3.04      8.62      1.02      0.00      5.68    669.88      1.00\n",
      "lambda[122]      3.42     14.84      0.98      0.00      5.75    592.17      1.00\n",
      "lambda[123]      2.55      5.39      0.92      0.00      5.67    685.82      1.00\n",
      "lambda[124]      3.02      9.70      1.00      0.01      5.34    675.03      1.00\n",
      "lambda[125]      2.65      9.62      0.96      0.01      4.83    508.24      1.00\n",
      "lambda[126]      2.58     11.28      0.96      0.00      4.68    878.68      1.00\n",
      "lambda[127]      3.29     15.18      0.95      0.00      5.27    935.56      1.00\n",
      "lambda[128]      4.86     33.39      0.97      0.00      6.87    332.46      1.00\n",
      "lambda[129]      3.49     24.83      0.87      0.00      5.21    869.06      1.00\n",
      "lambda[130]      3.26     12.07      0.93      0.00      6.09    796.97      1.00\n",
      "lambda[131]      4.79     40.44      1.04      0.00      6.42    493.61      1.00\n",
      "lambda[132]      2.69      6.48      0.97      0.00      5.14    645.55      1.01\n",
      "lambda[133]      2.83      7.60      0.95      0.00      5.40    816.31      1.00\n",
      "lambda[134]      3.03      7.30      1.02      0.00      6.57    787.05      1.00\n",
      "lambda[135]      2.51      6.10      0.94      0.00      5.02    804.65      1.00\n",
      "lambda[136]      2.76      7.84      0.94      0.00      6.06    817.61      1.00\n",
      "lambda[137]      3.06     10.88      1.05      0.00      5.60    827.83      1.00\n",
      "lambda[138]      3.46     11.51      0.97      0.00      6.39    611.52      1.00\n",
      "lambda[139]      2.72      6.41      0.96      0.00      5.75    627.65      1.00\n",
      "lambda[140]      3.18     11.93      0.97      0.00      5.80    710.82      1.00\n",
      "lambda[141]      2.92      8.48      0.94      0.00      6.34    657.91      1.00\n",
      "lambda[142]      3.48     12.33      0.98      0.00      6.25    862.29      1.00\n",
      "lambda[143]      2.78     11.43      0.94      0.00      5.51    858.43      1.00\n",
      "        msq 552782.81 17062984.00     52.33      1.91   1800.88    999.45      1.00\n",
      "      sigma      3.42      4.10      1.71      0.00      8.82    949.23      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    622.83      1.00\n",
      "       xisq    350.23   4725.99     19.65      0.73    225.05    908.24      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.57031297683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t2.53e-04 +- 1.90e-02\n",
      "[dimension 02/145]  inactive:\t9.66e-05 +- 3.16e-02\n",
      "[dimension 03/145]  inactive:\t1.83e-04 +- 2.84e-02\n",
      "[dimension 04/145]  inactive:\t4.87e-03 +- 3.87e-02\n",
      "[dimension 05/145]  inactive:\t-3.92e-04 +- 3.03e-02\n",
      "[dimension 06/145]  inactive:\t5.27e-03 +- 5.54e-02\n",
      "[dimension 07/145]  inactive:\t8.45e-04 +- 1.98e-02\n",
      "[dimension 08/145]  inactive:\t6.01e-04 +- 2.49e-02\n",
      "[dimension 09/145]  inactive:\t1.40e-03 +- 3.00e-02\n",
      "[dimension 10/145]  inactive:\t5.44e-04 +- 2.13e-02\n",
      "[dimension 11/145]  inactive:\t-1.18e-03 +- 2.59e-02\n",
      "[dimension 12/145]  inactive:\t9.23e-05 +- 2.73e-02\n",
      "[dimension 13/145]  inactive:\t5.38e-03 +- 4.57e-02\n",
      "[dimension 14/145]  inactive:\t-1.69e-03 +- 2.44e-02\n",
      "[dimension 15/145]  inactive:\t2.04e-03 +- 4.00e-02\n",
      "[dimension 16/145]  inactive:\t9.46e-04 +- 1.99e-02\n",
      "[dimension 17/145]  inactive:\t6.72e-04 +- 3.15e-02\n",
      "[dimension 18/145]  inactive:\t-7.64e-04 +- 2.78e-02\n",
      "[dimension 19/145]  inactive:\t-1.65e-03 +- 1.91e-02\n",
      "[dimension 20/145]  inactive:\t-1.20e-03 +- 2.83e-02\n",
      "[dimension 21/145]  inactive:\t-9.09e-04 +- 2.40e-02\n",
      "[dimension 22/145]  inactive:\t-1.25e-05 +- 2.10e-02\n",
      "[dimension 23/145]  inactive:\t-5.44e-04 +- 2.49e-02\n",
      "[dimension 24/145]  inactive:\t1.74e-03 +- 2.76e-02\n",
      "[dimension 25/145]  inactive:\t3.77e-03 +- 2.56e-02\n",
      "[dimension 26/145]  inactive:\t-4.03e-04 +- 2.25e-02\n",
      "[dimension 27/145]  inactive:\t1.14e-03 +- 2.55e-02\n",
      "[dimension 28/145]  inactive:\t9.63e-04 +- 1.95e-02\n",
      "[dimension 29/145]  inactive:\t6.28e-05 +- 2.88e-02\n",
      "[dimension 30/145]  inactive:\t1.37e-03 +- 3.09e-02\n",
      "[dimension 31/145]  inactive:\t5.15e-03 +- 4.12e-02\n",
      "[dimension 32/145]  inactive:\t-7.17e-04 +- 3.45e-02\n",
      "[dimension 33/145]  inactive:\t1.69e-03 +- 3.33e-02\n",
      "[dimension 34/145]  inactive:\t8.33e-04 +- 1.78e-02\n",
      "[dimension 35/145]  inactive:\t4.41e-04 +- 2.47e-02\n",
      "[dimension 36/145]  inactive:\t9.85e-04 +- 2.67e-02\n",
      "[dimension 37/145]  inactive:\t4.42e-03 +- 2.89e-02\n",
      "[dimension 38/145]  inactive:\t-8.94e-04 +- 3.21e-02\n",
      "[dimension 39/145]  inactive:\t2.79e-03 +- 4.72e-02\n",
      "[dimension 40/145]  inactive:\t4.74e-03 +- 3.61e-02\n",
      "[dimension 41/145]  inactive:\t-1.89e-03 +- 2.82e-02\n",
      "[dimension 42/145]  inactive:\t1.42e-02 +- 9.87e-02\n",
      "[dimension 43/145]  inactive:\t-7.99e-05 +- 1.86e-02\n",
      "[dimension 44/145]  inactive:\t-7.64e-04 +- 3.10e-02\n",
      "[dimension 45/145]  inactive:\t-1.71e-04 +- 2.62e-02\n",
      "[dimension 46/145]  inactive:\t1.02e-03 +- 1.61e-02\n",
      "[dimension 47/145]  inactive:\t-1.52e-03 +- 2.72e-02\n",
      "[dimension 48/145]  inactive:\t1.42e-03 +- 2.39e-02\n",
      "[dimension 49/145]  inactive:\t4.38e-03 +- 3.09e-02\n",
      "[dimension 50/145]  inactive:\t-1.56e-03 +- 2.42e-02\n",
      "[dimension 51/145]  inactive:\t3.50e-03 +- 3.71e-02\n",
      "[dimension 52/145]  inactive:\t5.85e-03 +- 2.58e-02\n",
      "[dimension 53/145]  inactive:\t-4.94e-04 +- 2.32e-02\n",
      "[dimension 54/145]  inactive:\t7.49e-04 +- 2.30e-02\n",
      "[dimension 55/145]  inactive:\t4.84e-04 +- 1.69e-02\n",
      "[dimension 56/145]  inactive:\t-1.64e-03 +- 2.04e-02\n",
      "[dimension 57/145]  inactive:\t1.82e-03 +- 3.56e-02\n",
      "[dimension 58/145]  inactive:\t1.60e-02 +- 8.28e-02\n",
      "[dimension 59/145]  inactive:\t-5.74e-04 +- 2.05e-02\n",
      "[dimension 60/145]  inactive:\t2.12e-03 +- 3.63e-02\n",
      "[dimension 61/145]  inactive:\t2.40e-03 +- 2.38e-02\n",
      "[dimension 62/145]  inactive:\t-5.05e-04 +- 2.11e-02\n",
      "[dimension 63/145]  active:\t6.87e-01 +- 4.30e-01\n",
      "[dimension 64/145]  inactive:\t-2.86e-03 +- 2.72e-02\n",
      "[dimension 65/145]  inactive:\t-4.84e-05 +- 2.44e-02\n",
      "[dimension 66/145]  inactive:\t4.70e-04 +- 2.46e-02\n",
      "[dimension 67/145]  inactive:\t1.29e-03 +- 2.50e-02\n",
      "[dimension 68/145]  inactive:\t-1.58e-03 +- 3.45e-02\n",
      "[dimension 69/145]  inactive:\t6.06e-03 +- 5.73e-02\n",
      "[dimension 70/145]  inactive:\t3.77e-03 +- 2.59e-02\n",
      "[dimension 71/145]  inactive:\t-3.32e-04 +- 2.52e-02\n",
      "[dimension 72/145]  inactive:\t5.15e-04 +- 2.22e-02\n",
      "[dimension 73/145]  inactive:\t5.30e-04 +- 1.71e-02\n",
      "[dimension 74/145]  inactive:\t-1.46e-03 +- 2.78e-02\n",
      "[dimension 75/145]  inactive:\t9.92e-04 +- 2.73e-02\n",
      "[dimension 76/145]  inactive:\t6.03e-03 +- 3.93e-02\n",
      "[dimension 77/145]  inactive:\t-1.23e-03 +- 2.78e-02\n",
      "[dimension 78/145]  inactive:\t6.93e-03 +- 6.27e-02\n",
      "[dimension 79/145]  inactive:\t4.56e-03 +- 2.83e-02\n",
      "[dimension 80/145]  inactive:\t-4.47e-04 +- 2.78e-02\n",
      "[dimension 81/145]  inactive:\t6.79e-04 +- 3.23e-02\n",
      "[dimension 82/145]  inactive:\t3.44e-04 +- 1.91e-02\n",
      "[dimension 83/145]  inactive:\t-1.33e-03 +- 2.09e-02\n",
      "[dimension 84/145]  inactive:\t-2.33e-03 +- 3.30e-02\n",
      "[dimension 85/145]  inactive:\t4.75e-03 +- 4.42e-02\n",
      "[dimension 86/145]  inactive:\t-5.89e-04 +- 1.96e-02\n",
      "[dimension 87/145]  inactive:\t4.90e-03 +- 5.54e-02\n",
      "[dimension 88/145]  inactive:\t2.35e-03 +- 2.31e-02\n",
      "[dimension 89/145]  inactive:\t-9.84e-04 +- 2.21e-02\n",
      "[dimension 90/145]  inactive:\t1.05e-01 +- 2.86e-01\n",
      "[dimension 91/145]  inactive:\t5.08e-05 +- 1.83e-02\n",
      "[dimension 92/145]  inactive:\t-1.29e-03 +- 2.23e-02\n",
      "[dimension 93/145]  inactive:\t-7.62e-04 +- 2.69e-02\n",
      "[dimension 94/145]  inactive:\t1.56e-03 +- 2.37e-02\n",
      "[dimension 95/145]  inactive:\t-4.94e-04 +- 3.05e-02\n",
      "[dimension 96/145]  inactive:\t1.89e-03 +- 4.42e-02\n",
      "[dimension 97/145]  inactive:\t4.11e-03 +- 2.99e-02\n",
      "[dimension 98/145]  inactive:\t-3.73e-04 +- 2.18e-02\n",
      "[dimension 99/145]  inactive:\t3.58e-03 +- 4.87e-02\n",
      "[dimension 100/145]  inactive:\t-4.77e-04 +- 1.82e-02\n",
      "[dimension 101/145]  inactive:\t-1.80e-03 +- 2.08e-02\n",
      "[dimension 102/145]  inactive:\t-1.07e-03 +- 2.55e-02\n",
      "[dimension 103/145]  inactive:\t1.20e-03 +- 2.45e-02\n",
      "[dimension 104/145]  inactive:\t-1.15e-03 +- 1.96e-02\n",
      "[dimension 105/145]  inactive:\t1.42e-05 +- 2.84e-02\n",
      "[dimension 106/145]  inactive:\t5.13e-03 +- 3.88e-02\n",
      "[dimension 107/145]  inactive:\t-9.15e-04 +- 2.13e-02\n",
      "[dimension 108/145]  inactive:\t1.44e-03 +- 3.24e-02\n",
      "[dimension 109/145]  inactive:\t-1.66e-04 +- 1.69e-02\n",
      "[dimension 110/145]  inactive:\t-1.49e-03 +- 3.53e-02\n",
      "[dimension 111/145]  inactive:\t3.49e-03 +- 4.22e-02\n",
      "[dimension 112/145]  inactive:\t1.54e-02 +- 9.83e-02\n",
      "[dimension 113/145]  inactive:\t-1.19e-03 +- 2.18e-02\n",
      "[dimension 114/145]  inactive:\t2.42e-03 +- 4.48e-02\n",
      "[dimension 115/145]  inactive:\t1.67e-03 +- 1.98e-02\n",
      "[dimension 116/145]  inactive:\t1.15e-04 +- 3.32e-02\n",
      "[dimension 117/145]  inactive:\t1.74e-03 +- 2.68e-02\n",
      "[dimension 118/145]  inactive:\t2.94e-03 +- 2.54e-02\n",
      "[dimension 119/145]  inactive:\t-2.10e-03 +- 3.25e-02\n",
      "[dimension 120/145]  inactive:\t-2.48e-04 +- 3.86e-02\n",
      "[dimension 121/145]  inactive:\t5.13e-03 +- 4.19e-02\n",
      "[dimension 122/145]  inactive:\t-2.71e-03 +- 3.35e-02\n",
      "[dimension 123/145]  inactive:\t3.31e-03 +- 4.85e-02\n",
      "[dimension 124/145]  inactive:\t-1.49e-03 +- 2.04e-02\n",
      "[dimension 125/145]  inactive:\t-1.84e-03 +- 2.78e-02\n",
      "[dimension 126/145]  inactive:\t-6.14e-04 +- 2.33e-02\n",
      "[dimension 127/145]  inactive:\t-6.24e-05 +- 1.71e-02\n",
      "[dimension 128/145]  inactive:\t-4.77e-04 +- 3.00e-02\n",
      "[dimension 129/145]  inactive:\t7.58e-04 +- 2.82e-02\n",
      "[dimension 130/145]  inactive:\t3.54e-03 +- 3.06e-02\n",
      "[dimension 131/145]  inactive:\t-1.12e-03 +- 2.68e-02\n",
      "[dimension 132/145]  inactive:\t3.47e-03 +- 3.69e-02\n",
      "[dimension 133/145]  inactive:\t2.22e-03 +- 2.04e-02\n",
      "[dimension 134/145]  inactive:\t-6.77e-04 +- 2.48e-02\n",
      "[dimension 135/145]  inactive:\t6.72e-04 +- 2.61e-02\n",
      "[dimension 136/145]  inactive:\t8.56e-04 +- 1.90e-02\n",
      "[dimension 137/145]  inactive:\t-5.09e-04 +- 2.93e-02\n",
      "[dimension 138/145]  inactive:\t2.08e-04 +- 2.58e-02\n",
      "[dimension 139/145]  inactive:\t3.53e-04 +- 2.65e-02\n",
      "[dimension 140/145]  inactive:\t-8.11e-04 +- 2.93e-02\n",
      "[dimension 141/145]  inactive:\t1.23e-03 +- 2.54e-02\n",
      "[dimension 142/145]  inactive:\t1.42e-03 +- 1.95e-02\n",
      "[dimension 143/145]  inactive:\t1.92e-03 +- 4.06e-02\n",
      "[dimension 144/145]  inactive:\t5.05e-04 +- 2.10e-02\n",
      "[dimension 145/145]  inactive:\t1.59e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[7.635355e-05]\n",
      "cov_act[[7.800758e-06]]\n",
      "Active_dimensions: [62]\n",
      "73, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:36<00:00, 40.80it/s, 31 steps of size 1.53e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    575.03      1.00\n",
      "  lambda[0]      2.29      5.52      0.96      0.00      4.62    815.50      1.00\n",
      "  lambda[1]      3.07      8.73      1.03      0.00      5.64    548.63      1.00\n",
      "  lambda[2]      2.92     10.03      0.98      0.00      5.56    642.00      1.00\n",
      "  lambda[3]      3.54     11.96      1.02      0.00      6.31    723.19      1.00\n",
      "  lambda[4]      3.12     10.52      1.06      0.00      5.33    552.29      1.00\n",
      "  lambda[5]      3.29     12.96      0.95      0.00      6.05    866.56      1.00\n",
      "  lambda[6]      4.32     16.98      1.06      0.00      6.97    522.87      1.00\n",
      "  lambda[7]      3.41     12.79      0.96      0.00      6.38    486.99      1.00\n",
      "  lambda[8]      2.49      4.46      1.00      0.00      5.60    853.39      1.00\n",
      "  lambda[9]      2.86      8.49      0.99      0.00      5.57    478.07      1.00\n",
      " lambda[10]      3.47     10.38      1.05      0.00      6.40    586.29      1.00\n",
      " lambda[11]      2.58      5.59      1.00      0.01      6.04    853.51      1.00\n",
      " lambda[12]      4.89     27.02      0.98      0.00      7.58    690.25      1.00\n",
      " lambda[13]      2.88      9.38      0.97      0.00      6.05    784.95      1.00\n",
      " lambda[14]      4.31     20.21      0.92      0.00      5.46    528.07      1.00\n",
      " lambda[15]      3.41     10.54      1.00      0.00      6.00    693.66      1.00\n",
      " lambda[16]      3.39      9.57      0.99      0.00      7.73    688.86      1.00\n",
      " lambda[17]      3.22     18.68      0.96      0.00      4.83    691.99      1.00\n",
      " lambda[18]      2.77      6.77      0.99      0.00      6.05    438.80      1.01\n",
      " lambda[19]      2.84      6.73      0.95      0.00      6.42    414.97      1.01\n",
      " lambda[20]      2.60      6.26      0.93      0.00      5.49    787.28      1.00\n",
      " lambda[21]      3.57     16.29      0.99      0.00      5.97    821.21      1.00\n",
      " lambda[22]      3.05     13.29      1.01      0.00      5.19    470.55      1.00\n",
      " lambda[23]      3.30     10.36      0.98      0.00      6.03    773.61      1.00\n",
      " lambda[24]      3.29     10.92      1.01      0.00      6.01    636.98      1.00\n",
      " lambda[25]      3.73     14.32      0.97      0.01      7.10    455.00      1.00\n",
      " lambda[26]      3.22     12.44      0.97      0.00      5.91    762.93      1.00\n",
      " lambda[27]      3.04      8.19      0.98      0.00      5.57    606.07      1.00\n",
      " lambda[28]      2.80      7.39      1.07      0.00      5.37    664.05      1.00\n",
      " lambda[29]      2.74      6.66      0.94      0.00      5.83    639.38      1.00\n",
      " lambda[30]      3.84     14.56      1.03      0.01      7.37    513.25      1.00\n",
      " lambda[31]      3.84     15.11      1.01      0.00      6.94    758.28      1.00\n",
      " lambda[32]      3.19      9.13      0.97      0.00      6.66    510.51      1.00\n",
      " lambda[33]      3.28     10.10      0.95      0.00      6.95    736.94      1.00\n",
      " lambda[34]      2.52      8.23      0.97      0.00      4.98    683.36      1.00\n",
      " lambda[35]      2.52      6.63      1.00      0.00      4.98    843.88      1.00\n",
      " lambda[36]      3.53     13.17      1.05      0.00      5.68    773.65      1.00\n",
      " lambda[37]      3.31     11.14      0.99      0.00      5.95    712.69      1.00\n",
      " lambda[38]      3.00      8.24      0.86      0.00      6.41    830.59      1.00\n",
      " lambda[39]      3.55     17.58      0.96      0.00      5.56    354.62      1.00\n",
      " lambda[40]      4.14     15.01      0.92      0.00      8.01    624.57      1.00\n",
      " lambda[41]     47.82    794.63      0.96      0.00      8.25    404.41      1.00\n",
      " lambda[42]      2.57      6.35      0.91      0.00      4.93    635.77      1.00\n",
      " lambda[43]      3.62     22.52      0.98      0.00      5.72    964.10      1.00\n",
      " lambda[44]      2.66      9.43      0.92      0.00      5.09    873.50      1.00\n",
      " lambda[45]      2.48      5.39      1.00      0.00      5.50    829.04      1.00\n",
      " lambda[46]      2.60      6.68      1.00      0.01      5.03    741.28      1.00\n",
      " lambda[47]      2.82      6.65      0.96      0.00      6.16    346.04      1.00\n",
      " lambda[48]      2.68      7.92      1.01      0.01      5.50    762.54      1.00\n",
      " lambda[49]      2.65      7.50      0.93      0.00      5.15    856.82      1.00\n",
      " lambda[50]      2.69      6.96      1.00      0.00      5.11    660.02      1.00\n",
      " lambda[51]      4.12     13.71      1.06      0.00      6.42    791.03      1.00\n",
      " lambda[52]      3.13      8.31      0.97      0.00      5.86    571.73      1.00\n",
      " lambda[53]      2.83      7.16      0.93      0.00      5.65    627.23      1.00\n",
      " lambda[54]      2.08      4.65      0.92      0.00      4.42    546.08      1.00\n",
      " lambda[55]      3.54     17.04      0.97      0.00      5.33    751.75      1.00\n",
      " lambda[56]      2.65      5.93      1.01      0.00      5.23    667.77      1.00\n",
      " lambda[57]      3.38     10.73      0.95      0.00      5.73    635.98      1.01\n",
      " lambda[58]      2.48      6.62      0.96      0.00      4.71    766.71      1.00\n",
      " lambda[59]      3.53     10.99      0.97      0.00      7.01    373.57      1.00\n",
      " lambda[60]      2.70      6.97      0.95      0.00      5.40    604.84      1.00\n",
      " lambda[61]      2.67      5.33      1.01      0.00      6.55    704.50      1.00\n",
      " lambda[62]   6514.61  64593.67    383.32      0.01   3158.91    627.71      1.00\n",
      " lambda[63]      2.14      4.53      0.98      0.00      4.80    801.12      1.00\n",
      " lambda[64]      3.05      9.25      0.98      0.00      5.65    751.61      1.00\n",
      " lambda[65]      3.68     14.14      0.98      0.00      7.00    683.77      1.00\n",
      " lambda[66]      3.38     11.89      0.98      0.00      6.70    780.03      1.00\n",
      " lambda[67]      2.61      6.99      0.93      0.00      5.29    754.35      1.00\n",
      " lambda[68]      2.53      5.86      0.92      0.00      5.44    797.90      1.00\n",
      " lambda[69]      4.22     17.39      0.96      0.00      6.83    657.52      1.00\n",
      " lambda[70]      3.02      9.54      0.98      0.00      5.74    673.09      1.00\n",
      " lambda[71]      2.87     13.55      0.99      0.00      4.94    784.76      1.00\n",
      " lambda[72]      3.38     12.34      1.00      0.00      5.43    354.80      1.00\n",
      " lambda[73]      2.61      5.79      1.04      0.00      5.52    711.65      1.00\n",
      " lambda[74]      2.19      3.93      1.03      0.00      4.94    964.20      1.00\n",
      " lambda[75]      5.22     42.22      0.99      0.00      6.31    488.03      1.00\n",
      " lambda[76]      2.75      6.90      0.98      0.00      5.53    820.40      1.00\n",
      " lambda[77]      3.88     23.23      1.05      0.00      5.50    452.08      1.00\n",
      " lambda[78]      3.55     12.09      1.03      0.00      5.86    634.43      1.00\n",
      " lambda[79]      2.75      7.05      1.04      0.00      5.44    784.50      1.00\n",
      " lambda[80]      4.11     20.54      1.01      0.00      6.39    648.52      1.00\n",
      " lambda[81]      2.35      5.43      0.91      0.00      4.99    977.21      1.00\n",
      " lambda[82]      2.62     10.96      0.96      0.00      4.67    755.13      1.00\n",
      " lambda[83]      2.90      9.06      0.99      0.00      5.04    733.21      1.00\n",
      " lambda[84]      3.85     21.80      0.97      0.00      6.27    863.68      1.00\n",
      " lambda[85]      2.83      8.24      0.99      0.00      6.02    650.24      1.00\n",
      " lambda[86]      3.57     16.86      0.99      0.00      6.09    805.40      1.00\n",
      " lambda[87]      3.12     11.27      0.96      0.01      5.80    583.12      1.00\n",
      " lambda[88]      2.83      7.18      0.93      0.00      6.01    771.64      1.00\n",
      " lambda[89]    180.80   2403.45      1.09      0.00     53.97    435.37      1.00\n",
      " lambda[90]      2.52      5.57      1.00      0.00      5.39    436.49      1.00\n",
      " lambda[91]      2.49      7.54      0.92      0.01      4.62    722.97      1.00\n",
      " lambda[92]      2.43      5.06      0.98      0.00      5.16    682.52      1.01\n",
      " lambda[93]      2.38      5.17      0.94      0.00      5.02    670.61      1.00\n",
      " lambda[94]      2.68      8.22      0.90      0.00      5.58    668.42      1.00\n",
      " lambda[95]      3.06     11.99      0.99      0.00      6.05    586.78      1.00\n",
      " lambda[96]      2.49      5.38      0.97      0.00      5.35    532.77      1.00\n",
      " lambda[97]      3.19     12.30      1.02      0.00      5.76    724.17      1.00\n",
      " lambda[98]      3.97     27.22      0.95      0.00      5.56    414.64      1.00\n",
      " lambda[99]      2.45      5.76      0.97      0.00      5.18    888.51      1.00\n",
      "lambda[100]      3.09     10.95      0.91      0.01      6.36    704.17      1.00\n",
      "lambda[101]      2.85      8.24      0.96      0.00      5.84    729.96      1.00\n",
      "lambda[102]      2.55      6.19      0.92      0.00      5.12    734.21      1.00\n",
      "lambda[103]      2.35      4.82      0.97      0.00      4.96    544.71      1.00\n",
      "lambda[104]      3.01     14.08      0.99      0.00      5.67    745.37      1.00\n",
      "lambda[105]      2.86      6.52      1.01      0.00      6.58    673.58      1.00\n",
      "lambda[106]      2.76      7.17      1.04      0.01      5.67    421.26      1.00\n",
      "lambda[107]      3.99     15.37      1.00      0.00      6.54    438.35      1.01\n",
      "lambda[108]      2.39      9.75      0.97      0.00      4.92    905.25      1.00\n",
      "lambda[109]      4.44     35.31      0.97      0.00      7.28    981.46      1.00\n",
      "lambda[110]      3.23      9.23      1.03      0.00      6.03    780.56      1.00\n",
      "lambda[111]      2.69      7.82      0.89      0.00      5.51    892.66      1.00\n",
      "lambda[112]      2.62      5.84      0.93      0.00      6.15    918.77      1.00\n",
      "lambda[113]      3.19     11.89      1.01      0.00      5.48    670.20      1.00\n",
      "lambda[114]      4.29     14.83      1.02      0.00      7.44    692.96      1.00\n",
      "lambda[115]      3.85     14.87      0.96      0.00      6.14    724.21      1.00\n",
      "lambda[116]      8.26    142.75      1.07      0.00      5.58    965.07      1.00\n",
      "lambda[117]      3.37     11.96      0.96      0.00      6.21    886.49      1.00\n",
      "lambda[118]      3.23     10.48      0.97      0.00      6.34    756.82      1.00\n",
      "lambda[119]      2.78      8.41      0.97      0.00      5.79    932.57      1.00\n",
      "lambda[120]      4.37     26.39      0.96      0.00      6.77    889.18      1.00\n",
      "lambda[121]      3.79     14.30      0.91      0.00      5.84    693.62      1.00\n",
      "lambda[122]      3.17     11.14      0.97      0.00      5.83    946.13      1.00\n",
      "lambda[123]      2.56      5.53      0.91      0.00      5.60    672.07      1.00\n",
      "lambda[124]      2.49      4.82      0.98      0.00      5.73    621.89      1.00\n",
      "lambda[125]      2.95      7.66      0.97      0.00      6.36    433.29      1.00\n",
      "lambda[126]      2.57      6.83      0.91      0.00      5.22    655.41      1.00\n",
      "lambda[127]      3.98     16.40      0.96      0.00      6.17    844.21      1.00\n",
      "lambda[128]      2.83      9.38      0.95      0.00      4.76    375.97      1.00\n",
      "lambda[129]      3.66     14.31      1.01      0.00      7.41    940.63      1.00\n",
      "lambda[130]      3.31      9.12      0.99      0.00      6.18    591.32      1.00\n",
      "lambda[131]      3.36     12.82      0.97      0.00      6.54    700.65      1.00\n",
      "lambda[132]      2.82      6.95      0.97      0.00      5.88    833.84      1.00\n",
      "lambda[133]      2.38      5.95      1.00      0.00      4.91    937.64      1.00\n",
      "lambda[134]      3.89     16.76      0.95      0.00      7.40    730.78      1.00\n",
      "lambda[135]      2.57      8.30      0.89      0.00      4.76    718.18      1.00\n",
      "lambda[136]      3.25      8.48      0.99      0.00      6.37    608.50      1.00\n",
      "lambda[137]      2.65      7.05      0.96      0.00      5.48    636.62      1.00\n",
      "lambda[138]      3.15     12.24      1.02      0.00      5.03    802.08      1.00\n",
      "lambda[139]      3.15      9.34      1.06      0.00      5.77    823.85      1.00\n",
      "lambda[140]      2.96      7.84      0.95      0.00      5.72    611.26      1.00\n",
      "lambda[141]      2.72      9.56      0.92      0.00      5.12    572.54      1.00\n",
      "lambda[142]      3.66     14.28      0.98      0.01      5.74    668.23      1.00\n",
      "lambda[143]      2.54      5.51      0.97      0.00      5.45    721.85      1.00\n",
      "        msq      1.64      1.20      1.34      0.52      2.89    760.99      1.00\n",
      "      sigma      2.85      4.05      1.12      0.00      8.16   1377.13      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    770.07      1.00\n",
      "       xisq     16.20     36.81      6.70      0.73     32.32    817.25      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 41.583377838134766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.16e-04 +- 1.05e-02\n",
      "[dimension 02/145]  inactive:\t6.42e-04 +- 1.86e-02\n",
      "[dimension 03/145]  inactive:\t2.97e-04 +- 1.31e-02\n",
      "[dimension 04/145]  inactive:\t2.32e-03 +- 2.30e-02\n",
      "[dimension 05/145]  inactive:\t7.83e-05 +- 1.51e-02\n",
      "[dimension 06/145]  inactive:\t8.41e-04 +- 2.24e-02\n",
      "[dimension 07/145]  inactive:\t8.50e-04 +- 1.41e-02\n",
      "[dimension 08/145]  inactive:\t3.50e-04 +- 1.51e-02\n",
      "[dimension 09/145]  inactive:\t6.30e-04 +- 1.62e-02\n",
      "[dimension 10/145]  inactive:\t3.49e-04 +- 1.15e-02\n",
      "[dimension 11/145]  inactive:\t-1.04e-04 +- 1.51e-02\n",
      "[dimension 12/145]  inactive:\t1.31e-04 +- 1.57e-02\n",
      "[dimension 13/145]  inactive:\t2.09e-03 +- 2.51e-02\n",
      "[dimension 14/145]  inactive:\t-1.69e-04 +- 1.78e-02\n",
      "[dimension 15/145]  inactive:\t9.06e-04 +- 2.68e-02\n",
      "[dimension 16/145]  inactive:\t6.13e-04 +- 1.54e-02\n",
      "[dimension 17/145]  inactive:\t6.44e-04 +- 2.15e-02\n",
      "[dimension 18/145]  inactive:\t1.85e-04 +- 1.42e-02\n",
      "[dimension 19/145]  inactive:\t-6.14e-04 +- 1.20e-02\n",
      "[dimension 20/145]  inactive:\t-1.63e-04 +- 1.63e-02\n",
      "[dimension 21/145]  inactive:\t-4.35e-04 +- 1.29e-02\n",
      "[dimension 22/145]  inactive:\t3.80e-04 +- 1.32e-02\n",
      "[dimension 23/145]  inactive:\t-1.52e-04 +- 2.01e-02\n",
      "[dimension 24/145]  inactive:\t9.17e-04 +- 1.83e-02\n",
      "[dimension 25/145]  inactive:\t1.91e-03 +- 1.67e-02\n",
      "[dimension 26/145]  inactive:\t-6.01e-05 +- 1.62e-02\n",
      "[dimension 27/145]  inactive:\t6.36e-04 +- 1.67e-02\n",
      "[dimension 28/145]  inactive:\t7.62e-04 +- 1.40e-02\n",
      "[dimension 29/145]  inactive:\t1.87e-04 +- 1.66e-02\n",
      "[dimension 30/145]  inactive:\t4.34e-04 +- 1.44e-02\n",
      "[dimension 31/145]  inactive:\t2.59e-03 +- 2.45e-02\n",
      "[dimension 32/145]  inactive:\t7.14e-04 +- 3.22e-02\n",
      "[dimension 33/145]  inactive:\t1.75e-03 +- 3.04e-02\n",
      "[dimension 34/145]  inactive:\t5.77e-04 +- 1.36e-02\n",
      "[dimension 35/145]  inactive:\t1.30e-03 +- 2.78e-02\n",
      "[dimension 36/145]  inactive:\t6.51e-04 +- 1.63e-02\n",
      "[dimension 37/145]  inactive:\t1.88e-03 +- 1.64e-02\n",
      "[dimension 38/145]  inactive:\t-2.51e-04 +- 1.75e-02\n",
      "[dimension 39/145]  inactive:\t4.93e-04 +- 1.66e-02\n",
      "[dimension 40/145]  inactive:\t2.57e-03 +- 2.66e-02\n",
      "[dimension 41/145]  inactive:\t-2.44e-04 +- 2.27e-02\n",
      "[dimension 42/145]  inactive:\t1.38e-02 +- 1.02e-01\n",
      "[dimension 43/145]  inactive:\t1.52e-04 +- 1.16e-02\n",
      "[dimension 44/145]  inactive:\t-6.01e-05 +- 1.82e-02\n",
      "[dimension 45/145]  inactive:\t2.97e-04 +- 1.48e-02\n",
      "[dimension 46/145]  inactive:\t5.52e-04 +- 1.06e-02\n",
      "[dimension 47/145]  inactive:\t-4.14e-04 +- 1.44e-02\n",
      "[dimension 48/145]  inactive:\t5.31e-04 +- 1.57e-02\n",
      "[dimension 49/145]  inactive:\t1.28e-03 +- 1.75e-02\n",
      "[dimension 50/145]  inactive:\t-4.32e-04 +- 1.52e-02\n",
      "[dimension 51/145]  inactive:\t6.63e-04 +- 1.46e-02\n",
      "[dimension 52/145]  inactive:\t3.26e-03 +- 1.83e-02\n",
      "[dimension 53/145]  inactive:\t-2.75e-04 +- 1.77e-02\n",
      "[dimension 54/145]  inactive:\t9.65e-05 +- 1.26e-02\n",
      "[dimension 55/145]  inactive:\t2.43e-04 +- 9.27e-03\n",
      "[dimension 56/145]  inactive:\t-1.31e-03 +- 1.63e-02\n",
      "[dimension 57/145]  inactive:\t4.45e-04 +- 1.75e-02\n",
      "[dimension 58/145]  inactive:\t3.97e-03 +- 3.78e-02\n",
      "[dimension 59/145]  inactive:\t-3.82e-04 +- 1.10e-02\n",
      "[dimension 60/145]  inactive:\t1.04e-03 +- 2.25e-02\n",
      "[dimension 61/145]  inactive:\t1.42e-03 +- 1.67e-02\n",
      "[dimension 62/145]  inactive:\t-2.96e-04 +- 1.23e-02\n",
      "[dimension 63/145]  active:\t7.75e-01 +- 3.67e-01\n",
      "[dimension 64/145]  inactive:\t-6.46e-04 +- 1.18e-02\n",
      "[dimension 65/145]  inactive:\t-1.53e-05 +- 1.31e-02\n",
      "[dimension 66/145]  inactive:\t8.84e-04 +- 1.91e-02\n",
      "[dimension 67/145]  inactive:\t8.71e-04 +- 1.66e-02\n",
      "[dimension 68/145]  inactive:\t1.15e-05 +- 1.47e-02\n",
      "[dimension 69/145]  inactive:\t7.44e-04 +- 1.50e-02\n",
      "[dimension 70/145]  inactive:\t2.72e-03 +- 2.01e-02\n",
      "[dimension 71/145]  inactive:\t5.98e-05 +- 1.52e-02\n",
      "[dimension 72/145]  inactive:\t3.41e-04 +- 1.31e-02\n",
      "[dimension 73/145]  inactive:\t3.52e-04 +- 1.14e-02\n",
      "[dimension 74/145]  inactive:\t-4.22e-06 +- 1.84e-02\n",
      "[dimension 75/145]  inactive:\t2.00e-04 +- 1.18e-02\n",
      "[dimension 76/145]  inactive:\t3.68e-03 +- 3.87e-02\n",
      "[dimension 77/145]  inactive:\t-3.68e-04 +- 1.83e-02\n",
      "[dimension 78/145]  inactive:\t4.84e-03 +- 5.34e-02\n",
      "[dimension 79/145]  inactive:\t3.87e-03 +- 2.78e-02\n",
      "[dimension 80/145]  inactive:\t3.64e-04 +- 2.04e-02\n",
      "[dimension 81/145]  inactive:\t1.01e-03 +- 2.18e-02\n",
      "[dimension 82/145]  inactive:\t1.10e-04 +- 8.79e-03\n",
      "[dimension 83/145]  inactive:\t-7.78e-04 +- 1.24e-02\n",
      "[dimension 84/145]  inactive:\t-2.98e-04 +- 1.55e-02\n",
      "[dimension 85/145]  inactive:\t1.21e-03 +- 1.83e-02\n",
      "[dimension 86/145]  inactive:\t-2.41e-04 +- 1.16e-02\n",
      "[dimension 87/145]  inactive:\t2.15e-03 +- 3.10e-02\n",
      "[dimension 88/145]  inactive:\t1.08e-03 +- 1.41e-02\n",
      "[dimension 89/145]  inactive:\t-2.94e-04 +- 1.23e-02\n",
      "[dimension 90/145]  inactive:\t8.61e-02 +- 2.61e-01\n",
      "[dimension 91/145]  inactive:\t8.31e-05 +- 9.82e-03\n",
      "[dimension 92/145]  inactive:\t-2.59e-04 +- 1.22e-02\n",
      "[dimension 93/145]  inactive:\t-4.76e-05 +- 1.57e-02\n",
      "[dimension 94/145]  inactive:\t4.66e-04 +- 1.31e-02\n",
      "[dimension 95/145]  inactive:\t-2.02e-05 +- 1.38e-02\n",
      "[dimension 96/145]  inactive:\t1.01e-03 +- 2.92e-02\n",
      "[dimension 97/145]  inactive:\t1.09e-03 +- 1.37e-02\n",
      "[dimension 98/145]  inactive:\t-2.77e-04 +- 1.58e-02\n",
      "[dimension 99/145]  inactive:\t1.03e-03 +- 2.15e-02\n",
      "[dimension 100/145]  inactive:\t-1.59e-04 +- 1.03e-02\n",
      "[dimension 101/145]  inactive:\t-7.30e-04 +- 1.15e-02\n",
      "[dimension 102/145]  inactive:\t-6.11e-06 +- 1.49e-02\n",
      "[dimension 103/145]  inactive:\t2.12e-04 +- 1.24e-02\n",
      "[dimension 104/145]  inactive:\t-2.18e-04 +- 9.79e-03\n",
      "[dimension 105/145]  inactive:\t5.58e-05 +- 1.43e-02\n",
      "[dimension 106/145]  inactive:\t1.98e-03 +- 1.94e-02\n",
      "[dimension 107/145]  inactive:\t-4.19e-04 +- 1.33e-02\n",
      "[dimension 108/145]  inactive:\t3.25e-03 +- 4.82e-02\n",
      "[dimension 109/145]  inactive:\t-3.63e-05 +- 1.14e-02\n",
      "[dimension 110/145]  inactive:\t-1.02e-04 +- 2.07e-02\n",
      "[dimension 111/145]  inactive:\t1.61e-03 +- 2.79e-02\n",
      "[dimension 112/145]  inactive:\t1.54e-03 +- 2.30e-02\n",
      "[dimension 113/145]  inactive:\t-3.96e-04 +- 1.17e-02\n",
      "[dimension 114/145]  inactive:\t1.93e-04 +- 1.55e-02\n",
      "[dimension 115/145]  inactive:\t1.84e-03 +- 1.96e-02\n",
      "[dimension 116/145]  inactive:\t1.57e-03 +- 3.91e-02\n",
      "[dimension 117/145]  inactive:\t4.71e-03 +- 5.32e-02\n",
      "[dimension 118/145]  inactive:\t1.21e-03 +- 1.39e-02\n",
      "[dimension 119/145]  inactive:\t-4.79e-04 +- 1.95e-02\n",
      "[dimension 120/145]  inactive:\t1.59e-04 +- 1.41e-02\n",
      "[dimension 121/145]  inactive:\t2.61e-03 +- 2.71e-02\n",
      "[dimension 122/145]  inactive:\t-7.25e-04 +- 1.82e-02\n",
      "[dimension 123/145]  inactive:\t1.18e-03 +- 3.00e-02\n",
      "[dimension 124/145]  inactive:\t-3.55e-04 +- 1.12e-02\n",
      "[dimension 125/145]  inactive:\t-2.42e-04 +- 1.31e-02\n",
      "[dimension 126/145]  inactive:\t-2.53e-04 +- 1.28e-02\n",
      "[dimension 127/145]  inactive:\t2.42e-04 +- 1.06e-02\n",
      "[dimension 128/145]  inactive:\t1.53e-04 +- 2.21e-02\n",
      "[dimension 129/145]  inactive:\t5.83e-04 +- 1.88e-02\n",
      "[dimension 130/145]  inactive:\t1.54e-03 +- 1.80e-02\n",
      "[dimension 131/145]  inactive:\t-7.51e-05 +- 1.67e-02\n",
      "[dimension 132/145]  inactive:\t1.81e-03 +- 2.59e-02\n",
      "[dimension 133/145]  inactive:\t1.27e-03 +- 1.42e-02\n",
      "[dimension 134/145]  inactive:\t-1.10e-04 +- 1.55e-02\n",
      "[dimension 135/145]  inactive:\t1.13e-03 +- 2.87e-02\n",
      "[dimension 136/145]  inactive:\t5.90e-04 +- 1.18e-02\n",
      "[dimension 137/145]  inactive:\t3.35e-04 +- 2.07e-02\n",
      "[dimension 138/145]  inactive:\t2.58e-04 +- 1.30e-02\n",
      "[dimension 139/145]  inactive:\t7.34e-04 +- 1.64e-02\n",
      "[dimension 140/145]  inactive:\t1.27e-04 +- 2.09e-02\n",
      "[dimension 141/145]  inactive:\t5.82e-04 +- 1.51e-02\n",
      "[dimension 142/145]  inactive:\t1.14e-03 +- 1.39e-02\n",
      "[dimension 143/145]  inactive:\t1.04e-03 +- 2.36e-02\n",
      "[dimension 144/145]  inactive:\t3.52e-04 +- 1.29e-02\n",
      "[dimension 145/145]  inactive:\t-3.04e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8984237]\n",
      "cov_act[[0.01995712]]\n",
      "Active_dimensions: [62]\n",
      "74, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.91it/s, 15 steps of size 1.94e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    599.85      1.00\n",
      "  lambda[0]      2.39      9.32      0.90      0.00      4.94    996.44      1.00\n",
      "  lambda[1]      3.01     10.64      0.93      0.00      4.67    719.06      1.00\n",
      "  lambda[2]      2.61      5.72      0.95      0.00      5.27    437.82      1.00\n",
      "  lambda[3]      5.97     47.78      1.01      0.00      6.97    527.67      1.00\n",
      "  lambda[4]      2.87      7.57      0.97      0.00      5.90    623.83      1.01\n",
      "  lambda[5]      4.59     24.01      1.03      0.00      6.98    413.44      1.00\n",
      "  lambda[6]      2.66      7.37      1.02      0.00      5.69    779.34      1.00\n",
      "  lambda[7]      2.57      5.69      0.90      0.01      5.57    823.92      1.00\n",
      "  lambda[8]      2.33      4.59      0.99      0.01      5.11    946.65      1.00\n",
      "  lambda[9]      2.44      6.45      0.95      0.00      4.40    919.03      1.00\n",
      " lambda[10]      3.42     12.66      1.02      0.00      5.19    679.16      1.01\n",
      " lambda[11]      3.92     26.51      1.04      0.00      6.34    492.66      1.00\n",
      " lambda[12]      4.25     14.87      1.14      0.00      7.14    483.02      1.00\n",
      " lambda[13]      3.12      9.18      0.96      0.00      5.61    567.47      1.00\n",
      " lambda[14]      3.73     14.23      1.04      0.00      5.73    528.00      1.00\n",
      " lambda[15]      2.42      6.72      0.95      0.00      4.82    909.76      1.00\n",
      " lambda[16]      3.12      7.03      0.99      0.00      7.04    694.48      1.00\n",
      " lambda[17]      3.73     30.76      0.95      0.00      5.67    669.49      1.00\n",
      " lambda[18]      3.12     10.45      0.96      0.00      5.60    835.40      1.00\n",
      " lambda[19]      3.26      8.53      1.03      0.00      6.81    404.49      1.01\n",
      " lambda[20]      3.03     14.24      0.95      0.00      6.22    874.86      1.00\n",
      " lambda[21]      2.65      6.96      0.98      0.00      6.03    777.65      1.00\n",
      " lambda[22]      2.98      8.03      1.06      0.00      5.75    683.89      1.00\n",
      " lambda[23]      3.87     19.36      1.08      0.00      5.47    819.21      1.00\n",
      " lambda[24]      3.19     10.04      1.02      0.00      6.44    902.49      1.00\n",
      " lambda[25]      2.79      6.36      0.96      0.00      5.99    500.68      1.00\n",
      " lambda[26]      3.04     10.85      1.02      0.00      6.01    615.36      1.00\n",
      " lambda[27]      2.70      6.69      0.94      0.00      5.86    579.71      1.00\n",
      " lambda[28]      2.80      7.36      1.09      0.01      5.72    759.40      1.00\n",
      " lambda[29]      3.56     14.11      1.00      0.00      6.43    700.55      1.00\n",
      " lambda[30]      3.86     14.94      0.99      0.01      7.09    549.75      1.00\n",
      " lambda[31]      3.61     15.87      0.99      0.00      5.18    914.99      1.00\n",
      " lambda[32]      3.95     21.08      0.97      0.00      7.05    681.35      1.00\n",
      " lambda[33]      2.67      9.08      0.95      0.01      4.82    874.17      1.00\n",
      " lambda[34]      3.31     15.18      0.98      0.00      5.80    603.47      1.00\n",
      " lambda[35]      2.53      5.65      1.03      0.00      5.54    785.41      1.00\n",
      " lambda[36]      2.87     12.09      0.93      0.00      5.17    993.07      1.00\n",
      " lambda[37]      3.35     16.22      1.00      0.00      6.19    997.65      1.00\n",
      " lambda[38]      3.22      7.48      0.95      0.00      6.87    795.91      1.00\n",
      " lambda[39]      3.29     12.88      0.97      0.00      5.91    957.22      1.00\n",
      " lambda[40]      5.87     46.04      0.96      0.00      6.39    746.56      1.00\n",
      " lambda[41]     12.31     74.25      1.02      0.00     10.04    321.07      1.00\n",
      " lambda[42]      2.92     10.06      1.03      0.00      5.78    562.39      1.00\n",
      " lambda[43]      2.87      7.84      1.04      0.00      5.86    918.23      1.00\n",
      " lambda[44]      2.66      6.87      1.02      0.01      4.96    813.09      1.00\n",
      " lambda[45]      2.44      7.28      0.99      0.00      4.70    656.40      1.00\n",
      " lambda[46]      3.31     12.45      1.00      0.00      5.42    663.66      1.00\n",
      " lambda[47]      2.73      8.72      1.07      0.00      5.81    862.55      1.00\n",
      " lambda[48]      2.60      9.07      1.04      0.01      4.73    683.96      1.00\n",
      " lambda[49]      3.50     10.08      0.96      0.00      6.36    759.00      1.00\n",
      " lambda[50]      3.45     19.36      0.95      0.00      5.46    706.67      1.00\n",
      " lambda[51]      3.81     16.12      1.01      0.00      6.58    829.89      1.00\n",
      " lambda[52]      3.08     11.97      0.96      0.00      5.12    894.05      1.00\n",
      " lambda[53]      3.43     11.26      0.96      0.00      5.80    626.19      1.00\n",
      " lambda[54]      2.43      8.09      1.00      0.00      4.52    685.33      1.00\n",
      " lambda[55]      3.03     16.30      0.95      0.00      5.58    837.22      1.00\n",
      " lambda[56]      2.89      7.93      1.02      0.00      5.24    784.83      1.00\n",
      " lambda[57]      8.93     43.12      1.05      0.00     10.99    314.17      1.00\n",
      " lambda[58]      2.50      7.13      0.92      0.00      5.26    680.39      1.00\n",
      " lambda[59]      3.34     10.51      1.00      0.00      6.53    661.22      1.00\n",
      " lambda[60]      4.30     24.66      1.03      0.00      5.86    616.33      1.00\n",
      " lambda[61]      3.10     11.85      1.08      0.00      5.61    954.17      1.00\n",
      " lambda[62]    980.85  11101.98    126.61      0.00   1013.27    516.27      1.00\n",
      " lambda[63]      2.52      5.63      0.94      0.00      5.84    861.82      1.00\n",
      " lambda[64]      2.68      6.83      1.00      0.00      5.59    814.26      1.00\n",
      " lambda[65]      2.77      6.99      0.89      0.00      5.64    657.82      1.00\n",
      " lambda[66]      3.11      8.48      0.93      0.00      6.74    670.11      1.00\n",
      " lambda[67]      3.04      9.21      1.04      0.00      6.26    811.24      1.00\n",
      " lambda[68]      3.00      7.80      0.96      0.01      5.65    523.26      1.00\n",
      " lambda[69]      2.71      8.21      0.91      0.00      4.90    845.18      1.00\n",
      " lambda[70]      3.03     11.72      0.99      0.00      5.42    662.09      1.00\n",
      " lambda[71]      3.02      8.87      0.91      0.00      5.42    528.95      1.00\n",
      " lambda[72]      2.17      4.77      0.91      0.00      4.67    762.24      1.00\n",
      " lambda[73]      3.62     15.16      0.97      0.00      6.26    578.42      1.00\n",
      " lambda[74]      3.15      9.84      0.92      0.01      6.27    782.72      1.00\n",
      " lambda[75]      5.33     24.51      1.09      0.00      6.93    530.90      1.00\n",
      " lambda[76]      3.02      7.23      1.02      0.00      6.22    716.34      1.00\n",
      " lambda[77]     10.89     74.19      1.03      0.00      7.67    374.63      1.00\n",
      " lambda[78]      3.33     10.65      1.07      0.00      6.16    771.00      1.01\n",
      " lambda[79]      3.25     12.17      0.94      0.00      5.44    720.19      1.00\n",
      " lambda[80]      3.64     18.68      1.00      0.00      5.77    885.44      1.00\n",
      " lambda[81]      3.06      8.57      0.97      0.00      6.15    754.66      1.00\n",
      " lambda[82]      2.56      8.21      0.89      0.00      4.73    819.69      1.00\n",
      " lambda[83]      3.36     11.79      1.01      0.00      5.79    853.85      1.00\n",
      " lambda[84]      3.38     12.12      1.05      0.00      6.16    753.90      1.00\n",
      " lambda[85]      2.37      5.72      0.87      0.00      5.46    987.84      1.00\n",
      " lambda[86]      4.11     16.29      1.01      0.00      6.57    883.41      1.00\n",
      " lambda[87]      4.59     19.65      1.02      0.00      7.22    619.43      1.00\n",
      " lambda[88]      2.67      6.48      0.99      0.00      5.46    749.68      1.00\n",
      " lambda[89]     92.95    671.49      1.26      0.00    101.06    687.91      1.00\n",
      " lambda[90]      2.75      7.49      0.95      0.00      5.05    591.50      1.00\n",
      " lambda[91]      2.56      6.00      0.96      0.00      5.47    829.08      1.00\n",
      " lambda[92]      3.01      9.15      1.07      0.00      5.68    936.24      1.00\n",
      " lambda[93]      2.86      7.95      1.00      0.00      5.72    735.20      1.00\n",
      " lambda[94]      2.84      6.77      0.95      0.00      6.50    785.17      1.00\n",
      " lambda[95]      4.15     29.24      0.91      0.00      5.32    611.68      1.00\n",
      " lambda[96]      2.64      7.22      0.95      0.00      5.01    774.27      1.00\n",
      " lambda[97]      2.60      6.34      1.02      0.00      6.10    854.51      1.00\n",
      " lambda[98]      5.12     40.57      1.04      0.00      5.58    422.26      1.00\n",
      " lambda[99]      2.66      7.30      0.96      0.00      5.06    509.84      1.00\n",
      "lambda[100]      3.12     10.94      0.95      0.00      6.84    615.88      1.00\n",
      "lambda[101]      3.16      9.51      0.93      0.00      6.33    537.49      1.00\n",
      "lambda[102]      3.31      9.49      1.07      0.00      6.22    576.20      1.00\n",
      "lambda[103]      2.96     12.46      0.95      0.00      5.35    610.55      1.00\n",
      "lambda[104]      3.19      9.18      0.96      0.00      6.05    548.26      1.00\n",
      "lambda[105]      3.99     15.07      1.00      0.00      7.60    577.74      1.00\n",
      "lambda[106]      2.62      6.96      0.99      0.00      6.12    603.49      1.00\n",
      "lambda[107]      3.75     15.25      1.05      0.00      5.42    722.00      1.00\n",
      "lambda[108]      2.68      9.41      0.95      0.00      5.18    647.93      1.00\n",
      "lambda[109]      5.30     37.44      1.01      0.00      6.44    675.45      1.00\n",
      "lambda[110]      3.23     10.44      1.03      0.00      5.92    782.48      1.00\n",
      "lambda[111]      5.06     37.60      1.01      0.00      7.18    694.00      1.00\n",
      "lambda[112]      2.11      3.81      0.98      0.01      5.23   1133.76      1.00\n",
      "lambda[113]      3.29     10.67      0.99      0.00      5.97    628.19      1.00\n",
      "lambda[114]      3.45     16.67      0.90      0.00      5.46    882.58      1.00\n",
      "lambda[115]      3.98     31.32      1.05      0.00      6.55    949.59      1.00\n",
      "lambda[116]      3.38     10.65      1.02      0.00      6.42    426.10      1.00\n",
      "lambda[117]      3.04      9.52      0.97      0.00      5.90   1041.42      1.00\n",
      "lambda[118]      3.89     25.37      1.01      0.00      5.00    942.43      1.00\n",
      "lambda[119]      2.98     15.88      0.98      0.00      5.49    973.98      1.00\n",
      "lambda[120]      3.88     16.06      1.03      0.00      6.26    930.38      1.00\n",
      "lambda[121]      3.80     22.79      0.94      0.00      5.67    511.25      1.00\n",
      "lambda[122]      3.25     10.46      1.01      0.00      5.22    700.74      1.00\n",
      "lambda[123]      2.59      5.72      0.93      0.00      5.47    718.76      1.00\n",
      "lambda[124]      2.48      5.42      0.98      0.00      5.58    914.00      1.00\n",
      "lambda[125]      3.02     10.40      0.96      0.00      6.07    897.16      1.00\n",
      "lambda[126]      2.23      4.70      0.92      0.00      4.76    828.03      1.00\n",
      "lambda[127]      3.02     10.07      0.99      0.00      4.95    833.85      1.00\n",
      "lambda[128]      2.77      8.00      0.97      0.00      5.42    647.85      1.00\n",
      "lambda[129]      6.60    101.48      0.94      0.00      5.55    999.47      1.00\n",
      "lambda[130]      2.91      9.17      0.99      0.00      5.50    976.46      1.00\n",
      "lambda[131]      3.60     14.62      0.98      0.00      6.01    709.33      1.00\n",
      "lambda[132]      2.39      5.38      0.93      0.00      5.04    864.62      1.00\n",
      "lambda[133]      3.05      8.44      1.03      0.00      5.46    662.50      1.00\n",
      "lambda[134]      3.34      8.54      1.00      0.00      7.31    449.37      1.00\n",
      "lambda[135]      2.55     10.30      0.92      0.00      4.62    915.88      1.00\n",
      "lambda[136]      2.81      7.27      1.01      0.00      5.60    860.68      1.00\n",
      "lambda[137]      2.58      6.35      1.04      0.00      5.22    746.90      1.00\n",
      "lambda[138]      2.63      7.50      0.98      0.00      5.22    638.80      1.00\n",
      "lambda[139]      3.11     13.22      0.94      0.00      6.22    750.17      1.00\n",
      "lambda[140]      3.98     13.29      0.93      0.00      8.56    413.16      1.01\n",
      "lambda[141]      2.54      6.03      0.92      0.00      5.94    665.22      1.01\n",
      "lambda[142]      4.20     18.17      0.96      0.00      6.56    596.61      1.00\n",
      "lambda[143]      2.31      4.75      1.01      0.00      5.35    843.23      1.00\n",
      "        msq   2531.44  28467.80     28.85      1.18    748.03    916.52      1.00\n",
      "      sigma      3.45      4.19      1.87      0.01      9.13   1257.11      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.14    525.00      1.00\n",
      "       xisq      1.28      0.81      1.08      0.47      2.21    652.31      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.15549612045288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-3.37e-04 +- 2.07e-02\n",
      "[dimension 02/145]  inactive:\t-5.55e-04 +- 2.64e-02\n",
      "[dimension 03/145]  inactive:\t3.40e-04 +- 3.01e-02\n",
      "[dimension 04/145]  inactive:\t9.24e-03 +- 5.49e-02\n",
      "[dimension 05/145]  inactive:\t-1.05e-03 +- 3.17e-02\n",
      "[dimension 06/145]  inactive:\t5.19e-03 +- 5.64e-02\n",
      "[dimension 07/145]  inactive:\t4.36e-04 +- 2.24e-02\n",
      "[dimension 08/145]  inactive:\t9.12e-04 +- 2.96e-02\n",
      "[dimension 09/145]  inactive:\t4.14e-04 +- 2.36e-02\n",
      "[dimension 10/145]  inactive:\t5.47e-04 +- 2.07e-02\n",
      "[dimension 11/145]  inactive:\t-1.21e-03 +- 3.08e-02\n",
      "[dimension 12/145]  inactive:\t1.20e-03 +- 3.63e-02\n",
      "[dimension 13/145]  inactive:\t6.60e-03 +- 4.90e-02\n",
      "[dimension 14/145]  inactive:\t-2.01e-03 +- 3.07e-02\n",
      "[dimension 15/145]  inactive:\t9.97e-04 +- 4.59e-02\n",
      "[dimension 16/145]  inactive:\t7.70e-04 +- 2.18e-02\n",
      "[dimension 17/145]  inactive:\t9.86e-04 +- 3.73e-02\n",
      "[dimension 18/145]  inactive:\t-7.35e-05 +- 4.47e-02\n",
      "[dimension 19/145]  inactive:\t-2.53e-03 +- 2.38e-02\n",
      "[dimension 20/145]  inactive:\t-2.02e-03 +- 3.70e-02\n",
      "[dimension 21/145]  inactive:\t-1.60e-03 +- 2.67e-02\n",
      "[dimension 22/145]  inactive:\t2.16e-05 +- 2.40e-02\n",
      "[dimension 23/145]  inactive:\t-9.93e-04 +- 3.10e-02\n",
      "[dimension 24/145]  inactive:\t3.01e-03 +- 3.67e-02\n",
      "[dimension 25/145]  inactive:\t4.13e-03 +- 2.77e-02\n",
      "[dimension 26/145]  inactive:\t-6.42e-04 +- 2.77e-02\n",
      "[dimension 27/145]  inactive:\t8.05e-04 +- 2.53e-02\n",
      "[dimension 28/145]  inactive:\t8.61e-04 +- 2.26e-02\n",
      "[dimension 29/145]  inactive:\t-1.78e-04 +- 3.09e-02\n",
      "[dimension 30/145]  inactive:\t2.48e-03 +- 3.93e-02\n",
      "[dimension 31/145]  inactive:\t6.82e-03 +- 4.75e-02\n",
      "[dimension 32/145]  inactive:\t-1.46e-03 +- 3.17e-02\n",
      "[dimension 33/145]  inactive:\t4.92e-03 +- 5.34e-02\n",
      "[dimension 34/145]  inactive:\t1.14e-03 +- 2.20e-02\n",
      "[dimension 35/145]  inactive:\t7.42e-04 +- 2.86e-02\n",
      "[dimension 36/145]  inactive:\t9.87e-04 +- 2.63e-02\n",
      "[dimension 37/145]  inactive:\t4.47e-03 +- 2.86e-02\n",
      "[dimension 38/145]  inactive:\t-2.08e-03 +- 4.22e-02\n",
      "[dimension 39/145]  inactive:\t1.91e-03 +- 3.56e-02\n",
      "[dimension 40/145]  inactive:\t4.04e-03 +- 3.65e-02\n",
      "[dimension 41/145]  inactive:\t-1.79e-03 +- 3.75e-02\n",
      "[dimension 42/145]  inactive:\t2.29e-02 +- 1.24e-01\n",
      "[dimension 43/145]  inactive:\t-1.93e-04 +- 2.13e-02\n",
      "[dimension 44/145]  inactive:\t-3.45e-04 +- 3.07e-02\n",
      "[dimension 45/145]  inactive:\t-2.73e-04 +- 2.41e-02\n",
      "[dimension 46/145]  inactive:\t8.56e-04 +- 1.63e-02\n",
      "[dimension 47/145]  inactive:\t-2.35e-03 +- 3.70e-02\n",
      "[dimension 48/145]  inactive:\t1.42e-03 +- 2.42e-02\n",
      "[dimension 49/145]  inactive:\t2.59e-03 +- 2.27e-02\n",
      "[dimension 50/145]  inactive:\t-2.57e-03 +- 3.43e-02\n",
      "[dimension 51/145]  inactive:\t4.67e-03 +- 4.23e-02\n",
      "[dimension 52/145]  inactive:\t5.66e-03 +- 2.58e-02\n",
      "[dimension 53/145]  inactive:\t-9.48e-04 +- 2.81e-02\n",
      "[dimension 54/145]  inactive:\t7.96e-04 +- 2.51e-02\n",
      "[dimension 55/145]  inactive:\t6.38e-04 +- 1.96e-02\n",
      "[dimension 56/145]  inactive:\t-2.83e-03 +- 2.61e-02\n",
      "[dimension 57/145]  inactive:\t1.21e-03 +- 3.29e-02\n",
      "[dimension 58/145]  inactive:\t2.74e-02 +- 1.10e-01\n",
      "[dimension 59/145]  inactive:\t-5.41e-04 +- 2.22e-02\n",
      "[dimension 60/145]  inactive:\t2.09e-03 +- 3.57e-02\n",
      "[dimension 61/145]  inactive:\t3.88e-03 +- 3.19e-02\n",
      "[dimension 62/145]  inactive:\t-6.41e-04 +- 2.28e-02\n",
      "[dimension 63/145]  active:\t6.26e-01 +- 4.59e-01\n",
      "[dimension 64/145]  inactive:\t-3.26e-03 +- 2.79e-02\n",
      "[dimension 65/145]  inactive:\t-6.11e-04 +- 2.65e-02\n",
      "[dimension 66/145]  inactive:\t9.17e-04 +- 2.82e-02\n",
      "[dimension 67/145]  inactive:\t1.48e-03 +- 3.31e-02\n",
      "[dimension 68/145]  inactive:\t-1.13e-03 +- 3.47e-02\n",
      "[dimension 69/145]  inactive:\t4.20e-03 +- 4.20e-02\n",
      "[dimension 70/145]  inactive:\t2.77e-03 +- 2.13e-02\n",
      "[dimension 71/145]  inactive:\t-8.45e-05 +- 3.02e-02\n",
      "[dimension 72/145]  inactive:\t5.23e-04 +- 2.82e-02\n",
      "[dimension 73/145]  inactive:\t3.59e-04 +- 1.83e-02\n",
      "[dimension 74/145]  inactive:\t-2.43e-03 +- 3.70e-02\n",
      "[dimension 75/145]  inactive:\t2.05e-03 +- 3.70e-02\n",
      "[dimension 76/145]  inactive:\t7.35e-03 +- 4.59e-02\n",
      "[dimension 77/145]  inactive:\t-1.81e-03 +- 3.87e-02\n",
      "[dimension 78/145]  inactive:\t2.13e-02 +- 1.16e-01\n",
      "[dimension 79/145]  inactive:\t6.27e-03 +- 3.44e-02\n",
      "[dimension 80/145]  inactive:\t7.63e-04 +- 3.50e-02\n",
      "[dimension 81/145]  inactive:\t2.30e-03 +- 3.61e-02\n",
      "[dimension 82/145]  inactive:\t6.27e-04 +- 2.09e-02\n",
      "[dimension 83/145]  inactive:\t-1.49e-03 +- 1.94e-02\n",
      "[dimension 84/145]  inactive:\t-1.05e-03 +- 3.41e-02\n",
      "[dimension 85/145]  inactive:\t4.09e-03 +- 3.98e-02\n",
      "[dimension 86/145]  inactive:\t-7.60e-04 +- 1.93e-02\n",
      "[dimension 87/145]  inactive:\t3.61e-03 +- 4.81e-02\n",
      "[dimension 88/145]  inactive:\t4.84e-03 +- 3.42e-02\n",
      "[dimension 89/145]  inactive:\t-4.08e-05 +- 2.24e-02\n",
      "[dimension 90/145]  inactive:\t1.13e-01 +- 2.92e-01\n",
      "[dimension 91/145]  inactive:\t2.20e-04 +- 2.11e-02\n",
      "[dimension 92/145]  inactive:\t-1.21e-03 +- 2.31e-02\n",
      "[dimension 93/145]  inactive:\t-5.63e-04 +- 2.73e-02\n",
      "[dimension 94/145]  inactive:\t2.28e-03 +- 2.98e-02\n",
      "[dimension 95/145]  inactive:\t-3.75e-05 +- 3.03e-02\n",
      "[dimension 96/145]  inactive:\t1.52e-03 +- 5.01e-02\n",
      "[dimension 97/145]  inactive:\t2.73e-03 +- 2.71e-02\n",
      "[dimension 98/145]  inactive:\t-2.69e-04 +- 2.55e-02\n",
      "[dimension 99/145]  inactive:\t5.02e-03 +- 5.42e-02\n",
      "[dimension 100/145]  inactive:\t-3.71e-04 +- 1.90e-02\n",
      "[dimension 101/145]  inactive:\t-1.99e-03 +- 2.29e-02\n",
      "[dimension 102/145]  inactive:\t-1.17e-03 +- 3.25e-02\n",
      "[dimension 103/145]  inactive:\t1.50e-03 +- 2.92e-02\n",
      "[dimension 104/145]  inactive:\t-7.85e-04 +- 2.00e-02\n",
      "[dimension 105/145]  inactive:\t2.21e-04 +- 3.15e-02\n",
      "[dimension 106/145]  inactive:\t6.96e-03 +- 3.92e-02\n",
      "[dimension 107/145]  inactive:\t-8.09e-04 +- 2.27e-02\n",
      "[dimension 108/145]  inactive:\t8.43e-03 +- 7.60e-02\n",
      "[dimension 109/145]  inactive:\t-5.23e-04 +- 1.93e-02\n",
      "[dimension 110/145]  inactive:\t-4.08e-04 +- 4.58e-02\n",
      "[dimension 111/145]  inactive:\t3.62e-03 +- 4.62e-02\n",
      "[dimension 112/145]  inactive:\t8.88e-03 +- 6.32e-02\n",
      "[dimension 113/145]  inactive:\t-1.30e-03 +- 2.25e-02\n",
      "[dimension 114/145]  inactive:\t1.97e-03 +- 3.93e-02\n",
      "[dimension 115/145]  inactive:\t2.09e-03 +- 2.35e-02\n",
      "[dimension 116/145]  inactive:\t-5.84e-04 +- 2.93e-02\n",
      "[dimension 117/145]  inactive:\t5.37e-03 +- 5.06e-02\n",
      "[dimension 118/145]  inactive:\t2.92e-03 +- 2.50e-02\n",
      "[dimension 119/145]  inactive:\t-1.91e-03 +- 3.54e-02\n",
      "[dimension 120/145]  inactive:\t3.82e-04 +- 2.94e-02\n",
      "[dimension 121/145]  inactive:\t4.74e-03 +- 3.92e-02\n",
      "[dimension 122/145]  inactive:\t-2.10e-03 +- 2.91e-02\n",
      "[dimension 123/145]  inactive:\t4.42e-03 +- 5.32e-02\n",
      "[dimension 124/145]  inactive:\t-1.82e-03 +- 2.17e-02\n",
      "[dimension 125/145]  inactive:\t-1.57e-03 +- 2.72e-02\n",
      "[dimension 126/145]  inactive:\t-1.21e-03 +- 3.04e-02\n",
      "[dimension 127/145]  inactive:\t2.55e-04 +- 1.78e-02\n",
      "[dimension 128/145]  inactive:\t-8.80e-04 +- 3.53e-02\n",
      "[dimension 129/145]  inactive:\t6.34e-05 +- 2.81e-02\n",
      "[dimension 130/145]  inactive:\t3.68e-03 +- 3.15e-02\n",
      "[dimension 131/145]  inactive:\t-1.22e-03 +- 3.35e-02\n",
      "[dimension 132/145]  inactive:\t6.06e-03 +- 5.26e-02\n",
      "[dimension 133/145]  inactive:\t2.37e-03 +- 2.13e-02\n",
      "[dimension 134/145]  inactive:\t-8.04e-04 +- 3.03e-02\n",
      "[dimension 135/145]  inactive:\t1.30e-03 +- 3.38e-02\n",
      "[dimension 136/145]  inactive:\t8.56e-04 +- 1.96e-02\n",
      "[dimension 137/145]  inactive:\t1.58e-05 +- 3.12e-02\n",
      "[dimension 138/145]  inactive:\t5.69e-04 +- 2.39e-02\n",
      "[dimension 139/145]  inactive:\t-3.15e-04 +- 2.76e-02\n",
      "[dimension 140/145]  inactive:\t-1.24e-03 +- 4.28e-02\n",
      "[dimension 141/145]  inactive:\t2.59e-03 +- 3.80e-02\n",
      "[dimension 142/145]  inactive:\t1.65e-03 +- 2.17e-02\n",
      "[dimension 143/145]  inactive:\t1.54e-03 +- 3.93e-02\n",
      "[dimension 144/145]  inactive:\t3.46e-04 +- 2.08e-02\n",
      "[dimension 145/145]  inactive:\t5.69e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.69570744]\n",
      "cov_act[[0.0370309]]\n",
      "Active_dimensions: [62]\n",
      "75, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 51.37it/s, 31 steps of size 1.40e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    471.97      1.00\n",
      "  lambda[0]      2.54      7.87      0.98      0.00      5.05   1015.56      1.00\n",
      "  lambda[1]      3.05      9.71      1.01      0.01      5.96    591.52      1.01\n",
      "  lambda[2]      3.14     11.57      1.01      0.00      6.08    561.22      1.00\n",
      "  lambda[3]      3.95     21.29      0.98      0.00      6.10    699.71      1.00\n",
      "  lambda[4]      2.47      5.11      1.04      0.00      5.06    888.16      1.00\n",
      "  lambda[5]      2.76      7.22      0.98      0.00      5.67    848.22      1.00\n",
      "  lambda[6]      3.66     13.76      0.97      0.00      6.84    692.50      1.00\n",
      "  lambda[7]      2.86      6.60      0.99      0.00      6.12    572.35      1.00\n",
      "  lambda[8]      2.35      5.13      0.96      0.01      5.41   1063.98      1.00\n",
      "  lambda[9]      2.48      6.12      0.95      0.00      5.08    942.78      1.00\n",
      " lambda[10]      3.40     12.59      1.08      0.00      6.32    389.27      1.00\n",
      " lambda[11]      2.77      7.00      1.01      0.01      5.73    829.62      1.00\n",
      " lambda[12]      4.83     19.02      1.00      0.00      7.99    706.58      1.00\n",
      " lambda[13]      2.72      8.40      0.95      0.00      5.14    378.08      1.00\n",
      " lambda[14]      4.05     28.00      0.94      0.00      5.19    610.08      1.00\n",
      " lambda[15]      3.27     10.26      1.00      0.00      5.57    461.23      1.00\n",
      " lambda[16]      3.39      9.09      0.96      0.00      8.10    735.79      1.00\n",
      " lambda[17]      3.35     22.26      0.97      0.00      4.90    790.02      1.00\n",
      " lambda[18]      2.59      5.70      0.96      0.00      5.86    944.81      1.01\n",
      " lambda[19]      4.15     21.66      1.01      0.01      6.34    737.61      1.00\n",
      " lambda[20]      2.81      7.32      1.00      0.00      5.10    819.24      1.00\n",
      " lambda[21]      3.46     11.38      1.01      0.00      6.71    623.40      1.00\n",
      " lambda[22]      3.23     14.10      1.01      0.00      5.00    415.57      1.00\n",
      " lambda[23]      2.86      7.46      0.98      0.00      5.08    706.33      1.00\n",
      " lambda[24]      3.34     10.24      1.01      0.00      6.31    843.92      1.00\n",
      " lambda[25]      3.11      7.98      0.97      0.00      6.35    434.57      1.00\n",
      " lambda[26]      2.70      6.37      1.00      0.00      5.15    711.07      1.00\n",
      " lambda[27]      2.71      7.00      0.95      0.00      5.36    661.57      1.00\n",
      " lambda[28]      2.89      9.73      1.04      0.01      5.98    765.13      1.00\n",
      " lambda[29]      2.87      7.68      0.97      0.00      6.42    523.09      1.00\n",
      " lambda[30]      3.96     20.93      1.05      0.01      6.68    711.25      1.00\n",
      " lambda[31]      3.40     10.61      0.98      0.00      6.72    718.71      1.00\n",
      " lambda[32]      3.13     10.65      0.96      0.00      5.58   1020.59      1.00\n",
      " lambda[33]      3.04      9.27      0.96      0.00      5.30    741.43      1.00\n",
      " lambda[34]      2.56      6.47      1.00      0.00      5.07   1037.81      1.00\n",
      " lambda[35]      2.40      5.17      1.00      0.00      4.98    858.65      1.00\n",
      " lambda[36]      3.11     10.09      1.06      0.00      5.88    772.93      1.00\n",
      " lambda[37]      3.02      7.50      1.00      0.00      6.55    646.55      1.00\n",
      " lambda[38]      2.90      7.74      0.97      0.00      5.78    784.23      1.00\n",
      " lambda[39]      3.12      8.42      1.00      0.00      5.91    682.08      1.00\n",
      " lambda[40]      3.73     14.02      0.94      0.00      6.16    937.18      1.00\n",
      " lambda[41]     13.50     77.48      0.96      0.00     10.81    123.54      1.02\n",
      " lambda[42]      2.34      4.52      0.97      0.00      5.16    760.63      1.00\n",
      " lambda[43]      2.88     14.41      1.04      0.00      5.64    999.54      1.00\n",
      " lambda[44]      2.45      5.35      0.94      0.00      5.64    632.40      1.00\n",
      " lambda[45]      2.31      4.86      0.96      0.00      5.10    923.87      1.00\n",
      " lambda[46]      2.54      8.61      1.01      0.00      4.71    809.60      1.00\n",
      " lambda[47]      2.64      5.43      0.96      0.00      6.28    637.03      1.00\n",
      " lambda[48]      2.74      7.74      1.01      0.01      5.29    765.29      1.00\n",
      " lambda[49]      3.04      8.42      0.96      0.00      5.94    814.42      1.00\n",
      " lambda[50]      3.52     14.38      1.00      0.00      5.82    448.73      1.00\n",
      " lambda[51]      5.71     41.00      1.04      0.00      8.20    839.41      1.00\n",
      " lambda[52]      3.00      9.56      0.91      0.00      5.31    514.21      1.00\n",
      " lambda[53]      2.93      9.97      0.96      0.00      5.45    913.30      1.00\n",
      " lambda[54]      2.12      4.09      0.94      0.00      5.03    880.75      1.00\n",
      " lambda[55]      3.42     11.07      0.97      0.00      6.16    644.58      1.00\n",
      " lambda[56]      2.71      7.46      0.99      0.00      4.96    793.61      1.00\n",
      " lambda[57]      4.38     14.10      1.02      0.00      7.72    491.26      1.00\n",
      " lambda[58]      2.35      5.47      0.93      0.00      4.69    788.71      1.00\n",
      " lambda[59]      3.04      7.38      0.95      0.00      6.33    634.39      1.00\n",
      " lambda[60]      2.90      9.05      0.97      0.00      5.26    688.42      1.00\n",
      " lambda[61]      2.95     10.43      1.04      0.00      6.05    900.20      1.00\n",
      " lambda[62]   6697.62 172058.36    215.23      0.01   1749.74    944.73      1.00\n",
      " lambda[63]      2.25      4.42      1.03      0.01      4.57    793.83      1.00\n",
      " lambda[64]      2.58      5.99      1.02      0.01      5.17    796.69      1.00\n",
      " lambda[65]      3.14     10.08      0.97      0.00      5.63    511.60      1.00\n",
      " lambda[66]      3.36     10.11      1.00      0.00      6.72    631.93      1.00\n",
      " lambda[67]      2.66      6.86      0.96      0.01      5.47    960.60      1.00\n",
      " lambda[68]      3.90     26.66      0.96      0.00      6.35    625.93      1.00\n",
      " lambda[69]      4.38     14.34      0.94      0.00      7.97    742.12      1.00\n",
      " lambda[70]      2.60      6.44      1.03      0.00      5.00    697.80      1.00\n",
      " lambda[71]      3.29     15.67      0.97      0.00      5.07    769.03      1.00\n",
      " lambda[72]      2.79      9.13      0.95      0.00      5.41    779.64      1.00\n",
      " lambda[73]      2.91      9.52      0.98      0.00      5.75    666.39      1.00\n",
      " lambda[74]      2.47      4.81      1.10      0.01      5.62    558.65      1.00\n",
      " lambda[75]      4.43     18.54      1.00      0.00      6.59    532.53      1.00\n",
      " lambda[76]      3.24      8.49      1.01      0.00      7.08    656.99      1.00\n",
      " lambda[77]     11.57    123.95      1.09      0.00      6.78    335.51      1.00\n",
      " lambda[78]      4.05     18.35      1.07      0.00      6.62    580.41      1.00\n",
      " lambda[79]      2.87      8.26      1.04      0.00      5.68    734.77      1.01\n",
      " lambda[80]      3.19     10.80      0.99      0.00      6.37   1043.70      1.00\n",
      " lambda[81]      2.38      7.17      0.98      0.00      4.61    623.71      1.00\n",
      " lambda[82]      2.61      6.75      0.95      0.00      5.24    603.16      1.00\n",
      " lambda[83]      2.47      6.22      0.92      0.00      4.94    893.37      1.00\n",
      " lambda[84]      3.56     26.75      0.97      0.00      5.59    936.11      1.00\n",
      " lambda[85]      2.81     11.09      0.91      0.00      5.05    362.53      1.00\n",
      " lambda[86]      3.22      9.16      1.00      0.01      5.69    759.70      1.00\n",
      " lambda[87]      2.87      7.65      0.96      0.00      5.46    756.19      1.00\n",
      " lambda[88]      2.94     10.19      0.99      0.00      5.59    904.25      1.00\n",
      " lambda[89]    202.46   2007.23      1.15      0.00    148.59    646.63      1.00\n",
      " lambda[90]      2.55      6.85      0.95      0.00      5.32    940.82      1.00\n",
      " lambda[91]      2.56      6.68      0.96      0.01      5.27    676.08      1.00\n",
      " lambda[92]      2.58      6.52      0.99      0.00      5.13    829.17      1.00\n",
      " lambda[93]      2.64      7.73      1.03      0.00      4.80    541.64      1.00\n",
      " lambda[94]      2.63      6.87      0.94      0.00      5.26    768.02      1.00\n",
      " lambda[95]      3.15      8.59      1.03      0.00      6.52    667.89      1.00\n",
      " lambda[96]      2.97     11.44      0.93      0.00      5.43    487.62      1.00\n",
      " lambda[97]      3.69     20.69      1.03      0.00      5.62    611.97      1.00\n",
      " lambda[98]      6.28     83.52      0.98      0.00      6.60    790.36      1.00\n",
      " lambda[99]      2.91      7.86      0.98      0.00      6.07    552.36      1.00\n",
      "lambda[100]      3.17     10.29      0.91      0.00      5.89    854.34      1.00\n",
      "lambda[101]      2.59      6.57      1.00      0.00      5.29    609.75      1.00\n",
      "lambda[102]      2.93      8.07      0.93      0.00      5.46    539.77      1.00\n",
      "lambda[103]      2.36      4.98      0.98      0.00      6.17    815.63      1.00\n",
      "lambda[104]      3.48     20.34      1.00      0.00      6.23    584.26      1.00\n",
      "lambda[105]      3.39     10.78      1.03      0.00      7.23    792.15      1.00\n",
      "lambda[106]      2.49      5.34      1.00      0.01      5.28    613.56      1.00\n",
      "lambda[107]      4.05     18.48      1.00      0.00      5.81    432.96      1.00\n",
      "lambda[108]      2.52      8.99      0.99      0.00      4.97    678.88      1.00\n",
      "lambda[109]      3.07      7.71      1.00      0.00      6.16    547.41      1.00\n",
      "lambda[110]      3.78     18.84      0.99      0.00      6.09    832.92      1.00\n",
      "lambda[111]      3.04     13.29      0.93      0.00      6.01    684.66      1.00\n",
      "lambda[112]      3.14     11.90      1.00      0.00      5.64    654.52      1.00\n",
      "lambda[113]      3.80     14.69      1.01      0.00      7.23    834.15      1.00\n",
      "lambda[114]      3.29      9.26      1.00      0.00      6.31    787.01      1.00\n",
      "lambda[115]      3.43     12.45      0.96      0.00      6.08    826.82      1.00\n",
      "lambda[116]      3.83     17.49      1.01      0.00      5.36    300.72      1.00\n",
      "lambda[117]      3.12      9.46      0.94      0.00      7.00    752.79      1.00\n",
      "lambda[118]      3.36     13.45      0.95      0.00      6.25    952.60      1.00\n",
      "lambda[119]      2.64      6.00      1.01      0.00      5.56    878.69      1.00\n",
      "lambda[120]      3.23      9.97      0.95      0.00      6.65    702.41      1.00\n",
      "lambda[121]      2.83      8.48      0.90      0.00      5.53    839.42      1.00\n",
      "lambda[122]      3.56     16.32      1.00      0.00      5.99    746.95      1.00\n",
      "lambda[123]      2.62      6.25      0.90      0.00      5.82    940.99      1.00\n",
      "lambda[124]      2.45      5.25      0.97      0.00      5.08    749.85      1.00\n",
      "lambda[125]      2.66      7.31      0.97      0.01      5.39    645.98      1.00\n",
      "lambda[126]      2.47      5.79      0.96      0.00      5.15    812.12      1.00\n",
      "lambda[127]      4.24     15.59      1.02      0.00      6.58    718.86      1.00\n",
      "lambda[128]      2.92     10.04      0.99      0.00      5.35    387.82      1.00\n",
      "lambda[129]      3.79     14.96      0.99      0.00      6.14    972.28      1.00\n",
      "lambda[130]      2.95      7.73      0.98      0.00      6.43    758.95      1.00\n",
      "lambda[131]      4.32     22.55      0.98      0.00      6.71    715.54      1.00\n",
      "lambda[132]      2.55      5.75      0.89      0.00      5.50    898.65      1.00\n",
      "lambda[133]      2.58      5.72      0.97      0.00      5.46    945.02      1.00\n",
      "lambda[134]      3.54     10.77      0.95      0.00      7.48    822.68      1.00\n",
      "lambda[135]      2.90     14.85      0.91      0.00      4.84    782.06      1.00\n",
      "lambda[136]      3.03      7.96      1.02      0.01      5.96    553.60      1.00\n",
      "lambda[137]      2.69      7.85      0.99      0.00      5.09    783.87      1.00\n",
      "lambda[138]      3.07     10.45      1.00      0.00      5.35    743.77      1.00\n",
      "lambda[139]      3.04      8.02      1.01      0.00      5.84    915.69      1.00\n",
      "lambda[140]      3.22      9.62      0.96      0.00      5.82    807.72      1.00\n",
      "lambda[141]      2.51      5.93      0.97      0.00      5.46    673.25      1.00\n",
      "lambda[142]      4.40     26.70      0.95      0.01      6.01    694.17      1.00\n",
      "lambda[143]      2.29      4.64      0.95      0.01      4.96    627.83      1.00\n",
      "        msq      1.47      0.84      1.25      0.44      2.57   1056.66      1.00\n",
      "      sigma      3.16      4.19      1.44      0.00      9.16    823.91      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    502.80      1.00\n",
      "       xisq      1.14      0.62      0.99      0.43      1.96   1430.33      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.14447999000549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.36e-05 +- 1.53e-02\n",
      "[dimension 02/145]  inactive:\t5.41e-04 +- 2.38e-02\n",
      "[dimension 03/145]  inactive:\t5.55e-04 +- 2.53e-02\n",
      "[dimension 04/145]  inactive:\t3.62e-03 +- 3.12e-02\n",
      "[dimension 05/145]  inactive:\t-1.07e-04 +- 1.76e-02\n",
      "[dimension 06/145]  inactive:\t1.67e-03 +- 2.94e-02\n",
      "[dimension 07/145]  inactive:\t8.49e-04 +- 1.77e-02\n",
      "[dimension 08/145]  inactive:\t1.27e-03 +- 2.43e-02\n",
      "[dimension 09/145]  inactive:\t3.95e-04 +- 1.64e-02\n",
      "[dimension 10/145]  inactive:\t4.73e-04 +- 1.44e-02\n",
      "[dimension 11/145]  inactive:\t-1.59e-06 +- 2.16e-02\n",
      "[dimension 12/145]  inactive:\t2.87e-04 +- 2.40e-02\n",
      "[dimension 13/145]  inactive:\t5.17e-03 +- 4.50e-02\n",
      "[dimension 14/145]  inactive:\t-5.21e-05 +- 2.03e-02\n",
      "[dimension 15/145]  inactive:\t2.04e-03 +- 3.72e-02\n",
      "[dimension 16/145]  inactive:\t6.19e-04 +- 1.95e-02\n",
      "[dimension 17/145]  inactive:\t5.76e-04 +- 2.59e-02\n",
      "[dimension 18/145]  inactive:\t7.03e-04 +- 2.43e-02\n",
      "[dimension 19/145]  inactive:\t-1.37e-03 +- 1.70e-02\n",
      "[dimension 20/145]  inactive:\t-4.75e-04 +- 2.45e-02\n",
      "[dimension 21/145]  inactive:\t-1.06e-03 +- 1.95e-02\n",
      "[dimension 22/145]  inactive:\t4.60e-04 +- 1.81e-02\n",
      "[dimension 23/145]  inactive:\t-1.71e-04 +- 2.64e-02\n",
      "[dimension 24/145]  inactive:\t1.11e-03 +- 2.37e-02\n",
      "[dimension 25/145]  inactive:\t3.07e-03 +- 2.26e-02\n",
      "[dimension 26/145]  inactive:\t-1.19e-04 +- 2.29e-02\n",
      "[dimension 27/145]  inactive:\t8.68e-04 +- 1.99e-02\n",
      "[dimension 28/145]  inactive:\t5.40e-04 +- 1.54e-02\n",
      "[dimension 29/145]  inactive:\t1.19e-03 +- 3.07e-02\n",
      "[dimension 30/145]  inactive:\t1.75e-03 +- 2.43e-02\n",
      "[dimension 31/145]  inactive:\t5.06e-03 +- 4.27e-02\n",
      "[dimension 32/145]  inactive:\t-8.39e-04 +- 2.38e-02\n",
      "[dimension 33/145]  inactive:\t3.41e-03 +- 4.11e-02\n",
      "[dimension 34/145]  inactive:\t9.10e-04 +- 1.73e-02\n",
      "[dimension 35/145]  inactive:\t8.80e-04 +- 2.12e-02\n",
      "[dimension 36/145]  inactive:\t1.02e-03 +- 2.22e-02\n",
      "[dimension 37/145]  inactive:\t2.68e-03 +- 2.17e-02\n",
      "[dimension 38/145]  inactive:\t-7.11e-04 +- 2.39e-02\n",
      "[dimension 39/145]  inactive:\t1.15e-03 +- 2.47e-02\n",
      "[dimension 40/145]  inactive:\t4.13e-03 +- 3.48e-02\n",
      "[dimension 41/145]  inactive:\t-2.83e-04 +- 3.14e-02\n",
      "[dimension 42/145]  inactive:\t2.41e-02 +- 1.33e-01\n",
      "[dimension 43/145]  inactive:\t3.18e-04 +- 1.53e-02\n",
      "[dimension 44/145]  inactive:\t2.93e-04 +- 2.38e-02\n",
      "[dimension 45/145]  inactive:\t3.66e-05 +- 1.79e-02\n",
      "[dimension 46/145]  inactive:\t7.33e-04 +- 1.29e-02\n",
      "[dimension 47/145]  inactive:\t-8.09e-04 +- 1.78e-02\n",
      "[dimension 48/145]  inactive:\t1.53e-03 +- 2.44e-02\n",
      "[dimension 49/145]  inactive:\t1.98e-03 +- 2.07e-02\n",
      "[dimension 50/145]  inactive:\t-1.22e-03 +- 2.69e-02\n",
      "[dimension 51/145]  inactive:\t4.31e-03 +- 4.15e-02\n",
      "[dimension 52/145]  inactive:\t6.20e-03 +- 2.78e-02\n",
      "[dimension 53/145]  inactive:\t-4.67e-04 +- 2.18e-02\n",
      "[dimension 54/145]  inactive:\t6.64e-04 +- 2.02e-02\n",
      "[dimension 55/145]  inactive:\t4.90e-04 +- 1.33e-02\n",
      "[dimension 56/145]  inactive:\t-2.46e-03 +- 2.46e-02\n",
      "[dimension 57/145]  inactive:\t1.57e-03 +- 3.12e-02\n",
      "[dimension 58/145]  inactive:\t1.20e-02 +- 6.75e-02\n",
      "[dimension 59/145]  inactive:\t-3.39e-04 +- 1.50e-02\n",
      "[dimension 60/145]  inactive:\t1.74e-03 +- 3.12e-02\n",
      "[dimension 61/145]  inactive:\t2.23e-03 +- 2.31e-02\n",
      "[dimension 62/145]  inactive:\t-2.96e-04 +- 1.71e-02\n",
      "[dimension 63/145]  active:\t6.36e-01 +- 4.43e-01\n",
      "[dimension 64/145]  inactive:\t-1.46e-03 +- 1.95e-02\n",
      "[dimension 65/145]  inactive:\t2.25e-04 +- 1.80e-02\n",
      "[dimension 66/145]  inactive:\t8.14e-04 +- 2.08e-02\n",
      "[dimension 67/145]  inactive:\t1.46e-03 +- 2.03e-02\n",
      "[dimension 68/145]  inactive:\t6.10e-05 +- 2.14e-02\n",
      "[dimension 69/145]  inactive:\t3.70e-03 +- 4.01e-02\n",
      "[dimension 70/145]  inactive:\t4.30e-03 +- 2.69e-02\n",
      "[dimension 71/145]  inactive:\t7.85e-04 +- 2.55e-02\n",
      "[dimension 72/145]  inactive:\t5.72e-04 +- 1.76e-02\n",
      "[dimension 73/145]  inactive:\t5.98e-04 +- 1.55e-02\n",
      "[dimension 74/145]  inactive:\t-1.69e-04 +- 2.78e-02\n",
      "[dimension 75/145]  inactive:\t1.12e-03 +- 2.21e-02\n",
      "[dimension 76/145]  inactive:\t4.77e-03 +- 3.49e-02\n",
      "[dimension 77/145]  inactive:\t-6.46e-04 +- 2.80e-02\n",
      "[dimension 78/145]  inactive:\t1.27e-02 +- 9.19e-02\n",
      "[dimension 79/145]  inactive:\t5.64e-03 +- 3.36e-02\n",
      "[dimension 80/145]  inactive:\t9.94e-04 +- 2.75e-02\n",
      "[dimension 81/145]  inactive:\t2.03e-03 +- 3.33e-02\n",
      "[dimension 82/145]  inactive:\t-1.12e-05 +- 1.37e-02\n",
      "[dimension 83/145]  inactive:\t-1.04e-03 +- 1.53e-02\n",
      "[dimension 84/145]  inactive:\t-6.24e-04 +- 1.87e-02\n",
      "[dimension 85/145]  inactive:\t1.99e-03 +- 2.53e-02\n",
      "[dimension 86/145]  inactive:\t-3.93e-04 +- 1.63e-02\n",
      "[dimension 87/145]  inactive:\t3.02e-03 +- 3.85e-02\n",
      "[dimension 88/145]  inactive:\t2.35e-03 +- 2.17e-02\n",
      "[dimension 89/145]  inactive:\t-5.35e-04 +- 1.91e-02\n",
      "[dimension 90/145]  inactive:\t1.26e-01 +- 3.02e-01\n",
      "[dimension 91/145]  inactive:\t7.70e-06 +- 1.51e-02\n",
      "[dimension 92/145]  inactive:\t-8.62e-04 +- 2.14e-02\n",
      "[dimension 93/145]  inactive:\t-2.33e-04 +- 2.02e-02\n",
      "[dimension 94/145]  inactive:\t1.28e-03 +- 2.33e-02\n",
      "[dimension 95/145]  inactive:\t2.52e-05 +- 1.94e-02\n",
      "[dimension 96/145]  inactive:\t7.59e-04 +- 2.61e-02\n",
      "[dimension 97/145]  inactive:\t2.08e-03 +- 2.03e-02\n",
      "[dimension 98/145]  inactive:\t-7.22e-04 +- 2.57e-02\n",
      "[dimension 99/145]  inactive:\t6.45e-03 +- 5.69e-02\n",
      "[dimension 100/145]  inactive:\t-1.85e-04 +- 1.48e-02\n",
      "[dimension 101/145]  inactive:\t-1.41e-03 +- 1.67e-02\n",
      "[dimension 102/145]  inactive:\t2.65e-04 +- 2.05e-02\n",
      "[dimension 103/145]  inactive:\t1.08e-03 +- 2.23e-02\n",
      "[dimension 104/145]  inactive:\t-5.00e-04 +- 1.50e-02\n",
      "[dimension 105/145]  inactive:\t1.02e-04 +- 2.04e-02\n",
      "[dimension 106/145]  inactive:\t4.73e-03 +- 3.26e-02\n",
      "[dimension 107/145]  inactive:\t-5.83e-04 +- 1.61e-02\n",
      "[dimension 108/145]  inactive:\t9.38e-03 +- 7.93e-02\n",
      "[dimension 109/145]  inactive:\t8.65e-05 +- 1.58e-02\n",
      "[dimension 110/145]  inactive:\t-4.81e-05 +- 2.42e-02\n",
      "[dimension 111/145]  inactive:\t2.15e-03 +- 3.24e-02\n",
      "[dimension 112/145]  inactive:\t3.37e-03 +- 3.48e-02\n",
      "[dimension 113/145]  inactive:\t-1.03e-03 +- 2.05e-02\n",
      "[dimension 114/145]  inactive:\t2.14e-03 +- 4.54e-02\n",
      "[dimension 115/145]  inactive:\t1.71e-03 +- 2.04e-02\n",
      "[dimension 116/145]  inactive:\t1.56e-03 +- 3.50e-02\n",
      "[dimension 117/145]  inactive:\t7.22e-03 +- 6.40e-02\n",
      "[dimension 118/145]  inactive:\t2.08e-03 +- 1.95e-02\n",
      "[dimension 119/145]  inactive:\t-9.68e-04 +- 2.50e-02\n",
      "[dimension 120/145]  inactive:\t3.80e-04 +- 2.29e-02\n",
      "[dimension 121/145]  inactive:\t2.58e-03 +- 2.75e-02\n",
      "[dimension 122/145]  inactive:\t-8.96e-04 +- 2.11e-02\n",
      "[dimension 123/145]  inactive:\t2.91e-03 +- 3.82e-02\n",
      "[dimension 124/145]  inactive:\t-5.61e-04 +- 1.59e-02\n",
      "[dimension 125/145]  inactive:\t-7.59e-04 +- 2.15e-02\n",
      "[dimension 126/145]  inactive:\t-3.30e-04 +- 1.93e-02\n",
      "[dimension 127/145]  inactive:\t2.70e-04 +- 1.46e-02\n",
      "[dimension 128/145]  inactive:\t-2.89e-04 +- 2.70e-02\n",
      "[dimension 129/145]  inactive:\t1.04e-03 +- 2.60e-02\n",
      "[dimension 130/145]  inactive:\t2.74e-03 +- 2.43e-02\n",
      "[dimension 131/145]  inactive:\t-1.21e-04 +- 2.54e-02\n",
      "[dimension 132/145]  inactive:\t4.76e-03 +- 4.68e-02\n",
      "[dimension 133/145]  inactive:\t2.05e-03 +- 1.90e-02\n",
      "[dimension 134/145]  inactive:\t-1.92e-04 +- 2.17e-02\n",
      "[dimension 135/145]  inactive:\t1.07e-03 +- 2.45e-02\n",
      "[dimension 136/145]  inactive:\t1.06e-03 +- 1.74e-02\n",
      "[dimension 137/145]  inactive:\t4.79e-04 +- 2.39e-02\n",
      "[dimension 138/145]  inactive:\t4.57e-04 +- 1.61e-02\n",
      "[dimension 139/145]  inactive:\t5.43e-04 +- 2.07e-02\n",
      "[dimension 140/145]  inactive:\t-3.96e-04 +- 2.13e-02\n",
      "[dimension 141/145]  inactive:\t1.29e-03 +- 2.18e-02\n",
      "[dimension 142/145]  inactive:\t1.34e-03 +- 1.64e-02\n",
      "[dimension 143/145]  inactive:\t1.81e-03 +- 3.25e-02\n",
      "[dimension 144/145]  inactive:\t3.90e-04 +- 1.62e-02\n",
      "[dimension 145/145]  inactive:\t-8.37e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8607104]\n",
      "cov_act[[0.02993637]]\n",
      "Active_dimensions: [62]\n",
      "76, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:28<00:00, 52.19it/s, 31 steps of size 1.48e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    948.59      1.00\n",
      "  lambda[0]      2.37      6.41      0.97      0.00      4.89    666.65      1.00\n",
      "  lambda[1]      2.71      8.30      0.96      0.00      5.25    722.60      1.00\n",
      "  lambda[2]      3.21     13.07      1.03      0.00      5.58    568.23      1.00\n",
      "  lambda[3]      3.20     11.19      1.05      0.01      6.72    608.93      1.00\n",
      "  lambda[4]      2.83      8.66      1.11      0.00      5.92    851.07      1.00\n",
      "  lambda[5]      2.89     15.89      0.96      0.00      4.79    683.55      1.00\n",
      "  lambda[6]      2.90     10.93      1.01      0.00      5.64    858.06      1.00\n",
      "  lambda[7]      3.17      8.90      0.98      0.00      6.17    654.62      1.00\n",
      "  lambda[8]      2.25      4.17      0.96      0.00      5.12   1077.80      1.00\n",
      "  lambda[9]      2.37      5.87      0.99      0.00      4.75   1031.63      1.00\n",
      " lambda[10]      3.70     14.45      1.02      0.00      6.27    873.72      1.00\n",
      " lambda[11]      2.78      6.92      0.97      0.01      6.10    792.65      1.00\n",
      " lambda[12]      4.31     13.78      1.03      0.00      8.07    473.30      1.00\n",
      " lambda[13]      2.78      7.93      0.94      0.00      5.11    647.36      1.00\n",
      " lambda[14]      4.34     24.53      0.92      0.00      5.36    676.05      1.00\n",
      " lambda[15]      3.03     10.99      0.94      0.00      5.78   1057.35      1.00\n",
      " lambda[16]      3.68      9.38      1.03      0.00      8.33    589.88      1.00\n",
      " lambda[17]      3.42     20.54      0.97      0.00      5.12    710.02      1.00\n",
      " lambda[18]      2.90      8.49      0.97      0.00      5.50    816.23      1.00\n",
      " lambda[19]      3.53     17.20      1.00      0.00      5.68    813.14      1.00\n",
      " lambda[20]      2.84      6.63      0.96      0.01      6.01    688.86      1.00\n",
      " lambda[21]      2.97      8.94      0.96      0.00      6.19    664.01      1.00\n",
      " lambda[22]      2.65      9.78      0.96      0.00      4.89    499.91      1.00\n",
      " lambda[23]      3.03      7.84      0.98      0.00      6.21    681.78      1.00\n",
      " lambda[24]      3.28     10.44      0.98      0.00      6.30    812.54      1.00\n",
      " lambda[25]      3.26      9.10      1.03      0.01      6.29    452.25      1.00\n",
      " lambda[26]      2.91     10.28      1.00      0.00      5.69    886.24      1.00\n",
      " lambda[27]      2.84      6.85      0.99      0.00      5.97    432.59      1.00\n",
      " lambda[28]      2.61      7.74      1.00      0.00      5.03    540.38      1.00\n",
      " lambda[29]      3.10      8.48      0.96      0.00      6.22    649.64      1.00\n",
      " lambda[30]      3.48     13.77      1.03      0.01      7.61    940.96      1.00\n",
      " lambda[31]      3.47     12.29      0.99      0.00      6.28    716.40      1.00\n",
      " lambda[32]      2.96      6.55      0.96      0.00      6.53    780.03      1.00\n",
      " lambda[33]      2.96     10.66      0.95      0.01      5.53    922.05      1.00\n",
      " lambda[34]      2.90      9.82      0.94      0.00      5.15    529.12      1.00\n",
      " lambda[35]      2.36      5.04      1.00      0.00      4.83    920.25      1.00\n",
      " lambda[36]      4.01     20.67      1.04      0.00      6.50    755.93      1.00\n",
      " lambda[37]      3.40     16.72      1.03      0.00      5.19    675.04      1.00\n",
      " lambda[38]      2.84      8.42      0.97      0.00      6.26    878.89      1.00\n",
      " lambda[39]      3.23     10.19      0.99      0.01      6.39    769.24      1.00\n",
      " lambda[40]      3.56     13.43      0.90      0.01      6.09    905.72      1.00\n",
      " lambda[41]     18.59    165.27      1.01      0.00     10.18    448.92      1.00\n",
      " lambda[42]      3.29     20.31      1.01      0.00      5.46    952.11      1.00\n",
      " lambda[43]      2.96     15.13      0.98      0.00      5.81    967.56      1.00\n",
      " lambda[44]      2.43      6.45      0.94      0.00      4.89    908.10      1.00\n",
      " lambda[45]      2.33      4.80      0.98      0.00      5.05    635.72      1.00\n",
      " lambda[46]      2.78     10.04      1.00      0.00      5.42    736.82      1.00\n",
      " lambda[47]      2.82      9.89      0.98      0.00      6.09    853.40      1.00\n",
      " lambda[48]      2.99     11.67      1.00      0.00      5.18    758.79      1.00\n",
      " lambda[49]      2.68      7.18      0.98      0.00      5.26    761.59      1.00\n",
      " lambda[50]      2.65      7.30      0.95      0.00      5.40    897.57      1.00\n",
      " lambda[51]      3.90     14.21      1.00      0.00      7.02    568.63      1.00\n",
      " lambda[52]      2.84      7.83      0.96      0.01      5.54    584.19      1.00\n",
      " lambda[53]      2.99     10.23      0.95      0.00      5.62    909.44      1.00\n",
      " lambda[54]      2.42      9.32      0.96      0.00      4.27    547.38      1.00\n",
      " lambda[55]      3.67     17.15      0.98      0.00      5.71    708.74      1.00\n",
      " lambda[56]      2.51      5.96      0.96      0.00      4.88    865.01      1.00\n",
      " lambda[57]      4.13     13.12      0.99      0.00      6.74    748.48      1.00\n",
      " lambda[58]      2.34      4.95      0.96      0.00      5.10    598.25      1.00\n",
      " lambda[59]      3.02      7.65      0.99      0.00      6.99    372.91      1.00\n",
      " lambda[60]      3.03     11.30      0.94      0.00      5.23    878.18      1.00\n",
      " lambda[61]      2.69      8.95      0.97      0.01      6.00    945.47      1.00\n",
      " lambda[62]   1196.28  15920.55    183.04      0.01   1000.45    473.63      1.00\n",
      " lambda[63]      2.34      5.46      0.97      0.00      5.05    742.86      1.00\n",
      " lambda[64]      3.06      8.15      1.02      0.00      5.52    670.00      1.00\n",
      " lambda[65]      3.28     12.64      0.99      0.00      5.42    797.46      1.00\n",
      " lambda[66]      2.95      6.71      1.00      0.00      6.33    971.47      1.00\n",
      " lambda[67]      2.72      7.04      0.98      0.00      5.39    882.07      1.00\n",
      " lambda[68]      3.82     22.53      0.91      0.00      5.17    862.36      1.00\n",
      " lambda[69]      3.60     11.82      0.95      0.00      6.36    619.89      1.00\n",
      " lambda[70]      2.47      8.53      0.99      0.00      4.88    978.35      1.00\n",
      " lambda[71]      2.45      6.61      0.98      0.00      4.92    653.31      1.00\n",
      " lambda[72]      2.95      9.00      0.98      0.00      6.00    521.59      1.00\n",
      " lambda[73]      3.08     19.44      1.02      0.00      5.18   1004.63      1.00\n",
      " lambda[74]      2.40      5.53      1.03      0.00      5.46    953.36      1.00\n",
      " lambda[75]      3.47     12.85      1.03      0.00      5.65    931.79      1.00\n",
      " lambda[76]      3.26      9.64      0.96      0.00      7.31    738.56      1.00\n",
      " lambda[77]     13.48    253.48      1.01      0.00      6.20    837.96      1.00\n",
      " lambda[78]      3.70     12.44      1.08      0.00      6.97    480.27      1.00\n",
      " lambda[79]      3.09      9.55      1.00      0.00      5.49    550.01      1.00\n",
      " lambda[80]      3.48     11.57      1.00      0.00      7.05    934.50      1.00\n",
      " lambda[81]      2.39      7.09      0.96      0.00      4.82   1064.09      1.00\n",
      " lambda[82]      2.56      7.48      0.94      0.00      4.63    764.33      1.00\n",
      " lambda[83]      2.84      7.88      0.91      0.00      6.06    708.88      1.00\n",
      " lambda[84]      4.17     21.95      0.98      0.00      5.83    743.02      1.00\n",
      " lambda[85]      2.70     10.16      0.95      0.00      5.63    781.14      1.00\n",
      " lambda[86]      3.12      7.90      1.03      0.00      5.87    637.93      1.00\n",
      " lambda[87]      3.71     13.77      0.98      0.00      6.66    561.72      1.00\n",
      " lambda[88]      2.63      6.64      0.95      0.00      6.35    801.69      1.00\n",
      " lambda[89]     86.25    924.54      1.11      0.00     39.22    490.49      1.00\n",
      " lambda[90]      2.49      5.93      1.00      0.00      4.84    682.38      1.00\n",
      " lambda[91]      2.50      6.35      0.97      0.00      4.81    751.81      1.00\n",
      " lambda[92]      2.69      5.99      1.03      0.01      5.27    672.14      1.00\n",
      " lambda[93]      2.58      6.50      0.99      0.00      5.06    544.76      1.00\n",
      " lambda[94]      2.52      6.89      0.98      0.00      4.74    650.12      1.00\n",
      " lambda[95]      3.67     12.53      1.02      0.00      6.45    680.57      1.00\n",
      " lambda[96]      2.98     12.55      0.94      0.00      5.86    580.29      1.00\n",
      " lambda[97]      3.14     13.00      1.01      0.00      6.11    572.23      1.01\n",
      " lambda[98]      4.60     25.92      0.98      0.00      5.56    497.11      1.00\n",
      " lambda[99]      2.55      6.95      1.00      0.00      4.98    955.81      1.00\n",
      "lambda[100]      2.94      9.21      0.92      0.00      5.72    838.20      1.00\n",
      "lambda[101]      2.84      8.13      1.00      0.00      5.77    499.34      1.00\n",
      "lambda[102]      3.00      9.17      0.87      0.00      5.76    862.46      1.00\n",
      "lambda[103]      2.32      4.45      1.00      0.00      4.99    666.42      1.00\n",
      "lambda[104]      3.29     12.50      0.98      0.00      6.23    462.69      1.00\n",
      "lambda[105]      3.03      6.94      1.04      0.00      6.32    822.89      1.00\n",
      "lambda[106]      2.68      6.41      1.02      0.00      5.39    489.73      1.00\n",
      "lambda[107]      4.98     24.91      0.98      0.00      6.48    488.29      1.00\n",
      "lambda[108]      2.56     10.51      0.95      0.00      4.79    820.40      1.00\n",
      "lambda[109]      3.26      9.60      0.96      0.00      6.97    817.11      1.00\n",
      "lambda[110]      3.50     12.23      1.04      0.01      6.69    762.34      1.00\n",
      "lambda[111]      3.11      9.05      0.91      0.00      5.81    590.82      1.00\n",
      "lambda[112]      2.93     10.73      0.94      0.00      5.79    914.15      1.00\n",
      "lambda[113]      4.10     16.40      0.99      0.00      6.10    842.43      1.00\n",
      "lambda[114]      3.40     12.29      0.93      0.00      7.18    775.70      1.00\n",
      "lambda[115]      4.42     19.75      0.89      0.00      5.80    705.12      1.00\n",
      "lambda[116]      3.97     27.33      1.01      0.00      5.39    467.71      1.00\n",
      "lambda[117]      3.51     13.76      0.96      0.00      6.10    620.45      1.00\n",
      "lambda[118]      3.20     10.44      0.98      0.00      6.58    863.31      1.00\n",
      "lambda[119]      2.52      6.48      1.02      0.01      5.06    950.71      1.00\n",
      "lambda[120]      3.89     20.60      0.98      0.00      6.42    848.14      1.00\n",
      "lambda[121]      3.04      8.71      0.91      0.00      6.46    702.69      1.00\n",
      "lambda[122]      3.14      8.82      1.03      0.00      5.71    622.73      1.00\n",
      "lambda[123]      2.82      9.04      0.93      0.00      5.40    446.50      1.00\n",
      "lambda[124]      2.50      5.02      1.03      0.01      5.20    588.94      1.00\n",
      "lambda[125]      2.79      7.75      1.00      0.01      5.59    627.94      1.00\n",
      "lambda[126]      2.34      5.86      1.00      0.00      4.92   1070.25      1.00\n",
      "lambda[127]      4.02     20.02      0.99      0.00      6.29    814.00      1.00\n",
      "lambda[128]      3.20     14.54      0.99      0.00      5.37    628.68      1.00\n",
      "lambda[129]      3.83     12.85      0.99      0.00      6.56    803.34      1.00\n",
      "lambda[130]      3.29      8.96      0.98      0.00      6.30    735.79      1.00\n",
      "lambda[131]      4.48     19.88      0.98      0.00      6.86    500.52      1.00\n",
      "lambda[132]      2.59      5.30      0.95      0.00      5.83    820.29      1.00\n",
      "lambda[133]      2.43      4.92      1.00      0.00      5.55    948.06      1.00\n",
      "lambda[134]      3.35      8.17      0.91      0.00      7.67    678.55      1.00\n",
      "lambda[135]      2.75      9.77      0.98      0.00      5.83    771.71      1.00\n",
      "lambda[136]      3.26      8.94      1.00      0.00      6.23    584.82      1.00\n",
      "lambda[137]      2.58      6.98      0.98      0.00      5.83    780.63      1.00\n",
      "lambda[138]      3.32     12.59      1.00      0.00      5.63    835.42      1.00\n",
      "lambda[139]      3.28      9.55      0.97      0.00      6.43    828.90      1.00\n",
      "lambda[140]      3.12      8.35      0.99      0.01      5.83    880.79      1.00\n",
      "lambda[141]      2.54      6.76      0.89      0.00      5.58    751.81      1.00\n",
      "lambda[142]      5.34     28.22      0.99      0.00      7.21    445.02      1.00\n",
      "lambda[143]      2.50      5.73      0.97      0.00      4.68    544.90      1.01\n",
      "        msq   5885.48  61049.31     48.49      0.97   1259.86    554.78      1.00\n",
      "      sigma      4.59      6.21      2.08      0.00     12.50   1661.44      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    946.96      1.00\n",
      "       xisq    312.77   2780.65     16.12      1.04    197.90    693.91      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 33.524352073669434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-9.34e-05 +- 1.69e-02\n",
      "[dimension 02/145]  inactive:\t-7.15e-04 +- 2.34e-02\n",
      "[dimension 03/145]  inactive:\t5.31e-04 +- 2.85e-02\n",
      "[dimension 04/145]  inactive:\t4.88e-03 +- 3.73e-02\n",
      "[dimension 05/145]  inactive:\t-8.15e-04 +- 2.44e-02\n",
      "[dimension 06/145]  inactive:\t1.09e-03 +- 2.60e-02\n",
      "[dimension 07/145]  inactive:\t5.92e-04 +- 1.93e-02\n",
      "[dimension 08/145]  inactive:\t7.40e-04 +- 3.19e-02\n",
      "[dimension 09/145]  inactive:\t3.41e-04 +- 2.45e-02\n",
      "[dimension 10/145]  inactive:\t2.66e-04 +- 1.70e-02\n",
      "[dimension 11/145]  inactive:\t-6.37e-04 +- 3.03e-02\n",
      "[dimension 12/145]  inactive:\t-1.20e-04 +- 3.30e-02\n",
      "[dimension 13/145]  inactive:\t6.03e-03 +- 4.56e-02\n",
      "[dimension 14/145]  inactive:\t-1.52e-03 +- 2.71e-02\n",
      "[dimension 15/145]  inactive:\t1.10e-03 +- 3.83e-02\n",
      "[dimension 16/145]  inactive:\t1.30e-03 +- 2.11e-02\n",
      "[dimension 17/145]  inactive:\t2.00e-04 +- 3.03e-02\n",
      "[dimension 18/145]  inactive:\t-1.59e-04 +- 2.55e-02\n",
      "[dimension 19/145]  inactive:\t-2.14e-03 +- 2.07e-02\n",
      "[dimension 20/145]  inactive:\t-1.24e-03 +- 2.88e-02\n",
      "[dimension 21/145]  inactive:\t-1.91e-03 +- 2.66e-02\n",
      "[dimension 22/145]  inactive:\t6.98e-05 +- 2.31e-02\n",
      "[dimension 23/145]  inactive:\t-6.73e-04 +- 3.12e-02\n",
      "[dimension 24/145]  inactive:\t1.61e-03 +- 2.70e-02\n",
      "[dimension 25/145]  inactive:\t2.83e-03 +- 2.14e-02\n",
      "[dimension 26/145]  inactive:\t-7.86e-04 +- 3.12e-02\n",
      "[dimension 27/145]  inactive:\t1.03e-03 +- 2.41e-02\n",
      "[dimension 28/145]  inactive:\t9.11e-04 +- 2.02e-02\n",
      "[dimension 29/145]  inactive:\t-4.57e-04 +- 2.62e-02\n",
      "[dimension 30/145]  inactive:\t7.89e-04 +- 2.73e-02\n",
      "[dimension 31/145]  inactive:\t5.42e-03 +- 3.96e-02\n",
      "[dimension 32/145]  inactive:\t-1.57e-03 +- 2.78e-02\n",
      "[dimension 33/145]  inactive:\t1.60e-03 +- 3.20e-02\n",
      "[dimension 34/145]  inactive:\t8.94e-04 +- 2.08e-02\n",
      "[dimension 35/145]  inactive:\t-8.21e-05 +- 2.29e-02\n",
      "[dimension 36/145]  inactive:\t8.14e-04 +- 2.46e-02\n",
      "[dimension 37/145]  inactive:\t4.11e-03 +- 2.83e-02\n",
      "[dimension 38/145]  inactive:\t-1.58e-03 +- 2.95e-02\n",
      "[dimension 39/145]  inactive:\t5.44e-04 +- 2.56e-02\n",
      "[dimension 40/145]  inactive:\t5.29e-03 +- 3.99e-02\n",
      "[dimension 41/145]  inactive:\t-1.97e-03 +- 3.34e-02\n",
      "[dimension 42/145]  inactive:\t2.84e-02 +- 1.46e-01\n",
      "[dimension 43/145]  inactive:\t-6.35e-05 +- 1.96e-02\n",
      "[dimension 44/145]  inactive:\t-2.65e-04 +- 2.70e-02\n",
      "[dimension 45/145]  inactive:\t-4.02e-05 +- 2.16e-02\n",
      "[dimension 46/145]  inactive:\t1.14e-03 +- 1.66e-02\n",
      "[dimension 47/145]  inactive:\t-1.54e-03 +- 2.55e-02\n",
      "[dimension 48/145]  inactive:\t2.05e-03 +- 2.97e-02\n",
      "[dimension 49/145]  inactive:\t3.07e-03 +- 2.63e-02\n",
      "[dimension 50/145]  inactive:\t-1.88e-03 +- 2.77e-02\n",
      "[dimension 51/145]  inactive:\t2.71e-03 +- 2.95e-02\n",
      "[dimension 52/145]  inactive:\t6.15e-03 +- 2.75e-02\n",
      "[dimension 53/145]  inactive:\t-1.05e-03 +- 2.42e-02\n",
      "[dimension 54/145]  inactive:\t2.16e-04 +- 2.16e-02\n",
      "[dimension 55/145]  inactive:\t6.37e-04 +- 1.57e-02\n",
      "[dimension 56/145]  inactive:\t-2.27e-03 +- 2.25e-02\n",
      "[dimension 57/145]  inactive:\t6.52e-04 +- 2.54e-02\n",
      "[dimension 58/145]  inactive:\t1.11e-02 +- 6.49e-02\n",
      "[dimension 59/145]  inactive:\t-5.63e-04 +- 1.69e-02\n",
      "[dimension 60/145]  inactive:\t1.85e-03 +- 3.50e-02\n",
      "[dimension 61/145]  inactive:\t2.49e-03 +- 2.57e-02\n",
      "[dimension 62/145]  inactive:\t-5.25e-04 +- 2.33e-02\n",
      "[dimension 63/145]  active:\t7.19e-01 +- 4.17e-01\n",
      "[dimension 64/145]  inactive:\t-2.26e-03 +- 2.25e-02\n",
      "[dimension 65/145]  inactive:\t-6.20e-04 +- 2.31e-02\n",
      "[dimension 66/145]  inactive:\t5.93e-04 +- 2.67e-02\n",
      "[dimension 67/145]  inactive:\t1.36e-03 +- 2.74e-02\n",
      "[dimension 68/145]  inactive:\t-6.38e-04 +- 2.75e-02\n",
      "[dimension 69/145]  inactive:\t3.74e-03 +- 3.78e-02\n",
      "[dimension 70/145]  inactive:\t3.57e-03 +- 2.42e-02\n",
      "[dimension 71/145]  inactive:\t6.72e-05 +- 2.39e-02\n",
      "[dimension 72/145]  inactive:\t2.17e-04 +- 2.05e-02\n",
      "[dimension 73/145]  inactive:\t7.29e-05 +- 2.06e-02\n",
      "[dimension 74/145]  inactive:\t-1.17e-03 +- 3.08e-02\n",
      "[dimension 75/145]  inactive:\t5.87e-04 +- 2.41e-02\n",
      "[dimension 76/145]  inactive:\t4.54e-03 +- 3.50e-02\n",
      "[dimension 77/145]  inactive:\t-1.97e-03 +- 3.67e-02\n",
      "[dimension 78/145]  inactive:\t6.09e-03 +- 6.15e-02\n",
      "[dimension 79/145]  inactive:\t5.65e-03 +- 3.30e-02\n",
      "[dimension 80/145]  inactive:\t-3.40e-04 +- 3.36e-02\n",
      "[dimension 81/145]  inactive:\t1.60e-03 +- 3.35e-02\n",
      "[dimension 82/145]  inactive:\t2.35e-04 +- 1.55e-02\n",
      "[dimension 83/145]  inactive:\t-1.03e-03 +- 1.55e-02\n",
      "[dimension 84/145]  inactive:\t-1.00e-03 +- 2.30e-02\n",
      "[dimension 85/145]  inactive:\t4.20e-03 +- 3.94e-02\n",
      "[dimension 86/145]  inactive:\t-4.55e-04 +- 1.97e-02\n",
      "[dimension 87/145]  inactive:\t2.39e-03 +- 3.95e-02\n",
      "[dimension 88/145]  inactive:\t3.52e-03 +- 2.81e-02\n",
      "[dimension 89/145]  inactive:\t-6.36e-04 +- 2.08e-02\n",
      "[dimension 90/145]  inactive:\t8.24e-02 +- 2.59e-01\n",
      "[dimension 91/145]  inactive:\t-1.15e-04 +- 1.86e-02\n",
      "[dimension 92/145]  inactive:\t-1.19e-03 +- 2.37e-02\n",
      "[dimension 93/145]  inactive:\t-4.70e-04 +- 2.77e-02\n",
      "[dimension 94/145]  inactive:\t1.80e-03 +- 2.79e-02\n",
      "[dimension 95/145]  inactive:\t-2.61e-04 +- 2.21e-02\n",
      "[dimension 96/145]  inactive:\t1.79e-03 +- 4.26e-02\n",
      "[dimension 97/145]  inactive:\t2.78e-03 +- 2.46e-02\n",
      "[dimension 98/145]  inactive:\t-7.98e-04 +- 2.39e-02\n",
      "[dimension 99/145]  inactive:\t6.00e-03 +- 5.88e-02\n",
      "[dimension 100/145]  inactive:\t-3.99e-04 +- 1.77e-02\n",
      "[dimension 101/145]  inactive:\t-2.48e-03 +- 2.21e-02\n",
      "[dimension 102/145]  inactive:\t3.15e-04 +- 2.72e-02\n",
      "[dimension 103/145]  inactive:\t1.09e-03 +- 2.37e-02\n",
      "[dimension 104/145]  inactive:\t-9.67e-04 +- 1.67e-02\n",
      "[dimension 105/145]  inactive:\t3.68e-04 +- 3.35e-02\n",
      "[dimension 106/145]  inactive:\t4.21e-03 +- 3.03e-02\n",
      "[dimension 107/145]  inactive:\t-1.48e-03 +- 2.36e-02\n",
      "[dimension 108/145]  inactive:\t8.61e-03 +- 8.17e-02\n",
      "[dimension 109/145]  inactive:\t-4.28e-04 +- 2.00e-02\n",
      "[dimension 110/145]  inactive:\t-1.20e-03 +- 2.98e-02\n",
      "[dimension 111/145]  inactive:\t2.34e-03 +- 3.70e-02\n",
      "[dimension 112/145]  inactive:\t4.13e-03 +- 3.68e-02\n",
      "[dimension 113/145]  inactive:\t-1.71e-03 +- 2.20e-02\n",
      "[dimension 114/145]  inactive:\t1.64e-03 +- 4.52e-02\n",
      "[dimension 115/145]  inactive:\t2.25e-03 +- 2.65e-02\n",
      "[dimension 116/145]  inactive:\t2.36e-03 +- 7.03e-02\n",
      "[dimension 117/145]  inactive:\t4.63e-03 +- 5.16e-02\n",
      "[dimension 118/145]  inactive:\t2.98e-03 +- 2.44e-02\n",
      "[dimension 119/145]  inactive:\t-2.55e-03 +- 3.87e-02\n",
      "[dimension 120/145]  inactive:\t4.78e-04 +- 2.62e-02\n",
      "[dimension 121/145]  inactive:\t5.13e-03 +- 4.26e-02\n",
      "[dimension 122/145]  inactive:\t-2.63e-03 +- 4.11e-02\n",
      "[dimension 123/145]  inactive:\t1.90e-03 +- 3.86e-02\n",
      "[dimension 124/145]  inactive:\t-1.46e-03 +- 2.00e-02\n",
      "[dimension 125/145]  inactive:\t-1.12e-03 +- 2.32e-02\n",
      "[dimension 126/145]  inactive:\t-6.48e-04 +- 2.59e-02\n",
      "[dimension 127/145]  inactive:\t6.61e-05 +- 1.91e-02\n",
      "[dimension 128/145]  inactive:\t-1.70e-03 +- 3.31e-02\n",
      "[dimension 129/145]  inactive:\t3.33e-05 +- 2.49e-02\n",
      "[dimension 130/145]  inactive:\t3.98e-03 +- 3.02e-02\n",
      "[dimension 131/145]  inactive:\t-1.15e-03 +- 3.88e-02\n",
      "[dimension 132/145]  inactive:\t7.48e-03 +- 6.02e-02\n",
      "[dimension 133/145]  inactive:\t2.24e-03 +- 2.13e-02\n",
      "[dimension 134/145]  inactive:\t-2.02e-04 +- 2.55e-02\n",
      "[dimension 135/145]  inactive:\t1.14e-03 +- 3.26e-02\n",
      "[dimension 136/145]  inactive:\t1.02e-03 +- 1.94e-02\n",
      "[dimension 137/145]  inactive:\t-3.30e-04 +- 4.27e-02\n",
      "[dimension 138/145]  inactive:\t4.76e-04 +- 2.65e-02\n",
      "[dimension 139/145]  inactive:\t6.84e-04 +- 2.37e-02\n",
      "[dimension 140/145]  inactive:\t-1.18e-03 +- 2.62e-02\n",
      "[dimension 141/145]  inactive:\t1.57e-03 +- 3.29e-02\n",
      "[dimension 142/145]  inactive:\t1.24e-03 +- 1.79e-02\n",
      "[dimension 143/145]  inactive:\t8.04e-04 +- 3.65e-02\n",
      "[dimension 144/145]  inactive:\t4.27e-04 +- 2.54e-02\n",
      "[dimension 145/145]  inactive:\t-2.88e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8508538]\n",
      "cov_act[[0.02674374]]\n",
      "Active_dimensions: [62]\n",
      "77, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:33<00:00, 44.63it/s, 31 steps of size 1.45e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    414.53      1.00\n",
      "  lambda[0]      2.52      8.34      0.98      0.00      5.14    835.80      1.00\n",
      "  lambda[1]      2.93     10.70      1.00      0.00      5.84    594.89      1.01\n",
      "  lambda[2]      3.04     11.42      1.04      0.00      5.22    592.40      1.00\n",
      "  lambda[3]      3.02     10.64      1.04      0.00      5.89    643.17      1.01\n",
      "  lambda[4]      2.67      6.94      0.96      0.00      5.29    993.49      1.00\n",
      "  lambda[5]      2.91      7.72      0.98      0.00      5.63    703.45      1.00\n",
      "  lambda[6]      4.41     16.66      1.01      0.00      9.08    504.78      1.00\n",
      "  lambda[7]      3.28     10.06      0.96      0.00      6.48    501.75      1.00\n",
      "  lambda[8]      2.32      4.31      0.97      0.00      5.61   1056.59      1.00\n",
      "  lambda[9]      2.36      6.98      0.92      0.00      4.47    927.37      1.00\n",
      " lambda[10]      3.40     11.81      1.03      0.00      6.48    921.31      1.00\n",
      " lambda[11]      2.82      6.70      1.00      0.00      5.85    824.71      1.00\n",
      " lambda[12]      3.40      9.53      0.99      0.00      6.37    635.43      1.00\n",
      " lambda[13]      2.60      7.45      0.89      0.00      5.34    765.67      1.00\n",
      " lambda[14]      4.02     22.21      0.96      0.00      5.82    851.65      1.00\n",
      " lambda[15]      3.31     12.15      1.01      0.01      5.22    583.95      1.00\n",
      " lambda[16]      3.51      9.89      0.97      0.00      8.01    681.18      1.00\n",
      " lambda[17]      3.20     15.65      0.99      0.00      5.19    607.61      1.00\n",
      " lambda[18]      2.43      5.16      0.95      0.00      5.35    903.29      1.01\n",
      " lambda[19]      3.42     14.34      1.02      0.01      5.76    732.98      1.00\n",
      " lambda[20]      2.72      6.41      1.02      0.00      5.42    867.37      1.00\n",
      " lambda[21]      3.62     12.86      1.04      0.01      6.94    769.24      1.00\n",
      " lambda[22]      3.21     11.99      0.98      0.00      5.63    432.29      1.00\n",
      " lambda[23]      3.00      7.74      1.02      0.00      5.79    770.83      1.00\n",
      " lambda[24]      3.52     15.09      1.02      0.00      6.04    749.79      1.00\n",
      " lambda[25]      2.90      7.16      0.97      0.01      5.96    476.73      1.00\n",
      " lambda[26]      3.15     10.21      0.97      0.00      5.35    635.63      1.00\n",
      " lambda[27]      2.98      7.61      0.99      0.00      6.85    688.33      1.00\n",
      " lambda[28]      2.46      5.66      1.02      0.00      5.32    754.48      1.00\n",
      " lambda[29]      2.81      7.45      0.90      0.00      5.55    650.97      1.00\n",
      " lambda[30]      6.66     71.87      1.03      0.00      6.98    524.73      1.00\n",
      " lambda[31]      3.37     10.64      1.05      0.00      6.42    685.09      1.00\n",
      " lambda[32]      3.04     10.63      1.01      0.00      5.69    970.03      1.00\n",
      " lambda[33]      3.15     10.62      0.94      0.00      5.45    848.51      1.00\n",
      " lambda[34]      2.86      9.54      0.99      0.00      5.81    546.10      1.00\n",
      " lambda[35]      2.39      5.50      0.98      0.00      4.92    894.13      1.00\n",
      " lambda[36]      3.23     14.63      1.01      0.00      5.65    822.53      1.00\n",
      " lambda[37]      2.94      6.45      1.00      0.00      6.47    685.48      1.00\n",
      " lambda[38]      3.17     10.68      0.92      0.00      5.46    742.70      1.00\n",
      " lambda[39]      3.68     16.68      0.96      0.00      5.85    689.98      1.00\n",
      " lambda[40]      3.86     15.05      0.92      0.00      6.30    657.86      1.00\n",
      " lambda[41]      7.90     62.51      0.95      0.00      8.57    638.20      1.00\n",
      " lambda[42]      3.16     13.06      0.95      0.00      5.50    778.85      1.00\n",
      " lambda[43]      3.72     26.46      0.91      0.00      5.82    820.58      1.00\n",
      " lambda[44]      3.13     10.87      0.99      0.00      6.00    718.83      1.00\n",
      " lambda[45]      2.55      6.67      0.95      0.00      4.96    848.27      1.00\n",
      " lambda[46]      2.82     10.42      0.97      0.00      4.96    699.08      1.00\n",
      " lambda[47]      3.47     21.55      0.99      0.00      6.44    507.47      1.00\n",
      " lambda[48]      2.71      8.10      1.04      0.01      5.31    735.63      1.00\n",
      " lambda[49]      2.91      8.09      0.95      0.00      5.70    780.98      1.00\n",
      " lambda[50]      2.78      7.43      0.98      0.00      5.76    855.57      1.00\n",
      " lambda[51]      4.49     15.71      1.00      0.00      7.73    816.18      1.00\n",
      " lambda[52]      3.46     13.34      0.97      0.00      5.69    643.47      1.00\n",
      " lambda[53]      3.38     11.04      0.93      0.00      6.26    699.79      1.00\n",
      " lambda[54]      2.59      9.37      0.93      0.00      5.02    553.05      1.00\n",
      " lambda[55]      3.54     14.46      1.02      0.00      5.80    781.34      1.00\n",
      " lambda[56]      3.13     16.58      1.02      0.00      5.02    817.66      1.00\n",
      " lambda[57]      4.53     29.43      0.96      0.00      6.48    425.09      1.00\n",
      " lambda[58]      2.38      5.35      0.95      0.00      4.96    641.58      1.00\n",
      " lambda[59]      2.96      7.18      0.95      0.00      6.61    495.79      1.00\n",
      " lambda[60]      3.31     12.37      0.95      0.00      5.51    556.70      1.00\n",
      " lambda[61]      3.17     11.42      1.02      0.00      5.71    864.68      1.00\n",
      " lambda[62]   4783.86  61726.06    302.37      0.00   2948.73    799.53      1.00\n",
      " lambda[63]      2.46     10.29      0.99      0.00      4.68    940.85      1.00\n",
      " lambda[64]      2.84      7.27      0.98      0.01      5.45    750.84      1.00\n",
      " lambda[65]      3.46     12.26      0.97      0.00      5.82    661.17      1.00\n",
      " lambda[66]      3.00      7.33      1.03      0.00      6.30    724.24      1.00\n",
      " lambda[67]      3.22      9.57      0.97      0.00      6.39    873.20      1.00\n",
      " lambda[68]      3.43     22.73      0.96      0.00      5.49    781.87      1.00\n",
      " lambda[69]      3.79     12.67      0.95      0.00      7.28    911.91      1.00\n",
      " lambda[70]      2.78      7.92      0.96      0.00      6.12    920.43      1.00\n",
      " lambda[71]      2.83     12.68      0.98      0.00      4.42    659.51      1.00\n",
      " lambda[72]      2.57      5.95      0.96      0.00      5.14    792.03      1.00\n",
      " lambda[73]      2.71      6.08      1.01      0.00      5.52    662.18      1.00\n",
      " lambda[74]      2.32      4.10      1.05      0.00      5.09    907.03      1.00\n",
      " lambda[75]      3.55     11.00      0.99      0.00      6.09    910.34      1.00\n",
      " lambda[76]      2.83      7.08      0.99      0.00      5.82    708.86      1.00\n",
      " lambda[77]     14.62    103.43      1.10      0.00      8.84    292.02      1.01\n",
      " lambda[78]      2.99      8.12      1.03      0.01      6.09    724.47      1.00\n",
      " lambda[79]      3.13      8.90      1.02      0.00      6.46    695.05      1.00\n",
      " lambda[80]      5.41     48.88      1.01      0.00      6.92    948.93      1.00\n",
      " lambda[81]      2.41      6.40      1.03      0.00      4.79    906.07      1.00\n",
      " lambda[82]      2.75     11.91      0.94      0.00      4.54    391.77      1.00\n",
      " lambda[83]      2.42      6.13      0.93      0.00      5.51   1067.32      1.00\n",
      " lambda[84]      3.21     16.18      1.03      0.00      5.88    871.84      1.00\n",
      " lambda[85]      2.83      7.68      0.97      0.00      5.70    495.32      1.00\n",
      " lambda[86]      3.10     15.01      1.00      0.01      5.64    759.92      1.00\n",
      " lambda[87]      3.25      9.22      0.96      0.00      6.59    731.77      1.00\n",
      " lambda[88]      2.54      7.76      0.96      0.00      5.41    847.36      1.00\n",
      " lambda[89]    152.88   1044.67      1.29      0.00    173.63    132.38      1.02\n",
      " lambda[90]      2.35      6.40      0.99      0.00      4.37    754.07      1.00\n",
      " lambda[91]      2.55      6.06      0.96      0.01      4.96    792.83      1.00\n",
      " lambda[92]      2.34      4.43      0.96      0.00      5.46    755.06      1.00\n",
      " lambda[93]      2.75     10.55      0.98      0.00      5.44    952.21      1.00\n",
      " lambda[94]      2.40      7.85      0.97      0.00      4.36    620.08      1.00\n",
      " lambda[95]      2.95      8.51      1.05      0.00      6.27    899.39      1.00\n",
      " lambda[96]      2.65      7.52      0.93      0.00      5.03    539.46      1.00\n",
      " lambda[97]      3.10     11.13      1.00      0.00      5.50    749.19      1.00\n",
      " lambda[98]      6.00     41.45      0.97      0.00      5.81    204.10      1.00\n",
      " lambda[99]      2.69      7.36      1.01      0.00      5.09    675.48      1.00\n",
      "lambda[100]      3.38     13.43      0.95      0.00      6.29    845.57      1.00\n",
      "lambda[101]      3.01      9.60      0.95      0.00      5.77    698.63      1.00\n",
      "lambda[102]      2.58      6.56      0.87      0.00      4.99    725.25      1.00\n",
      "lambda[103]      2.29      4.09      0.99      0.00      5.39    665.03      1.00\n",
      "lambda[104]      2.87      8.48      0.94      0.00      5.54    565.15      1.00\n",
      "lambda[105]      3.16      9.05      1.00      0.00      6.42    643.93      1.00\n",
      "lambda[106]      2.41      5.12      1.03      0.00      5.08    709.57      1.00\n",
      "lambda[107]      3.85     17.68      1.00      0.00      6.56    445.38      1.01\n",
      "lambda[108]      2.61      8.85      0.94      0.00      5.41    798.28      1.00\n",
      "lambda[109]      2.94      6.68      1.00      0.00      6.66    694.25      1.00\n",
      "lambda[110]      2.97      7.49      1.05      0.00      6.15    786.36      1.00\n",
      "lambda[111]      3.64     11.92      0.98      0.00      6.68    665.36      1.00\n",
      "lambda[112]      2.88     11.88      0.93      0.02      5.82   1005.76      1.00\n",
      "lambda[113]      3.62     13.32      1.06      0.00      6.09    739.08      1.00\n",
      "lambda[114]      3.90     12.21      1.04      0.00      7.79    726.33      1.00\n",
      "lambda[115]      3.82     13.37      0.93      0.00      6.31    750.15      1.00\n",
      "lambda[116]      3.71     15.88      1.10      0.00      5.60    433.84      1.00\n",
      "lambda[117]      3.18      9.64      0.98      0.00      6.00    867.58      1.00\n",
      "lambda[118]      3.55     15.24      0.99      0.00      6.18    825.85      1.00\n",
      "lambda[119]      2.60      8.00      0.98      0.00      5.42    996.42      1.00\n",
      "lambda[120]      4.35     21.00      0.97      0.00      6.72    743.01      1.00\n",
      "lambda[121]      2.94     10.84      0.92      0.00      5.57    864.00      1.00\n",
      "lambda[122]      3.66     20.05      1.02      0.00      5.90    855.65      1.00\n",
      "lambda[123]      2.43      6.57      0.90      0.00      5.10    783.70      1.00\n",
      "lambda[124]      2.79      5.83      0.97      0.00      6.52    745.87      1.00\n",
      "lambda[125]      2.83      7.52      0.98      0.00      5.96    609.87      1.00\n",
      "lambda[126]      2.46      5.93      0.90      0.00      4.48    780.24      1.00\n",
      "lambda[127]      3.60     14.98      0.97      0.00      6.58    828.82      1.00\n",
      "lambda[128]      3.05     12.46      0.95      0.00      4.94    415.61      1.00\n",
      "lambda[129]      3.85     16.29      0.98      0.00      6.33    937.75      1.00\n",
      "lambda[130]      3.02      7.54      0.96      0.00      6.45    722.97      1.00\n",
      "lambda[131]      5.27     38.10      1.01      0.00      6.53    369.75      1.00\n",
      "lambda[132]      2.56      5.32      0.94      0.00      5.62    897.19      1.00\n",
      "lambda[133]      2.63      5.93      0.97      0.00      5.29    980.87      1.00\n",
      "lambda[134]      3.69     12.94      0.95      0.00      7.46    780.50      1.00\n",
      "lambda[135]      2.40      6.62      0.98      0.00      4.58    542.50      1.00\n",
      "lambda[136]      2.86      7.09      1.00      0.01      5.43    415.80      1.00\n",
      "lambda[137]      2.58      7.87      0.97      0.00      4.86    759.17      1.00\n",
      "lambda[138]      3.23     11.44      0.98      0.00      5.10    699.45      1.00\n",
      "lambda[139]      3.40     12.22      0.99      0.00      6.38    834.76      1.00\n",
      "lambda[140]      3.04      8.66      0.95      0.00      5.71    878.10      1.00\n",
      "lambda[141]      2.39      4.81      0.96      0.00      5.29    649.18      1.00\n",
      "lambda[142]      7.10     87.29      0.93      0.01      6.04    630.50      1.00\n",
      "lambda[143]      2.30      4.65      1.01      0.01      5.12    841.61      1.00\n",
      "        msq      1.65      1.11      1.38      0.59      2.98    722.86      1.00\n",
      "      sigma      3.98      5.92      1.44      0.00     11.59   1315.01      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    505.92      1.02\n",
      "       xisq     15.90     34.25      6.83      0.55     33.98    779.82      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 37.88143515586853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.62e-05 +- 1.15e-02\n",
      "[dimension 02/145]  inactive:\t7.82e-04 +- 1.62e-02\n",
      "[dimension 03/145]  inactive:\t3.74e-04 +- 1.55e-02\n",
      "[dimension 04/145]  inactive:\t1.48e-03 +- 1.73e-02\n",
      "[dimension 05/145]  inactive:\t5.84e-05 +- 1.26e-02\n",
      "[dimension 06/145]  inactive:\t9.82e-04 +- 2.23e-02\n",
      "[dimension 07/145]  inactive:\t7.65e-04 +- 1.56e-02\n",
      "[dimension 08/145]  inactive:\t8.26e-04 +- 2.05e-02\n",
      "[dimension 09/145]  inactive:\t3.79e-04 +- 1.37e-02\n",
      "[dimension 10/145]  inactive:\t4.05e-04 +- 1.24e-02\n",
      "[dimension 11/145]  inactive:\t1.15e-04 +- 1.57e-02\n",
      "[dimension 12/145]  inactive:\t3.21e-04 +- 1.45e-02\n",
      "[dimension 13/145]  inactive:\t2.36e-03 +- 2.77e-02\n",
      "[dimension 14/145]  inactive:\t1.35e-04 +- 1.65e-02\n",
      "[dimension 15/145]  inactive:\t1.08e-03 +- 2.75e-02\n",
      "[dimension 16/145]  inactive:\t8.03e-04 +- 1.64e-02\n",
      "[dimension 17/145]  inactive:\t8.15e-04 +- 2.19e-02\n",
      "[dimension 18/145]  inactive:\t1.37e-03 +- 2.60e-02\n",
      "[dimension 19/145]  inactive:\t-5.88e-04 +- 1.26e-02\n",
      "[dimension 20/145]  inactive:\t-1.71e-04 +- 1.81e-02\n",
      "[dimension 21/145]  inactive:\t-7.45e-04 +- 1.59e-02\n",
      "[dimension 22/145]  inactive:\t1.98e-04 +- 1.58e-02\n",
      "[dimension 23/145]  inactive:\t-5.96e-05 +- 1.98e-02\n",
      "[dimension 24/145]  inactive:\t9.83e-04 +- 1.91e-02\n",
      "[dimension 25/145]  inactive:\t2.22e-03 +- 1.88e-02\n",
      "[dimension 26/145]  inactive:\t1.89e-04 +- 1.66e-02\n",
      "[dimension 27/145]  inactive:\t9.87e-04 +- 2.01e-02\n",
      "[dimension 28/145]  inactive:\t5.59e-04 +- 1.51e-02\n",
      "[dimension 29/145]  inactive:\t8.31e-04 +- 1.82e-02\n",
      "[dimension 30/145]  inactive:\t7.64e-04 +- 1.74e-02\n",
      "[dimension 31/145]  inactive:\t7.53e-03 +- 6.01e-02\n",
      "[dimension 32/145]  inactive:\t-2.90e-04 +- 1.93e-02\n",
      "[dimension 33/145]  inactive:\t2.31e-03 +- 3.32e-02\n",
      "[dimension 34/145]  inactive:\t6.51e-04 +- 1.44e-02\n",
      "[dimension 35/145]  inactive:\t1.83e-03 +- 3.25e-02\n",
      "[dimension 36/145]  inactive:\t4.75e-04 +- 1.51e-02\n",
      "[dimension 37/145]  inactive:\t2.10e-03 +- 1.91e-02\n",
      "[dimension 38/145]  inactive:\t-1.04e-04 +- 1.87e-02\n",
      "[dimension 39/145]  inactive:\t1.03e-03 +- 1.98e-02\n",
      "[dimension 40/145]  inactive:\t4.40e-03 +- 3.96e-02\n",
      "[dimension 41/145]  inactive:\t1.10e-04 +- 2.60e-02\n",
      "[dimension 42/145]  inactive:\t6.96e-03 +- 6.64e-02\n",
      "[dimension 43/145]  inactive:\t3.01e-04 +- 1.35e-02\n",
      "[dimension 44/145]  inactive:\t4.55e-04 +- 2.35e-02\n",
      "[dimension 45/145]  inactive:\t2.59e-04 +- 1.66e-02\n",
      "[dimension 46/145]  inactive:\t5.71e-04 +- 1.13e-02\n",
      "[dimension 47/145]  inactive:\t-4.73e-04 +- 1.58e-02\n",
      "[dimension 48/145]  inactive:\t9.50e-04 +- 1.95e-02\n",
      "[dimension 49/145]  inactive:\t1.17e-03 +- 1.54e-02\n",
      "[dimension 50/145]  inactive:\t-3.31e-04 +- 1.75e-02\n",
      "[dimension 51/145]  inactive:\t1.53e-03 +- 2.23e-02\n",
      "[dimension 52/145]  inactive:\t4.17e-03 +- 2.17e-02\n",
      "[dimension 53/145]  inactive:\t-4.33e-04 +- 1.98e-02\n",
      "[dimension 54/145]  inactive:\t1.84e-04 +- 1.61e-02\n",
      "[dimension 55/145]  inactive:\t4.09e-04 +- 1.18e-02\n",
      "[dimension 56/145]  inactive:\t-1.18e-03 +- 1.58e-02\n",
      "[dimension 57/145]  inactive:\t2.59e-03 +- 3.42e-02\n",
      "[dimension 58/145]  inactive:\t6.19e-03 +- 5.34e-02\n",
      "[dimension 59/145]  inactive:\t-3.17e-04 +- 1.29e-02\n",
      "[dimension 60/145]  inactive:\t7.84e-04 +- 2.00e-02\n",
      "[dimension 61/145]  inactive:\t1.81e-03 +- 2.00e-02\n",
      "[dimension 62/145]  inactive:\t-1.36e-04 +- 1.61e-02\n",
      "[dimension 63/145]  active:\t6.74e-01 +- 4.30e-01\n",
      "[dimension 64/145]  inactive:\t-6.03e-04 +- 1.20e-02\n",
      "[dimension 65/145]  inactive:\t1.88e-04 +- 1.79e-02\n",
      "[dimension 66/145]  inactive:\t1.18e-03 +- 2.06e-02\n",
      "[dimension 67/145]  inactive:\t8.66e-04 +- 1.67e-02\n",
      "[dimension 68/145]  inactive:\t3.10e-04 +- 1.79e-02\n",
      "[dimension 69/145]  inactive:\t1.38e-03 +- 2.18e-02\n",
      "[dimension 70/145]  inactive:\t3.46e-03 +- 2.35e-02\n",
      "[dimension 71/145]  inactive:\t7.08e-04 +- 2.06e-02\n",
      "[dimension 72/145]  inactive:\t3.85e-04 +- 1.18e-02\n",
      "[dimension 73/145]  inactive:\t3.16e-04 +- 1.17e-02\n",
      "[dimension 74/145]  inactive:\t2.28e-04 +- 2.16e-02\n",
      "[dimension 75/145]  inactive:\t6.08e-04 +- 1.48e-02\n",
      "[dimension 76/145]  inactive:\t2.68e-03 +- 2.54e-02\n",
      "[dimension 77/145]  inactive:\t-3.16e-04 +- 1.77e-02\n",
      "[dimension 78/145]  inactive:\t2.17e-02 +- 1.22e-01\n",
      "[dimension 79/145]  inactive:\t3.91e-03 +- 2.73e-02\n",
      "[dimension 80/145]  inactive:\t7.71e-04 +- 2.25e-02\n",
      "[dimension 81/145]  inactive:\t3.65e-03 +- 4.24e-02\n",
      "[dimension 82/145]  inactive:\t2.23e-04 +- 1.06e-02\n",
      "[dimension 83/145]  inactive:\t-8.91e-04 +- 1.25e-02\n",
      "[dimension 84/145]  inactive:\t-2.32e-04 +- 1.54e-02\n",
      "[dimension 85/145]  inactive:\t1.39e-03 +- 1.92e-02\n",
      "[dimension 86/145]  inactive:\t-2.91e-04 +- 1.45e-02\n",
      "[dimension 87/145]  inactive:\t2.34e-03 +- 3.44e-02\n",
      "[dimension 88/145]  inactive:\t1.86e-03 +- 1.84e-02\n",
      "[dimension 89/145]  inactive:\t-1.85e-04 +- 1.38e-02\n",
      "[dimension 90/145]  inactive:\t1.22e-01 +- 3.02e-01\n",
      "[dimension 91/145]  inactive:\t2.58e-06 +- 1.02e-02\n",
      "[dimension 92/145]  inactive:\t-2.63e-04 +- 1.60e-02\n",
      "[dimension 93/145]  inactive:\t4.35e-05 +- 1.38e-02\n",
      "[dimension 94/145]  inactive:\t1.14e-03 +- 1.93e-02\n",
      "[dimension 95/145]  inactive:\t3.87e-05 +- 1.45e-02\n",
      "[dimension 96/145]  inactive:\t3.00e-04 +- 1.67e-02\n",
      "[dimension 97/145]  inactive:\t1.34e-03 +- 1.53e-02\n",
      "[dimension 98/145]  inactive:\t-3.90e-04 +- 1.79e-02\n",
      "[dimension 99/145]  inactive:\t7.39e-03 +- 6.72e-02\n",
      "[dimension 100/145]  inactive:\t-1.02e-04 +- 1.14e-02\n",
      "[dimension 101/145]  inactive:\t-9.59e-04 +- 1.37e-02\n",
      "[dimension 102/145]  inactive:\t-6.21e-05 +- 1.74e-02\n",
      "[dimension 103/145]  inactive:\t5.06e-04 +- 1.51e-02\n",
      "[dimension 104/145]  inactive:\t-3.81e-04 +- 1.20e-02\n",
      "[dimension 105/145]  inactive:\t1.58e-04 +- 1.79e-02\n",
      "[dimension 106/145]  inactive:\t3.31e-03 +- 2.69e-02\n",
      "[dimension 107/145]  inactive:\t-3.04e-04 +- 1.28e-02\n",
      "[dimension 108/145]  inactive:\t5.61e-03 +- 6.36e-02\n",
      "[dimension 109/145]  inactive:\t-7.58e-05 +- 1.30e-02\n",
      "[dimension 110/145]  inactive:\t3.96e-05 +- 1.95e-02\n",
      "[dimension 111/145]  inactive:\t1.29e-03 +- 2.22e-02\n",
      "[dimension 112/145]  inactive:\t2.63e-03 +- 2.78e-02\n",
      "[dimension 113/145]  inactive:\t-3.49e-04 +- 1.61e-02\n",
      "[dimension 114/145]  inactive:\t1.78e-03 +- 3.40e-02\n",
      "[dimension 115/145]  inactive:\t1.86e-03 +- 2.09e-02\n",
      "[dimension 116/145]  inactive:\t1.59e-03 +- 3.46e-02\n",
      "[dimension 117/145]  inactive:\t5.15e-03 +- 5.24e-02\n",
      "[dimension 118/145]  inactive:\t1.18e-03 +- 1.45e-02\n",
      "[dimension 119/145]  inactive:\t-4.05e-04 +- 2.22e-02\n",
      "[dimension 120/145]  inactive:\t4.44e-05 +- 1.56e-02\n",
      "[dimension 121/145]  inactive:\t3.12e-03 +- 3.00e-02\n",
      "[dimension 122/145]  inactive:\t-6.55e-04 +- 1.88e-02\n",
      "[dimension 123/145]  inactive:\t3.52e-03 +- 4.88e-02\n",
      "[dimension 124/145]  inactive:\t1.18e-04 +- 1.33e-02\n",
      "[dimension 125/145]  inactive:\t-2.16e-04 +- 2.15e-02\n",
      "[dimension 126/145]  inactive:\t4.09e-05 +- 1.65e-02\n",
      "[dimension 127/145]  inactive:\t1.51e-04 +- 1.18e-02\n",
      "[dimension 128/145]  inactive:\t2.96e-04 +- 1.98e-02\n",
      "[dimension 129/145]  inactive:\t7.32e-04 +- 2.26e-02\n",
      "[dimension 130/145]  inactive:\t1.94e-03 +- 2.08e-02\n",
      "[dimension 131/145]  inactive:\t4.19e-04 +- 2.09e-02\n",
      "[dimension 132/145]  inactive:\t5.66e-03 +- 5.90e-02\n",
      "[dimension 133/145]  inactive:\t1.27e-03 +- 1.46e-02\n",
      "[dimension 134/145]  inactive:\t-1.69e-05 +- 1.60e-02\n",
      "[dimension 135/145]  inactive:\t6.73e-04 +- 1.87e-02\n",
      "[dimension 136/145]  inactive:\t5.97e-04 +- 1.17e-02\n",
      "[dimension 137/145]  inactive:\t5.40e-04 +- 2.36e-02\n",
      "[dimension 138/145]  inactive:\t2.84e-04 +- 1.11e-02\n",
      "[dimension 139/145]  inactive:\t6.77e-04 +- 1.78e-02\n",
      "[dimension 140/145]  inactive:\t4.79e-04 +- 2.21e-02\n",
      "[dimension 141/145]  inactive:\t1.41e-03 +- 2.44e-02\n",
      "[dimension 142/145]  inactive:\t1.21e-03 +- 1.47e-02\n",
      "[dimension 143/145]  inactive:\t1.97e-03 +- 2.98e-02\n",
      "[dimension 144/145]  inactive:\t5.13e-04 +- 1.32e-02\n",
      "[dimension 145/145]  inactive:\t4.44e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8877876]\n",
      "cov_act[[0.02638312]]\n",
      "Active_dimensions: [62]\n",
      "78, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:24<00:00, 60.27it/s, 15 steps of size 2.27e-01. acc. prob=0.89] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    423.34      1.00\n",
      "  lambda[0]      2.70      8.97      0.94      0.00      5.28    776.32      1.00\n",
      "  lambda[1]      3.68     20.30      0.95      0.01      5.32    328.28      1.00\n",
      "  lambda[2]      3.03      8.59      1.00      0.01      5.66    415.57      1.00\n",
      "  lambda[3]      3.27     10.93      1.06      0.00      6.37    748.79      1.00\n",
      "  lambda[4]      2.79      6.88      0.98      0.00      5.71    836.87      1.00\n",
      "  lambda[5]      3.57     18.79      0.97      0.00      5.79    886.57      1.00\n",
      "  lambda[6]      2.70      6.87      0.91      0.00      5.65    808.20      1.00\n",
      "  lambda[7]      2.76      6.56      0.93      0.00      6.16    871.78      1.00\n",
      "  lambda[8]      2.62      6.17      0.96      0.00      5.66    704.41      1.00\n",
      "  lambda[9]      2.88      7.68      1.03      0.00      5.56    696.40      1.00\n",
      " lambda[10]      3.35     10.50      1.02      0.00      6.74    783.31      1.00\n",
      " lambda[11]      2.69      6.89      0.93      0.01      5.89    911.10      1.00\n",
      " lambda[12]      4.90     27.63      0.94      0.00      7.64    501.64      1.00\n",
      " lambda[13]      2.49      6.15      0.93      0.00      4.98    892.59      1.00\n",
      " lambda[14]      5.31     39.69      1.00      0.00      6.96    538.84      1.00\n",
      " lambda[15]      2.58      6.45      1.01      0.00      5.46    960.57      1.00\n",
      " lambda[16]      2.86      8.67      0.97      0.00      5.91    991.69      1.00\n",
      " lambda[17]      2.83      6.94      1.03      0.00      5.93    736.27      1.00\n",
      " lambda[18]      3.12     11.06      0.92      0.00      5.41    806.67      1.00\n",
      " lambda[19]      2.69      6.80      1.03      0.00      5.71    942.99      1.00\n",
      " lambda[20]      3.65     14.97      1.06      0.00      7.59    649.56      1.00\n",
      " lambda[21]      2.57      6.18      0.98      0.00      5.70    569.24      1.00\n",
      " lambda[22]      2.58      7.18      1.04      0.00      5.18    949.70      1.00\n",
      " lambda[23]      3.21     14.89      1.05      0.00      5.41    947.20      1.00\n",
      " lambda[24]      3.60     14.53      1.03      0.00      6.18    794.35      1.00\n",
      " lambda[25]      2.54      8.35      0.96      0.01      5.33    557.21      1.00\n",
      " lambda[26]      3.07     14.01      0.97      0.00      5.81    908.28      1.00\n",
      " lambda[27]      2.82      7.48      0.87      0.00      6.26    894.11      1.00\n",
      " lambda[28]      2.52      5.93      0.96      0.00      6.14    712.08      1.00\n",
      " lambda[29]      3.26     21.76      0.93      0.01      5.86    939.54      1.00\n",
      " lambda[30]      2.91      7.80      0.96      0.00      6.19    636.92      1.00\n",
      " lambda[31]      3.06      8.51      0.97      0.00      5.68    641.01      1.00\n",
      " lambda[32]      3.97     18.60      0.99      0.00      7.43    595.93      1.00\n",
      " lambda[33]      2.36      5.02      0.97      0.00      4.98    839.55      1.00\n",
      " lambda[34]      3.11     11.37      1.00      0.00      6.09    627.95      1.00\n",
      " lambda[35]      2.91      7.57      0.99      0.00      5.90    761.21      1.00\n",
      " lambda[36]      3.05      7.65      1.02      0.00      6.38    610.28      1.00\n",
      " lambda[37]      3.11     10.38      0.98      0.00      5.56    936.88      1.00\n",
      " lambda[38]      3.96     24.29      1.00      0.00      6.13    906.06      1.00\n",
      " lambda[39]      3.07     11.49      0.98      0.00      5.56    706.37      1.00\n",
      " lambda[40]      2.87      8.09      1.01      0.00      5.70    825.53      1.00\n",
      " lambda[41]     14.10    129.69      1.03      0.00      9.41    459.79      1.00\n",
      " lambda[42]      2.22      5.10      0.96      0.00      4.91    955.83      1.00\n",
      " lambda[43]      5.50     64.95      1.02      0.00      5.73    513.51      1.00\n",
      " lambda[44]      2.74      7.25      0.98      0.00      5.85    923.11      1.00\n",
      " lambda[45]      2.65      9.35      0.97      0.01      5.17    932.14      1.00\n",
      " lambda[46]      2.98     12.15      0.95      0.00      4.39    848.06      1.00\n",
      " lambda[47]      2.47      5.57      1.08      0.00      5.49    814.83      1.00\n",
      " lambda[48]      3.63      9.67      0.97      0.00      7.49    607.90      1.00\n",
      " lambda[49]      3.03      7.77      1.08      0.00      6.74    766.32      1.00\n",
      " lambda[50]      4.50     35.59      0.98      0.01      5.96    960.32      1.00\n",
      " lambda[51]      3.73     10.17      1.03      0.00      7.23    549.32      1.00\n",
      " lambda[52]      3.26     15.45      0.95      0.00      5.17    723.88      1.00\n",
      " lambda[53]      3.37     12.69      0.96      0.00      6.56    602.63      1.00\n",
      " lambda[54]      2.43      6.26      0.95      0.00      4.65    876.42      1.00\n",
      " lambda[55]      3.50     18.89      0.85      0.00      5.55    910.36      1.00\n",
      " lambda[56]      2.60      7.37      0.99      0.00      5.25    710.56      1.00\n",
      " lambda[57]     12.23     81.08      1.09      0.01     11.65    446.00      1.00\n",
      " lambda[58]      2.52      6.45      0.96      0.00      5.14    650.48      1.00\n",
      " lambda[59]      3.01      8.16      1.03      0.00      6.47    824.64      1.00\n",
      " lambda[60]      3.65     17.81      1.04      0.00      5.48    905.42      1.00\n",
      " lambda[61]      2.56      6.21      1.00      0.00      5.45    756.01      1.00\n",
      " lambda[62]    505.84   2411.72    133.42      0.01    822.78    356.01      1.00\n",
      " lambda[63]      2.88     11.61      0.99      0.00      5.19    932.48      1.00\n",
      " lambda[64]      2.47      6.01      0.97      0.00      4.81    870.38      1.00\n",
      " lambda[65]      3.00     10.68      0.95      0.00      5.72    807.61      1.00\n",
      " lambda[66]      3.42     10.20      0.96      0.00      6.96    742.40      1.00\n",
      " lambda[67]      3.05      9.19      1.03      0.00      5.86    906.36      1.00\n",
      " lambda[68]      3.26      9.54      0.98      0.00      6.02    725.61      1.00\n",
      " lambda[69]      3.56     13.58      0.99      0.00      6.78    630.45      1.00\n",
      " lambda[70]      2.55      6.43      0.99      0.00      4.78    617.58      1.00\n",
      " lambda[71]      3.25     10.41      1.03      0.01      5.66    537.08      1.00\n",
      " lambda[72]      2.63      6.95      1.01      0.01      5.34    604.27      1.00\n",
      " lambda[73]      3.08     11.37      0.95      0.00      5.98    612.66      1.01\n",
      " lambda[74]      2.73      8.18      1.00      0.01      5.71    762.79      1.00\n",
      " lambda[75]      5.67     33.82      1.03      0.00      7.77    861.88      1.00\n",
      " lambda[76]      2.73      6.17      0.99      0.00      5.79    706.55      1.00\n",
      " lambda[77]      7.90     63.38      0.98      0.00      6.66    527.33      1.00\n",
      " lambda[78]      2.97      7.70      1.02      0.01      6.16    554.69      1.00\n",
      " lambda[79]      2.68      9.96      0.94      0.01      4.69    716.49      1.00\n",
      " lambda[80]      3.33      9.07      1.00      0.00      6.93    601.23      1.00\n",
      " lambda[81]      2.83      6.84      1.00      0.00      6.41    681.03      1.00\n",
      " lambda[82]      2.56      6.50      0.95      0.00      5.33    775.96      1.00\n",
      " lambda[83]      3.42     11.38      1.02      0.00      6.53    716.92      1.00\n",
      " lambda[84]      6.61     74.74      0.94      0.00      6.21    947.32      1.00\n",
      " lambda[85]      2.81     10.94      0.98      0.00      6.05    849.34      1.00\n",
      " lambda[86]      4.30     23.88      0.98      0.00      6.59    655.95      1.00\n",
      " lambda[87]      2.79      7.19      0.94      0.00      5.64    869.96      1.00\n",
      " lambda[88]      2.83      7.71      0.98      0.01      5.56    431.41      1.00\n",
      " lambda[89]     80.54    590.50      1.33      0.00     92.99    270.18      1.00\n",
      " lambda[90]      2.54      6.44      0.93      0.00      5.27    668.88      1.00\n",
      " lambda[91]      2.88      8.94      1.04      0.00      5.10    432.80      1.00\n",
      " lambda[92]      2.75      6.24      0.96      0.00      5.86    936.29      1.00\n",
      " lambda[93]      2.52      8.67      1.01      0.00      4.72    725.68      1.00\n",
      " lambda[94]      3.13      8.86      0.99      0.00      6.07    742.33      1.00\n",
      " lambda[95]      3.63     13.65      1.00      0.00      6.46    748.16      1.00\n",
      " lambda[96]      3.45     10.89      1.03      0.00      5.93    462.73      1.00\n",
      " lambda[97]      2.41      4.96      1.04      0.00      5.21    731.94      1.00\n",
      " lambda[98]      4.97     25.90      1.01      0.00      5.90    333.82      1.00\n",
      " lambda[99]      2.61      7.48      0.94      0.00      6.01    908.25      1.00\n",
      "lambda[100]      3.04      9.81      1.01      0.00      6.38    941.43      1.00\n",
      "lambda[101]      3.19      9.71      0.99      0.00      5.84    589.66      1.00\n",
      "lambda[102]      2.79      8.22      0.99      0.00      6.05    953.54      1.00\n",
      "lambda[103]      3.33     17.56      0.92      0.00      5.36    328.97      1.00\n",
      "lambda[104]      2.84      8.56      0.97      0.00      4.84    551.77      1.00\n",
      "lambda[105]      3.28      8.65      0.99      0.00      6.57    715.81      1.00\n",
      "lambda[106]      2.85     10.90      0.92      0.00      5.12    694.83      1.00\n",
      "lambda[107]      4.19     14.61      1.05      0.01      6.33    420.47      1.00\n",
      "lambda[108]      2.49      7.26      0.97      0.00      5.30    925.85      1.00\n",
      "lambda[109]      4.26     14.32      1.00      0.00      7.49    586.81      1.00\n",
      "lambda[110]      3.49     14.37      1.00      0.00      5.76    738.15      1.00\n",
      "lambda[111]      7.39     82.27      1.05      0.00      6.38    653.85      1.00\n",
      "lambda[112]      2.20      4.26      1.03      0.01      4.83    767.22      1.00\n",
      "lambda[113]      3.90     17.08      0.99      0.00      6.27    319.57      1.00\n",
      "lambda[114]      2.93     22.35      0.93      0.00      4.99   1000.91      1.00\n",
      "lambda[115]      3.61     14.86      1.00      0.00      6.51    846.88      1.00\n",
      "lambda[116]      3.67     23.92      1.00      0.01      5.97    975.82      1.00\n",
      "lambda[117]      3.26     11.99      0.95      0.00      6.02    922.36      1.00\n",
      "lambda[118]      3.00     12.22      0.96      0.00      5.74    757.90      1.00\n",
      "lambda[119]      4.08     13.57      0.99      0.00      7.04    684.89      1.00\n",
      "lambda[120]      3.58     10.77      0.94      0.00      7.59    695.26      1.00\n",
      "lambda[121]      3.14      9.07      0.97      0.00      6.17    627.21      1.00\n",
      "lambda[122]      3.93     21.29      0.96      0.00      5.64    488.34      1.00\n",
      "lambda[123]      2.55      5.37      0.92      0.00      6.12    662.99      1.00\n",
      "lambda[124]      2.95      7.59      0.98      0.01      6.41    861.55      1.00\n",
      "lambda[125]      2.94      8.72      0.91      0.00      6.31    728.81      1.00\n",
      "lambda[126]      2.41      7.26      0.95      0.00      5.06    841.05      1.00\n",
      "lambda[127]      3.00      9.62      0.96      0.00      5.23    866.94      1.00\n",
      "lambda[128]      4.73     36.43      0.99      0.00      6.45    417.62      1.00\n",
      "lambda[129]      3.44     18.62      0.91      0.00      5.11    772.67      1.00\n",
      "lambda[130]      3.00      8.65      0.93      0.00      5.98    733.10      1.00\n",
      "lambda[131]      4.79     32.40      1.01      0.00      5.54    525.97      1.00\n",
      "lambda[132]      2.82      6.84      1.04      0.00      5.59    734.36      1.00\n",
      "lambda[133]      2.64      6.61      0.92      0.00      5.19    820.50      1.00\n",
      "lambda[134]      2.84      7.10      0.98      0.00      5.91    912.25      1.00\n",
      "lambda[135]      2.32      5.41      0.96      0.00      4.51    976.14      1.00\n",
      "lambda[136]      3.00      8.77      0.96      0.00      5.90    521.65      1.00\n",
      "lambda[137]      3.00     10.10      1.05      0.00      5.59    825.07      1.00\n",
      "lambda[138]      3.42     12.78      0.97      0.00      6.24    684.75      1.00\n",
      "lambda[139]      2.77      6.45      0.96      0.00      5.54    665.02      1.00\n",
      "lambda[140]      2.96     11.06      0.96      0.00      5.67    928.88      1.00\n",
      "lambda[141]      2.82      8.06      0.93      0.00      6.09    676.38      1.00\n",
      "lambda[142]      3.69     15.87      0.99      0.00      5.85    691.68      1.00\n",
      "lambda[143]      2.56      9.82      0.96      0.00      5.01    987.48      1.00\n",
      "        msq  26549.28 581251.19     29.28      1.11    828.14    984.69      1.00\n",
      "      sigma      4.73      5.79      2.25      0.01     13.03   1252.82      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    659.98      1.00\n",
      "       xisq      1.26      0.65      1.10      0.45      2.14    875.82      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 28.806435108184814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.41e-04 +- 2.13e-02\n",
      "[dimension 02/145]  inactive:\t5.99e-05 +- 3.32e-02\n",
      "[dimension 03/145]  inactive:\t3.31e-04 +- 3.09e-02\n",
      "[dimension 04/145]  inactive:\t4.66e-03 +- 3.52e-02\n",
      "[dimension 05/145]  inactive:\t-4.21e-04 +- 3.32e-02\n",
      "[dimension 06/145]  inactive:\t3.50e-03 +- 4.39e-02\n",
      "[dimension 07/145]  inactive:\t6.94e-04 +- 2.07e-02\n",
      "[dimension 08/145]  inactive:\t5.93e-04 +- 2.84e-02\n",
      "[dimension 09/145]  inactive:\t4.91e-04 +- 2.56e-02\n",
      "[dimension 10/145]  inactive:\t2.76e-04 +- 2.22e-02\n",
      "[dimension 11/145]  inactive:\t-7.63e-04 +- 2.99e-02\n",
      "[dimension 12/145]  inactive:\t-1.85e-04 +- 2.89e-02\n",
      "[dimension 13/145]  inactive:\t6.49e-03 +- 4.92e-02\n",
      "[dimension 14/145]  inactive:\t-1.53e-03 +- 2.61e-02\n",
      "[dimension 15/145]  inactive:\t7.54e-04 +- 3.96e-02\n",
      "[dimension 16/145]  inactive:\t7.43e-04 +- 2.23e-02\n",
      "[dimension 17/145]  inactive:\t-6.00e-05 +- 2.97e-02\n",
      "[dimension 18/145]  inactive:\t-4.65e-04 +- 3.06e-02\n",
      "[dimension 19/145]  inactive:\t-2.09e-03 +- 2.26e-02\n",
      "[dimension 20/145]  inactive:\t-1.31e-03 +- 2.96e-02\n",
      "[dimension 21/145]  inactive:\t-2.94e-03 +- 3.43e-02\n",
      "[dimension 22/145]  inactive:\t-9.76e-05 +- 2.43e-02\n",
      "[dimension 23/145]  inactive:\t-5.29e-04 +- 2.64e-02\n",
      "[dimension 24/145]  inactive:\t1.52e-03 +- 2.92e-02\n",
      "[dimension 25/145]  inactive:\t4.34e-03 +- 2.81e-02\n",
      "[dimension 26/145]  inactive:\t-6.39e-04 +- 2.58e-02\n",
      "[dimension 27/145]  inactive:\t8.10e-04 +- 2.81e-02\n",
      "[dimension 28/145]  inactive:\t1.13e-03 +- 2.16e-02\n",
      "[dimension 29/145]  inactive:\t-1.52e-05 +- 2.88e-02\n",
      "[dimension 30/145]  inactive:\t2.30e-03 +- 3.38e-02\n",
      "[dimension 31/145]  inactive:\t6.09e-03 +- 4.49e-02\n",
      "[dimension 32/145]  inactive:\t-1.40e-03 +- 2.91e-02\n",
      "[dimension 33/145]  inactive:\t5.42e-03 +- 5.56e-02\n",
      "[dimension 34/145]  inactive:\t8.90e-04 +- 2.02e-02\n",
      "[dimension 35/145]  inactive:\t6.40e-04 +- 3.35e-02\n",
      "[dimension 36/145]  inactive:\t2.22e-03 +- 3.34e-02\n",
      "[dimension 37/145]  inactive:\t5.38e-03 +- 3.35e-02\n",
      "[dimension 38/145]  inactive:\t-2.11e-03 +- 3.68e-02\n",
      "[dimension 39/145]  inactive:\t1.82e-03 +- 3.64e-02\n",
      "[dimension 40/145]  inactive:\t3.49e-03 +- 3.17e-02\n",
      "[dimension 41/145]  inactive:\t-1.54e-03 +- 2.62e-02\n",
      "[dimension 42/145]  inactive:\t2.20e-02 +- 1.21e-01\n",
      "[dimension 43/145]  inactive:\t-3.60e-04 +- 1.98e-02\n",
      "[dimension 44/145]  inactive:\t2.51e-04 +- 3.55e-02\n",
      "[dimension 45/145]  inactive:\t-6.71e-04 +- 2.87e-02\n",
      "[dimension 46/145]  inactive:\t9.83e-04 +- 1.73e-02\n",
      "[dimension 47/145]  inactive:\t-1.98e-03 +- 3.56e-02\n",
      "[dimension 48/145]  inactive:\t1.89e-03 +- 2.68e-02\n",
      "[dimension 49/145]  inactive:\t5.50e-03 +- 3.41e-02\n",
      "[dimension 50/145]  inactive:\t-1.66e-03 +- 2.70e-02\n",
      "[dimension 51/145]  inactive:\t3.54e-03 +- 3.67e-02\n",
      "[dimension 52/145]  inactive:\t6.07e-03 +- 2.57e-02\n",
      "[dimension 53/145]  inactive:\t-1.01e-03 +- 2.68e-02\n",
      "[dimension 54/145]  inactive:\t7.91e-04 +- 2.48e-02\n",
      "[dimension 55/145]  inactive:\t6.40e-04 +- 1.85e-02\n",
      "[dimension 56/145]  inactive:\t-2.40e-03 +- 2.46e-02\n",
      "[dimension 57/145]  inactive:\t1.94e-03 +- 3.93e-02\n",
      "[dimension 58/145]  inactive:\t2.76e-02 +- 1.11e-01\n",
      "[dimension 59/145]  inactive:\t-5.16e-04 +- 2.08e-02\n",
      "[dimension 60/145]  inactive:\t1.71e-03 +- 3.43e-02\n",
      "[dimension 61/145]  inactive:\t3.37e-03 +- 2.78e-02\n",
      "[dimension 62/145]  inactive:\t-1.10e-04 +- 2.44e-02\n",
      "[dimension 63/145]  active:\t6.26e-01 +- 4.57e-01\n",
      "[dimension 64/145]  inactive:\t-3.64e-03 +- 3.11e-02\n",
      "[dimension 65/145]  inactive:\t-5.36e-04 +- 2.47e-02\n",
      "[dimension 66/145]  inactive:\t3.82e-04 +- 2.58e-02\n",
      "[dimension 67/145]  inactive:\t2.27e-03 +- 3.18e-02\n",
      "[dimension 68/145]  inactive:\t-1.65e-03 +- 3.69e-02\n",
      "[dimension 69/145]  inactive:\t5.03e-03 +- 5.06e-02\n",
      "[dimension 70/145]  inactive:\t3.67e-03 +- 2.47e-02\n",
      "[dimension 71/145]  inactive:\t3.48e-04 +- 3.20e-02\n",
      "[dimension 72/145]  inactive:\t3.96e-04 +- 2.64e-02\n",
      "[dimension 73/145]  inactive:\t4.33e-04 +- 1.85e-02\n",
      "[dimension 74/145]  inactive:\t-1.42e-03 +- 2.74e-02\n",
      "[dimension 75/145]  inactive:\t4.81e-04 +- 2.60e-02\n",
      "[dimension 76/145]  inactive:\t7.48e-03 +- 4.58e-02\n",
      "[dimension 77/145]  inactive:\t-1.58e-03 +- 3.24e-02\n",
      "[dimension 78/145]  inactive:\t1.16e-02 +- 8.54e-02\n",
      "[dimension 79/145]  inactive:\t6.37e-03 +- 3.57e-02\n",
      "[dimension 80/145]  inactive:\t-5.94e-04 +- 3.20e-02\n",
      "[dimension 81/145]  inactive:\t1.83e-03 +- 3.64e-02\n",
      "[dimension 82/145]  inactive:\t3.46e-04 +- 2.09e-02\n",
      "[dimension 83/145]  inactive:\t-1.99e-03 +- 2.15e-02\n",
      "[dimension 84/145]  inactive:\t-2.24e-03 +- 3.20e-02\n",
      "[dimension 85/145]  inactive:\t4.51e-03 +- 4.12e-02\n",
      "[dimension 86/145]  inactive:\t-1.08e-03 +- 2.45e-02\n",
      "[dimension 87/145]  inactive:\t3.54e-03 +- 5.32e-02\n",
      "[dimension 88/145]  inactive:\t2.72e-03 +- 2.42e-02\n",
      "[dimension 89/145]  inactive:\t-1.27e-03 +- 2.29e-02\n",
      "[dimension 90/145]  inactive:\t1.28e-01 +- 3.11e-01\n",
      "[dimension 91/145]  inactive:\t1.89e-04 +- 2.51e-02\n",
      "[dimension 92/145]  inactive:\t-2.01e-03 +- 2.74e-02\n",
      "[dimension 93/145]  inactive:\t-4.43e-04 +- 2.69e-02\n",
      "[dimension 94/145]  inactive:\t1.40e-03 +- 2.42e-02\n",
      "[dimension 95/145]  inactive:\t-6.32e-04 +- 3.02e-02\n",
      "[dimension 96/145]  inactive:\t4.62e-04 +- 3.85e-02\n",
      "[dimension 97/145]  inactive:\t3.90e-03 +- 3.03e-02\n",
      "[dimension 98/145]  inactive:\t-9.05e-05 +- 2.77e-02\n",
      "[dimension 99/145]  inactive:\t8.45e-03 +- 7.66e-02\n",
      "[dimension 100/145]  inactive:\t-7.16e-04 +- 1.96e-02\n",
      "[dimension 101/145]  inactive:\t-2.64e-03 +- 2.34e-02\n",
      "[dimension 102/145]  inactive:\t-6.13e-04 +- 2.71e-02\n",
      "[dimension 103/145]  inactive:\t1.38e-03 +- 2.71e-02\n",
      "[dimension 104/145]  inactive:\t-1.28e-03 +- 1.91e-02\n",
      "[dimension 105/145]  inactive:\t-5.57e-05 +- 2.58e-02\n",
      "[dimension 106/145]  inactive:\t5.30e-03 +- 3.31e-02\n",
      "[dimension 107/145]  inactive:\t-1.40e-03 +- 2.04e-02\n",
      "[dimension 108/145]  inactive:\t1.24e-02 +- 8.94e-02\n",
      "[dimension 109/145]  inactive:\t-3.35e-04 +- 1.85e-02\n",
      "[dimension 110/145]  inactive:\t-1.20e-03 +- 3.62e-02\n",
      "[dimension 111/145]  inactive:\t3.57e-03 +- 4.27e-02\n",
      "[dimension 112/145]  inactive:\t1.08e-02 +- 7.55e-02\n",
      "[dimension 113/145]  inactive:\t-1.10e-03 +- 1.98e-02\n",
      "[dimension 114/145]  inactive:\t3.27e-03 +- 5.02e-02\n",
      "[dimension 115/145]  inactive:\t1.68e-03 +- 2.06e-02\n",
      "[dimension 116/145]  inactive:\t7.13e-04 +- 3.56e-02\n",
      "[dimension 117/145]  inactive:\t4.54e-03 +- 4.91e-02\n",
      "[dimension 118/145]  inactive:\t3.15e-03 +- 2.76e-02\n",
      "[dimension 119/145]  inactive:\t-2.20e-03 +- 3.36e-02\n",
      "[dimension 120/145]  inactive:\t1.07e-03 +- 4.58e-02\n",
      "[dimension 121/145]  inactive:\t4.97e-03 +- 4.04e-02\n",
      "[dimension 122/145]  inactive:\t-2.96e-03 +- 3.50e-02\n",
      "[dimension 123/145]  inactive:\t3.67e-03 +- 5.32e-02\n",
      "[dimension 124/145]  inactive:\t-1.53e-03 +- 2.02e-02\n",
      "[dimension 125/145]  inactive:\t-1.76e-03 +- 3.03e-02\n",
      "[dimension 126/145]  inactive:\t-1.24e-03 +- 2.85e-02\n",
      "[dimension 127/145]  inactive:\t7.40e-05 +- 1.82e-02\n",
      "[dimension 128/145]  inactive:\t-1.07e-03 +- 2.96e-02\n",
      "[dimension 129/145]  inactive:\t2.36e-04 +- 2.91e-02\n",
      "[dimension 130/145]  inactive:\t4.00e-03 +- 3.19e-02\n",
      "[dimension 131/145]  inactive:\t-1.35e-03 +- 3.37e-02\n",
      "[dimension 132/145]  inactive:\t6.76e-03 +- 5.75e-02\n",
      "[dimension 133/145]  inactive:\t2.76e-03 +- 2.25e-02\n",
      "[dimension 134/145]  inactive:\t-5.92e-04 +- 2.73e-02\n",
      "[dimension 135/145]  inactive:\t2.15e-04 +- 2.84e-02\n",
      "[dimension 136/145]  inactive:\t9.29e-04 +- 1.92e-02\n",
      "[dimension 137/145]  inactive:\t5.27e-05 +- 3.19e-02\n",
      "[dimension 138/145]  inactive:\t4.26e-04 +- 2.63e-02\n",
      "[dimension 139/145]  inactive:\t1.41e-04 +- 2.91e-02\n",
      "[dimension 140/145]  inactive:\t-1.25e-03 +- 3.43e-02\n",
      "[dimension 141/145]  inactive:\t1.44e-03 +- 2.85e-02\n",
      "[dimension 142/145]  inactive:\t1.55e-03 +- 2.09e-02\n",
      "[dimension 143/145]  inactive:\t3.28e-04 +- 3.27e-02\n",
      "[dimension 144/145]  inactive:\t4.65e-04 +- 2.39e-02\n",
      "[dimension 145/145]  inactive:\t9.54e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.00038801]\n",
      "cov_act[[3.9260834e-05]]\n",
      "Active_dimensions: [62]\n",
      "79, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.90it/s, 15 steps of size 1.89e-01. acc. prob=0.90] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    694.91      1.00\n",
      "  lambda[0]      2.28      6.33      0.90      0.00      4.54    728.40      1.00\n",
      "  lambda[1]      2.92     11.98      0.97      0.00      5.20    753.58      1.00\n",
      "  lambda[2]      2.63      5.23      0.99      0.01      6.02    627.69      1.00\n",
      "  lambda[3]      4.79     30.69      1.06      0.00      6.88    717.85      1.00\n",
      "  lambda[4]      2.94     11.07      1.00      0.00      5.62   1008.38      1.00\n",
      "  lambda[5]      3.04     10.09      1.00      0.00      6.48    922.26      1.00\n",
      "  lambda[6]      3.12     11.78      0.95      0.00      5.24    758.28      1.00\n",
      "  lambda[7]      2.71      7.27      0.91      0.00      5.41    559.13      1.00\n",
      "  lambda[8]      2.42      4.39      0.97      0.01      5.46    551.25      1.01\n",
      "  lambda[9]      2.48      4.80      0.99      0.00      5.80    814.49      1.00\n",
      " lambda[10]      3.46     12.81      1.05      0.00      6.11    673.96      1.00\n",
      " lambda[11]      2.52      6.42      1.03      0.00      5.17    832.69      1.00\n",
      " lambda[12]      3.92     13.53      0.97      0.01      7.12    557.40      1.00\n",
      " lambda[13]      2.66      6.87      1.03      0.00      5.78    647.45      1.00\n",
      " lambda[14]      7.02    124.68      0.95      0.00      5.01    885.94      1.00\n",
      " lambda[15]      3.32      9.08      0.99      0.00      6.76    822.79      1.01\n",
      " lambda[16]      3.99     13.23      0.99      0.00      7.14    628.64      1.00\n",
      " lambda[17]      4.24     40.67      0.95      0.00      5.16    717.16      1.00\n",
      " lambda[18]      2.81      5.94      0.90      0.00      7.60    811.56      1.00\n",
      " lambda[19]      2.90      8.37      1.08      0.00      6.18    777.09      1.00\n",
      " lambda[20]      2.87     10.64      0.94      0.00      5.49    901.01      1.00\n",
      " lambda[21]      2.61      5.96      1.01      0.00      5.74    678.19      1.00\n",
      " lambda[22]      2.60      5.69      1.00      0.00      5.59    705.05      1.00\n",
      " lambda[23]      2.66      7.17      1.02      0.00      4.69    668.59      1.00\n",
      " lambda[24]      3.47     12.28      0.91      0.00      6.37    805.63      1.00\n",
      " lambda[25]      2.38      4.90      0.98      0.01      5.74    528.00      1.00\n",
      " lambda[26]      3.46     27.24      0.98      0.00      5.14   1010.97      1.00\n",
      " lambda[27]      2.92      6.70      0.92      0.00      6.78    635.70      1.00\n",
      " lambda[28]      2.84      7.13      1.00      0.01      6.03    406.31      1.00\n",
      " lambda[29]      2.78      8.30      0.98      0.00      5.66    858.28      1.00\n",
      " lambda[30]      3.31     11.63      0.98      0.00      6.92    541.52      1.00\n",
      " lambda[31]      3.59     15.02      0.98      0.00      5.43    899.95      1.00\n",
      " lambda[32]      4.64     28.64      1.03      0.00      6.74    814.65      1.00\n",
      " lambda[33]      3.23     12.00      0.92      0.00      5.99    586.20      1.00\n",
      " lambda[34]      2.51      5.43      0.96      0.01      5.08    601.26      1.00\n",
      " lambda[35]      3.59     11.87      1.03      0.00      6.18    453.55      1.00\n",
      " lambda[36]      3.55     13.42      1.01      0.00      7.49    751.91      1.00\n",
      " lambda[37]      3.34     12.76      1.00      0.00      5.58    602.77      1.00\n",
      " lambda[38]      3.55      8.92      1.03      0.00      7.53    715.05      1.00\n",
      " lambda[39]      2.78      7.39      0.96      0.01      5.59    688.78      1.00\n",
      " lambda[40]      3.51     16.73      0.88      0.00      5.40    790.33      1.00\n",
      " lambda[41]     72.82    789.55      0.87      0.00     10.24    450.77      1.01\n",
      " lambda[42]      2.61      7.53      0.98      0.00      5.44    854.60      1.00\n",
      " lambda[43]      3.68     14.05      1.06      0.00      7.29   1020.58      1.00\n",
      " lambda[44]      2.71      6.55      0.95      0.00      5.52    625.67      1.00\n",
      " lambda[45]      2.36      5.20      1.00      0.00      5.01    639.78      1.00\n",
      " lambda[46]      2.61      7.10      0.95      0.00      5.15    751.74      1.00\n",
      " lambda[47]      3.16      8.42      0.96      0.00      6.05    521.85      1.00\n",
      " lambda[48]      2.64      9.51      0.95      0.01      5.55    914.46      1.00\n",
      " lambda[49]      3.83     15.89      0.94      0.00      6.33    552.52      1.01\n",
      " lambda[50]      3.01      7.77      0.94      0.00      6.14    712.03      1.00\n",
      " lambda[51]      8.68    134.29      1.04      0.00      6.90    869.36      1.00\n",
      " lambda[52]      2.61      6.08      1.02      0.00      6.07    870.35      1.00\n",
      " lambda[53]      2.64      7.26      0.99      0.00      4.95    723.09      1.00\n",
      " lambda[54]      2.19      5.31      0.92      0.01      4.35    866.33      1.00\n",
      " lambda[55]      3.18     12.14      1.02      0.00      5.42    714.62      1.00\n",
      " lambda[56]      3.29     10.63      1.04      0.00      5.74    677.26      1.00\n",
      " lambda[57]      5.97     29.14      0.96      0.00      7.53    438.51      1.00\n",
      " lambda[58]      2.19      4.42      0.92      0.00      5.16    899.52      1.00\n",
      " lambda[59]      3.70     21.33      0.99      0.00      5.83    973.08      1.00\n",
      " lambda[60]      3.65     14.82      0.98      0.00      5.82    916.13      1.00\n",
      " lambda[61]      3.14     11.64      1.02      0.00      5.32    668.18      1.00\n",
      " lambda[62]   1034.45   3660.56    195.56      0.01   2083.44    680.79      1.00\n",
      " lambda[63]      2.62      6.98      0.98      0.00      4.86    532.70      1.00\n",
      " lambda[64]      2.70      8.10      0.98      0.00      5.32    738.86      1.00\n",
      " lambda[65]      3.16     10.62      0.96      0.00      5.43    764.49      1.00\n",
      " lambda[66]      3.57     14.30      1.04      0.00      6.56    750.37      1.00\n",
      " lambda[67]      2.82      7.33      0.97      0.00      6.22    631.05      1.00\n",
      " lambda[68]      3.71     14.29      1.01      0.00      6.43    421.03      1.01\n",
      " lambda[69]      3.99     16.69      0.96      0.00      6.18    701.02      1.00\n",
      " lambda[70]      2.78      6.71      0.96      0.00      6.04    691.42      1.00\n",
      " lambda[71]      3.59     15.60      1.01      0.00      5.69    701.38      1.00\n",
      " lambda[72]      2.61      5.96      0.98      0.01      5.13    478.28      1.00\n",
      " lambda[73]      2.98      9.20      1.01      0.00      6.12    686.92      1.00\n",
      " lambda[74]      2.72      6.67      0.97      0.01      6.16    842.59      1.00\n",
      " lambda[75]      4.81     20.23      0.97      0.00      7.79    823.45      1.00\n",
      " lambda[76]      3.46     11.87      0.94      0.00      5.72    737.41      1.00\n",
      " lambda[77]      5.82     55.53      0.98      0.00      6.64    945.83      1.00\n",
      " lambda[78]      3.46     11.34      1.01      0.00      6.16    412.29      1.00\n",
      " lambda[79]      2.81      8.04      0.95      0.00      5.50    840.54      1.00\n",
      " lambda[80]      4.20     27.59      1.02      0.00      5.73    864.90      1.00\n",
      " lambda[81]      2.98      7.99      0.93      0.00      6.09    576.92      1.00\n",
      " lambda[82]      2.37      6.47      0.96      0.00      4.45    779.38      1.00\n",
      " lambda[83]      3.12      9.51      0.97      0.00      6.09    778.86      1.00\n",
      " lambda[84]      3.27     11.56      1.02      0.00      6.12    724.34      1.00\n",
      " lambda[85]      3.36     11.34      0.99      0.00      6.21    639.64      1.00\n",
      " lambda[86]      2.82      7.07      0.98      0.00      5.78    651.34      1.00\n",
      " lambda[87]      3.02     11.15      0.94      0.00      6.04    802.69      1.00\n",
      " lambda[88]      2.47      5.11      0.99      0.01      5.80    784.84      1.00\n",
      " lambda[89]   1978.84  49248.14      1.34      0.00    181.00    998.52      1.00\n",
      " lambda[90]      2.73      6.52      1.05      0.00      5.43    530.29      1.00\n",
      " lambda[91]      2.75      7.90      1.00      0.00      5.22    573.73      1.00\n",
      " lambda[92]      2.89      7.24      1.02      0.00      5.62    842.78      1.00\n",
      " lambda[93]      2.60      5.18      1.03      0.00      6.04    767.40      1.00\n",
      " lambda[94]      2.88      7.69      1.04      0.00      5.50    750.96      1.00\n",
      " lambda[95]      3.15     11.89      0.92      0.00      5.54    579.57      1.00\n",
      " lambda[96]      2.67      5.98      0.92      0.00      5.91    931.42      1.00\n",
      " lambda[97]      2.74      7.30      0.97      0.00      5.61    667.03      1.00\n",
      " lambda[98]      3.63     19.95      1.02      0.00      5.76    907.09      1.00\n",
      " lambda[99]      2.77      7.15      1.00      0.00      6.03    804.84      1.00\n",
      "lambda[100]      2.97      9.16      0.90      0.00      5.96    770.22      1.00\n",
      "lambda[101]      2.72      6.33      0.94      0.01      5.87    653.88      1.00\n",
      "lambda[102]      3.07      9.61      0.94      0.00      6.10    647.93      1.00\n",
      "lambda[103]      2.59     10.94      0.87      0.00      5.84    924.72      1.00\n",
      "lambda[104]      2.47      7.53      0.95      0.00      4.78   1035.53      1.00\n",
      "lambda[105]      3.68      9.74      1.05      0.00      7.18    568.35      1.00\n",
      "lambda[106]      2.52      5.58      0.93      0.00      5.70    771.47      1.00\n",
      "lambda[107]      7.48     77.41      0.96      0.00      5.64    723.45      1.00\n",
      "lambda[108]      2.31      4.47      0.99      0.01      5.51    686.88      1.00\n",
      "lambda[109]      5.84     95.04      0.93      0.00      5.47   1006.50      1.00\n",
      "lambda[110]      3.21      8.30      0.97      0.00      6.74    420.62      1.00\n",
      "lambda[111]      7.10     84.46      1.00      0.00      6.50    582.42      1.00\n",
      "lambda[112]      2.51      6.20      0.94      0.01      5.32    687.51      1.00\n",
      "lambda[113]      3.67     13.41      0.94      0.00      5.79    697.60      1.00\n",
      "lambda[114]      5.13     63.12      1.05      0.00      6.67    918.02      1.00\n",
      "lambda[115]      3.95     17.37      1.05      0.00      6.99    771.37      1.00\n",
      "lambda[116]      4.16     28.10      1.01      0.00      5.95    614.56      1.00\n",
      "lambda[117]      3.21     11.10      0.98      0.00      6.21    727.03      1.00\n",
      "lambda[118]      3.07     10.80      0.88      0.00      5.50    801.75      1.00\n",
      "lambda[119]      2.42      4.97      1.02      0.00      5.35    770.64      1.00\n",
      "lambda[120]      5.47     46.99      0.97      0.00      7.04    800.74      1.00\n",
      "lambda[121]      2.75      5.72      0.94      0.00      6.58    885.59      1.00\n",
      "lambda[122]      2.72      7.11      1.01      0.01      5.44    727.71      1.00\n",
      "lambda[123]      2.87      8.67      0.92      0.00      5.86    845.27      1.00\n",
      "lambda[124]      2.64      5.95      1.04      0.00      5.99    875.24      1.00\n",
      "lambda[125]      2.82      8.48      0.95      0.00      5.59    747.31      1.00\n",
      "lambda[126]      2.39      7.22      0.95      0.00      5.09    849.66      1.00\n",
      "lambda[127]      3.24      9.65      0.97      0.00      5.73    636.69      1.00\n",
      "lambda[128]      2.29      4.80      0.94      0.00      4.87    884.84      1.00\n",
      "lambda[129]      4.93     51.87      0.95      0.00      5.96   1007.29      1.00\n",
      "lambda[130]      3.05      7.36      0.96      0.00      6.44    694.83      1.00\n",
      "lambda[131]      3.63     19.15      1.00      0.00      5.73    747.26      1.00\n",
      "lambda[132]      2.90      7.07      1.01      0.00      6.04    770.19      1.00\n",
      "lambda[133]      2.92     13.54      0.95      0.00      5.01    980.83      1.00\n",
      "lambda[134]      3.42      9.59      1.00      0.00      7.62    695.55      1.00\n",
      "lambda[135]      2.51      6.27      0.94      0.00      5.05    652.01      1.00\n",
      "lambda[136]      3.03     13.97      0.99      0.01      5.49    754.51      1.00\n",
      "lambda[137]      2.64      7.94      0.98      0.01      5.07    694.61      1.00\n",
      "lambda[138]      2.87      8.17      0.97      0.00      5.22    736.05      1.00\n",
      "lambda[139]      2.89      8.18      1.00      0.00      5.26    703.09      1.00\n",
      "lambda[140]      3.27     10.75      0.94      0.00      5.77    635.68      1.00\n",
      "lambda[141]      2.87      8.49      0.90      0.00      5.78    665.72      1.01\n",
      "lambda[142]      3.62     16.99      1.01      0.01      5.66    754.68      1.00\n",
      "lambda[143]      2.45      6.60      0.91      0.01      5.82    588.14      1.00\n",
      "        msq      1.46      0.85      1.25      0.47      2.52    707.07      1.00\n",
      "      sigma      4.48      5.99      2.13      0.00     12.17   1179.11      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    877.20      1.00\n",
      "       xisq      1.15      0.60      1.00      0.42      1.95    975.50      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.69855618476868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.19e-04 +- 1.55e-02\n",
      "[dimension 02/145]  inactive:\t-1.89e-04 +- 1.76e-02\n",
      "[dimension 03/145]  inactive:\t1.90e-04 +- 2.15e-02\n",
      "[dimension 04/145]  inactive:\t4.40e-03 +- 3.56e-02\n",
      "[dimension 05/145]  inactive:\t-2.50e-04 +- 2.09e-02\n",
      "[dimension 06/145]  inactive:\t1.83e-03 +- 2.83e-02\n",
      "[dimension 07/145]  inactive:\t8.44e-04 +- 1.80e-02\n",
      "[dimension 08/145]  inactive:\t5.75e-04 +- 2.02e-02\n",
      "[dimension 09/145]  inactive:\t4.06e-04 +- 1.58e-02\n",
      "[dimension 10/145]  inactive:\t4.16e-04 +- 1.61e-02\n",
      "[dimension 11/145]  inactive:\t-7.31e-05 +- 1.86e-02\n",
      "[dimension 12/145]  inactive:\t5.32e-04 +- 1.99e-02\n",
      "[dimension 13/145]  inactive:\t4.05e-03 +- 3.99e-02\n",
      "[dimension 14/145]  inactive:\t-6.19e-04 +- 1.99e-02\n",
      "[dimension 15/145]  inactive:\t1.93e-03 +- 3.46e-02\n",
      "[dimension 16/145]  inactive:\t8.52e-04 +- 2.18e-02\n",
      "[dimension 17/145]  inactive:\t1.63e-03 +- 3.95e-02\n",
      "[dimension 18/145]  inactive:\t7.77e-04 +- 2.46e-02\n",
      "[dimension 19/145]  inactive:\t-1.23e-03 +- 1.67e-02\n",
      "[dimension 20/145]  inactive:\t-5.47e-04 +- 2.09e-02\n",
      "[dimension 21/145]  inactive:\t-7.71e-04 +- 1.76e-02\n",
      "[dimension 22/145]  inactive:\t5.84e-06 +- 1.83e-02\n",
      "[dimension 23/145]  inactive:\t-1.09e-04 +- 1.98e-02\n",
      "[dimension 24/145]  inactive:\t1.32e-03 +- 2.45e-02\n",
      "[dimension 25/145]  inactive:\t2.94e-03 +- 2.11e-02\n",
      "[dimension 26/145]  inactive:\t-2.44e-04 +- 1.97e-02\n",
      "[dimension 27/145]  inactive:\t1.15e-03 +- 2.42e-02\n",
      "[dimension 28/145]  inactive:\t9.64e-04 +- 1.88e-02\n",
      "[dimension 29/145]  inactive:\t4.09e-04 +- 2.27e-02\n",
      "[dimension 30/145]  inactive:\t1.39e-03 +- 2.69e-02\n",
      "[dimension 31/145]  inactive:\t3.63e-03 +- 3.25e-02\n",
      "[dimension 32/145]  inactive:\t-4.84e-04 +- 2.22e-02\n",
      "[dimension 33/145]  inactive:\t4.81e-03 +- 4.67e-02\n",
      "[dimension 34/145]  inactive:\t1.02e-03 +- 1.84e-02\n",
      "[dimension 35/145]  inactive:\t8.12e-04 +- 2.20e-02\n",
      "[dimension 36/145]  inactive:\t1.95e-03 +- 2.81e-02\n",
      "[dimension 37/145]  inactive:\t3.58e-03 +- 2.48e-02\n",
      "[dimension 38/145]  inactive:\t-3.48e-04 +- 2.33e-02\n",
      "[dimension 39/145]  inactive:\t2.38e-03 +- 3.44e-02\n",
      "[dimension 40/145]  inactive:\t2.24e-03 +- 2.35e-02\n",
      "[dimension 41/145]  inactive:\t-7.51e-04 +- 2.49e-02\n",
      "[dimension 42/145]  inactive:\t2.87e-02 +- 1.45e-01\n",
      "[dimension 43/145]  inactive:\t2.68e-04 +- 1.69e-02\n",
      "[dimension 44/145]  inactive:\t2.53e-05 +- 2.65e-02\n",
      "[dimension 45/145]  inactive:\t1.34e-04 +- 1.98e-02\n",
      "[dimension 46/145]  inactive:\t5.63e-04 +- 1.37e-02\n",
      "[dimension 47/145]  inactive:\t-1.29e-03 +- 2.71e-02\n",
      "[dimension 48/145]  inactive:\t2.03e-03 +- 2.69e-02\n",
      "[dimension 49/145]  inactive:\t1.83e-03 +- 1.99e-02\n",
      "[dimension 50/145]  inactive:\t-1.04e-03 +- 2.83e-02\n",
      "[dimension 51/145]  inactive:\t2.30e-03 +- 2.66e-02\n",
      "[dimension 52/145]  inactive:\t4.96e-03 +- 2.49e-02\n",
      "[dimension 53/145]  inactive:\t-8.30e-04 +- 1.86e-02\n",
      "[dimension 54/145]  inactive:\t3.23e-04 +- 1.68e-02\n",
      "[dimension 55/145]  inactive:\t6.14e-04 +- 1.49e-02\n",
      "[dimension 56/145]  inactive:\t-1.32e-03 +- 1.63e-02\n",
      "[dimension 57/145]  inactive:\t2.19e-03 +- 3.52e-02\n",
      "[dimension 58/145]  inactive:\t1.16e-02 +- 7.14e-02\n",
      "[dimension 59/145]  inactive:\t-2.77e-04 +- 1.39e-02\n",
      "[dimension 60/145]  inactive:\t1.35e-03 +- 2.98e-02\n",
      "[dimension 61/145]  inactive:\t3.37e-03 +- 3.00e-02\n",
      "[dimension 62/145]  inactive:\t-4.60e-04 +- 1.92e-02\n",
      "[dimension 63/145]  active:\t6.48e-01 +- 4.39e-01\n",
      "[dimension 64/145]  inactive:\t-9.38e-04 +- 1.50e-02\n",
      "[dimension 65/145]  inactive:\t2.11e-04 +- 1.87e-02\n",
      "[dimension 66/145]  inactive:\t4.80e-04 +- 2.09e-02\n",
      "[dimension 67/145]  inactive:\t1.48e-03 +- 2.25e-02\n",
      "[dimension 68/145]  inactive:\t-4.99e-05 +- 2.18e-02\n",
      "[dimension 69/145]  inactive:\t4.48e-03 +- 4.51e-02\n",
      "[dimension 70/145]  inactive:\t3.29e-03 +- 2.34e-02\n",
      "[dimension 71/145]  inactive:\t6.43e-04 +- 2.53e-02\n",
      "[dimension 72/145]  inactive:\t9.95e-04 +- 2.29e-02\n",
      "[dimension 73/145]  inactive:\t5.67e-04 +- 1.63e-02\n",
      "[dimension 74/145]  inactive:\t-5.55e-04 +- 2.42e-02\n",
      "[dimension 75/145]  inactive:\t6.62e-04 +- 1.85e-02\n",
      "[dimension 76/145]  inactive:\t5.77e-03 +- 4.04e-02\n",
      "[dimension 77/145]  inactive:\t-4.18e-04 +- 2.88e-02\n",
      "[dimension 78/145]  inactive:\t7.64e-03 +- 6.31e-02\n",
      "[dimension 79/145]  inactive:\t5.20e-03 +- 3.08e-02\n",
      "[dimension 80/145]  inactive:\t3.67e-04 +- 2.36e-02\n",
      "[dimension 81/145]  inactive:\t2.57e-03 +- 3.48e-02\n",
      "[dimension 82/145]  inactive:\t3.60e-04 +- 1.58e-02\n",
      "[dimension 83/145]  inactive:\t-9.68e-04 +- 1.43e-02\n",
      "[dimension 84/145]  inactive:\t-9.94e-04 +- 2.08e-02\n",
      "[dimension 85/145]  inactive:\t2.63e-03 +- 2.85e-02\n",
      "[dimension 86/145]  inactive:\t-8.89e-04 +- 1.98e-02\n",
      "[dimension 87/145]  inactive:\t1.35e-03 +- 2.45e-02\n",
      "[dimension 88/145]  inactive:\t1.95e-03 +- 2.07e-02\n",
      "[dimension 89/145]  inactive:\t-4.66e-04 +- 1.62e-02\n",
      "[dimension 90/145]  inactive:\t1.28e-01 +- 3.04e-01\n",
      "[dimension 91/145]  inactive:\t3.95e-05 +- 1.74e-02\n",
      "[dimension 92/145]  inactive:\t-8.27e-04 +- 1.77e-02\n",
      "[dimension 93/145]  inactive:\t-1.60e-04 +- 1.93e-02\n",
      "[dimension 94/145]  inactive:\t1.27e-03 +- 2.01e-02\n",
      "[dimension 95/145]  inactive:\t1.84e-04 +- 2.22e-02\n",
      "[dimension 96/145]  inactive:\t1.40e-03 +- 4.15e-02\n",
      "[dimension 97/145]  inactive:\t2.21e-03 +- 2.28e-02\n",
      "[dimension 98/145]  inactive:\t-2.25e-04 +- 2.14e-02\n",
      "[dimension 99/145]  inactive:\t4.06e-03 +- 4.43e-02\n",
      "[dimension 100/145]  inactive:\t-2.25e-04 +- 1.50e-02\n",
      "[dimension 101/145]  inactive:\t-1.71e-03 +- 1.87e-02\n",
      "[dimension 102/145]  inactive:\t1.41e-04 +- 2.38e-02\n",
      "[dimension 103/145]  inactive:\t1.11e-03 +- 2.40e-02\n",
      "[dimension 104/145]  inactive:\t-6.04e-04 +- 1.58e-02\n",
      "[dimension 105/145]  inactive:\t3.32e-04 +- 1.91e-02\n",
      "[dimension 106/145]  inactive:\t6.26e-03 +- 3.95e-02\n",
      "[dimension 107/145]  inactive:\t-5.99e-04 +- 1.76e-02\n",
      "[dimension 108/145]  inactive:\t8.65e-03 +- 8.30e-02\n",
      "[dimension 109/145]  inactive:\t-3.20e-04 +- 1.71e-02\n",
      "[dimension 110/145]  inactive:\t5.93e-04 +- 2.77e-02\n",
      "[dimension 111/145]  inactive:\t1.13e-03 +- 2.41e-02\n",
      "[dimension 112/145]  inactive:\t5.59e-03 +- 5.41e-02\n",
      "[dimension 113/145]  inactive:\t-8.08e-04 +- 1.69e-02\n",
      "[dimension 114/145]  inactive:\t3.87e-03 +- 5.32e-02\n",
      "[dimension 115/145]  inactive:\t1.66e-03 +- 1.97e-02\n",
      "[dimension 116/145]  inactive:\t8.71e-06 +- 2.31e-02\n",
      "[dimension 117/145]  inactive:\t3.17e-03 +- 3.90e-02\n",
      "[dimension 118/145]  inactive:\t2.28e-03 +- 2.08e-02\n",
      "[dimension 119/145]  inactive:\t-9.01e-04 +- 2.53e-02\n",
      "[dimension 120/145]  inactive:\t2.68e-04 +- 1.98e-02\n",
      "[dimension 121/145]  inactive:\t3.90e-03 +- 3.68e-02\n",
      "[dimension 122/145]  inactive:\t-1.35e-03 +- 2.44e-02\n",
      "[dimension 123/145]  inactive:\t6.92e-04 +- 1.95e-02\n",
      "[dimension 124/145]  inactive:\t-8.10e-04 +- 1.75e-02\n",
      "[dimension 125/145]  inactive:\t-7.80e-04 +- 2.08e-02\n",
      "[dimension 126/145]  inactive:\t-2.30e-04 +- 1.87e-02\n",
      "[dimension 127/145]  inactive:\t3.31e-04 +- 1.30e-02\n",
      "[dimension 128/145]  inactive:\t2.67e-04 +- 2.72e-02\n",
      "[dimension 129/145]  inactive:\t1.99e-04 +- 1.81e-02\n",
      "[dimension 130/145]  inactive:\t2.04e-03 +- 1.99e-02\n",
      "[dimension 131/145]  inactive:\t-1.07e-04 +- 2.49e-02\n",
      "[dimension 132/145]  inactive:\t2.79e-03 +- 3.15e-02\n",
      "[dimension 133/145]  inactive:\t1.89e-03 +- 1.74e-02\n",
      "[dimension 134/145]  inactive:\t-2.04e-04 +- 2.37e-02\n",
      "[dimension 135/145]  inactive:\t8.18e-04 +- 2.65e-02\n",
      "[dimension 136/145]  inactive:\t8.95e-04 +- 1.52e-02\n",
      "[dimension 137/145]  inactive:\t1.43e-04 +- 2.28e-02\n",
      "[dimension 138/145]  inactive:\t7.02e-04 +- 2.08e-02\n",
      "[dimension 139/145]  inactive:\t5.54e-04 +- 2.11e-02\n",
      "[dimension 140/145]  inactive:\t-2.00e-04 +- 2.30e-02\n",
      "[dimension 141/145]  inactive:\t1.08e-03 +- 2.39e-02\n",
      "[dimension 142/145]  inactive:\t1.44e-03 +- 1.69e-02\n",
      "[dimension 143/145]  inactive:\t1.03e-03 +- 2.63e-02\n",
      "[dimension 144/145]  inactive:\t6.43e-04 +- 1.64e-02\n",
      "[dimension 145/145]  inactive:\t8.40e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.7001085]\n",
      "cov_act[[0.02578811]]\n",
      "Active_dimensions: [62]\n",
      "80, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:34<00:00, 43.83it/s, 31 steps of size 1.52e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    581.98      1.00\n",
      "  lambda[0]      2.22      6.00      0.93      0.00      4.57    784.19      1.00\n",
      "  lambda[1]      3.36     11.91      0.98      0.00      6.51    596.58      1.01\n",
      "  lambda[2]      3.09     11.89      1.00      0.00      5.79    671.84      1.00\n",
      "  lambda[3]      4.68     26.03      1.00      0.00      6.81    647.53      1.00\n",
      "  lambda[4]      2.52      5.91      1.02      0.00      4.90    824.94      1.00\n",
      "  lambda[5]      2.97      9.04      0.95      0.00      5.75    836.97      1.00\n",
      "  lambda[6]      3.63     14.41      0.99      0.00      5.92    546.49      1.00\n",
      "  lambda[7]      3.29      9.79      1.01      0.00      5.95    554.27      1.00\n",
      "  lambda[8]      2.28      4.15      0.98      0.00      5.33    797.76      1.00\n",
      "  lambda[9]      2.35      7.63      0.95      0.00      4.16    866.86      1.00\n",
      " lambda[10]      3.53     11.31      1.04      0.00      6.52    709.18      1.00\n",
      " lambda[11]      2.76      6.28      1.00      0.01      5.94    777.99      1.00\n",
      " lambda[12]      4.33     14.91      1.00      0.00      8.22    549.58      1.00\n",
      " lambda[13]      2.71     11.23      0.96      0.00      5.28    902.84      1.00\n",
      " lambda[14]      4.26     19.26      0.98      0.00      6.21    598.35      1.00\n",
      " lambda[15]      2.67      7.80      0.98      0.00      5.09    750.19      1.00\n",
      " lambda[16]      3.89     11.40      1.01      0.00      8.53    671.65      1.00\n",
      " lambda[17]      2.95     12.68      0.96      0.00      5.37    603.06      1.00\n",
      " lambda[18]      2.50      7.12      0.95      0.00      5.10   1052.16      1.00\n",
      " lambda[19]      2.96     10.64      1.00      0.00      5.86    875.05      1.00\n",
      " lambda[20]      3.21     12.28      0.99      0.00      6.34    847.03      1.00\n",
      " lambda[21]      2.82      6.71      0.97      0.00      6.17    776.34      1.00\n",
      " lambda[22]      2.95     13.12      0.96      0.00      5.37    495.61      1.00\n",
      " lambda[23]      2.99      7.73      0.99      0.00      5.96    768.62      1.00\n",
      " lambda[24]      3.42     11.52      0.96      0.00      6.05    730.16      1.00\n",
      " lambda[25]      2.99      6.80      0.95      0.01      6.53    630.00      1.00\n",
      " lambda[26]      2.86      9.08      1.00      0.00      5.26    596.07      1.00\n",
      " lambda[27]      2.93      8.36      1.02      0.00      5.20    603.37      1.00\n",
      " lambda[28]      2.82     10.56      1.00      0.00      5.95    630.22      1.00\n",
      " lambda[29]      2.91      7.39      0.92      0.00      6.31    739.88      1.00\n",
      " lambda[30]      3.73     16.15      1.03      0.01      7.14    746.96      1.00\n",
      " lambda[31]      3.82     13.28      1.00      0.00      6.84    593.83      1.00\n",
      " lambda[32]      3.38     13.18      0.94      0.00      5.75    859.09      1.00\n",
      " lambda[33]      2.83     10.63      0.94      0.01      5.39    922.84      1.00\n",
      " lambda[34]      2.87      9.36      0.93      0.00      6.04    657.62      1.00\n",
      " lambda[35]      2.39      5.73      1.03      0.00      4.72    910.91      1.00\n",
      " lambda[36]      3.21     10.84      1.07      0.00      6.18    878.10      1.00\n",
      " lambda[37]      3.02      8.36      1.00      0.00      6.07    786.56      1.00\n",
      " lambda[38]      2.70      6.40      0.95      0.00      5.31    817.23      1.00\n",
      " lambda[39]      3.92     16.80      1.02      0.00      6.43    345.11      1.00\n",
      " lambda[40]      3.36     12.62      0.90      0.00      6.36   1002.81      1.00\n",
      " lambda[41]      7.07     56.20      0.90      0.00      8.40    633.53      1.00\n",
      " lambda[42]      2.37      4.49      0.96      0.00      5.24    943.82      1.00\n",
      " lambda[43]      4.35     36.46      0.97      0.00      5.72    960.96      1.00\n",
      " lambda[44]      2.64      6.41      0.95      0.00      5.61    584.06      1.00\n",
      " lambda[45]      2.46      5.45      1.00      0.00      5.20    788.03      1.00\n",
      " lambda[46]      2.87      8.58      1.04      0.00      5.21    792.74      1.00\n",
      " lambda[47]      2.43      4.85      1.00      0.00      5.53    679.42      1.00\n",
      " lambda[48]      2.87     10.36      0.98      0.01      5.14    841.07      1.00\n",
      " lambda[49]      2.71      6.37      0.94      0.00      5.83    759.75      1.00\n",
      " lambda[50]      2.86      8.79      0.96      0.00      5.53    713.40      1.00\n",
      " lambda[51]      4.00     12.47      0.95      0.00      7.78    538.85      1.00\n",
      " lambda[52]      3.79     26.24      0.90      0.00      5.66    847.26      1.00\n",
      " lambda[53]      2.90      7.96      0.94      0.00      5.56    728.18      1.00\n",
      " lambda[54]      2.34      6.02      1.00      0.01      4.84    510.71      1.00\n",
      " lambda[55]      4.07     21.86      0.96      0.00      6.11    740.49      1.00\n",
      " lambda[56]      2.71      6.17      0.97      0.00      5.54    704.73      1.00\n",
      " lambda[57]      5.39     18.86      1.01      0.00      8.22    425.30      1.00\n",
      " lambda[58]      2.53      6.84      0.94      0.00      4.73    753.75      1.00\n",
      " lambda[59]      3.21      9.07      0.93      0.00      6.44    473.47      1.00\n",
      " lambda[60]      2.72      7.02      0.94      0.00      5.23    716.18      1.00\n",
      " lambda[61]      2.70      5.87      1.02      0.00      5.50    548.75      1.00\n",
      " lambda[62]   3291.24  63969.70    156.71      0.00    965.02    501.94      1.00\n",
      " lambda[63]      3.03     21.31      1.01      0.00      5.43    881.09      1.00\n",
      " lambda[64]      2.67      6.57      1.01      0.01      5.48    839.87      1.00\n",
      " lambda[65]      3.14      9.50      0.96      0.00      5.78    583.67      1.00\n",
      " lambda[66]      2.86      6.29      1.04      0.00      6.66    861.97      1.00\n",
      " lambda[67]      2.70      8.18      0.94      0.00      5.18    911.61      1.00\n",
      " lambda[68]      3.59     20.58      0.97      0.00      6.16    882.60      1.00\n",
      " lambda[69]      3.38     11.01      0.92      0.00      6.61    846.57      1.00\n",
      " lambda[70]      2.54      6.69      1.03      0.00      5.30    551.90      1.00\n",
      " lambda[71]      2.62      6.94      1.00      0.00      5.04    473.80      1.00\n",
      " lambda[72]      2.76      6.86      0.94      0.00      5.64    721.75      1.00\n",
      " lambda[73]      2.59      6.13      0.97      0.00      5.12    693.25      1.00\n",
      " lambda[74]      2.35      4.14      1.05      0.01      5.56    970.32      1.00\n",
      " lambda[75]      3.90     13.03      1.06      0.00      5.97    931.79      1.00\n",
      " lambda[76]      3.32      9.84      0.99      0.00      6.72    712.62      1.00\n",
      " lambda[77]      6.06     35.71      1.14      0.00      7.38    407.68      1.00\n",
      " lambda[78]      3.65     17.07      1.07      0.00      6.26    591.76      1.00\n",
      " lambda[79]      2.82      7.04      1.02      0.00      6.61    795.76      1.00\n",
      " lambda[80]      4.33     26.25      1.06      0.00      6.38    789.05      1.00\n",
      " lambda[81]      2.58      7.05      0.97      0.00      4.99    681.31      1.00\n",
      " lambda[82]      2.31      5.63      0.92      0.00      4.87    891.23      1.00\n",
      " lambda[83]      2.84      8.55      0.90      0.00      5.53    787.65      1.00\n",
      " lambda[84]      4.33     45.27      1.01      0.00      5.76    935.10      1.00\n",
      " lambda[85]      2.50      7.65      0.91      0.00      5.17    422.27      1.00\n",
      " lambda[86]      3.64     14.25      0.98      0.00      5.32    702.93      1.00\n",
      " lambda[87]      3.32     12.66      0.97      0.00      6.61    627.15      1.00\n",
      " lambda[88]      2.79      9.08      0.96      0.00      5.48    997.14      1.00\n",
      " lambda[89]     78.71    414.12      1.51      0.01    176.48    250.29      1.01\n",
      " lambda[90]      2.28      4.72      0.99      0.00      5.19    826.05      1.00\n",
      " lambda[91]      2.45      6.40      0.95      0.01      4.78    861.48      1.00\n",
      " lambda[92]      2.65      6.56      1.03      0.01      5.18    687.61      1.00\n",
      " lambda[93]      2.55      6.39      1.03      0.00      4.62    492.48      1.00\n",
      " lambda[94]      2.34      6.27      0.98      0.00      4.66    672.27      1.00\n",
      " lambda[95]      3.23     10.59      1.03      0.00      6.40    777.71      1.00\n",
      " lambda[96]      3.35     13.72      1.00      0.00      5.00    526.37      1.00\n",
      " lambda[97]      3.47     16.06      0.98      0.00      5.59    625.45      1.00\n",
      " lambda[98]      4.07     24.28      0.94      0.00      5.17    529.61      1.00\n",
      " lambda[99]      2.56      6.59      0.98      0.00      4.64    517.72      1.00\n",
      "lambda[100]      2.98     10.11      0.93      0.00      5.71    657.59      1.00\n",
      "lambda[101]      2.62      6.46      0.95      0.01      5.61    601.61      1.00\n",
      "lambda[102]      2.59      6.71      0.88      0.00      5.30    951.17      1.00\n",
      "lambda[103]      2.24      4.20      0.95      0.00      5.21    635.35      1.00\n",
      "lambda[104]      3.58     23.39      0.95      0.00      6.20    422.05      1.00\n",
      "lambda[105]      3.32     10.34      1.02      0.00      6.54    769.15      1.00\n",
      "lambda[106]      2.57      6.36      1.01      0.01      5.40    580.49      1.00\n",
      "lambda[107]      3.64     15.36      1.01      0.00      6.16    716.77      1.00\n",
      "lambda[108]      2.47     10.69      0.96      0.00      4.81    720.23      1.00\n",
      "lambda[109]      3.07      9.39      0.94      0.00      6.86    790.34      1.00\n",
      "lambda[110]      3.99     18.11      0.97      0.00      6.71    876.43      1.00\n",
      "lambda[111]      3.05      9.50      0.93      0.00      6.85    645.82      1.00\n",
      "lambda[112]      2.74      6.45      0.97      0.01      6.28    711.61      1.00\n",
      "lambda[113]      3.17     10.31      1.00      0.00      6.01    672.26      1.00\n",
      "lambda[114]      3.44      9.19      0.99      0.00      6.00    645.28      1.00\n",
      "lambda[115]      3.75     14.55      0.93      0.00      5.70    724.30      1.00\n",
      "lambda[116]      3.52     14.42      0.95      0.00      5.85    404.07      1.00\n",
      "lambda[117]      3.91     19.34      1.03      0.00      6.54    785.50      1.00\n",
      "lambda[118]      3.03      9.77      0.94      0.00      6.35    885.79      1.00\n",
      "lambda[119]      2.65      8.24      0.97      0.00      5.56    916.31      1.00\n",
      "lambda[120]      3.95     19.18      0.98      0.00      6.14    778.35      1.00\n",
      "lambda[121]      2.98      8.29      0.95      0.00      6.48    643.52      1.00\n",
      "lambda[122]      3.13      9.41      0.99      0.00      6.19    756.57      1.00\n",
      "lambda[123]      2.80      7.06      0.86      0.00      6.10    730.61      1.00\n",
      "lambda[124]      2.54      5.32      0.99      0.00      5.78    761.25      1.00\n",
      "lambda[125]      2.83      7.58      0.97      0.00      6.17    650.73      1.00\n",
      "lambda[126]      2.46      6.69      0.95      0.00      4.81    939.27      1.00\n",
      "lambda[127]      4.27     16.82      1.02      0.00      7.27    540.03      1.00\n",
      "lambda[128]      2.69      7.29      0.96      0.00      5.05    754.58      1.00\n",
      "lambda[129]      3.75     15.10      1.00      0.00      6.61    979.99      1.00\n",
      "lambda[130]      3.35      9.12      0.94      0.00      6.93    715.31      1.01\n",
      "lambda[131]      3.47     11.33      1.00      0.01      6.17    677.16      1.00\n",
      "lambda[132]      2.81      6.81      0.95      0.00      5.86    836.83      1.00\n",
      "lambda[133]      2.53      6.48      1.02      0.00      5.19    837.16      1.00\n",
      "lambda[134]      3.41      8.58      0.88      0.00      7.37    642.92      1.00\n",
      "lambda[135]      2.80     10.41      0.94      0.00      4.70    699.81      1.00\n",
      "lambda[136]      2.92      7.47      1.02      0.01      5.99    677.38      1.00\n",
      "lambda[137]      2.68      7.58      0.97      0.00      5.43    717.87      1.00\n",
      "lambda[138]      3.00      8.37      1.02      0.00      5.51    847.97      1.00\n",
      "lambda[139]      3.20      9.38      0.99      0.00      5.97    971.24      1.00\n",
      "lambda[140]      3.13      9.61      0.97      0.00      6.29    857.95      1.00\n",
      "lambda[141]      2.17      4.75      0.88      0.00      4.74    819.70      1.00\n",
      "lambda[142]      5.06     23.65      0.96      0.01      7.04    366.46      1.00\n",
      "lambda[143]      2.22      4.27      1.00      0.00      4.99    705.98      1.00\n",
      "        msq   6939.28 104503.39     43.42      1.42   1298.33    958.28      1.00\n",
      "      sigma      5.93      8.26      2.70      0.01     16.52   1292.70      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1130.87      1.00\n",
      "       xisq    218.22   1915.86     14.38      0.92    174.49    945.03      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 37.90872097015381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-1.39e-04 +- 1.67e-02\n",
      "[dimension 02/145]  inactive:\t-5.24e-04 +- 2.53e-02\n",
      "[dimension 03/145]  inactive:\t4.37e-04 +- 2.74e-02\n",
      "[dimension 04/145]  inactive:\t7.30e-03 +- 5.18e-02\n",
      "[dimension 05/145]  inactive:\t-4.72e-04 +- 2.18e-02\n",
      "[dimension 06/145]  inactive:\t2.22e-03 +- 3.58e-02\n",
      "[dimension 07/145]  inactive:\t6.66e-04 +- 1.97e-02\n",
      "[dimension 08/145]  inactive:\t5.36e-04 +- 2.69e-02\n",
      "[dimension 09/145]  inactive:\t2.06e-05 +- 2.21e-02\n",
      "[dimension 10/145]  inactive:\t3.24e-04 +- 1.68e-02\n",
      "[dimension 11/145]  inactive:\t-1.37e-03 +- 2.53e-02\n",
      "[dimension 12/145]  inactive:\t-4.05e-04 +- 2.62e-02\n",
      "[dimension 13/145]  inactive:\t5.10e-03 +- 4.14e-02\n",
      "[dimension 14/145]  inactive:\t-1.17e-03 +- 2.56e-02\n",
      "[dimension 15/145]  inactive:\t-1.39e-05 +- 3.40e-02\n",
      "[dimension 16/145]  inactive:\t6.88e-04 +- 2.02e-02\n",
      "[dimension 17/145]  inactive:\t2.65e-04 +- 3.37e-02\n",
      "[dimension 18/145]  inactive:\t3.69e-04 +- 2.79e-02\n",
      "[dimension 19/145]  inactive:\t-1.80e-03 +- 1.87e-02\n",
      "[dimension 20/145]  inactive:\t-1.15e-03 +- 2.63e-02\n",
      "[dimension 21/145]  inactive:\t-2.57e-03 +- 3.02e-02\n",
      "[dimension 22/145]  inactive:\t-3.10e-04 +- 2.59e-02\n",
      "[dimension 23/145]  inactive:\t-9.65e-04 +- 3.39e-02\n",
      "[dimension 24/145]  inactive:\t1.63e-03 +- 2.83e-02\n",
      "[dimension 25/145]  inactive:\t3.43e-03 +- 2.45e-02\n",
      "[dimension 26/145]  inactive:\t-1.01e-03 +- 2.83e-02\n",
      "[dimension 27/145]  inactive:\t5.52e-04 +- 2.54e-02\n",
      "[dimension 28/145]  inactive:\t8.93e-04 +- 2.10e-02\n",
      "[dimension 29/145]  inactive:\t-5.54e-04 +- 2.57e-02\n",
      "[dimension 30/145]  inactive:\t1.92e-03 +- 3.32e-02\n",
      "[dimension 31/145]  inactive:\t5.96e-03 +- 4.31e-02\n",
      "[dimension 32/145]  inactive:\t-2.40e-03 +- 3.06e-02\n",
      "[dimension 33/145]  inactive:\t2.58e-03 +- 3.99e-02\n",
      "[dimension 34/145]  inactive:\t7.79e-04 +- 2.06e-02\n",
      "[dimension 35/145]  inactive:\t2.37e-04 +- 2.69e-02\n",
      "[dimension 36/145]  inactive:\t7.86e-04 +- 2.53e-02\n",
      "[dimension 37/145]  inactive:\t3.63e-03 +- 2.65e-02\n",
      "[dimension 38/145]  inactive:\t-1.59e-03 +- 2.98e-02\n",
      "[dimension 39/145]  inactive:\t1.01e-03 +- 2.69e-02\n",
      "[dimension 40/145]  inactive:\t5.65e-03 +- 4.26e-02\n",
      "[dimension 41/145]  inactive:\t-1.48e-03 +- 3.54e-02\n",
      "[dimension 42/145]  inactive:\t1.02e-02 +- 7.51e-02\n",
      "[dimension 43/145]  inactive:\t-6.33e-04 +- 2.01e-02\n",
      "[dimension 44/145]  inactive:\t-1.49e-04 +- 3.58e-02\n",
      "[dimension 45/145]  inactive:\t-3.81e-04 +- 2.66e-02\n",
      "[dimension 46/145]  inactive:\t1.17e-03 +- 1.74e-02\n",
      "[dimension 47/145]  inactive:\t-1.92e-03 +- 2.86e-02\n",
      "[dimension 48/145]  inactive:\t1.34e-03 +- 2.54e-02\n",
      "[dimension 49/145]  inactive:\t2.60e-03 +- 2.34e-02\n",
      "[dimension 50/145]  inactive:\t-1.57e-03 +- 2.84e-02\n",
      "[dimension 51/145]  inactive:\t2.45e-03 +- 2.89e-02\n",
      "[dimension 52/145]  inactive:\t6.18e-03 +- 2.74e-02\n",
      "[dimension 53/145]  inactive:\t-1.67e-03 +- 3.15e-02\n",
      "[dimension 54/145]  inactive:\t-8.72e-04 +- 2.46e-02\n",
      "[dimension 55/145]  inactive:\t6.48e-04 +- 1.65e-02\n",
      "[dimension 56/145]  inactive:\t-3.04e-03 +- 2.60e-02\n",
      "[dimension 57/145]  inactive:\t1.04e-03 +- 2.94e-02\n",
      "[dimension 58/145]  inactive:\t1.76e-02 +- 8.57e-02\n",
      "[dimension 59/145]  inactive:\t-7.80e-04 +- 1.72e-02\n",
      "[dimension 60/145]  inactive:\t-4.54e-05 +- 3.27e-02\n",
      "[dimension 61/145]  inactive:\t2.33e-03 +- 2.48e-02\n",
      "[dimension 62/145]  inactive:\t-8.85e-04 +- 2.28e-02\n",
      "[dimension 63/145]  active:\t6.64e-01 +- 4.42e-01\n",
      "[dimension 64/145]  inactive:\t-2.55e-03 +- 2.44e-02\n",
      "[dimension 65/145]  inactive:\t-1.31e-05 +- 2.77e-02\n",
      "[dimension 66/145]  inactive:\t7.36e-04 +- 2.50e-02\n",
      "[dimension 67/145]  inactive:\t1.74e-03 +- 2.74e-02\n",
      "[dimension 68/145]  inactive:\t-3.33e-04 +- 3.05e-02\n",
      "[dimension 69/145]  inactive:\t4.18e-03 +- 4.54e-02\n",
      "[dimension 70/145]  inactive:\t3.72e-03 +- 2.53e-02\n",
      "[dimension 71/145]  inactive:\t1.06e-04 +- 2.26e-02\n",
      "[dimension 72/145]  inactive:\t5.34e-04 +- 2.06e-02\n",
      "[dimension 73/145]  inactive:\t-8.22e-05 +- 2.20e-02\n",
      "[dimension 74/145]  inactive:\t-1.70e-03 +- 3.20e-02\n",
      "[dimension 75/145]  inactive:\t2.19e-04 +- 2.09e-02\n",
      "[dimension 76/145]  inactive:\t5.51e-03 +- 4.06e-02\n",
      "[dimension 77/145]  inactive:\t-1.90e-03 +- 3.98e-02\n",
      "[dimension 78/145]  inactive:\t1.28e-02 +- 9.01e-02\n",
      "[dimension 79/145]  inactive:\t6.03e-03 +- 3.57e-02\n",
      "[dimension 80/145]  inactive:\t-2.93e-04 +- 2.99e-02\n",
      "[dimension 81/145]  inactive:\t1.25e-03 +- 3.18e-02\n",
      "[dimension 82/145]  inactive:\t2.12e-04 +- 1.65e-02\n",
      "[dimension 83/145]  inactive:\t-1.37e-03 +- 1.59e-02\n",
      "[dimension 84/145]  inactive:\t-1.28e-03 +- 2.61e-02\n",
      "[dimension 85/145]  inactive:\t2.46e-03 +- 2.77e-02\n",
      "[dimension 86/145]  inactive:\t-4.14e-04 +- 1.89e-02\n",
      "[dimension 87/145]  inactive:\t1.66e-03 +- 3.82e-02\n",
      "[dimension 88/145]  inactive:\t2.81e-03 +- 2.59e-02\n",
      "[dimension 89/145]  inactive:\t-9.14e-04 +- 2.23e-02\n",
      "[dimension 90/145]  inactive:\t1.60e-01 +- 3.45e-01\n",
      "[dimension 91/145]  inactive:\t2.35e-05 +- 1.62e-02\n",
      "[dimension 92/145]  inactive:\t-1.25e-03 +- 2.32e-02\n",
      "[dimension 93/145]  inactive:\t-1.05e-03 +- 2.97e-02\n",
      "[dimension 94/145]  inactive:\t1.98e-03 +- 2.76e-02\n",
      "[dimension 95/145]  inactive:\t-3.33e-04 +- 2.01e-02\n",
      "[dimension 96/145]  inactive:\t2.78e-03 +- 4.92e-02\n",
      "[dimension 97/145]  inactive:\t2.47e-03 +- 2.48e-02\n",
      "[dimension 98/145]  inactive:\t-1.44e-03 +- 2.93e-02\n",
      "[dimension 99/145]  inactive:\t2.64e-03 +- 3.73e-02\n",
      "[dimension 100/145]  inactive:\t-5.48e-04 +- 1.70e-02\n",
      "[dimension 101/145]  inactive:\t-2.77e-03 +- 2.31e-02\n",
      "[dimension 102/145]  inactive:\t-8.10e-04 +- 2.44e-02\n",
      "[dimension 103/145]  inactive:\t6.52e-04 +- 2.17e-02\n",
      "[dimension 104/145]  inactive:\t-1.14e-03 +- 1.74e-02\n",
      "[dimension 105/145]  inactive:\t-5.75e-04 +- 2.79e-02\n",
      "[dimension 106/145]  inactive:\t5.25e-03 +- 3.53e-02\n",
      "[dimension 107/145]  inactive:\t-1.50e-03 +- 2.30e-02\n",
      "[dimension 108/145]  inactive:\t6.11e-03 +- 6.52e-02\n",
      "[dimension 109/145]  inactive:\t-4.48e-04 +- 1.90e-02\n",
      "[dimension 110/145]  inactive:\t-1.33e-03 +- 2.87e-02\n",
      "[dimension 111/145]  inactive:\t1.98e-03 +- 3.64e-02\n",
      "[dimension 112/145]  inactive:\t3.73e-03 +- 3.46e-02\n",
      "[dimension 113/145]  inactive:\t-1.53e-03 +- 2.15e-02\n",
      "[dimension 114/145]  inactive:\t1.37e-03 +- 3.45e-02\n",
      "[dimension 115/145]  inactive:\t2.53e-03 +- 2.52e-02\n",
      "[dimension 116/145]  inactive:\t1.96e-03 +- 6.06e-02\n",
      "[dimension 117/145]  inactive:\t4.91e-03 +- 4.92e-02\n",
      "[dimension 118/145]  inactive:\t3.48e-03 +- 2.73e-02\n",
      "[dimension 119/145]  inactive:\t-2.09e-03 +- 3.30e-02\n",
      "[dimension 120/145]  inactive:\t5.96e-05 +- 2.59e-02\n",
      "[dimension 121/145]  inactive:\t4.31e-03 +- 3.63e-02\n",
      "[dimension 122/145]  inactive:\t-2.61e-03 +- 3.42e-02\n",
      "[dimension 123/145]  inactive:\t1.47e-03 +- 3.02e-02\n",
      "[dimension 124/145]  inactive:\t-1.45e-03 +- 2.08e-02\n",
      "[dimension 125/145]  inactive:\t-1.31e-03 +- 2.30e-02\n",
      "[dimension 126/145]  inactive:\t-6.55e-04 +- 2.48e-02\n",
      "[dimension 127/145]  inactive:\t7.84e-05 +- 1.83e-02\n",
      "[dimension 128/145]  inactive:\t-8.18e-04 +- 3.45e-02\n",
      "[dimension 129/145]  inactive:\t5.19e-04 +- 2.76e-02\n",
      "[dimension 130/145]  inactive:\t3.48e-03 +- 2.87e-02\n",
      "[dimension 131/145]  inactive:\t-1.47e-03 +- 3.24e-02\n",
      "[dimension 132/145]  inactive:\t4.29e-03 +- 4.24e-02\n",
      "[dimension 133/145]  inactive:\t2.44e-03 +- 2.18e-02\n",
      "[dimension 134/145]  inactive:\t-1.39e-04 +- 2.67e-02\n",
      "[dimension 135/145]  inactive:\t4.37e-04 +- 3.04e-02\n",
      "[dimension 136/145]  inactive:\t9.41e-04 +- 2.05e-02\n",
      "[dimension 137/145]  inactive:\t-4.02e-04 +- 3.15e-02\n",
      "[dimension 138/145]  inactive:\t5.67e-04 +- 2.32e-02\n",
      "[dimension 139/145]  inactive:\t5.78e-04 +- 2.32e-02\n",
      "[dimension 140/145]  inactive:\t-1.11e-03 +- 2.75e-02\n",
      "[dimension 141/145]  inactive:\t1.45e-03 +- 3.02e-02\n",
      "[dimension 142/145]  inactive:\t1.02e-03 +- 1.61e-02\n",
      "[dimension 143/145]  inactive:\t1.90e-03 +- 4.07e-02\n",
      "[dimension 144/145]  inactive:\t1.68e-04 +- 1.76e-02\n",
      "[dimension 145/145]  inactive:\t-1.88e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8217118]\n",
      "cov_act[[0.04294456]]\n",
      "Active_dimensions: [62]\n",
      "81, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:35<00:00, 42.19it/s, 31 steps of size 1.10e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    280.89      1.00\n",
      "  lambda[0]      2.49      6.78      0.93      0.00      4.57    740.36      1.00\n",
      "  lambda[1]      2.96      8.02      1.02      0.00      6.28    613.66      1.01\n",
      "  lambda[2]      3.48     13.58      1.02      0.00      5.10    276.35      1.00\n",
      "  lambda[3]      3.28      9.09      1.03      0.00      7.12    534.85      1.00\n",
      "  lambda[4]      2.98      7.88      1.02      0.00      5.59    451.03      1.00\n",
      "  lambda[5]      4.73     56.71      0.93      0.00      5.04    639.69      1.00\n",
      "  lambda[6]      4.00     19.29      0.99      0.00      6.21    659.55      1.00\n",
      "  lambda[7]      2.59      5.37      0.95      0.00      5.09    674.71      1.00\n",
      "  lambda[8]      2.64      5.14      0.98      0.00      6.47    495.68      1.02\n",
      "  lambda[9]      2.83      8.10      0.90      0.00      5.46    629.79      1.00\n",
      " lambda[10]      3.80     14.81      1.00      0.00      5.47    803.66      1.00\n",
      " lambda[11]      2.90     10.89      0.92      0.00      5.72    948.18      1.00\n",
      " lambda[12]      4.12     18.63      1.05      0.00      6.99    595.55      1.00\n",
      " lambda[13]      2.44      5.16      0.92      0.00      5.39    772.82      1.00\n",
      " lambda[14]      2.84      7.28      0.96      0.00      5.17    648.14      1.01\n",
      " lambda[15]      3.76     11.82      1.00      0.00      7.09    650.52      1.00\n",
      " lambda[16]      3.26      7.87      1.01      0.00      6.82    425.19      1.00\n",
      " lambda[17]      3.07      8.83      0.96      0.00      6.14    434.22      1.00\n",
      " lambda[18]      2.63      6.33      0.95      0.00      5.20    630.39      1.00\n",
      " lambda[19]      3.96     18.73      1.05      0.01      6.71    557.73      1.00\n",
      " lambda[20]      2.70      6.10      1.03      0.00      5.69    734.30      1.00\n",
      " lambda[21]      3.49     11.11      1.00      0.00      6.48    707.66      1.00\n",
      " lambda[22]      2.51      6.21      0.97      0.00      4.96    640.14      1.00\n",
      " lambda[23]      3.21      8.46      1.07      0.00      7.02    658.19      1.00\n",
      " lambda[24]      3.82     14.84      1.01      0.00      6.47    713.84      1.00\n",
      " lambda[25]      2.79      7.67      1.00      0.00      5.86    329.96      1.01\n",
      " lambda[26]      2.91      8.12      0.98      0.00      5.83    839.85      1.00\n",
      " lambda[27]      2.73      7.38      0.96      0.00      5.37    628.01      1.01\n",
      " lambda[28]      2.77      6.81      1.03      0.00      5.73    839.06      1.00\n",
      " lambda[29]      2.81      6.85      0.99      0.00      6.24    659.31      1.00\n",
      " lambda[30]      3.39     13.46      1.03      0.01      6.43    749.92      1.00\n",
      " lambda[31]      3.06      9.01      1.00      0.00      6.06    706.91      1.00\n",
      " lambda[32]      2.86      8.89      1.00      0.00      5.49    927.52      1.00\n",
      " lambda[33]      3.22     11.11      0.95      0.00      5.52    851.32      1.00\n",
      " lambda[34]      2.45      6.26      1.02      0.00      4.73    808.47      1.00\n",
      " lambda[35]      2.50      6.42      0.96      0.00      5.41    872.74      1.00\n",
      " lambda[36]      3.26     10.66      0.96      0.01      6.62    970.63      1.00\n",
      " lambda[37]      3.78     14.86      1.02      0.00      6.64    497.95      1.00\n",
      " lambda[38]      2.95      7.97      0.93      0.00      5.77    846.67      1.00\n",
      " lambda[39]      3.10      8.68      1.05      0.01      6.40    677.52      1.00\n",
      " lambda[40]      3.64     12.52      0.95      0.01      6.71    952.89      1.00\n",
      " lambda[41]      8.94     68.52      0.97      0.00      9.53    220.89      1.00\n",
      " lambda[42]      3.14     10.64      1.01      0.00      5.96    722.17      1.00\n",
      " lambda[43]      2.72     10.48      1.00      0.00      5.55    974.84      1.00\n",
      " lambda[44]      2.35      7.16      0.93      0.00      4.71    855.64      1.00\n",
      " lambda[45]      2.22      4.53      0.96      0.00      5.03    902.86      1.00\n",
      " lambda[46]      3.07     14.86      1.01      0.00      4.79    588.44      1.00\n",
      " lambda[47]      2.51      6.52      0.95      0.00      5.30    768.90      1.00\n",
      " lambda[48]      2.65      7.03      1.00      0.01      5.05    824.00      1.00\n",
      " lambda[49]      2.81      6.57      0.99      0.00      6.62    622.11      1.00\n",
      " lambda[50]      2.37      4.88      0.98      0.00      4.70    753.91      1.00\n",
      " lambda[51]      4.67     20.85      1.04      0.00      7.47    981.52      1.00\n",
      " lambda[52]      2.48      8.06      0.94      0.00      5.06    640.12      1.00\n",
      " lambda[53]      2.92      7.08      0.88      0.00      6.26    946.70      1.00\n",
      " lambda[54]      2.34      6.32      0.95      0.00      4.20    521.12      1.00\n",
      " lambda[55]      3.26      7.62      1.08      0.01      7.19    743.13      1.00\n",
      " lambda[56]      2.58      5.79      1.00      0.01      5.91    648.91      1.00\n",
      " lambda[57]      3.40      9.19      0.98      0.00      6.48    418.64      1.00\n",
      " lambda[58]      2.34      5.06      0.94      0.00      5.12    851.91      1.00\n",
      " lambda[59]      2.55      7.79      0.93      0.00      5.07   1032.05      1.00\n",
      " lambda[60]      2.48      5.22      0.98      0.00      5.84    676.94      1.00\n",
      " lambda[61]      3.34     10.88      1.04      0.00      6.27    796.88      1.00\n",
      " lambda[62]   2255.53  15566.94    388.61      0.01   2583.72    556.34      1.00\n",
      " lambda[63]      2.92     13.77      1.07      0.00      4.47    813.64      1.00\n",
      " lambda[64]      2.85     10.76      0.97      0.00      5.24    812.18      1.00\n",
      " lambda[65]      3.11     11.47      0.93      0.01      4.68    601.05      1.00\n",
      " lambda[66]      3.42     10.91      0.97      0.00      6.02    533.39      1.00\n",
      " lambda[67]      3.52     10.74      1.05      0.00      6.93    501.72      1.00\n",
      " lambda[68]      2.95      8.19      0.96      0.00      6.03    592.10      1.00\n",
      " lambda[69]      3.60     10.06      1.02      0.00      7.22    635.21      1.00\n",
      " lambda[70]      2.56      6.04      0.94      0.00      5.24    652.83      1.00\n",
      " lambda[71]      2.74      7.57      0.98      0.00      5.31    673.83      1.00\n",
      " lambda[72]      3.03      7.98      1.01      0.00      6.11    570.53      1.00\n",
      " lambda[73]      2.93     12.58      0.95      0.00      5.56    488.76      1.00\n",
      " lambda[74]      2.84      8.25      1.09      0.01      6.24    519.18      1.00\n",
      " lambda[75]      3.59     10.58      1.02      0.00      6.84   1017.25      1.00\n",
      " lambda[76]      3.26      8.82      1.00      0.00      6.55    650.27      1.00\n",
      " lambda[77]     23.63    259.49      1.06      0.00      7.85    454.98      1.01\n",
      " lambda[78]      3.49     16.57      0.99      0.01      4.93    849.01      1.00\n",
      " lambda[79]      3.05      9.75      1.03      0.00      5.60    745.63      1.00\n",
      " lambda[80]      3.12     10.10      1.04      0.00      5.82   1063.36      1.00\n",
      " lambda[81]      2.85      9.89      0.98      0.00      5.40    899.99      1.00\n",
      " lambda[82]      2.56      6.79      0.94      0.00      4.88    735.23      1.00\n",
      " lambda[83]      2.32      5.80      0.90      0.00      4.69    890.59      1.00\n",
      " lambda[84]      2.98     12.31      0.96      0.01      5.92    941.86      1.00\n",
      " lambda[85]      2.60      7.78      0.93      0.00      5.28    638.48      1.00\n",
      " lambda[86]      2.95      8.09      0.97      0.01      5.47    747.97      1.00\n",
      " lambda[87]      2.91      7.62      0.97      0.00      5.97    663.09      1.00\n",
      " lambda[88]      2.94     10.18      0.95      0.00      5.40    810.24      1.00\n",
      " lambda[89]     30.96    152.36      1.06      0.00     12.50    146.95      1.01\n",
      " lambda[90]      2.61      7.22      0.95      0.00      5.26    913.91      1.00\n",
      " lambda[91]      2.55      6.57      0.93      0.00      5.13    758.35      1.00\n",
      " lambda[92]      2.67      6.73      0.96      0.00      5.69    688.99      1.00\n",
      " lambda[93]      2.56      6.46      0.95      0.00      5.17    847.41      1.00\n",
      " lambda[94]      2.54      6.41      0.96      0.00      5.17    764.11      1.00\n",
      " lambda[95]     11.23    245.94      1.02      0.00      5.92    922.19      1.00\n",
      " lambda[96]      2.35      5.93      0.93      0.00      4.88    607.13      1.00\n",
      " lambda[97]      4.21     24.93      0.98      0.00      5.74    516.51      1.00\n",
      " lambda[98]      8.37     67.90      1.05      0.00      7.71    169.79      1.01\n",
      " lambda[99]      2.79      6.89      1.00      0.00      5.89    464.08      1.00\n",
      "lambda[100]      3.70     15.06      0.97      0.00      7.40    861.69      1.00\n",
      "lambda[101]      2.44      5.50      0.95      0.00      4.93    654.64      1.00\n",
      "lambda[102]      2.77      7.84      0.85      0.00      5.05    909.65      1.00\n",
      "lambda[103]      2.65      8.75      0.97      0.00      5.46    914.67      1.00\n",
      "lambda[104]      2.41      5.02      0.95      0.00      5.32    670.47      1.00\n",
      "lambda[105]      3.00      8.26      0.96      0.00      6.23    813.71      1.00\n",
      "lambda[106]      2.57      5.91      0.97      0.00      5.81    862.35      1.00\n",
      "lambda[107]      3.40      9.61      1.02      0.00      6.52    280.90      1.01\n",
      "lambda[108]      2.54      7.10      0.96      0.01      5.13    801.30      1.00\n",
      "lambda[109]      3.55     13.96      0.95      0.00      6.49    439.95      1.00\n",
      "lambda[110]      3.05      9.32      1.04      0.00      5.71    785.46      1.00\n",
      "lambda[111]      3.83     14.05      0.98      0.00      6.49    568.14      1.00\n",
      "lambda[112]      2.81      7.73      1.00      0.00      5.34    694.56      1.00\n",
      "lambda[113]      3.52     10.80      1.00      0.00      6.85    620.58      1.00\n",
      "lambda[114]      3.79     11.17      1.00      0.00      7.60    697.78      1.00\n",
      "lambda[115]      3.09     10.64      0.91      0.00      5.57    572.53      1.00\n",
      "lambda[116]      3.10     12.01      1.02      0.00      5.43    715.12      1.00\n",
      "lambda[117]      3.09      8.79      1.01      0.00      5.67    561.68      1.01\n",
      "lambda[118]      2.96      7.43      1.03      0.00      5.87    613.45      1.00\n",
      "lambda[119]      2.53      5.54      1.01      0.01      5.28    856.07      1.00\n",
      "lambda[120]      3.24      9.55      0.95      0.00      6.65    661.98      1.00\n",
      "lambda[121]      3.22     17.98      0.87      0.00      5.00    867.38      1.00\n",
      "lambda[122]      3.81     16.78      0.99      0.00      6.67    698.58      1.00\n",
      "lambda[123]      2.72      7.25      0.93      0.00      5.90    757.24      1.00\n",
      "lambda[124]      2.91      7.71      0.93      0.01      7.13    690.78      1.00\n",
      "lambda[125]      2.71      7.11      0.98      0.01      5.46    657.54      1.00\n",
      "lambda[126]      2.20      4.21      0.92      0.00      4.93    788.25      1.00\n",
      "lambda[127]      5.03     29.76      0.97      0.00      7.08    466.51      1.00\n",
      "lambda[128]      2.58      6.30      0.95      0.00      5.58    709.41      1.00\n",
      "lambda[129]      3.48     15.02      0.98      0.00      6.56    940.29      1.00\n",
      "lambda[130]      3.14      9.05      1.04      0.00      6.19    817.01      1.00\n",
      "lambda[131]      3.17     12.45      0.99      0.00      5.19    603.33      1.00\n",
      "lambda[132]      2.71      6.70      0.95      0.00      6.23    857.58      1.00\n",
      "lambda[133]      2.64      7.01      0.99      0.00      5.27    814.92      1.00\n",
      "lambda[134]      3.47     10.21      1.02      0.00      7.08    718.61      1.00\n",
      "lambda[135]      3.30     14.08      0.98      0.00      5.88    557.23      1.00\n",
      "lambda[136]      2.73      7.85      1.01      0.00      5.55    828.42      1.00\n",
      "lambda[137]      2.96      9.16      1.00      0.00      5.33    810.84      1.00\n",
      "lambda[138]      3.16     10.67      1.06      0.00      5.80    856.66      1.00\n",
      "lambda[139]      2.85      6.15      1.00      0.00      6.41    651.49      1.00\n",
      "lambda[140]      3.35      9.51      1.03      0.00      6.40    576.87      1.00\n",
      "lambda[141]      2.59      6.03      1.03      0.00      5.05    581.64      1.00\n",
      "lambda[142]      5.00     37.82      0.92      0.01      5.77    631.71      1.00\n",
      "lambda[143]      2.52      6.14      0.96      0.00      5.19    821.43      1.00\n",
      "        msq      1.63      0.94      1.37      0.50      2.90    728.35      1.00\n",
      "      sigma      4.71      7.12      1.61      0.00     14.13    837.67      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    575.64      1.00\n",
      "       xisq     23.70    132.24      7.15      0.57     37.92    450.09      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 39.23949694633484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t1.93e-04 +- 1.17e-02\n",
      "[dimension 02/145]  inactive:\t4.04e-04 +- 1.79e-02\n",
      "[dimension 03/145]  inactive:\t2.94e-04 +- 1.65e-02\n",
      "[dimension 04/145]  inactive:\t2.17e-03 +- 2.19e-02\n",
      "[dimension 05/145]  inactive:\t-9.72e-05 +- 1.45e-02\n",
      "[dimension 06/145]  inactive:\t1.07e-03 +- 2.49e-02\n",
      "[dimension 07/145]  inactive:\t6.86e-04 +- 1.45e-02\n",
      "[dimension 08/145]  inactive:\t9.56e-04 +- 2.05e-02\n",
      "[dimension 09/145]  inactive:\t4.63e-04 +- 1.69e-02\n",
      "[dimension 10/145]  inactive:\t4.27e-04 +- 1.27e-02\n",
      "[dimension 11/145]  inactive:\t2.29e-04 +- 1.83e-02\n",
      "[dimension 12/145]  inactive:\t2.92e-04 +- 1.52e-02\n",
      "[dimension 13/145]  inactive:\t1.92e-03 +- 2.36e-02\n",
      "[dimension 14/145]  inactive:\t-3.78e-05 +- 1.90e-02\n",
      "[dimension 15/145]  inactive:\t6.48e-04 +- 1.95e-02\n",
      "[dimension 16/145]  inactive:\t6.87e-04 +- 1.67e-02\n",
      "[dimension 17/145]  inactive:\t5.14e-05 +- 1.60e-02\n",
      "[dimension 18/145]  inactive:\t6.91e-04 +- 2.61e-02\n",
      "[dimension 19/145]  inactive:\t-5.06e-04 +- 1.16e-02\n",
      "[dimension 20/145]  inactive:\t-2.57e-04 +- 1.69e-02\n",
      "[dimension 21/145]  inactive:\t-5.88e-04 +- 1.44e-02\n",
      "[dimension 22/145]  inactive:\t2.22e-04 +- 1.59e-02\n",
      "[dimension 23/145]  inactive:\t2.08e-04 +- 1.74e-02\n",
      "[dimension 24/145]  inactive:\t7.41e-04 +- 1.85e-02\n",
      "[dimension 25/145]  inactive:\t2.11e-03 +- 1.77e-02\n",
      "[dimension 26/145]  inactive:\t3.73e-05 +- 1.65e-02\n",
      "[dimension 27/145]  inactive:\t7.64e-04 +- 1.90e-02\n",
      "[dimension 28/145]  inactive:\t5.39e-04 +- 1.26e-02\n",
      "[dimension 29/145]  inactive:\t4.16e-04 +- 1.74e-02\n",
      "[dimension 30/145]  inactive:\t9.84e-04 +- 1.84e-02\n",
      "[dimension 31/145]  inactive:\t3.77e-03 +- 3.63e-02\n",
      "[dimension 32/145]  inactive:\t-1.67e-04 +- 1.85e-02\n",
      "[dimension 33/145]  inactive:\t1.23e-03 +- 2.30e-02\n",
      "[dimension 34/145]  inactive:\t6.09e-04 +- 1.46e-02\n",
      "[dimension 35/145]  inactive:\t3.33e-04 +- 1.36e-02\n",
      "[dimension 36/145]  inactive:\t2.61e-04 +- 1.28e-02\n",
      "[dimension 37/145]  inactive:\t2.56e-03 +- 2.06e-02\n",
      "[dimension 38/145]  inactive:\t-3.52e-04 +- 1.91e-02\n",
      "[dimension 39/145]  inactive:\t4.97e-04 +- 1.76e-02\n",
      "[dimension 40/145]  inactive:\t2.12e-03 +- 2.34e-02\n",
      "[dimension 41/145]  inactive:\t-3.19e-04 +- 1.71e-02\n",
      "[dimension 42/145]  inactive:\t8.82e-03 +- 8.03e-02\n",
      "[dimension 43/145]  inactive:\t1.53e-04 +- 1.41e-02\n",
      "[dimension 44/145]  inactive:\t2.01e-05 +- 1.58e-02\n",
      "[dimension 45/145]  inactive:\t3.15e-04 +- 1.37e-02\n",
      "[dimension 46/145]  inactive:\t3.43e-04 +- 9.42e-03\n",
      "[dimension 47/145]  inactive:\t-4.75e-04 +- 1.49e-02\n",
      "[dimension 48/145]  inactive:\t5.77e-04 +- 1.64e-02\n",
      "[dimension 49/145]  inactive:\t9.30e-04 +- 1.59e-02\n",
      "[dimension 50/145]  inactive:\t-2.60e-04 +- 1.56e-02\n",
      "[dimension 51/145]  inactive:\t6.30e-04 +- 1.37e-02\n",
      "[dimension 52/145]  inactive:\t3.97e-03 +- 2.07e-02\n",
      "[dimension 53/145]  inactive:\t-1.52e-04 +- 1.29e-02\n",
      "[dimension 54/145]  inactive:\t2.48e-04 +- 1.46e-02\n",
      "[dimension 55/145]  inactive:\t2.12e-04 +- 1.02e-02\n",
      "[dimension 56/145]  inactive:\t-1.20e-03 +- 1.59e-02\n",
      "[dimension 57/145]  inactive:\t1.56e-03 +- 2.95e-02\n",
      "[dimension 58/145]  inactive:\t5.16e-03 +- 4.18e-02\n",
      "[dimension 59/145]  inactive:\t-2.99e-04 +- 1.33e-02\n",
      "[dimension 60/145]  inactive:\t9.71e-04 +- 2.41e-02\n",
      "[dimension 61/145]  inactive:\t1.16e-03 +- 1.57e-02\n",
      "[dimension 62/145]  inactive:\t-8.40e-05 +- 1.41e-02\n",
      "[dimension 63/145]  active:\t7.79e-01 +- 3.66e-01\n",
      "[dimension 64/145]  inactive:\t-1.16e-03 +- 1.71e-02\n",
      "[dimension 65/145]  inactive:\t4.69e-04 +- 2.12e-02\n",
      "[dimension 66/145]  inactive:\t8.07e-04 +- 2.33e-02\n",
      "[dimension 67/145]  inactive:\t8.51e-04 +- 1.80e-02\n",
      "[dimension 68/145]  inactive:\t1.22e-04 +- 2.07e-02\n",
      "[dimension 69/145]  inactive:\t2.74e-03 +- 3.39e-02\n",
      "[dimension 70/145]  inactive:\t2.64e-03 +- 1.98e-02\n",
      "[dimension 71/145]  inactive:\t3.06e-04 +- 1.52e-02\n",
      "[dimension 72/145]  inactive:\t5.89e-04 +- 1.63e-02\n",
      "[dimension 73/145]  inactive:\t2.95e-04 +- 1.28e-02\n",
      "[dimension 74/145]  inactive:\t-1.33e-04 +- 2.04e-02\n",
      "[dimension 75/145]  inactive:\t1.51e-03 +- 2.70e-02\n",
      "[dimension 76/145]  inactive:\t2.60e-03 +- 2.33e-02\n",
      "[dimension 77/145]  inactive:\t-3.19e-04 +- 2.25e-02\n",
      "[dimension 78/145]  inactive:\t1.93e-02 +- 1.18e-01\n",
      "[dimension 79/145]  inactive:\t3.31e-03 +- 2.48e-02\n",
      "[dimension 80/145]  inactive:\t2.50e-04 +- 1.98e-02\n",
      "[dimension 81/145]  inactive:\t1.34e-03 +- 2.53e-02\n",
      "[dimension 82/145]  inactive:\t1.61e-04 +- 1.27e-02\n",
      "[dimension 83/145]  inactive:\t-6.50e-04 +- 1.10e-02\n",
      "[dimension 84/145]  inactive:\t-1.07e-04 +- 1.18e-02\n",
      "[dimension 85/145]  inactive:\t1.73e-03 +- 2.35e-02\n",
      "[dimension 86/145]  inactive:\t-4.56e-04 +- 1.38e-02\n",
      "[dimension 87/145]  inactive:\t7.59e-04 +- 2.03e-02\n",
      "[dimension 88/145]  inactive:\t1.45e-03 +- 1.61e-02\n",
      "[dimension 89/145]  inactive:\t-3.25e-04 +- 1.40e-02\n",
      "[dimension 90/145]  inactive:\t5.07e-02 +- 2.04e-01\n",
      "[dimension 91/145]  inactive:\t7.52e-05 +- 1.20e-02\n",
      "[dimension 92/145]  inactive:\t-1.98e-04 +- 1.80e-02\n",
      "[dimension 93/145]  inactive:\t-3.69e-05 +- 1.54e-02\n",
      "[dimension 94/145]  inactive:\t6.87e-04 +- 1.50e-02\n",
      "[dimension 95/145]  inactive:\t5.11e-05 +- 1.37e-02\n",
      "[dimension 96/145]  inactive:\t2.36e-03 +- 4.95e-02\n",
      "[dimension 97/145]  inactive:\t1.07e-03 +- 1.41e-02\n",
      "[dimension 98/145]  inactive:\t-2.41e-04 +- 2.01e-02\n",
      "[dimension 99/145]  inactive:\t8.10e-03 +- 7.09e-02\n",
      "[dimension 100/145]  inactive:\t-1.71e-04 +- 1.15e-02\n",
      "[dimension 101/145]  inactive:\t-8.72e-04 +- 1.27e-02\n",
      "[dimension 102/145]  inactive:\t7.59e-05 +- 1.76e-02\n",
      "[dimension 103/145]  inactive:\t5.30e-04 +- 1.53e-02\n",
      "[dimension 104/145]  inactive:\t-3.10e-04 +- 1.04e-02\n",
      "[dimension 105/145]  inactive:\t2.68e-04 +- 1.56e-02\n",
      "[dimension 106/145]  inactive:\t3.66e-03 +- 3.05e-02\n",
      "[dimension 107/145]  inactive:\t-4.34e-04 +- 1.39e-02\n",
      "[dimension 108/145]  inactive:\t6.78e-03 +- 6.79e-02\n",
      "[dimension 109/145]  inactive:\t8.22e-05 +- 1.28e-02\n",
      "[dimension 110/145]  inactive:\t1.91e-04 +- 1.99e-02\n",
      "[dimension 111/145]  inactive:\t1.18e-03 +- 2.23e-02\n",
      "[dimension 112/145]  inactive:\t2.67e-03 +- 3.05e-02\n",
      "[dimension 113/145]  inactive:\t-2.99e-04 +- 1.41e-02\n",
      "[dimension 114/145]  inactive:\t8.11e-04 +- 2.67e-02\n",
      "[dimension 115/145]  inactive:\t1.63e-03 +- 1.85e-02\n",
      "[dimension 116/145]  inactive:\t3.92e-04 +- 1.84e-02\n",
      "[dimension 117/145]  inactive:\t2.61e-03 +- 3.69e-02\n",
      "[dimension 118/145]  inactive:\t1.69e-03 +- 1.73e-02\n",
      "[dimension 119/145]  inactive:\t-2.87e-04 +- 1.84e-02\n",
      "[dimension 120/145]  inactive:\t5.51e-05 +- 1.58e-02\n",
      "[dimension 121/145]  inactive:\t1.80e-03 +- 2.16e-02\n",
      "[dimension 122/145]  inactive:\t-5.59e-04 +- 1.56e-02\n",
      "[dimension 123/145]  inactive:\t3.34e-03 +- 4.21e-02\n",
      "[dimension 124/145]  inactive:\t-5.08e-04 +- 1.36e-02\n",
      "[dimension 125/145]  inactive:\t-2.60e-04 +- 1.94e-02\n",
      "[dimension 126/145]  inactive:\t-2.71e-04 +- 1.45e-02\n",
      "[dimension 127/145]  inactive:\t1.92e-04 +- 9.68e-03\n",
      "[dimension 128/145]  inactive:\t4.89e-04 +- 2.31e-02\n",
      "[dimension 129/145]  inactive:\t2.74e-04 +- 1.57e-02\n",
      "[dimension 130/145]  inactive:\t1.56e-03 +- 1.78e-02\n",
      "[dimension 131/145]  inactive:\t2.40e-04 +- 2.39e-02\n",
      "[dimension 132/145]  inactive:\t2.78e-03 +- 3.40e-02\n",
      "[dimension 133/145]  inactive:\t1.32e-03 +- 1.38e-02\n",
      "[dimension 134/145]  inactive:\t-6.99e-05 +- 1.44e-02\n",
      "[dimension 135/145]  inactive:\t3.10e-04 +- 1.50e-02\n",
      "[dimension 136/145]  inactive:\t1.11e-03 +- 1.60e-02\n",
      "[dimension 137/145]  inactive:\t2.64e-04 +- 1.54e-02\n",
      "[dimension 138/145]  inactive:\t3.29e-04 +- 1.31e-02\n",
      "[dimension 139/145]  inactive:\t4.45e-04 +- 1.74e-02\n",
      "[dimension 140/145]  inactive:\t-6.36e-05 +- 1.51e-02\n",
      "[dimension 141/145]  inactive:\t1.20e-03 +- 2.18e-02\n",
      "[dimension 142/145]  inactive:\t1.10e-03 +- 1.31e-02\n",
      "[dimension 143/145]  inactive:\t1.06e-03 +- 2.26e-02\n",
      "[dimension 144/145]  inactive:\t3.06e-04 +- 1.36e-02\n",
      "[dimension 145/145]  inactive:\t7.48e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.94782877]\n",
      "cov_act[[0.03408352]]\n",
      "Active_dimensions: [62]\n",
      "82, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:33<00:00, 45.25it/s, 15 steps of size 2.04e-01. acc. prob=0.89] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.01      0.00      0.00      0.00      0.01    475.37      1.00\n",
      "  lambda[0]      2.87     14.54      0.99      0.00      5.49    982.13      1.00\n",
      "  lambda[1]      4.39     35.05      1.01      0.00      5.49    601.56      1.00\n",
      "  lambda[2]      3.33      9.70      1.01      0.00      5.80    431.15      1.00\n",
      "  lambda[3]      4.64     26.14      1.03      0.00      7.29    681.21      1.00\n",
      "  lambda[4]      2.55      6.13      0.98      0.00      5.80    855.29      1.00\n",
      "  lambda[5]      8.67    114.18      0.98      0.00      5.69    479.78      1.00\n",
      "  lambda[6]      3.11     12.74      0.99      0.00      5.59    673.92      1.00\n",
      "  lambda[7]      2.73      6.01      0.91      0.00      5.89    800.49      1.00\n",
      "  lambda[8]      2.52      5.32      0.97      0.00      5.41    884.57      1.00\n",
      "  lambda[9]      2.85      7.51      1.08      0.00      5.32    613.18      1.00\n",
      " lambda[10]      3.19      8.82      1.00      0.00      5.86    673.58      1.00\n",
      " lambda[11]      3.23     11.63      0.99      0.01      5.99    585.79      1.00\n",
      " lambda[12]      4.47     23.60      0.98      0.02      6.97    695.83      1.00\n",
      " lambda[13]      2.71      9.41      0.93      0.00      4.96    661.67      1.00\n",
      " lambda[14]      3.70     14.05      0.96      0.00      5.62    732.77      1.00\n",
      " lambda[15]      2.42      5.76      1.00      0.00      5.14    788.71      1.00\n",
      " lambda[16]      3.21     10.53      0.96      0.00      6.73    632.76      1.00\n",
      " lambda[17]      3.51     11.66      0.96      0.00      6.31    625.25      1.00\n",
      " lambda[18]      3.73     17.46      0.98      0.00      6.25    906.97      1.00\n",
      " lambda[19]      2.81      7.96      0.93      0.00      5.82    941.36      1.00\n",
      " lambda[20]      3.56     11.81      1.02      0.01      7.66    647.11      1.00\n",
      " lambda[21]      3.27     10.66      1.01      0.00      5.94    189.59      1.00\n",
      " lambda[22]      2.74      7.42      0.98      0.01      5.31    632.24      1.00\n",
      " lambda[23]      3.54     20.53      1.06      0.00      5.70    943.26      1.00\n",
      " lambda[24]      3.25      9.97      1.07      0.00      6.34    688.80      1.00\n",
      " lambda[25]      2.83      7.07      0.97      0.01      6.59    496.37      1.00\n",
      " lambda[26]      3.19     12.39      1.02      0.00      6.36    873.89      1.00\n",
      " lambda[27]      2.84      7.17      0.93      0.00      6.13    480.38      1.00\n",
      " lambda[28]      2.60      6.31      0.98      0.00      5.99    799.33      1.01\n",
      " lambda[29]      2.63      7.25      0.93      0.00      5.26    507.55      1.01\n",
      " lambda[30]      3.97     25.90      0.97      0.01      7.15    813.41      1.00\n",
      " lambda[31]      3.13     10.06      1.00      0.00      5.36    954.37      1.00\n",
      " lambda[32]      3.43     11.03      1.03      0.00      6.94    651.84      1.00\n",
      " lambda[33]      2.64      6.28      0.96      0.00      5.60    586.72      1.00\n",
      " lambda[34]      2.86     11.47      0.95      0.00      5.63    986.27      1.00\n",
      " lambda[35]      3.10      9.46      1.00      0.00      5.97    428.33      1.00\n",
      " lambda[36]      2.92      9.33      1.04      0.00      5.85    623.77      1.00\n",
      " lambda[37]      3.06      8.62      1.02      0.01      5.86    840.45      1.00\n",
      " lambda[38]      3.78     27.39      0.95      0.00      5.48   1017.03      1.00\n",
      " lambda[39]      3.60     15.00      0.93      0.00      5.76    748.07      1.00\n",
      " lambda[40]      3.61     14.61      0.98      0.00      6.63    841.78      1.00\n",
      " lambda[41]     13.81    149.90      1.05      0.00      9.84    451.34      1.00\n",
      " lambda[42]      2.35      6.39      0.95      0.00      4.75    744.83      1.00\n",
      " lambda[43]      6.02     76.36      1.07      0.00      6.06    618.07      1.00\n",
      " lambda[44]      3.07      7.94      1.04      0.01      6.63    884.86      1.00\n",
      " lambda[45]      2.52      8.31      0.90      0.00      4.56    962.61      1.00\n",
      " lambda[46]      2.73     10.58      1.01      0.00      4.71    882.60      1.00\n",
      " lambda[47]      2.68      6.35      1.00      0.00      5.69    656.68      1.00\n",
      " lambda[48]      3.07      9.08      0.97      0.01      5.98    647.77      1.00\n",
      " lambda[49]      2.71      6.83      0.96      0.00      5.66    578.25      1.00\n",
      " lambda[50]      3.37     11.93      0.92      0.01      5.86    602.15      1.00\n",
      " lambda[51]      2.97      9.26      0.94      0.00      5.64    848.82      1.00\n",
      " lambda[52]      2.83      9.81      0.98      0.00      4.85    832.45      1.00\n",
      " lambda[53]      3.18     12.04      0.96      0.00      5.09    799.07      1.00\n",
      " lambda[54]      2.25      6.95      0.89      0.00      4.40    731.34      1.00\n",
      " lambda[55]      3.65     19.55      0.88      0.00      5.41    604.83      1.00\n",
      " lambda[56]      2.84      8.83      1.00      0.01      5.38    749.47      1.00\n",
      " lambda[57]      8.44     53.16      1.03      0.00     10.25    568.29      1.00\n",
      " lambda[58]      2.63      8.31      0.92      0.00      5.07    645.08      1.00\n",
      " lambda[59]      3.23      8.64      1.08      0.00      6.40    764.93      1.00\n",
      " lambda[60]      3.13     12.77      1.04      0.01      5.35    763.61      1.00\n",
      " lambda[61]      2.35      5.53      1.01      0.00      4.76    932.14      1.00\n",
      " lambda[62]   1127.94  13353.03    121.57      0.01    800.36    935.20      1.00\n",
      " lambda[63]      2.42      5.95      0.96      0.00      4.98    832.97      1.00\n",
      " lambda[64]      2.93     10.85      1.01      0.00      5.41    722.96      1.00\n",
      " lambda[65]      2.99     12.31      1.02      0.00      5.60    830.38      1.00\n",
      " lambda[66]      2.71      6.76      0.95      0.00      5.70    881.33      1.00\n",
      " lambda[67]      3.13      9.26      1.06      0.00      6.00    942.65      1.00\n",
      " lambda[68]      3.44     11.12      1.01      0.00      6.53    746.08      1.00\n",
      " lambda[69]      2.88      9.09      0.97      0.00      5.33    709.63      1.00\n",
      " lambda[70]      3.43     13.68      0.95      0.00      5.88    532.15      1.00\n",
      " lambda[71]      2.93      7.87      1.08      0.00      5.76    455.06      1.00\n",
      " lambda[72]      2.59      9.48      0.91      0.00      5.08    595.19      1.00\n",
      " lambda[73]      4.33     29.52      0.99      0.00      5.87    907.80      1.00\n",
      " lambda[74]      2.64      7.57      0.97      0.00      5.42    798.44      1.00\n",
      " lambda[75]      4.95     18.82      1.11      0.00      7.95    804.58      1.00\n",
      " lambda[76]      2.71      6.44      1.05      0.00      5.36    480.44      1.00\n",
      " lambda[77]      7.37     82.42      1.05      0.00      5.90    916.97      1.00\n",
      " lambda[78]      3.62     11.36      1.02      0.00      6.29    452.08      1.00\n",
      " lambda[79]      2.89     10.19      0.94      0.00      5.10    852.53      1.00\n",
      " lambda[80]      3.94     14.60      1.02      0.00      7.35    658.23      1.00\n",
      " lambda[81]      2.93      9.65      1.07      0.00      5.86    865.60      1.00\n",
      " lambda[82]      2.51      6.69      0.98      0.00      5.16    711.34      1.00\n",
      " lambda[83]      3.05      8.78      0.98      0.00      5.95    759.69      1.00\n",
      " lambda[84]      3.33     14.35      1.02      0.00      5.93    633.32      1.00\n",
      " lambda[85]      2.88     11.22      0.98      0.00      5.48    861.45      1.00\n",
      " lambda[86]      3.95     24.44      0.91      0.00      5.99    968.61      1.00\n",
      " lambda[87]      3.12     10.42      0.97      0.00      5.61    692.52      1.00\n",
      " lambda[88]      2.77      6.70      1.03      0.00      5.70    844.25      1.00\n",
      " lambda[89]     70.98    297.45      1.57      0.00    154.73    318.46      1.01\n",
      " lambda[90]      2.71      8.76      0.92      0.00      4.82    550.83      1.00\n",
      " lambda[91]      2.82      8.13      0.97      0.00      5.27    482.66      1.00\n",
      " lambda[92]      3.27     11.81      0.98      0.00      5.96    606.23      1.00\n",
      " lambda[93]      2.37      5.70      0.99      0.00      4.57    501.03      1.00\n",
      " lambda[94]      2.99      8.59      0.96      0.00      6.02    736.82      1.00\n",
      " lambda[95]      3.80     15.06      0.95      0.00      6.07    548.42      1.01\n",
      " lambda[96]      3.02      9.86      0.93      0.00      5.65    826.24      1.00\n",
      " lambda[97]      2.85      7.29      0.99      0.01      5.73    671.75      1.00\n",
      " lambda[98]      4.68     39.07      1.08      0.00      5.67    454.78      1.00\n",
      " lambda[99]      2.36      5.52      0.91      0.01      4.98    652.25      1.00\n",
      "lambda[100]      3.19     11.20      0.99      0.01      6.30    878.16      1.00\n",
      "lambda[101]      3.71     19.88      1.02      0.00      5.96    563.19      1.00\n",
      "lambda[102]      2.35      5.17      0.95      0.00      5.05    765.15      1.00\n",
      "lambda[103]      2.68      7.97      0.93      0.00      5.68    768.02      1.00\n",
      "lambda[104]      2.84      9.43      0.93      0.00      4.76    590.50      1.00\n",
      "lambda[105]      3.21      8.21      1.06      0.00      6.52    605.40      1.00\n",
      "lambda[106]      2.75     10.70      0.92      0.00      5.58    851.03      1.00\n",
      "lambda[107]      5.04     26.76      0.99      0.00      6.22    516.17      1.00\n",
      "lambda[108]      2.37      5.15      0.93      0.01      4.94    721.30      1.00\n",
      "lambda[109]      6.93     74.29      0.98      0.00      6.55    868.09      1.00\n",
      "lambda[110]      3.53     11.71      1.06      0.00      5.85    666.39      1.00\n",
      "lambda[111]      5.44     48.10      1.00      0.00      6.43    631.31      1.00\n",
      "lambda[112]      2.07      3.90      0.95      0.01      5.01    804.69      1.00\n",
      "lambda[113]      4.16     18.40      0.93      0.00      6.75    792.71      1.00\n",
      "lambda[114]      4.61     59.53      1.01      0.00      5.79    996.56      1.00\n",
      "lambda[115]      3.36     10.32      1.02      0.00      6.67    803.24      1.00\n",
      "lambda[116]      3.02     10.57      1.08      0.01      6.16    874.34      1.00\n",
      "lambda[117]      3.09     10.17      0.94      0.00      5.35    818.01      1.00\n",
      "lambda[118]      2.37      5.04      0.91      0.00      5.13    749.80      1.00\n",
      "lambda[119]      3.34     10.67      0.93      0.00      6.21    673.54      1.00\n",
      "lambda[120]      3.28     10.00      1.01      0.00      6.47    778.16      1.00\n",
      "lambda[121]      3.86     35.59      0.94      0.00      5.68   1001.45      1.00\n",
      "lambda[122]      3.23     16.13      1.01      0.00      5.82    979.68      1.00\n",
      "lambda[123]      2.79      6.89      0.90      0.00      6.09    834.07      1.00\n",
      "lambda[124]      2.67      7.22      0.96      0.00      5.10    745.87      1.00\n",
      "lambda[125]      2.47      5.68      0.98      0.00      5.18    598.40      1.00\n",
      "lambda[126]      2.00      4.50      0.91      0.00      4.46    895.97      1.00\n",
      "lambda[127]      3.26     13.22      1.01      0.00      6.06    731.22      1.00\n",
      "lambda[128]      2.42      5.13      0.97      0.00      5.39    911.32      1.00\n",
      "lambda[129]      2.70      7.29      0.85      0.00      5.18    768.73      1.00\n",
      "lambda[130]      3.36     10.21      0.95      0.00      6.70    662.71      1.01\n",
      "lambda[131]      3.41     16.03      0.99      0.00      5.76    541.59      1.00\n",
      "lambda[132]      3.24     10.22      1.04      0.00      6.17    795.72      1.00\n",
      "lambda[133]      2.67      7.38      0.92      0.00      4.80    695.68      1.00\n",
      "lambda[134]      3.39     10.38      0.93      0.00      6.73    775.43      1.00\n",
      "lambda[135]      2.43      7.38      0.92      0.00      4.73    545.24      1.00\n",
      "lambda[136]      2.66      8.38      0.94      0.00      5.43    777.42      1.00\n",
      "lambda[137]      3.15     12.23      1.00      0.00      5.68    733.97      1.00\n",
      "lambda[138]      2.94      8.60      0.92      0.00      5.75    599.05      1.00\n",
      "lambda[139]      2.99     10.66      0.88      0.00      5.77    620.07      1.00\n",
      "lambda[140]      3.06      9.57      0.99      0.00      6.21    737.30      1.00\n",
      "lambda[141]      2.81      6.69      0.94      0.00      6.33    713.76      1.00\n",
      "lambda[142]      4.28     30.29      0.93      0.00      5.41    874.88      1.00\n",
      "lambda[143]      2.48      8.88      0.94      0.00      4.99    953.89      1.00\n",
      "        msq   4716.68  54792.64     29.35      0.81    696.58    382.46      1.00\n",
      "      sigma      5.52      7.79      2.28      0.01     15.55   1008.17      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13    505.39      1.00\n",
      "       xisq      1.29      0.71      1.13      0.44      2.16    613.48      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 37.565887212753296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-2.05e-04 +- 2.08e-02\n",
      "[dimension 02/145]  inactive:\t-1.80e-04 +- 2.90e-02\n",
      "[dimension 03/145]  inactive:\t6.13e-04 +- 3.16e-02\n",
      "[dimension 04/145]  inactive:\t7.37e-03 +- 4.92e-02\n",
      "[dimension 05/145]  inactive:\t-5.51e-04 +- 2.98e-02\n",
      "[dimension 06/145]  inactive:\t5.97e-03 +- 6.81e-02\n",
      "[dimension 07/145]  inactive:\t2.07e-04 +- 2.13e-02\n",
      "[dimension 08/145]  inactive:\t1.12e-03 +- 3.08e-02\n",
      "[dimension 09/145]  inactive:\t4.10e-04 +- 2.82e-02\n",
      "[dimension 10/145]  inactive:\t5.18e-04 +- 2.32e-02\n",
      "[dimension 11/145]  inactive:\t-1.26e-03 +- 3.32e-02\n",
      "[dimension 12/145]  inactive:\t-6.07e-05 +- 2.84e-02\n",
      "[dimension 13/145]  inactive:\t6.02e-03 +- 4.98e-02\n",
      "[dimension 14/145]  inactive:\t-1.39e-03 +- 2.50e-02\n",
      "[dimension 15/145]  inactive:\t1.45e-03 +- 4.37e-02\n",
      "[dimension 16/145]  inactive:\t9.26e-04 +- 2.13e-02\n",
      "[dimension 17/145]  inactive:\t4.90e-04 +- 3.53e-02\n",
      "[dimension 18/145]  inactive:\t-4.21e-04 +- 3.61e-02\n",
      "[dimension 19/145]  inactive:\t-2.61e-03 +- 2.35e-02\n",
      "[dimension 20/145]  inactive:\t-1.38e-03 +- 2.72e-02\n",
      "[dimension 21/145]  inactive:\t-3.64e-03 +- 3.61e-02\n",
      "[dimension 22/145]  inactive:\t4.82e-04 +- 2.45e-02\n",
      "[dimension 23/145]  inactive:\t-5.06e-04 +- 3.12e-02\n",
      "[dimension 24/145]  inactive:\t2.51e-03 +- 3.35e-02\n",
      "[dimension 25/145]  inactive:\t3.70e-03 +- 2.54e-02\n",
      "[dimension 26/145]  inactive:\t-5.83e-04 +- 3.52e-02\n",
      "[dimension 27/145]  inactive:\t9.42e-04 +- 3.27e-02\n",
      "[dimension 28/145]  inactive:\t1.10e-03 +- 2.25e-02\n",
      "[dimension 29/145]  inactive:\t6.72e-05 +- 2.97e-02\n",
      "[dimension 30/145]  inactive:\t1.56e-03 +- 3.14e-02\n",
      "[dimension 31/145]  inactive:\t6.80e-03 +- 4.64e-02\n",
      "[dimension 32/145]  inactive:\t-2.14e-03 +- 3.83e-02\n",
      "[dimension 33/145]  inactive:\t4.25e-03 +- 4.48e-02\n",
      "[dimension 34/145]  inactive:\t1.07e-03 +- 2.24e-02\n",
      "[dimension 35/145]  inactive:\t8.21e-04 +- 2.90e-02\n",
      "[dimension 36/145]  inactive:\t1.85e-03 +- 3.14e-02\n",
      "[dimension 37/145]  inactive:\t4.76e-03 +- 3.13e-02\n",
      "[dimension 38/145]  inactive:\t-2.34e-03 +- 3.97e-02\n",
      "[dimension 39/145]  inactive:\t1.96e-03 +- 4.06e-02\n",
      "[dimension 40/145]  inactive:\t4.87e-03 +- 3.68e-02\n",
      "[dimension 41/145]  inactive:\t-2.18e-03 +- 2.97e-02\n",
      "[dimension 42/145]  inactive:\t1.64e-02 +- 1.02e-01\n",
      "[dimension 43/145]  inactive:\t-2.34e-04 +- 2.19e-02\n",
      "[dimension 44/145]  inactive:\t-6.20e-04 +- 3.43e-02\n",
      "[dimension 45/145]  inactive:\t-4.30e-05 +- 3.51e-02\n",
      "[dimension 46/145]  inactive:\t9.62e-04 +- 1.72e-02\n",
      "[dimension 47/145]  inactive:\t-2.03e-03 +- 3.52e-02\n",
      "[dimension 48/145]  inactive:\t1.44e-03 +- 2.47e-02\n",
      "[dimension 49/145]  inactive:\t3.84e-03 +- 2.88e-02\n",
      "[dimension 50/145]  inactive:\t-1.82e-03 +- 2.82e-02\n",
      "[dimension 51/145]  inactive:\t3.84e-03 +- 3.58e-02\n",
      "[dimension 52/145]  inactive:\t4.78e-03 +- 2.34e-02\n",
      "[dimension 53/145]  inactive:\t-8.53e-04 +- 2.54e-02\n",
      "[dimension 54/145]  inactive:\t2.17e-04 +- 2.39e-02\n",
      "[dimension 55/145]  inactive:\t6.87e-04 +- 1.77e-02\n",
      "[dimension 56/145]  inactive:\t-2.62e-03 +- 2.41e-02\n",
      "[dimension 57/145]  inactive:\t1.34e-03 +- 3.21e-02\n",
      "[dimension 58/145]  inactive:\t1.99e-02 +- 8.95e-02\n",
      "[dimension 59/145]  inactive:\t-8.89e-04 +- 2.30e-02\n",
      "[dimension 60/145]  inactive:\t2.77e-03 +- 3.93e-02\n",
      "[dimension 61/145]  inactive:\t3.94e-03 +- 3.26e-02\n",
      "[dimension 62/145]  inactive:\t-3.80e-04 +- 2.28e-02\n",
      "[dimension 63/145]  active:\t6.07e-01 +- 4.65e-01\n",
      "[dimension 64/145]  inactive:\t-2.64e-03 +- 2.60e-02\n",
      "[dimension 65/145]  inactive:\t-5.14e-04 +- 2.84e-02\n",
      "[dimension 66/145]  inactive:\t4.03e-04 +- 2.68e-02\n",
      "[dimension 67/145]  inactive:\t1.40e-03 +- 2.61e-02\n",
      "[dimension 68/145]  inactive:\t-1.41e-03 +- 3.49e-02\n",
      "[dimension 69/145]  inactive:\t5.36e-03 +- 5.12e-02\n",
      "[dimension 70/145]  inactive:\t3.48e-03 +- 2.49e-02\n",
      "[dimension 71/145]  inactive:\t9.80e-04 +- 4.27e-02\n",
      "[dimension 72/145]  inactive:\t4.74e-04 +- 2.51e-02\n",
      "[dimension 73/145]  inactive:\t2.94e-04 +- 2.02e-02\n",
      "[dimension 74/145]  inactive:\t-2.59e-03 +- 3.60e-02\n",
      "[dimension 75/145]  inactive:\t3.04e-04 +- 2.48e-02\n",
      "[dimension 76/145]  inactive:\t9.23e-03 +- 5.24e-02\n",
      "[dimension 77/145]  inactive:\t-2.27e-03 +- 3.54e-02\n",
      "[dimension 78/145]  inactive:\t7.84e-03 +- 6.79e-02\n",
      "[dimension 79/145]  inactive:\t7.57e-03 +- 3.79e-02\n",
      "[dimension 80/145]  inactive:\t-2.27e-04 +- 3.41e-02\n",
      "[dimension 81/145]  inactive:\t3.83e-03 +- 4.54e-02\n",
      "[dimension 82/145]  inactive:\t5.69e-04 +- 2.19e-02\n",
      "[dimension 83/145]  inactive:\t-1.85e-03 +- 2.28e-02\n",
      "[dimension 84/145]  inactive:\t-2.16e-03 +- 3.17e-02\n",
      "[dimension 85/145]  inactive:\t3.88e-03 +- 3.56e-02\n",
      "[dimension 86/145]  inactive:\t-6.06e-04 +- 2.34e-02\n",
      "[dimension 87/145]  inactive:\t2.53e-03 +- 4.67e-02\n",
      "[dimension 88/145]  inactive:\t3.18e-03 +- 2.73e-02\n",
      "[dimension 89/145]  inactive:\t-1.26e-03 +- 2.47e-02\n",
      "[dimension 90/145]  inactive:\t1.67e-01 +- 3.45e-01\n",
      "[dimension 91/145]  inactive:\t6.91e-05 +- 2.08e-02\n",
      "[dimension 92/145]  inactive:\t-2.00e-03 +- 2.96e-02\n",
      "[dimension 93/145]  inactive:\t-1.60e-03 +- 3.46e-02\n",
      "[dimension 94/145]  inactive:\t1.33e-03 +- 2.23e-02\n",
      "[dimension 95/145]  inactive:\t-2.31e-04 +- 2.94e-02\n",
      "[dimension 96/145]  inactive:\t2.12e-03 +- 5.11e-02\n",
      "[dimension 97/145]  inactive:\t3.23e-03 +- 2.77e-02\n",
      "[dimension 98/145]  inactive:\t3.79e-04 +- 3.54e-02\n",
      "[dimension 99/145]  inactive:\t6.23e-03 +- 6.64e-02\n",
      "[dimension 100/145]  inactive:\t-7.23e-04 +- 1.98e-02\n",
      "[dimension 101/145]  inactive:\t-3.28e-03 +- 2.48e-02\n",
      "[dimension 102/145]  inactive:\t-3.69e-04 +- 3.02e-02\n",
      "[dimension 103/145]  inactive:\t1.40e-03 +- 2.52e-02\n",
      "[dimension 104/145]  inactive:\t-1.31e-03 +- 2.10e-02\n",
      "[dimension 105/145]  inactive:\t-5.52e-04 +- 2.92e-02\n",
      "[dimension 106/145]  inactive:\t5.39e-03 +- 3.52e-02\n",
      "[dimension 107/145]  inactive:\t-1.61e-03 +- 2.15e-02\n",
      "[dimension 108/145]  inactive:\t1.00e-02 +- 8.31e-02\n",
      "[dimension 109/145]  inactive:\t-6.52e-04 +- 2.03e-02\n",
      "[dimension 110/145]  inactive:\t-5.49e-04 +- 4.51e-02\n",
      "[dimension 111/145]  inactive:\t4.28e-03 +- 4.71e-02\n",
      "[dimension 112/145]  inactive:\t1.00e-02 +- 7.25e-02\n",
      "[dimension 113/145]  inactive:\t-1.29e-03 +- 2.34e-02\n",
      "[dimension 114/145]  inactive:\t5.31e-03 +- 6.27e-02\n",
      "[dimension 115/145]  inactive:\t2.43e-03 +- 2.48e-02\n",
      "[dimension 116/145]  inactive:\t5.46e-04 +- 3.79e-02\n",
      "[dimension 117/145]  inactive:\t3.20e-03 +- 3.90e-02\n",
      "[dimension 118/145]  inactive:\t2.91e-03 +- 2.66e-02\n",
      "[dimension 119/145]  inactive:\t-1.91e-03 +- 3.41e-02\n",
      "[dimension 120/145]  inactive:\t-4.81e-04 +- 4.16e-02\n",
      "[dimension 121/145]  inactive:\t4.21e-03 +- 3.65e-02\n",
      "[dimension 122/145]  inactive:\t-2.47e-03 +- 3.51e-02\n",
      "[dimension 123/145]  inactive:\t2.80e-03 +- 4.22e-02\n",
      "[dimension 124/145]  inactive:\t-1.97e-03 +- 2.37e-02\n",
      "[dimension 125/145]  inactive:\t-2.03e-03 +- 3.13e-02\n",
      "[dimension 126/145]  inactive:\t-9.22e-04 +- 2.39e-02\n",
      "[dimension 127/145]  inactive:\t3.18e-05 +- 1.59e-02\n",
      "[dimension 128/145]  inactive:\t-1.27e-03 +- 3.17e-02\n",
      "[dimension 129/145]  inactive:\t-2.53e-05 +- 2.78e-02\n",
      "[dimension 130/145]  inactive:\t3.44e-03 +- 2.91e-02\n",
      "[dimension 131/145]  inactive:\t-1.61e-03 +- 3.33e-02\n",
      "[dimension 132/145]  inactive:\t4.15e-03 +- 4.37e-02\n",
      "[dimension 133/145]  inactive:\t2.98e-03 +- 2.28e-02\n",
      "[dimension 134/145]  inactive:\t-4.40e-04 +- 2.87e-02\n",
      "[dimension 135/145]  inactive:\t8.26e-04 +- 3.37e-02\n",
      "[dimension 136/145]  inactive:\t1.26e-03 +- 2.22e-02\n",
      "[dimension 137/145]  inactive:\t-5.09e-05 +- 3.08e-02\n",
      "[dimension 138/145]  inactive:\t6.41e-04 +- 2.70e-02\n",
      "[dimension 139/145]  inactive:\t2.71e-04 +- 2.60e-02\n",
      "[dimension 140/145]  inactive:\t-1.40e-03 +- 3.13e-02\n",
      "[dimension 141/145]  inactive:\t1.41e-03 +- 2.93e-02\n",
      "[dimension 142/145]  inactive:\t1.83e-03 +- 2.18e-02\n",
      "[dimension 143/145]  inactive:\t8.02e-04 +- 3.10e-02\n",
      "[dimension 144/145]  inactive:\t1.91e-04 +- 2.19e-02\n",
      "[dimension 145/145]  inactive:\t6.56e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.81591344]\n",
      "cov_act[[0.0327068]]\n",
      "Active_dimensions: [62]\n",
      "83, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:36<00:00, 40.59it/s, 31 steps of size 1.35e-01. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    503.53      1.00\n",
      "  lambda[0]      2.39      6.24      0.97      0.00      5.14    938.02      1.00\n",
      "  lambda[1]      2.95      9.28      0.96      0.00      6.19    708.48      1.01\n",
      "  lambda[2]      2.70      6.88      1.00      0.00      5.26    663.33      1.00\n",
      "  lambda[3]      4.16     19.22      0.96      0.00      6.96    524.46      1.00\n",
      "  lambda[4]      2.79      9.12      1.02      0.00      5.03    971.08      1.00\n",
      "  lambda[5]      3.13     13.75      0.92      0.00      5.02    563.99      1.00\n",
      "  lambda[6]      3.89     17.55      1.03      0.00      7.06    457.69      1.00\n",
      "  lambda[7]      2.87      6.45      0.96      0.00      6.17    738.37      1.00\n",
      "  lambda[8]      2.34      5.49      0.95      0.00      5.22   1100.01      1.00\n",
      "  lambda[9]      2.34      5.56      0.94      0.00      5.12    950.96      1.00\n",
      " lambda[10]      3.48     13.30      1.04      0.00      6.19    884.14      1.00\n",
      " lambda[11]      2.87      7.19      0.98      0.01      6.33    781.10      1.00\n",
      " lambda[12]      4.21     15.47      1.01      0.00      7.48    791.87      1.00\n",
      " lambda[13]      2.62      6.68      0.93      0.00      5.65    859.27      1.00\n",
      " lambda[14]      4.58     32.95      0.90      0.00      5.25    768.77      1.00\n",
      " lambda[15]      3.18     10.82      0.98      0.00      5.15    495.39      1.00\n",
      " lambda[16]      3.50      9.48      0.94      0.00      7.92    667.18      1.00\n",
      " lambda[17]      3.34     14.25      0.95      0.00      5.74    605.22      1.00\n",
      " lambda[18]      2.43      5.33      0.96      0.00      5.34   1068.38      1.01\n",
      " lambda[19]      3.74     21.53      1.01      0.00      6.08    705.95      1.00\n",
      " lambda[20]      3.02      7.61      0.95      0.00      6.39    810.87      1.00\n",
      " lambda[21]      3.39     10.41      1.01      0.00      6.56    686.21      1.00\n",
      " lambda[22]      2.73      9.78      0.97      0.00      5.05    434.84      1.00\n",
      " lambda[23]      2.85      7.35      1.01      0.00      5.77    732.55      1.00\n",
      " lambda[24]      4.33     21.76      0.99      0.00      6.40    602.59      1.00\n",
      " lambda[25]      2.89      7.20      0.98      0.01      5.84    553.04      1.00\n",
      " lambda[26]      4.37     45.54      0.97      0.00      5.74    817.91      1.00\n",
      " lambda[27]      2.87      8.00      0.96      0.00      5.45    594.82      1.00\n",
      " lambda[28]      2.61      6.80      1.04      0.00      5.17    860.01      1.00\n",
      " lambda[29]      2.83      7.48      0.97      0.00      5.95    773.54      1.00\n",
      " lambda[30]      3.37     12.32      1.05      0.01      6.46    789.08      1.00\n",
      " lambda[31]      3.56     12.09      0.99      0.00      6.74    653.74      1.00\n",
      " lambda[32]      3.18     11.66      1.03      0.00      5.49    886.02      1.00\n",
      " lambda[33]      2.96      9.95      0.96      0.00      5.65    881.73      1.00\n",
      " lambda[34]      2.54      6.14      1.00      0.00      5.44    972.29      1.00\n",
      " lambda[35]      2.48      5.25      1.02      0.00      5.32    741.18      1.00\n",
      " lambda[36]      3.27     13.14      1.00      0.00      6.64    921.63      1.00\n",
      " lambda[37]      3.00      7.88      0.99      0.00      6.35    617.37      1.00\n",
      " lambda[38]      3.31     12.32      0.95      0.00      6.78    991.69      1.00\n",
      " lambda[39]      3.01      8.76      1.01      0.00      5.42    692.80      1.00\n",
      " lambda[40]      4.14     23.42      0.91      0.00      6.36    646.65      1.00\n",
      " lambda[41]     17.51    139.69      0.95      0.00      8.87    201.31      1.01\n",
      " lambda[42]      2.84      8.48      0.97      0.00      5.38    813.07      1.00\n",
      " lambda[43]      3.40     20.88      1.01      0.00      5.92    962.76      1.00\n",
      " lambda[44]      2.55      5.69      0.98      0.00      5.71    635.06      1.00\n",
      " lambda[45]      2.18      4.03      0.93      0.00      5.20    797.04      1.00\n",
      " lambda[46]      2.80      6.91      1.05      0.00      5.49    755.87      1.00\n",
      " lambda[47]      2.40      4.68      0.95      0.00      5.63    803.77      1.00\n",
      " lambda[48]      2.54      7.83      1.01      0.00      4.92    888.17      1.00\n",
      " lambda[49]      3.04      8.17      0.96      0.00      6.15    692.79      1.00\n",
      " lambda[50]      2.55      6.08      0.95      0.00      5.04    642.60      1.00\n",
      " lambda[51]      5.56     20.23      1.02      0.00      9.19    652.79      1.00\n",
      " lambda[52]      2.64      6.29      0.93      0.00      5.30    801.49      1.00\n",
      " lambda[53]      2.88      7.15      0.90      0.00      5.43    886.49      1.01\n",
      " lambda[54]      2.14      4.65      0.94      0.00      4.63    827.88      1.00\n",
      " lambda[55]      3.43     13.64      1.01      0.00      6.34    741.19      1.00\n",
      " lambda[56]      2.63      7.58      0.98      0.00      5.20    796.37      1.00\n",
      " lambda[57]      4.63     19.94      0.95      0.00      7.30    702.65      1.00\n",
      " lambda[58]      2.32      5.27      0.94      0.00      4.53    803.89      1.00\n",
      " lambda[59]      2.96      8.96      0.94      0.00      5.31    976.56      1.00\n",
      " lambda[60]      2.44      5.88      0.97      0.00      5.32    783.06      1.00\n",
      " lambda[61]      3.18     12.48      1.01      0.00      6.15    977.36      1.00\n",
      " lambda[62]   2269.07  21054.59    264.99      0.00   2283.70    619.87      1.00\n",
      " lambda[63]      2.46      9.28      1.03      0.00      4.98    836.81      1.00\n",
      " lambda[64]      2.75      6.28      0.98      0.01      5.22    797.36      1.00\n",
      " lambda[65]      3.11     10.82      0.94      0.00      5.73    761.45      1.00\n",
      " lambda[66]      3.56     12.35      1.00      0.00      7.09    663.23      1.00\n",
      " lambda[67]      2.79      7.01      0.95      0.00      6.18    834.77      1.00\n",
      " lambda[68]      3.58     15.25      0.94      0.00      6.88    631.55      1.00\n",
      " lambda[69]      4.01     12.06      1.00      0.00      7.82    810.98      1.00\n",
      " lambda[70]      2.77      7.20      0.99      0.01      5.98    676.14      1.00\n",
      " lambda[71]      2.96      9.51      0.95      0.00      5.87    570.30      1.00\n",
      " lambda[72]      2.90      8.83      0.98      0.01      5.62    695.60      1.00\n",
      " lambda[73]      2.88     11.00      0.96      0.00      5.23    508.77      1.00\n",
      " lambda[74]      2.25      3.81      1.01      0.01      5.28    816.42      1.00\n",
      " lambda[75]      4.44     23.70      1.04      0.00      6.95    559.20      1.00\n",
      " lambda[76]      2.96      6.82      0.99      0.00      6.53    705.96      1.00\n",
      " lambda[77]      4.33     20.17      1.07      0.00      6.05    307.06      1.00\n",
      " lambda[78]      4.02     18.82      1.00      0.00      6.04    582.29      1.00\n",
      " lambda[79]      3.06      8.71      1.00      0.00      6.12    551.88      1.01\n",
      " lambda[80]      3.46     14.33      0.99      0.00      7.00    842.16      1.00\n",
      " lambda[81]      2.39      8.60      0.98      0.00      4.48    690.47      1.00\n",
      " lambda[82]      2.66      8.34      0.96      0.00      4.76    537.85      1.00\n",
      " lambda[83]      2.61      6.77      0.94      0.00      5.63    814.55      1.00\n",
      " lambda[84]      3.30     20.60      0.99      0.01      5.73    949.81      1.00\n",
      " lambda[85]      2.65      7.20      0.93      0.00      4.95    464.42      1.00\n",
      " lambda[86]      3.11      8.61      0.98      0.01      5.47    775.35      1.00\n",
      " lambda[87]      3.52     13.02      0.96      0.00      6.67    596.05      1.00\n",
      " lambda[88]      2.71      9.05      0.96      0.00      5.53    966.61      1.00\n",
      " lambda[89]    144.37   2724.92      1.05      0.00     23.50    894.79      1.00\n",
      " lambda[90]      2.46      6.62      0.97      0.00      5.12    899.14      1.00\n",
      " lambda[91]      2.61      7.95      0.96      0.01      5.36    744.98      1.00\n",
      " lambda[92]      2.98     11.85      1.07      0.00      5.24    441.99      1.00\n",
      " lambda[93]      2.32      4.78      0.98      0.00      4.54    584.19      1.00\n",
      " lambda[94]      2.49      7.46      0.97      0.00      4.57    532.58      1.00\n",
      " lambda[95]      2.96     10.25      1.08      0.00      5.52    793.21      1.00\n",
      " lambda[96]      2.67      8.70      0.94      0.00      5.01    618.84      1.00\n",
      " lambda[97]      4.26     27.63      0.95      0.00      5.68    516.91      1.00\n",
      " lambda[98]      3.12     10.29      0.98      0.00      5.30    693.43      1.00\n",
      " lambda[99]      2.98      8.41      0.97      0.00      6.00    436.14      1.00\n",
      "lambda[100]      2.68      6.80      0.93      0.00      5.83    643.40      1.00\n",
      "lambda[101]      2.55      5.92      0.98      0.01      5.74    667.19      1.00\n",
      "lambda[102]      2.80      7.10      0.90      0.00      5.43    690.04      1.00\n",
      "lambda[103]      2.35      6.16      1.00      0.00      5.59    931.74      1.00\n",
      "lambda[104]      2.59      6.59      1.03      0.00      5.51    650.04      1.00\n",
      "lambda[105]      3.69     16.03      1.00      0.00      7.00    539.16      1.00\n",
      "lambda[106]      2.51      5.91      1.00      0.00      5.61    878.80      1.00\n",
      "lambda[107]      2.83     11.15      1.00      0.00      5.65    775.44      1.00\n",
      "lambda[108]      2.76      9.84      0.95      0.00      5.48    829.15      1.00\n",
      "lambda[109]      2.73      5.87      0.95      0.00      6.18    604.48      1.00\n",
      "lambda[110]      3.21      9.33      1.06      0.00      6.85    858.44      1.00\n",
      "lambda[111]      2.88      9.29      0.95      0.00      5.97    856.47      1.00\n",
      "lambda[112]      3.13     16.37      0.98      0.00      5.99    914.13      1.00\n",
      "lambda[113]      3.62     12.50      1.02      0.00      6.81    778.35      1.00\n",
      "lambda[114]      3.50     10.36      0.99      0.00      6.89    777.08      1.00\n",
      "lambda[115]      3.52     12.98      0.96      0.00      6.24    624.46      1.00\n",
      "lambda[116]      3.56     14.92      0.95      0.00      5.49    435.36      1.00\n",
      "lambda[117]      3.20     10.33      0.97      0.00      6.50    848.53      1.00\n",
      "lambda[118]      2.87      9.08      1.00      0.00      5.77    741.44      1.00\n",
      "lambda[119]      2.67      7.68      1.00      0.00      5.42    941.53      1.00\n",
      "lambda[120]      3.25     11.86      0.96      0.00      5.98    873.26      1.00\n",
      "lambda[121]      3.27     14.91      0.86      0.00      5.63    853.67      1.00\n",
      "lambda[122]      3.58     16.11      0.99      0.00      6.39    806.48      1.00\n",
      "lambda[123]      2.59      5.58      0.93      0.00      5.82    768.62      1.00\n",
      "lambda[124]      3.41     21.43      0.97      0.00      5.56    587.01      1.00\n",
      "lambda[125]      2.85      7.85      1.01      0.00      5.93    582.85      1.00\n",
      "lambda[126]      2.47      6.83      0.94      0.00      4.92    804.00      1.00\n",
      "lambda[127]      4.45     20.14      1.00      0.00      6.59    740.18      1.00\n",
      "lambda[128]      2.97     13.70      0.96      0.00      5.03    845.88      1.00\n",
      "lambda[129]      3.40     12.69      0.98      0.00      6.21   1039.51      1.00\n",
      "lambda[130]      3.23      7.96      1.00      0.00      6.63    706.12      1.00\n",
      "lambda[131]      3.51     15.15      0.95      0.00      5.42    663.53      1.00\n",
      "lambda[132]      2.45      5.32      0.97      0.00      5.32   1024.05      1.00\n",
      "lambda[133]      2.48      5.92      1.00      0.00      5.21    975.38      1.00\n",
      "lambda[134]      3.83     14.09      1.00      0.00      7.37    762.70      1.00\n",
      "lambda[135]      2.82     12.02      0.93      0.00      4.72    769.05      1.00\n",
      "lambda[136]      3.03      7.69      0.98      0.00      5.96    511.58      1.00\n",
      "lambda[137]      2.55      6.99      0.99      0.00      4.70    803.78      1.00\n",
      "lambda[138]      3.10     11.33      1.05      0.00      4.91    772.50      1.00\n",
      "lambda[139]      2.85      6.99      1.00      0.00      5.72    763.07      1.00\n",
      "lambda[140]      3.08      9.52      0.98      0.00      5.93    848.17      1.00\n",
      "lambda[141]      2.49      6.82      0.98      0.00      5.10    653.21      1.00\n",
      "lambda[142]      4.40     24.70      0.96      0.01      5.71    555.58      1.00\n",
      "lambda[143]      2.57      5.97      1.01      0.00      4.99    632.70      1.01\n",
      "        msq      1.48      0.89      1.26      0.45      2.60    915.49      1.00\n",
      "      sigma      5.47      7.65      2.12      0.00     15.75   1144.90      1.00\n",
      "    var_obs      0.10      0.02      0.10      0.07      0.13   1187.39      1.00\n",
      "       xisq      1.14      0.61      0.98      0.41      1.93   1322.33      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 41.92947793006897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t3.82e-05 +- 1.39e-02\n",
      "[dimension 02/145]  inactive:\t-1.70e-04 +- 1.96e-02\n",
      "[dimension 03/145]  inactive:\t1.15e-04 +- 1.97e-02\n",
      "[dimension 04/145]  inactive:\t3.96e-03 +- 3.12e-02\n",
      "[dimension 05/145]  inactive:\t-3.36e-04 +- 2.01e-02\n",
      "[dimension 06/145]  inactive:\t1.40e-03 +- 2.97e-02\n",
      "[dimension 07/145]  inactive:\t8.72e-04 +- 1.86e-02\n",
      "[dimension 08/145]  inactive:\t1.22e-03 +- 2.63e-02\n",
      "[dimension 09/145]  inactive:\t1.33e-04 +- 1.63e-02\n",
      "[dimension 10/145]  inactive:\t3.74e-04 +- 1.44e-02\n",
      "[dimension 11/145]  inactive:\t-1.64e-04 +- 2.28e-02\n",
      "[dimension 12/145]  inactive:\t-6.45e-05 +- 2.04e-02\n",
      "[dimension 13/145]  inactive:\t3.93e-03 +- 3.71e-02\n",
      "[dimension 14/145]  inactive:\t-5.25e-04 +- 2.07e-02\n",
      "[dimension 15/145]  inactive:\t7.23e-04 +- 3.54e-02\n",
      "[dimension 16/145]  inactive:\t6.78e-04 +- 1.83e-02\n",
      "[dimension 17/145]  inactive:\t-6.37e-05 +- 2.20e-02\n",
      "[dimension 18/145]  inactive:\t1.64e-04 +- 2.65e-02\n",
      "[dimension 19/145]  inactive:\t-1.01e-03 +- 1.46e-02\n",
      "[dimension 20/145]  inactive:\t-5.43e-04 +- 1.95e-02\n",
      "[dimension 21/145]  inactive:\t-9.72e-04 +- 1.93e-02\n",
      "[dimension 22/145]  inactive:\t4.72e-04 +- 1.74e-02\n",
      "[dimension 23/145]  inactive:\t-1.98e-04 +- 2.31e-02\n",
      "[dimension 24/145]  inactive:\t9.91e-04 +- 2.14e-02\n",
      "[dimension 25/145]  inactive:\t3.22e-03 +- 2.32e-02\n",
      "[dimension 26/145]  inactive:\t-1.54e-04 +- 2.23e-02\n",
      "[dimension 27/145]  inactive:\t1.37e-03 +- 2.54e-02\n",
      "[dimension 28/145]  inactive:\t6.07e-04 +- 1.60e-02\n",
      "[dimension 29/145]  inactive:\t4.54e-04 +- 2.39e-02\n",
      "[dimension 30/145]  inactive:\t7.20e-04 +- 2.15e-02\n",
      "[dimension 31/145]  inactive:\t3.45e-03 +- 2.97e-02\n",
      "[dimension 32/145]  inactive:\t-9.29e-04 +- 2.42e-02\n",
      "[dimension 33/145]  inactive:\t2.18e-03 +- 3.19e-02\n",
      "[dimension 34/145]  inactive:\t7.88e-04 +- 1.75e-02\n",
      "[dimension 35/145]  inactive:\t5.37e-04 +- 2.13e-02\n",
      "[dimension 36/145]  inactive:\t8.09e-04 +- 2.14e-02\n",
      "[dimension 37/145]  inactive:\t2.78e-03 +- 2.14e-02\n",
      "[dimension 38/145]  inactive:\t-6.40e-04 +- 2.14e-02\n",
      "[dimension 39/145]  inactive:\t8.45e-04 +- 2.75e-02\n",
      "[dimension 40/145]  inactive:\t3.42e-03 +- 3.15e-02\n",
      "[dimension 41/145]  inactive:\t-3.51e-04 +- 2.83e-02\n",
      "[dimension 42/145]  inactive:\t1.86e-02 +- 1.21e-01\n",
      "[dimension 43/145]  inactive:\t-1.32e-05 +- 1.70e-02\n",
      "[dimension 44/145]  inactive:\t-2.17e-04 +- 2.54e-02\n",
      "[dimension 45/145]  inactive:\t2.89e-04 +- 2.03e-02\n",
      "[dimension 46/145]  inactive:\t6.97e-04 +- 1.30e-02\n",
      "[dimension 47/145]  inactive:\t-1.23e-03 +- 2.30e-02\n",
      "[dimension 48/145]  inactive:\t7.85e-04 +- 2.14e-02\n",
      "[dimension 49/145]  inactive:\t1.68e-03 +- 1.95e-02\n",
      "[dimension 50/145]  inactive:\t-9.89e-04 +- 2.43e-02\n",
      "[dimension 51/145]  inactive:\t1.74e-03 +- 2.57e-02\n",
      "[dimension 52/145]  inactive:\t6.56e-03 +- 2.84e-02\n",
      "[dimension 53/145]  inactive:\t-4.24e-04 +- 2.15e-02\n",
      "[dimension 54/145]  inactive:\t2.61e-04 +- 1.78e-02\n",
      "[dimension 55/145]  inactive:\t3.07e-04 +- 1.33e-02\n",
      "[dimension 56/145]  inactive:\t-2.09e-03 +- 2.25e-02\n",
      "[dimension 57/145]  inactive:\t2.65e-03 +- 3.72e-02\n",
      "[dimension 58/145]  inactive:\t1.03e-02 +- 6.71e-02\n",
      "[dimension 59/145]  inactive:\t-5.46e-04 +- 1.50e-02\n",
      "[dimension 60/145]  inactive:\t1.28e-03 +- 2.94e-02\n",
      "[dimension 61/145]  inactive:\t1.51e-03 +- 1.92e-02\n",
      "[dimension 62/145]  inactive:\t-4.09e-04 +- 1.93e-02\n",
      "[dimension 63/145]  active:\t7.57e-01 +- 3.78e-01\n",
      "[dimension 64/145]  inactive:\t-1.62e-03 +- 1.85e-02\n",
      "[dimension 65/145]  inactive:\t-5.40e-05 +- 2.12e-02\n",
      "[dimension 66/145]  inactive:\t5.39e-04 +- 2.02e-02\n",
      "[dimension 67/145]  inactive:\t1.26e-03 +- 2.04e-02\n",
      "[dimension 68/145]  inactive:\t-3.65e-04 +- 1.99e-02\n",
      "[dimension 69/145]  inactive:\t3.14e-03 +- 3.40e-02\n",
      "[dimension 70/145]  inactive:\t4.03e-03 +- 2.54e-02\n",
      "[dimension 71/145]  inactive:\t3.84e-04 +- 2.07e-02\n",
      "[dimension 72/145]  inactive:\t4.72e-04 +- 1.86e-02\n",
      "[dimension 73/145]  inactive:\t1.91e-04 +- 1.58e-02\n",
      "[dimension 74/145]  inactive:\t-5.35e-04 +- 2.75e-02\n",
      "[dimension 75/145]  inactive:\t3.40e-04 +- 1.69e-02\n",
      "[dimension 76/145]  inactive:\t5.01e-03 +- 3.48e-02\n",
      "[dimension 77/145]  inactive:\t-9.23e-04 +- 2.64e-02\n",
      "[dimension 78/145]  inactive:\t7.91e-03 +- 6.65e-02\n",
      "[dimension 79/145]  inactive:\t5.16e-03 +- 3.22e-02\n",
      "[dimension 80/145]  inactive:\t1.28e-04 +- 2.71e-02\n",
      "[dimension 81/145]  inactive:\t1.32e-03 +- 2.69e-02\n",
      "[dimension 82/145]  inactive:\t1.90e-04 +- 1.30e-02\n",
      "[dimension 83/145]  inactive:\t-9.48e-04 +- 1.42e-02\n",
      "[dimension 84/145]  inactive:\t-5.92e-04 +- 1.93e-02\n",
      "[dimension 85/145]  inactive:\t1.72e-03 +- 2.44e-02\n",
      "[dimension 86/145]  inactive:\t-4.73e-04 +- 1.66e-02\n",
      "[dimension 87/145]  inactive:\t2.06e-03 +- 3.28e-02\n",
      "[dimension 88/145]  inactive:\t2.47e-03 +- 2.30e-02\n",
      "[dimension 89/145]  inactive:\t-4.36e-04 +- 1.58e-02\n",
      "[dimension 90/145]  inactive:\t6.61e-02 +- 2.24e-01\n",
      "[dimension 91/145]  inactive:\t5.61e-06 +- 1.52e-02\n",
      "[dimension 92/145]  inactive:\t-9.80e-04 +- 2.09e-02\n",
      "[dimension 93/145]  inactive:\t1.27e-05 +- 1.92e-02\n",
      "[dimension 94/145]  inactive:\t8.75e-04 +- 1.75e-02\n",
      "[dimension 95/145]  inactive:\t1.18e-04 +- 1.85e-02\n",
      "[dimension 96/145]  inactive:\t1.00e-03 +- 2.93e-02\n",
      "[dimension 97/145]  inactive:\t1.74e-03 +- 1.84e-02\n",
      "[dimension 98/145]  inactive:\t-7.98e-04 +- 2.21e-02\n",
      "[dimension 99/145]  inactive:\t2.48e-03 +- 3.35e-02\n",
      "[dimension 100/145]  inactive:\t-3.03e-04 +- 1.48e-02\n",
      "[dimension 101/145]  inactive:\t-1.35e-03 +- 1.47e-02\n",
      "[dimension 102/145]  inactive:\t-1.75e-04 +- 1.85e-02\n",
      "[dimension 103/145]  inactive:\t9.61e-04 +- 2.27e-02\n",
      "[dimension 104/145]  inactive:\t-4.74e-04 +- 1.42e-02\n",
      "[dimension 105/145]  inactive:\t-7.80e-06 +- 1.79e-02\n",
      "[dimension 106/145]  inactive:\t5.14e-03 +- 3.76e-02\n",
      "[dimension 107/145]  inactive:\t-6.43e-04 +- 1.81e-02\n",
      "[dimension 108/145]  inactive:\t2.94e-03 +- 4.37e-02\n",
      "[dimension 109/145]  inactive:\t-8.83e-05 +- 1.57e-02\n",
      "[dimension 110/145]  inactive:\t-3.11e-04 +- 2.20e-02\n",
      "[dimension 111/145]  inactive:\t1.00e-03 +- 2.25e-02\n",
      "[dimension 112/145]  inactive:\t2.95e-03 +- 3.23e-02\n",
      "[dimension 113/145]  inactive:\t-9.78e-04 +- 2.00e-02\n",
      "[dimension 114/145]  inactive:\t1.02e-03 +- 3.18e-02\n",
      "[dimension 115/145]  inactive:\t1.96e-03 +- 2.17e-02\n",
      "[dimension 116/145]  inactive:\t1.04e-03 +- 3.35e-02\n",
      "[dimension 117/145]  inactive:\t6.27e-03 +- 6.10e-02\n",
      "[dimension 118/145]  inactive:\t2.39e-03 +- 2.15e-02\n",
      "[dimension 119/145]  inactive:\t-7.89e-04 +- 2.28e-02\n",
      "[dimension 120/145]  inactive:\t6.21e-05 +- 2.17e-02\n",
      "[dimension 121/145]  inactive:\t2.53e-03 +- 2.74e-02\n",
      "[dimension 122/145]  inactive:\t-1.23e-03 +- 2.31e-02\n",
      "[dimension 123/145]  inactive:\t2.22e-03 +- 3.75e-02\n",
      "[dimension 124/145]  inactive:\t-7.81e-04 +- 1.59e-02\n",
      "[dimension 125/145]  inactive:\t-1.14e-03 +- 2.41e-02\n",
      "[dimension 126/145]  inactive:\t-3.95e-04 +- 2.06e-02\n",
      "[dimension 127/145]  inactive:\t2.60e-04 +- 1.45e-02\n",
      "[dimension 128/145]  inactive:\t-4.93e-04 +- 2.74e-02\n",
      "[dimension 129/145]  inactive:\t2.79e-04 +- 1.90e-02\n",
      "[dimension 130/145]  inactive:\t2.51e-03 +- 2.35e-02\n",
      "[dimension 131/145]  inactive:\t-5.17e-04 +- 2.67e-02\n",
      "[dimension 132/145]  inactive:\t2.69e-03 +- 3.33e-02\n",
      "[dimension 133/145]  inactive:\t1.66e-03 +- 1.68e-02\n",
      "[dimension 134/145]  inactive:\t-2.33e-04 +- 1.93e-02\n",
      "[dimension 135/145]  inactive:\t5.33e-04 +- 2.24e-02\n",
      "[dimension 136/145]  inactive:\t7.10e-04 +- 1.57e-02\n",
      "[dimension 137/145]  inactive:\t2.24e-07 +- 2.29e-02\n",
      "[dimension 138/145]  inactive:\t3.64e-04 +- 1.57e-02\n",
      "[dimension 139/145]  inactive:\t4.68e-04 +- 1.97e-02\n",
      "[dimension 140/145]  inactive:\t-4.57e-04 +- 2.18e-02\n",
      "[dimension 141/145]  inactive:\t1.02e-03 +- 2.33e-02\n",
      "[dimension 142/145]  inactive:\t1.09e-03 +- 1.49e-02\n",
      "[dimension 143/145]  inactive:\t1.19e-03 +- 2.93e-02\n",
      "[dimension 144/145]  inactive:\t3.91e-04 +- 1.81e-02\n",
      "[dimension 145/145]  inactive:\t1.88e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.8633541]\n",
      "cov_act[[0.04114513]]\n",
      "Active_dimensions: [62]\n",
      "84, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:29<00:00, 50.81it/s, 31 steps of size 2.09e-01. acc. prob=0.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.01    346.91      1.00\n",
      "  lambda[0]      3.08     24.17      0.94      0.00      5.20    997.11      1.00\n",
      "  lambda[1]      3.81     23.58      0.94      0.00      6.51    589.77      1.00\n",
      "  lambda[2]      2.92      7.67      1.01      0.00      5.96    352.54      1.00\n",
      "  lambda[3]      3.58     16.81      0.98      0.01      6.35    903.75      1.00\n",
      "  lambda[4]      2.80      6.65      0.97      0.00      5.84    706.41      1.00\n",
      "  lambda[5]      3.49     16.04      1.02      0.00      5.88    562.69      1.00\n",
      "  lambda[6]      2.94      8.09      0.98      0.00      6.02    651.84      1.00\n",
      "  lambda[7]      2.73      6.77      0.94      0.00      5.94    737.09      1.00\n",
      "  lambda[8]      2.75      7.27      0.96      0.00      5.72    773.59      1.00\n",
      "  lambda[9]      3.47     12.81      1.05      0.00      5.12    498.74      1.00\n",
      " lambda[10]      3.61     10.42      1.00      0.00      6.29    541.26      1.00\n",
      " lambda[11]      2.89     10.34      0.95      0.01      5.44    474.64      1.01\n",
      " lambda[12]      4.24     17.09      0.96      0.00      7.67    512.87      1.01\n",
      " lambda[13]      2.50      5.87      1.01      0.00      4.94    577.65      1.00\n",
      " lambda[14]      4.29     23.36      1.07      0.00      7.31    944.27      1.00\n",
      " lambda[15]      2.85      7.54      0.97      0.00      5.52    825.53      1.00\n",
      " lambda[16]      2.82      8.46      0.96      0.00      5.97   1005.99      1.00\n",
      " lambda[17]      2.78      8.14      0.97      0.00      5.43    702.82      1.00\n",
      " lambda[18]      2.54      7.09      0.93      0.00      4.64    765.85      1.00\n",
      " lambda[19]      2.69      7.15      1.06      0.00      5.56    942.77      1.00\n",
      " lambda[20]      3.68     12.47      1.05      0.00      7.69    723.63      1.00\n",
      " lambda[21]      2.40      4.78      0.99      0.00      5.51    551.99      1.00\n",
      " lambda[22]      2.57      6.54      0.99      0.00      5.18    809.75      1.00\n",
      " lambda[23]      2.81     17.28      1.01      0.00      4.71    978.91      1.00\n",
      " lambda[24]      3.46     12.21      1.01      0.00      6.54    788.12      1.00\n",
      " lambda[25]      2.36      6.33      0.94      0.01      5.27    674.16      1.00\n",
      " lambda[26]      3.10     14.17      1.01      0.00      5.40    530.56      1.00\n",
      " lambda[27]      2.60      6.59      0.90      0.00      5.32    852.52      1.00\n",
      " lambda[28]      2.61      5.51      1.00      0.00      6.45    658.71      1.01\n",
      " lambda[29]      4.68     56.59      0.94      0.00      6.26    998.06      1.00\n",
      " lambda[30]      2.99      9.68      0.96      0.02      6.06    827.44      1.00\n",
      " lambda[31]      3.11     10.74      1.01      0.00      5.12    864.87      1.00\n",
      " lambda[32]      2.92     10.37      1.01      0.00      6.31    975.42      1.00\n",
      " lambda[33]      2.30      4.63      0.95      0.00      5.27    576.62      1.00\n",
      " lambda[34]      3.13     10.10      1.03      0.00      6.71    776.08      1.00\n",
      " lambda[35]      2.83      7.13      1.00      0.00      5.78    809.46      1.00\n",
      " lambda[36]      3.02      7.98      1.03      0.00      6.36    704.29      1.00\n",
      " lambda[37]      3.56     16.89      1.01      0.01      6.35    887.86      1.00\n",
      " lambda[38]      4.00     35.85      1.01      0.00      6.22   1010.16      1.00\n",
      " lambda[39]      3.28     15.82      0.96      0.00      5.94    854.72      1.00\n",
      " lambda[40]      3.62     11.42      1.00      0.00      6.19    682.41      1.00\n",
      " lambda[41]      4.70     17.83      0.92      0.00      7.80    661.03      1.00\n",
      " lambda[42]      2.35      5.87      0.93      0.00      5.27   1060.64      1.00\n",
      " lambda[43]      4.10     26.88      1.04      0.00      6.02    499.37      1.00\n",
      " lambda[44]      2.79      7.41      0.96      0.01      5.38    861.21      1.00\n",
      " lambda[45]      2.75      7.84      0.98      0.01      4.90    843.55      1.00\n",
      " lambda[46]      2.40      5.74      0.94      0.00      4.88    708.31      1.00\n",
      " lambda[47]      2.51      4.76      1.04      0.00      5.67    706.69      1.00\n",
      " lambda[48]      3.13      7.32      1.02      0.00      6.58    754.79      1.00\n",
      " lambda[49]      3.34      9.45      1.03      0.00      6.14    758.95      1.00\n",
      " lambda[50]      3.39     14.08      0.96      0.00      5.72    676.76      1.00\n",
      " lambda[51]      3.58     19.70      1.03      0.00      6.90    799.82      1.00\n",
      " lambda[52]      2.67      9.15      0.99      0.00      5.17    924.53      1.00\n",
      " lambda[53]      3.53     12.84      0.97      0.00      6.41    511.04      1.00\n",
      " lambda[54]      2.29      5.13      0.91      0.00      4.75    742.39      1.00\n",
      " lambda[55]      3.28     16.59      0.90      0.00      5.61    946.61      1.00\n",
      " lambda[56]      2.94     10.27      0.97      0.00      5.45    754.70      1.00\n",
      " lambda[57]      7.35     66.56      1.01      0.00      7.58    700.45      1.00\n",
      " lambda[58]      2.55      5.89      0.94      0.00      5.23    648.14      1.00\n",
      " lambda[59]      2.87      6.70      1.03      0.00      6.63    825.90      1.00\n",
      " lambda[60]      2.81     10.54      0.95      0.00      5.08    801.36      1.00\n",
      " lambda[61]      2.43      5.29      0.95      0.00      5.47   1063.49      1.00\n",
      " lambda[62]   2981.39  52854.56    225.77      0.03   1340.58    518.60      1.00\n",
      " lambda[63]      3.32     13.05      0.96      0.00      6.07    403.52      1.00\n",
      " lambda[64]      2.60      7.28      0.97      0.00      5.07    901.86      1.00\n",
      " lambda[65]      3.31     13.26      0.94      0.00      6.13    906.63      1.00\n",
      " lambda[66]      2.99      7.83      0.97      0.00      5.75    765.14      1.00\n",
      " lambda[67]      3.07      9.69      1.06      0.00      5.87    771.74      1.00\n",
      " lambda[68]      3.33      8.96      0.97      0.01      7.15    702.34      1.00\n",
      " lambda[69]      3.43      9.89      1.01      0.00      6.70    731.68      1.00\n",
      " lambda[70]      2.93      9.38      0.97      0.00      5.00    607.88      1.00\n",
      " lambda[71]      3.41     19.83      1.06      0.00      5.24    575.15      1.00\n",
      " lambda[72]      2.34      5.97      1.01      0.00      4.46    664.54      1.00\n",
      " lambda[73]      4.64     40.76      0.93      0.00      6.13    978.35      1.00\n",
      " lambda[74]      3.14     16.09      0.96      0.01      5.62    499.85      1.00\n",
      " lambda[75]      3.92     15.11      1.06      0.00      6.72    632.75      1.00\n",
      " lambda[76]      2.76      7.53      1.01      0.00      5.86    500.71      1.00\n",
      " lambda[77]      3.06      8.81      0.99      0.00      5.14    886.46      1.00\n",
      " lambda[78]      2.95      7.48      1.04      0.00      5.73    601.65      1.00\n",
      " lambda[79]      2.97     10.08      0.92      0.00      5.15    728.31      1.00\n",
      " lambda[80]      2.97      8.44      0.97      0.00      5.90    587.77      1.00\n",
      " lambda[81]      2.76      5.83      1.01      0.00      6.62    756.24      1.00\n",
      " lambda[82]      2.73      8.01      0.95      0.00      5.24    776.63      1.00\n",
      " lambda[83]      3.53     10.14      1.08      0.00      6.24    619.48      1.00\n",
      " lambda[84]      3.49     11.34      1.01      0.00      6.76    590.89      1.00\n",
      " lambda[85]      2.38      4.70      0.93      0.00      5.50    781.00      1.00\n",
      " lambda[86]      3.86     14.79      0.98      0.00      6.65    838.03      1.00\n",
      " lambda[87]      2.65      6.39      0.97      0.00      5.34    817.05      1.00\n",
      " lambda[88]      2.93      7.99      0.97      0.00      5.65    519.58      1.00\n",
      " lambda[89]    399.99   6897.08      1.14      0.00     29.01    332.25      1.00\n",
      " lambda[90]      2.48      6.13      0.95      0.00      4.72    830.26      1.00\n",
      " lambda[91]      2.67      6.10      1.01      0.00      5.52    562.06      1.00\n",
      " lambda[92]      2.96      8.63      0.98      0.00      5.38    644.12      1.00\n",
      " lambda[93]      2.51      5.79      1.02      0.00      5.16    580.42      1.00\n",
      " lambda[94]      3.18      9.32      1.00      0.00      6.60    645.54      1.00\n",
      " lambda[95]      3.54     12.23      0.97      0.00      6.39    828.59      1.00\n",
      " lambda[96]      2.87      6.84      0.98      0.00      5.72    472.06      1.00\n",
      " lambda[97]      2.48      6.23      0.96      0.00      5.16    790.13      1.00\n",
      " lambda[98]      4.29     26.85      1.05      0.00      5.99    586.90      1.00\n",
      " lambda[99]      2.79      8.38      0.92      0.00      5.67    700.07      1.00\n",
      "lambda[100]      3.37     11.97      1.07      0.00      7.02    698.08      1.00\n",
      "lambda[101]      3.40     11.05      0.97      0.00      5.41    636.05      1.00\n",
      "lambda[102]      2.72      8.33      0.96      0.00      5.31    932.57      1.00\n",
      "lambda[103]      2.88     12.86      0.90      0.00      5.89    939.07      1.00\n",
      "lambda[104]      2.76      9.58      0.98      0.00      4.68    743.00      1.00\n",
      "lambda[105]      2.71      6.25      0.99      0.00      5.76    786.02      1.00\n",
      "lambda[106]      3.02     13.17      0.94      0.00      5.40    502.23      1.00\n",
      "lambda[107]      2.79      7.70      0.99      0.00      5.11    675.61      1.00\n",
      "lambda[108]      2.34      5.58      0.89      0.01      4.99    890.00      1.00\n",
      "lambda[109]      5.45     35.23      0.98      0.00      6.49    612.51      1.00\n",
      "lambda[110]      3.13     10.85      1.04      0.00      5.43    775.23      1.00\n",
      "lambda[111]      3.40     11.92      1.04      0.00      6.39    721.54      1.01\n",
      "lambda[112]      2.51      6.55      0.98      0.01      4.91    516.01      1.00\n",
      "lambda[113]      3.18      8.77      0.99      0.00      6.00    723.61      1.00\n",
      "lambda[114]      3.38     19.80      0.91      0.00      5.42    906.32      1.00\n",
      "lambda[115]      4.21     35.15      1.02      0.00      6.22    982.97      1.00\n",
      "lambda[116]      3.56     26.58      1.00      0.01      5.37    951.63      1.00\n",
      "lambda[117]      3.24     14.05      0.89      0.00      5.31    901.20      1.00\n",
      "lambda[118]      3.09      8.83      0.93      0.00      6.61    506.66      1.00\n",
      "lambda[119]      3.66     13.26      0.97      0.01      6.51    909.52      1.00\n",
      "lambda[120]      4.11     17.76      1.00      0.00      7.32    844.70      1.00\n",
      "lambda[121]      2.87      7.40      0.97      0.00      6.06    708.43      1.00\n",
      "lambda[122]      4.54     33.79      0.95      0.00      5.22    327.77      1.00\n",
      "lambda[123]      2.90      9.62      0.91      0.00      6.47    761.16      1.00\n",
      "lambda[124]      3.17     10.64      0.99      0.00      5.71    574.28      1.00\n",
      "lambda[125]      2.85      8.97      0.98      0.00      5.96    644.09      1.00\n",
      "lambda[126]      2.53      8.36      0.95      0.00      4.97    931.11      1.00\n",
      "lambda[127]      3.46     13.62      0.97      0.00      5.88    684.70      1.00\n",
      "lambda[128]      3.45     12.66      0.98      0.00      5.83    480.00      1.00\n",
      "lambda[129]      2.86      7.74      0.91      0.00      5.46    659.09      1.00\n",
      "lambda[130]      3.26     12.37      0.96      0.00      5.82    747.02      1.00\n",
      "lambda[131]      4.54     38.20      1.01      0.00      5.17    423.70      1.00\n",
      "lambda[132]      2.75      6.91      0.97      0.00      5.33    872.07      1.00\n",
      "lambda[133]      2.79      8.46      0.93      0.00      5.33    634.89      1.00\n",
      "lambda[134]      3.21      8.01      1.03      0.00      7.17    808.53      1.00\n",
      "lambda[135]      2.36      4.75      0.90      0.00      5.05    738.24      1.01\n",
      "lambda[136]      3.07     11.90      0.96      0.00      6.09    617.21      1.00\n",
      "lambda[137]      2.72      9.27      1.07      0.00      5.50    818.56      1.00\n",
      "lambda[138]      3.17      9.72      0.96      0.00      6.11    620.00      1.00\n",
      "lambda[139]      2.53      5.77      0.92      0.01      5.07    426.63      1.00\n",
      "lambda[140]      3.68     17.54      0.97      0.00      5.97    810.82      1.00\n",
      "lambda[141]      2.82      7.52      0.92      0.00      5.78    721.34      1.00\n",
      "lambda[142]      3.64     12.40      0.99      0.00      6.68    780.70      1.00\n",
      "lambda[143]      2.50      7.45      1.00      0.00      5.13    836.63      1.00\n",
      "        msq  64668.36 1633075.62     56.80      1.15   1581.89    885.02      1.00\n",
      "      sigma      3.06      3.90      1.50      0.00      8.20    872.92      1.00\n",
      "    var_obs      0.09      0.02      0.08      0.06      0.11    860.44      1.00\n",
      "       xisq    391.96   5118.92     18.83      0.76    268.93    914.86      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 34.50159502029419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-8.90e-05 +- 1.86e-02\n",
      "[dimension 02/145]  inactive:\t-6.42e-04 +- 3.01e-02\n",
      "[dimension 03/145]  inactive:\t-6.69e-05 +- 2.46e-02\n",
      "[dimension 04/145]  inactive:\t5.30e-03 +- 3.95e-02\n",
      "[dimension 05/145]  inactive:\t-8.72e-04 +- 2.30e-02\n",
      "[dimension 06/145]  inactive:\t3.11e-03 +- 4.29e-02\n",
      "[dimension 07/145]  inactive:\t5.32e-04 +- 1.76e-02\n",
      "[dimension 08/145]  inactive:\t1.15e-03 +- 3.00e-02\n",
      "[dimension 09/145]  inactive:\t2.77e-04 +- 2.29e-02\n",
      "[dimension 10/145]  inactive:\t4.49e-04 +- 1.86e-02\n",
      "[dimension 11/145]  inactive:\t-1.66e-03 +- 2.80e-02\n",
      "[dimension 12/145]  inactive:\t-4.79e-04 +- 2.26e-02\n",
      "[dimension 13/145]  inactive:\t4.43e-03 +- 3.77e-02\n",
      "[dimension 14/145]  inactive:\t-1.55e-03 +- 2.10e-02\n",
      "[dimension 15/145]  inactive:\t-1.15e-05 +- 3.27e-02\n",
      "[dimension 16/145]  inactive:\t8.10e-04 +- 1.90e-02\n",
      "[dimension 17/145]  inactive:\t-3.49e-04 +- 2.54e-02\n",
      "[dimension 18/145]  inactive:\t-7.17e-04 +- 2.48e-02\n",
      "[dimension 19/145]  inactive:\t-1.40e-03 +- 1.66e-02\n",
      "[dimension 20/145]  inactive:\t-1.14e-03 +- 2.37e-02\n",
      "[dimension 21/145]  inactive:\t-2.19e-03 +- 2.80e-02\n",
      "[dimension 22/145]  inactive:\t9.98e-05 +- 2.01e-02\n",
      "[dimension 23/145]  inactive:\t-8.63e-04 +- 2.42e-02\n",
      "[dimension 24/145]  inactive:\t1.13e-03 +- 2.24e-02\n",
      "[dimension 25/145]  inactive:\t3.21e-03 +- 2.28e-02\n",
      "[dimension 26/145]  inactive:\t-5.23e-04 +- 2.80e-02\n",
      "[dimension 27/145]  inactive:\t2.76e-04 +- 2.11e-02\n",
      "[dimension 28/145]  inactive:\t7.78e-04 +- 1.73e-02\n",
      "[dimension 29/145]  inactive:\t1.80e-04 +- 2.55e-02\n",
      "[dimension 30/145]  inactive:\t1.60e-03 +- 3.30e-02\n",
      "[dimension 31/145]  inactive:\t3.20e-03 +- 2.83e-02\n",
      "[dimension 32/145]  inactive:\t-1.28e-03 +- 2.40e-02\n",
      "[dimension 33/145]  inactive:\t1.34e-03 +- 2.82e-02\n",
      "[dimension 34/145]  inactive:\t6.97e-04 +- 1.71e-02\n",
      "[dimension 35/145]  inactive:\t8.45e-05 +- 2.41e-02\n",
      "[dimension 36/145]  inactive:\t5.63e-04 +- 2.20e-02\n",
      "[dimension 37/145]  inactive:\t3.54e-03 +- 2.36e-02\n",
      "[dimension 38/145]  inactive:\t-1.74e-03 +- 2.79e-02\n",
      "[dimension 39/145]  inactive:\t1.27e-03 +- 3.63e-02\n",
      "[dimension 40/145]  inactive:\t3.47e-03 +- 2.84e-02\n",
      "[dimension 41/145]  inactive:\t-2.30e-03 +- 2.97e-02\n",
      "[dimension 42/145]  inactive:\t4.89e-03 +- 4.86e-02\n",
      "[dimension 43/145]  inactive:\t-4.50e-04 +- 1.75e-02\n",
      "[dimension 44/145]  inactive:\t-1.29e-03 +- 3.36e-02\n",
      "[dimension 45/145]  inactive:\t-6.15e-04 +- 2.36e-02\n",
      "[dimension 46/145]  inactive:\t1.27e-03 +- 1.48e-02\n",
      "[dimension 47/145]  inactive:\t-1.84e-03 +- 2.76e-02\n",
      "[dimension 48/145]  inactive:\t9.88e-04 +- 2.20e-02\n",
      "[dimension 49/145]  inactive:\t3.27e-03 +- 2.47e-02\n",
      "[dimension 50/145]  inactive:\t-1.87e-03 +- 2.59e-02\n",
      "[dimension 51/145]  inactive:\t2.12e-03 +- 2.51e-02\n",
      "[dimension 52/145]  inactive:\t5.10e-03 +- 2.33e-02\n",
      "[dimension 53/145]  inactive:\t-5.73e-04 +- 2.21e-02\n",
      "[dimension 54/145]  inactive:\t1.26e-04 +- 2.06e-02\n",
      "[dimension 55/145]  inactive:\t4.02e-04 +- 1.56e-02\n",
      "[dimension 56/145]  inactive:\t-1.80e-03 +- 2.01e-02\n",
      "[dimension 57/145]  inactive:\t1.45e-03 +- 3.54e-02\n",
      "[dimension 58/145]  inactive:\t1.11e-02 +- 6.72e-02\n",
      "[dimension 59/145]  inactive:\t-6.52e-04 +- 1.98e-02\n",
      "[dimension 60/145]  inactive:\t3.82e-05 +- 2.34e-02\n",
      "[dimension 61/145]  inactive:\t1.68e-03 +- 1.89e-02\n",
      "[dimension 62/145]  inactive:\t-4.50e-04 +- 2.09e-02\n",
      "[dimension 63/145]  active:\t8.17e-01 +- 3.47e-01\n",
      "[dimension 64/145]  inactive:\t-2.33e-03 +- 2.49e-02\n",
      "[dimension 65/145]  inactive:\t-4.61e-04 +- 2.38e-02\n",
      "[dimension 66/145]  inactive:\t3.05e-04 +- 2.53e-02\n",
      "[dimension 67/145]  inactive:\t1.33e-03 +- 2.39e-02\n",
      "[dimension 68/145]  inactive:\t-1.54e-03 +- 3.16e-02\n",
      "[dimension 69/145]  inactive:\t4.03e-03 +- 4.82e-02\n",
      "[dimension 70/145]  inactive:\t3.52e-03 +- 2.34e-02\n",
      "[dimension 71/145]  inactive:\t1.88e-04 +- 3.15e-02\n",
      "[dimension 72/145]  inactive:\t3.50e-04 +- 2.26e-02\n",
      "[dimension 73/145]  inactive:\t2.16e-04 +- 1.49e-02\n",
      "[dimension 74/145]  inactive:\t-2.87e-03 +- 3.38e-02\n",
      "[dimension 75/145]  inactive:\t2.69e-04 +- 1.97e-02\n",
      "[dimension 76/145]  inactive:\t4.72e-03 +- 3.51e-02\n",
      "[dimension 77/145]  inactive:\t-1.76e-03 +- 2.68e-02\n",
      "[dimension 78/145]  inactive:\t2.98e-03 +- 3.52e-02\n",
      "[dimension 79/145]  inactive:\t4.47e-03 +- 2.74e-02\n",
      "[dimension 80/145]  inactive:\t-8.03e-04 +- 3.02e-02\n",
      "[dimension 81/145]  inactive:\t-9.89e-05 +- 2.73e-02\n",
      "[dimension 82/145]  inactive:\t2.96e-04 +- 1.71e-02\n",
      "[dimension 83/145]  inactive:\t-1.47e-03 +- 1.84e-02\n",
      "[dimension 84/145]  inactive:\t-2.19e-03 +- 2.86e-02\n",
      "[dimension 85/145]  inactive:\t3.03e-03 +- 2.94e-02\n",
      "[dimension 86/145]  inactive:\t-3.75e-04 +- 1.91e-02\n",
      "[dimension 87/145]  inactive:\t2.06e-03 +- 4.08e-02\n",
      "[dimension 88/145]  inactive:\t1.87e-03 +- 1.85e-02\n",
      "[dimension 89/145]  inactive:\t-9.81e-04 +- 1.92e-02\n",
      "[dimension 90/145]  inactive:\t7.09e-02 +- 2.38e-01\n",
      "[dimension 91/145]  inactive:\t1.95e-04 +- 1.82e-02\n",
      "[dimension 92/145]  inactive:\t-1.76e-03 +- 2.49e-02\n",
      "[dimension 93/145]  inactive:\t-6.63e-04 +- 2.48e-02\n",
      "[dimension 94/145]  inactive:\t1.25e-03 +- 2.10e-02\n",
      "[dimension 95/145]  inactive:\t-6.62e-04 +- 2.71e-02\n",
      "[dimension 96/145]  inactive:\t-3.66e-04 +- 3.66e-02\n",
      "[dimension 97/145]  inactive:\t2.32e-03 +- 2.21e-02\n",
      "[dimension 98/145]  inactive:\t-5.17e-04 +- 2.35e-02\n",
      "[dimension 99/145]  inactive:\t2.92e-03 +- 4.57e-02\n",
      "[dimension 100/145]  inactive:\t-6.41e-04 +- 1.65e-02\n",
      "[dimension 101/145]  inactive:\t-2.36e-03 +- 2.11e-02\n",
      "[dimension 102/145]  inactive:\t-1.61e-03 +- 2.58e-02\n",
      "[dimension 103/145]  inactive:\t7.94e-04 +- 2.59e-02\n",
      "[dimension 104/145]  inactive:\t-9.49e-04 +- 1.63e-02\n",
      "[dimension 105/145]  inactive:\t-4.31e-04 +- 1.99e-02\n",
      "[dimension 106/145]  inactive:\t3.26e-03 +- 2.54e-02\n",
      "[dimension 107/145]  inactive:\t-1.31e-03 +- 1.80e-02\n",
      "[dimension 108/145]  inactive:\t7.78e-04 +- 3.20e-02\n",
      "[dimension 109/145]  inactive:\t-2.68e-04 +- 1.56e-02\n",
      "[dimension 110/145]  inactive:\t-1.87e-03 +- 3.09e-02\n",
      "[dimension 111/145]  inactive:\t1.61e-03 +- 3.01e-02\n",
      "[dimension 112/145]  inactive:\t6.02e-03 +- 5.11e-02\n",
      "[dimension 113/145]  inactive:\t-1.35e-03 +- 2.12e-02\n",
      "[dimension 114/145]  inactive:\t-2.09e-05 +- 2.82e-02\n",
      "[dimension 115/145]  inactive:\t2.07e-03 +- 2.09e-02\n",
      "[dimension 116/145]  inactive:\t-2.53e-04 +- 2.94e-02\n",
      "[dimension 117/145]  inactive:\t1.98e-03 +- 3.57e-02\n",
      "[dimension 118/145]  inactive:\t2.69e-03 +- 2.32e-02\n",
      "[dimension 119/145]  inactive:\t-2.74e-03 +- 3.34e-02\n",
      "[dimension 120/145]  inactive:\t-4.73e-04 +- 3.75e-02\n",
      "[dimension 121/145]  inactive:\t5.46e-03 +- 4.20e-02\n",
      "[dimension 122/145]  inactive:\t-2.32e-03 +- 3.01e-02\n",
      "[dimension 123/145]  inactive:\t8.20e-04 +- 2.95e-02\n",
      "[dimension 124/145]  inactive:\t-1.64e-03 +- 1.97e-02\n",
      "[dimension 125/145]  inactive:\t-2.11e-03 +- 2.79e-02\n",
      "[dimension 126/145]  inactive:\t-1.13e-03 +- 2.34e-02\n",
      "[dimension 127/145]  inactive:\t8.51e-05 +- 1.57e-02\n",
      "[dimension 128/145]  inactive:\t-1.52e-03 +- 2.84e-02\n",
      "[dimension 129/145]  inactive:\t2.62e-04 +- 2.53e-02\n",
      "[dimension 130/145]  inactive:\t3.49e-03 +- 2.79e-02\n",
      "[dimension 131/145]  inactive:\t-1.41e-03 +- 2.53e-02\n",
      "[dimension 132/145]  inactive:\t2.82e-03 +- 3.49e-02\n",
      "[dimension 133/145]  inactive:\t2.06e-03 +- 1.83e-02\n",
      "[dimension 134/145]  inactive:\t-9.50e-04 +- 2.52e-02\n",
      "[dimension 135/145]  inactive:\t7.14e-04 +- 2.61e-02\n",
      "[dimension 136/145]  inactive:\t7.72e-04 +- 1.75e-02\n",
      "[dimension 137/145]  inactive:\t-7.46e-04 +- 2.73e-02\n",
      "[dimension 138/145]  inactive:\t2.96e-04 +- 1.80e-02\n",
      "[dimension 139/145]  inactive:\t2.55e-04 +- 2.40e-02\n",
      "[dimension 140/145]  inactive:\t-9.30e-04 +- 2.51e-02\n",
      "[dimension 141/145]  inactive:\t1.02e-03 +- 2.53e-02\n",
      "[dimension 142/145]  inactive:\t1.45e-03 +- 1.92e-02\n",
      "[dimension 143/145]  inactive:\t2.44e-04 +- 3.12e-02\n",
      "[dimension 144/145]  inactive:\t2.51e-04 +- 1.91e-02\n",
      "[dimension 145/145]  inactive:\t3.87e-09 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[1.7642975e-05]\n",
      "cov_act[[2.0302832e-06]]\n",
      "Active_dimensions: [62]\n",
      "85, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample: 100%|██████████| 1500/1500 [00:34<00:00, 43.96it/s, 31 steps of size 1.63e-01. acc. prob=0.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       eta1      0.00      0.00      0.00      0.00      0.00    468.34      1.00\n",
      "  lambda[0]      2.10      3.60      0.95      0.00      5.03    944.01      1.00\n",
      "  lambda[1]      2.88      9.79      0.99      0.00      5.50    688.80      1.00\n",
      "  lambda[2]      2.64      6.11      1.02      0.00      5.66    656.56      1.00\n",
      "  lambda[3]      3.96     16.83      0.96      0.00      6.45    578.42      1.00\n",
      "  lambda[4]      3.04      8.52      1.05      0.00      5.86    729.07      1.00\n",
      "  lambda[5]      2.92      7.39      0.99      0.00      5.64    801.24      1.00\n",
      "  lambda[6]      4.04     11.23      1.08      0.00      8.25    625.96      1.00\n",
      "  lambda[7]      3.59     10.60      0.99      0.00      6.46    635.84      1.01\n",
      "  lambda[8]      2.51      5.65      1.01      0.01      5.56   1013.84      1.00\n",
      "  lambda[9]      2.45      6.11      1.03      0.00      4.96    855.73      1.00\n",
      " lambda[10]      3.25     13.58      1.02      0.00      5.55    745.05      1.00\n",
      " lambda[11]      2.55      5.38      1.01      0.00      5.80    673.89      1.00\n",
      " lambda[12]      3.99     12.37      0.98      0.00      7.86    701.51      1.00\n",
      " lambda[13]      2.72      9.53      0.96      0.00      5.53    866.60      1.00\n",
      " lambda[14]      3.66     19.05      0.98      0.00      4.93    739.26      1.00\n",
      " lambda[15]      4.09     12.87      1.01      0.00      7.40    549.18      1.00\n",
      " lambda[16]      3.58      9.44      0.96      0.00      7.97    588.29      1.01\n",
      " lambda[17]      3.21     20.23      0.95      0.00      5.06    844.92      1.00\n",
      " lambda[18]      2.83      7.44      0.99      0.00      5.50    880.84      1.00\n",
      " lambda[19]      3.61     15.64      0.97      0.00      6.23    693.47      1.00\n",
      " lambda[20]      2.76      9.24      0.96      0.00      5.77    714.38      1.00\n",
      " lambda[21]      2.92      7.89      1.01      0.00      6.52    699.60      1.00\n",
      " lambda[22]      2.40      5.36      1.02      0.00      5.00    860.46      1.00\n",
      " lambda[23]      3.48     13.41      0.94      0.00      5.74    690.24      1.00\n",
      " lambda[24]      3.17     15.22      1.04      0.00      6.41    970.10      1.00\n",
      " lambda[25]      2.94      6.84      0.97      0.01      6.73    555.45      1.00\n",
      " lambda[26]      2.74      7.29      0.99      0.00      5.32    650.00      1.00\n",
      " lambda[27]      3.08      8.75      0.99      0.00      5.35    662.13      1.00\n",
      " lambda[28]      2.75      7.93      1.01      0.00      5.93    655.07      1.00\n",
      " lambda[29]      2.47      6.11      0.99      0.00      4.95    737.79      1.00\n",
      " lambda[30]      3.14      8.44      1.02      0.01      7.12    723.33      1.00\n",
      " lambda[31]      3.09     11.52      0.95      0.00      5.58    663.05      1.00\n",
      " lambda[32]      3.24     15.12      0.92      0.00      5.64    649.38      1.00\n",
      " lambda[33]      2.81      8.88      0.98      0.01      5.59    921.16      1.00\n",
      " lambda[34]      2.79      8.93      0.97      0.00      5.07    557.81      1.00\n",
      " lambda[35]      2.48      6.50      0.96      0.00      4.65    948.10      1.00\n",
      " lambda[36]      3.54     18.29      1.00      0.00      5.55    784.83      1.00\n",
      " lambda[37]      2.97      8.28      1.02      0.00      6.05    743.27      1.00\n",
      " lambda[38]      2.88      7.43      0.97      0.00      5.37    750.95      1.00\n",
      " lambda[39]      3.00      8.23      0.98      0.00      5.53    612.35      1.00\n",
      " lambda[40]      3.95     20.22      0.89      0.00      6.08    738.15      1.00\n",
      " lambda[41]      4.65     26.72      0.86      0.00      5.74    703.66      1.01\n",
      " lambda[42]      2.56      5.56      1.01      0.00      5.64    885.10      1.00\n",
      " lambda[43]      3.18     18.34      0.96      0.00      5.89    960.46      1.00\n",
      " lambda[44]      2.48      5.54      0.94      0.00      5.84   1048.45      1.00\n",
      " lambda[45]      2.49      5.77      0.93      0.00      4.72    591.48      1.00\n",
      " lambda[46]      2.67      7.06      1.00      0.00      5.27    738.81      1.00\n",
      " lambda[47]      2.63      7.68      0.90      0.01      5.28    624.38      1.00\n",
      " lambda[48]      2.36      6.56      1.02      0.01      4.69    792.77      1.00\n",
      " lambda[49]      2.94      7.62      0.98      0.00      6.28    820.03      1.00\n",
      " lambda[50]      2.67      7.11      1.02      0.00      5.82    738.26      1.00\n",
      " lambda[51]      4.34     13.76      1.07      0.00      6.93    777.55      1.00\n",
      " lambda[52]      3.15      9.54      0.93      0.00      6.40    439.08      1.00\n",
      " lambda[53]      2.90      7.82      0.93      0.00      5.43    703.65      1.00\n",
      " lambda[54]      2.14      5.80      0.95      0.00      3.98    470.97      1.00\n",
      " lambda[55]      3.11     13.89      0.98      0.00      5.62    930.89      1.00\n",
      " lambda[56]      2.56      5.50      0.99      0.00      5.10    715.76      1.00\n",
      " lambda[57]      3.20      9.35      0.92      0.00      6.26    901.24      1.00\n",
      " lambda[58]      2.48      5.40      0.98      0.01      5.49    616.13      1.00\n",
      " lambda[59]      2.90      8.09      0.95      0.00      6.10    556.98      1.00\n",
      " lambda[60]      3.23     10.33      0.96      0.00      5.93    760.22      1.00\n",
      " lambda[61]      2.59      5.47      1.02      0.00      5.96    685.06      1.00\n",
      " lambda[62]   4459.70  63430.52    408.72      0.03   2853.46    510.80      1.00\n",
      " lambda[63]      2.24      5.11      1.01      0.00      4.98    661.22      1.00\n",
      " lambda[64]      2.87      6.75      1.00      0.01      5.94    810.45      1.00\n",
      " lambda[65]      2.88      8.38      0.98      0.00      5.86    639.36      1.00\n",
      " lambda[66]      3.15      8.14      1.04      0.00      7.21    697.82      1.00\n",
      " lambda[67]      2.33      5.45      0.91      0.00      5.02    695.51      1.00\n",
      " lambda[68]      3.84     25.82      0.94      0.01      5.57    697.82      1.00\n",
      " lambda[69]      3.98     15.82      1.00      0.00      6.84    588.95      1.00\n",
      " lambda[70]      2.61      6.38      1.00      0.01      5.54    655.71      1.00\n",
      " lambda[71]      3.18     15.70      1.01      0.00      5.17    690.16      1.00\n",
      " lambda[72]      2.49      6.49      0.98      0.01      5.16    557.34      1.00\n",
      " lambda[73]      2.57      6.36      1.00      0.00      5.55    618.49      1.00\n",
      " lambda[74]      2.21      3.56      1.01      0.00      5.25    940.32      1.00\n",
      " lambda[75]      3.55     11.66      0.92      0.00      7.28    727.89      1.00\n",
      " lambda[76]      2.84      7.47      0.97      0.00      5.71    743.97      1.00\n",
      " lambda[77]     10.42    137.79      1.13      0.00      6.69    324.19      1.00\n",
      " lambda[78]      3.43     16.38      1.07      0.00      5.94    868.16      1.00\n",
      " lambda[79]      2.78      8.28      1.02      0.00      5.32    706.99      1.00\n",
      " lambda[80]      4.34     28.34      1.06      0.00      6.29    961.08      1.00\n",
      " lambda[81]      2.51      8.33      0.99      0.00      4.75    638.70      1.00\n",
      " lambda[82]      2.86      9.87      0.96      0.00      4.89    476.99      1.00\n",
      " lambda[83]      2.67      7.18      0.92      0.00      5.38    978.18      1.00\n",
      " lambda[84]      3.26     12.24      0.97      0.00      5.68    828.90      1.00\n",
      " lambda[85]      2.51      7.28      0.93      0.00      5.58   1038.31      1.00\n",
      " lambda[86]      2.74      7.79      1.02      0.00      5.71    930.69      1.00\n",
      " lambda[87]      2.97      8.89      0.95      0.01      5.94    581.72      1.01\n",
      " lambda[88]      2.61      6.76      0.94      0.00      5.43    869.73      1.00\n",
      " lambda[89]    127.81   1477.30      1.17      0.00     71.33    553.55      1.00\n",
      " lambda[90]      2.54      5.65      1.03      0.00      5.29    778.77      1.00\n",
      " lambda[91]      2.40      5.56      0.96      0.01      4.83    691.77      1.00\n",
      " lambda[92]      2.75      6.93      0.97      0.00      5.32    663.41      1.00\n",
      " lambda[93]      2.72      6.17      1.10      0.00      5.58    843.05      1.00\n",
      " lambda[94]      2.81     17.56      0.97      0.00      4.24    759.36      1.00\n",
      " lambda[95]      2.67      6.73      0.99      0.00      5.49   1042.27      1.00\n",
      " lambda[96]      2.74      7.33      0.99      0.00      5.71    496.95      1.00\n",
      " lambda[97]      3.37     13.52      1.00      0.00      5.81    642.20      1.00\n",
      " lambda[98]      8.37    102.98      0.93      0.00      5.31    440.50      1.00\n",
      " lambda[99]      2.59      6.79      0.99      0.00      4.67    561.62      1.00\n",
      "lambda[100]      2.74      7.55      0.96      0.00      5.38    812.30      1.00\n",
      "lambda[101]      2.69      6.60      0.96      0.00      5.77    764.17      1.00\n",
      "lambda[102]      2.60      6.96      0.95      0.00      5.13    901.76      1.00\n",
      "lambda[103]      2.22      4.19      1.01      0.00      5.02    667.54      1.00\n",
      "lambda[104]      3.06     16.81      0.96      0.00      6.19    591.94      1.00\n",
      "lambda[105]      2.62      5.23      1.00      0.00      6.29    673.40      1.00\n",
      "lambda[106]      2.46      5.21      1.00      0.00      5.21    571.12      1.00\n",
      "lambda[107]      2.82      9.20      0.99      0.00      5.12    658.61      1.00\n",
      "lambda[108]      2.58      6.33      0.94      0.00      5.15    465.64      1.00\n",
      "lambda[109]      6.40     90.91      0.99      0.00      6.35    989.79      1.00\n",
      "lambda[110]      3.25      9.83      1.03      0.00      6.31    700.86      1.00\n",
      "lambda[111]      3.31     11.44      0.95      0.00      6.22    772.23      1.00\n",
      "lambda[112]      2.67      7.07      0.96      0.00      5.55    823.23      1.00\n",
      "lambda[113]      3.28      9.95      1.01      0.00      6.10    517.83      1.00\n",
      "lambda[114]      3.91     11.24      1.02      0.00      7.62    680.18      1.00\n",
      "lambda[115]      3.83     15.60      0.94      0.00      5.59    634.51      1.00\n",
      "lambda[116]      2.77      8.53      0.96      0.00      5.41    767.65      1.00\n",
      "lambda[117]      3.34     13.23      0.96      0.00      6.37    727.22      1.00\n",
      "lambda[118]      3.20     12.24      0.92      0.00      5.98    990.43      1.00\n",
      "lambda[119]      2.39      5.89      0.97      0.01      5.50    909.00      1.00\n",
      "lambda[120]      3.88     15.67      0.98      0.00      6.81    773.20      1.00\n",
      "lambda[121]      3.23     10.90      0.94      0.00      5.97    868.14      1.00\n",
      "lambda[122]      2.72      6.50      1.00      0.00      5.99    947.41      1.00\n",
      "lambda[123]      2.68      5.84      0.94      0.00      6.58    632.60      1.00\n",
      "lambda[124]      2.60      5.33      1.02      0.00      6.53    904.84      1.00\n",
      "lambda[125]      2.77      7.17      0.97      0.00      5.88    883.72      1.00\n",
      "lambda[126]      2.73      7.50      0.95      0.00      5.45    665.14      1.00\n",
      "lambda[127]      4.31     22.84      1.02      0.00      6.46    849.80      1.00\n",
      "lambda[128]      2.52      7.79      0.96      0.00      4.60    749.72      1.00\n",
      "lambda[129]      3.04      9.57      1.00      0.00      5.61    712.62      1.00\n",
      "lambda[130]      3.35      8.73      0.96      0.00      6.45    624.73      1.00\n",
      "lambda[131]      3.28     13.78      0.94      0.00      5.93    892.80      1.00\n",
      "lambda[132]      3.06      8.54      0.96      0.00      5.79    446.51      1.00\n",
      "lambda[133]      2.69      8.33      1.00      0.00      5.61    622.55      1.00\n",
      "lambda[134]      3.15      7.27      0.95      0.00      7.25    534.03      1.00\n",
      "lambda[135]      2.67      7.55      0.89      0.00      4.96    638.95      1.00\n",
      "lambda[136]      2.69      6.22      0.97      0.00      6.12    840.10      1.00\n",
      "lambda[137]      2.66      7.96      0.95      0.00      4.77    536.69      1.00\n",
      "lambda[138]      3.08     11.27      1.02      0.00      5.28    632.35      1.00\n",
      "lambda[139]      3.23     10.74      1.00      0.00      5.98    848.65      1.00\n",
      "lambda[140]      2.85      8.30      0.93      0.00      5.27    968.83      1.00\n",
      "lambda[141]      2.76     11.00      0.93      0.00      5.02    573.77      1.00\n",
      "lambda[142]      4.04     14.48      0.97      0.00      6.91    706.39      1.00\n",
      "lambda[143]      2.20      4.36      0.98      0.00      4.70    655.37      1.00\n",
      "        msq      1.61      1.09      1.35      0.50      2.70    756.14      1.00\n",
      "      sigma      2.88      4.11      1.07      0.00      8.48   1392.49      1.00\n",
      "    var_obs      0.09      0.01      0.08      0.06      0.11    891.55      1.00\n",
      "       xisq     17.25     42.17      6.89      0.66     33.01    866.85      1.00\n",
      "\n",
      "Number of divergences: 1\n",
      "\n",
      "MCMC elapsed time: 39.17907691001892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dimension 01/145]  inactive:\t-6.40e-05 +- 9.87e-03\n",
      "[dimension 02/145]  inactive:\t1.39e-04 +- 1.48e-02\n",
      "[dimension 03/145]  inactive:\t2.35e-04 +- 1.22e-02\n",
      "[dimension 04/145]  inactive:\t2.69e-03 +- 2.44e-02\n",
      "[dimension 05/145]  inactive:\t-1.84e-04 +- 1.41e-02\n",
      "[dimension 06/145]  inactive:\t8.95e-04 +- 1.88e-02\n",
      "[dimension 07/145]  inactive:\t8.17e-04 +- 1.41e-02\n",
      "[dimension 08/145]  inactive:\t3.99e-04 +- 1.68e-02\n",
      "[dimension 09/145]  inactive:\t3.14e-04 +- 1.48e-02\n",
      "[dimension 10/145]  inactive:\t3.14e-04 +- 1.02e-02\n",
      "[dimension 11/145]  inactive:\t-2.60e-04 +- 1.48e-02\n",
      "[dimension 12/145]  inactive:\t1.09e-04 +- 1.17e-02\n",
      "[dimension 13/145]  inactive:\t2.50e-03 +- 2.81e-02\n",
      "[dimension 14/145]  inactive:\t-4.99e-05 +- 1.71e-02\n",
      "[dimension 15/145]  inactive:\t3.74e-04 +- 1.77e-02\n",
      "[dimension 16/145]  inactive:\t4.32e-04 +- 1.71e-02\n",
      "[dimension 17/145]  inactive:\t4.44e-04 +- 1.88e-02\n",
      "[dimension 18/145]  inactive:\t1.44e-03 +- 2.91e-02\n",
      "[dimension 19/145]  inactive:\t-8.76e-04 +- 1.30e-02\n",
      "[dimension 20/145]  inactive:\t-2.34e-04 +- 1.46e-02\n",
      "[dimension 21/145]  inactive:\t-5.41e-04 +- 1.40e-02\n",
      "[dimension 22/145]  inactive:\t1.63e-04 +- 1.18e-02\n",
      "[dimension 23/145]  inactive:\t-8.12e-05 +- 1.34e-02\n",
      "[dimension 24/145]  inactive:\t8.87e-04 +- 1.84e-02\n",
      "[dimension 25/145]  inactive:\t1.35e-03 +- 1.34e-02\n",
      "[dimension 26/145]  inactive:\t-1.77e-04 +- 1.40e-02\n",
      "[dimension 27/145]  inactive:\t3.32e-04 +- 1.44e-02\n",
      "[dimension 28/145]  inactive:\t7.08e-04 +- 1.37e-02\n",
      "[dimension 29/145]  inactive:\t7.09e-04 +- 2.07e-02\n",
      "[dimension 30/145]  inactive:\t6.53e-04 +- 1.62e-02\n",
      "[dimension 31/145]  inactive:\t1.70e-03 +- 1.84e-02\n",
      "[dimension 32/145]  inactive:\t-2.57e-04 +- 1.48e-02\n",
      "[dimension 33/145]  inactive:\t9.37e-04 +- 2.68e-02\n",
      "[dimension 34/145]  inactive:\t5.00e-04 +- 1.27e-02\n",
      "[dimension 35/145]  inactive:\t3.58e-04 +- 1.56e-02\n",
      "[dimension 36/145]  inactive:\t5.18e-04 +- 1.48e-02\n",
      "[dimension 37/145]  inactive:\t1.67e-03 +- 1.56e-02\n",
      "[dimension 38/145]  inactive:\t-5.02e-04 +- 1.68e-02\n",
      "[dimension 39/145]  inactive:\t5.73e-04 +- 1.84e-02\n",
      "[dimension 40/145]  inactive:\t2.84e-03 +- 2.83e-02\n",
      "[dimension 41/145]  inactive:\t-2.58e-04 +- 2.07e-02\n",
      "[dimension 42/145]  inactive:\t2.01e-03 +- 2.97e-02\n",
      "[dimension 43/145]  inactive:\t7.73e-05 +- 1.22e-02\n",
      "[dimension 44/145]  inactive:\t3.55e-04 +- 2.01e-02\n",
      "[dimension 45/145]  inactive:\t5.80e-05 +- 1.39e-02\n",
      "[dimension 46/145]  inactive:\t5.02e-04 +- 1.04e-02\n",
      "[dimension 47/145]  inactive:\t-6.00e-04 +- 1.67e-02\n",
      "[dimension 48/145]  inactive:\t2.71e-04 +- 1.59e-02\n",
      "[dimension 49/145]  inactive:\t9.14e-04 +- 1.38e-02\n",
      "[dimension 50/145]  inactive:\t-5.03e-04 +- 1.74e-02\n",
      "[dimension 51/145]  inactive:\t6.97e-04 +- 1.51e-02\n",
      "[dimension 52/145]  inactive:\t4.01e-03 +- 2.02e-02\n",
      "[dimension 53/145]  inactive:\t-8.00e-04 +- 1.76e-02\n",
      "[dimension 54/145]  inactive:\t7.41e-05 +- 1.34e-02\n",
      "[dimension 55/145]  inactive:\t3.27e-04 +- 9.28e-03\n",
      "[dimension 56/145]  inactive:\t-1.08e-03 +- 1.28e-02\n",
      "[dimension 57/145]  inactive:\t7.15e-04 +- 2.05e-02\n",
      "[dimension 58/145]  inactive:\t4.20e-03 +- 3.41e-02\n",
      "[dimension 59/145]  inactive:\t-2.99e-04 +- 1.19e-02\n",
      "[dimension 60/145]  inactive:\t1.51e-03 +- 2.81e-02\n",
      "[dimension 61/145]  inactive:\t1.52e-03 +- 1.84e-02\n",
      "[dimension 62/145]  inactive:\t-3.08e-04 +- 1.31e-02\n",
      "[dimension 63/145]  active:\t7.96e-01 +- 3.57e-01\n",
      "[dimension 64/145]  inactive:\t-7.18e-04 +- 1.16e-02\n",
      "[dimension 65/145]  inactive:\t-3.16e-05 +- 1.53e-02\n",
      "[dimension 66/145]  inactive:\t3.59e-04 +- 1.45e-02\n",
      "[dimension 67/145]  inactive:\t9.47e-04 +- 1.75e-02\n",
      "[dimension 68/145]  inactive:\t-2.54e-05 +- 1.40e-02\n",
      "[dimension 69/145]  inactive:\t3.12e-03 +- 3.72e-02\n",
      "[dimension 70/145]  inactive:\t2.55e-03 +- 2.02e-02\n",
      "[dimension 71/145]  inactive:\t-8.06e-05 +- 1.39e-02\n",
      "[dimension 72/145]  inactive:\t4.59e-04 +- 1.40e-02\n",
      "[dimension 73/145]  inactive:\t2.49e-04 +- 1.01e-02\n",
      "[dimension 74/145]  inactive:\t-2.03e-04 +- 1.90e-02\n",
      "[dimension 75/145]  inactive:\t2.32e-04 +- 1.15e-02\n",
      "[dimension 76/145]  inactive:\t2.51e-03 +- 2.21e-02\n",
      "[dimension 77/145]  inactive:\t-5.28e-04 +- 1.67e-02\n",
      "[dimension 78/145]  inactive:\t5.80e-03 +- 6.44e-02\n",
      "[dimension 79/145]  inactive:\t2.79e-03 +- 2.13e-02\n",
      "[dimension 80/145]  inactive:\t1.94e-04 +- 1.97e-02\n",
      "[dimension 81/145]  inactive:\t1.74e-03 +- 3.31e-02\n",
      "[dimension 82/145]  inactive:\t1.22e-04 +- 9.76e-03\n",
      "[dimension 83/145]  inactive:\t-8.40e-04 +- 1.15e-02\n",
      "[dimension 84/145]  inactive:\t-4.31e-04 +- 1.30e-02\n",
      "[dimension 85/145]  inactive:\t1.44e-03 +- 1.99e-02\n",
      "[dimension 86/145]  inactive:\t-3.20e-04 +- 1.10e-02\n",
      "[dimension 87/145]  inactive:\t7.03e-04 +- 2.01e-02\n",
      "[dimension 88/145]  inactive:\t1.52e-03 +- 1.60e-02\n",
      "[dimension 89/145]  inactive:\t-4.14e-04 +- 1.46e-02\n",
      "[dimension 90/145]  inactive:\t9.09e-02 +- 2.64e-01\n",
      "[dimension 91/145]  inactive:\t1.40e-05 +- 1.06e-02\n",
      "[dimension 92/145]  inactive:\t-3.31e-04 +- 1.22e-02\n",
      "[dimension 93/145]  inactive:\t-2.04e-04 +- 1.61e-02\n",
      "[dimension 94/145]  inactive:\t1.09e-03 +- 1.95e-02\n",
      "[dimension 95/145]  inactive:\t-4.49e-05 +- 1.36e-02\n",
      "[dimension 96/145]  inactive:\t1.09e-05 +- 1.71e-02\n",
      "[dimension 97/145]  inactive:\t1.25e-03 +- 1.48e-02\n",
      "[dimension 98/145]  inactive:\t-6.88e-04 +- 1.89e-02\n",
      "[dimension 99/145]  inactive:\t3.57e-03 +- 5.15e-02\n",
      "[dimension 100/145]  inactive:\t-2.56e-04 +- 1.14e-02\n",
      "[dimension 101/145]  inactive:\t-9.99e-04 +- 1.26e-02\n",
      "[dimension 102/145]  inactive:\t-2.99e-05 +- 1.54e-02\n",
      "[dimension 103/145]  inactive:\t6.82e-06 +- 1.48e-02\n",
      "[dimension 104/145]  inactive:\t-4.33e-04 +- 9.75e-03\n",
      "[dimension 105/145]  inactive:\t-9.95e-05 +- 1.84e-02\n",
      "[dimension 106/145]  inactive:\t1.58e-03 +- 1.62e-02\n",
      "[dimension 107/145]  inactive:\t-5.35e-04 +- 1.28e-02\n",
      "[dimension 108/145]  inactive:\t1.42e-03 +- 3.17e-02\n",
      "[dimension 109/145]  inactive:\t2.13e-05 +- 1.26e-02\n",
      "[dimension 110/145]  inactive:\t-5.05e-05 +- 1.98e-02\n",
      "[dimension 111/145]  inactive:\t1.26e-03 +- 2.21e-02\n",
      "[dimension 112/145]  inactive:\t1.63e-03 +- 2.07e-02\n",
      "[dimension 113/145]  inactive:\t-4.42e-04 +- 1.38e-02\n",
      "[dimension 114/145]  inactive:\t6.38e-04 +- 2.42e-02\n",
      "[dimension 115/145]  inactive:\t1.55e-03 +- 1.63e-02\n",
      "[dimension 116/145]  inactive:\t2.23e-03 +- 3.73e-02\n",
      "[dimension 117/145]  inactive:\t1.83e-03 +- 2.99e-02\n",
      "[dimension 118/145]  inactive:\t1.42e-03 +- 1.48e-02\n",
      "[dimension 119/145]  inactive:\t-6.04e-04 +- 1.86e-02\n",
      "[dimension 120/145]  inactive:\t5.42e-05 +- 1.39e-02\n",
      "[dimension 121/145]  inactive:\t2.30e-03 +- 2.46e-02\n",
      "[dimension 122/145]  inactive:\t-9.57e-04 +- 2.28e-02\n",
      "[dimension 123/145]  inactive:\t5.77e-04 +- 1.64e-02\n",
      "[dimension 124/145]  inactive:\t-2.68e-04 +- 1.31e-02\n",
      "[dimension 125/145]  inactive:\t-3.61e-04 +- 1.52e-02\n",
      "[dimension 126/145]  inactive:\t-3.04e-04 +- 1.26e-02\n",
      "[dimension 127/145]  inactive:\t2.94e-04 +- 1.15e-02\n",
      "[dimension 128/145]  inactive:\t5.91e-04 +- 2.50e-02\n",
      "[dimension 129/145]  inactive:\t3.66e-04 +- 1.63e-02\n",
      "[dimension 130/145]  inactive:\t1.07e-03 +- 1.44e-02\n",
      "[dimension 131/145]  inactive:\t-1.89e-04 +- 1.99e-02\n",
      "[dimension 132/145]  inactive:\t1.64e-03 +- 2.75e-02\n",
      "[dimension 133/145]  inactive:\t1.51e-03 +- 1.56e-02\n",
      "[dimension 134/145]  inactive:\t-1.02e-05 +- 1.77e-02\n",
      "[dimension 135/145]  inactive:\t4.24e-04 +- 1.83e-02\n",
      "[dimension 136/145]  inactive:\t6.55e-04 +- 1.28e-02\n",
      "[dimension 137/145]  inactive:\t7.77e-05 +- 1.77e-02\n",
      "[dimension 138/145]  inactive:\t3.79e-04 +- 1.19e-02\n",
      "[dimension 139/145]  inactive:\t2.58e-04 +- 1.57e-02\n",
      "[dimension 140/145]  inactive:\t-1.27e-04 +- 1.95e-02\n",
      "[dimension 141/145]  inactive:\t5.36e-04 +- 1.74e-02\n",
      "[dimension 142/145]  inactive:\t1.03e-03 +- 1.27e-02\n",
      "[dimension 143/145]  inactive:\t1.19e-03 +- 2.59e-02\n",
      "[dimension 144/145]  inactive:\t1.14e-04 +- 9.29e-03\n",
      "[dimension 145/145]  inactive:\t3.87e-10 +- 7.12e-04\n",
      "Identified a total of 1 active dimensions; expected 15.\n",
      "[]\n",
      "[]\n",
      "NUM of DIM: 144\n",
      "Num of all Thetas: 144\n",
      "mu_act[0.96790195]\n",
      "cov_act[[0.01519151]]\n",
      "Active_dimensions: [62]\n",
      "86, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/corner/corner.py:207: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n",
      "/Users/sachinsmart/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "sample:  68%|██████▊   | 1022/1500 [00:26<00:12, 38.41it/s, 31 steps of size 1.14e-01. acc. prob=0.96] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6a3b58858213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mnumpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_host_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mresults_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b97b66aab942>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, hypers)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# do inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrng_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# compute the mean and square root variance of each coefficient theta_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-86f87e277a40>\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(model, args, rng_key, X, Y, hypers)\u001b[0m\n\u001b[1;32m    205\u001b[0m     mcmc = MCMC(kernel, args.num_warmup, args.num_samples, num_chains=args.num_chains,\n\u001b[1;32m    206\u001b[0m                 progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True)\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nMCMC elapsed time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             states_flat, last_state = self._single_chain_mcmc(rng_key, init_state, init_params,\n\u001b[0;32m-> 1197\u001b[0;31m                                                               args, kwargs, collect_fields)\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36m_single_chain_mcmc\u001b[0;34m(self, rng_key, init_state, init_params, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                                     progbar_desc=functools.partial(get_progbar_desc_str,\n\u001b[1;32m   1087\u001b[0m                                                                    lower_idx),\n\u001b[0;32m-> 1088\u001b[0;31m                                     diagnostics_fn=diagnostics)\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# Get first argument of type `HMCState`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/util.py\u001b[0m in \u001b[0;36mfori_collect\u001b[0;34m(lower, upper, body_fun, init_val, transform, progbar, return_last_val, collection_size, **progbar_opts)\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogbar_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdiagnostics_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagnostics_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mlast_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0mdiagnostics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_diagnostics_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# noqa: E731\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m         \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_model_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mlower_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collection_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lower\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36mget_diagnostics_str\u001b[0;34m(mcmc_state)\u001b[0m\n\u001b[1;32m     89\u001b[0m         return '{} steps of size {:.2e}. acc. prob={:.2f}'.format(mcmc_state.num_steps,\n\u001b[1;32m     90\u001b[0m                                                                   \u001b[0mmcmc_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                                                   mcmc_state.mean_accept_prob)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'acc. prob={:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcmc_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_accept_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;31m# Simulates behavior of https://github.com/numpy/numpy/pull/9883\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_lexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_force\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_npy_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_dtype_from_pep3118\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_dtype_from_pep3118\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__dtype_from_pep3118\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_subdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKMAAADTCAYAAADtTqNBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAKQElEQVR4nO3de4xcZR3G8e9Tyk2wlHSBgMIWVCCGO0uwENBELhW8oURFSRBjWgKKBk2FYIwgkRDQiCBoRSWGohiwCZjITSVqAsStNngBVLAVAkgRQRQL1v784z0bJpvd2c6cObO/mX0+yWY7M6fn956dZ855Z99531VEYJbBvNlugNkEh9HScBgtDYfR0nAYLQ2H0dKY38nGIyMjsXjx4oaaYsNuzZo1z0TELtM9PmMYJS0DlgHstddejI+P97B5NpdIWt/u8Rkv0xGxMiLGImJsl12mDbVZbe4zWhoOo6XhMFoaDqOl4TBaGg6jpeEwWhoOo6XhMFoaDqOl4TBOsnjxYiRN++UPijSno0/tzAXr16+n3SQ1SX1szdziM6Ol4TBaGg6jpeEwWhoOo6XhMFoaDqOl4TBaGg6jpeEwWhozhlHSMknjksY3bNjQjzalNjo62nbs2mPa3VMni4WOjY3FsE/il9R2bDrbfgeJpDURMTbd475MWxoOo6XhMFoaDqOl4TBaGg6jpeEwWhoOo6XhMFoaAx3GdtNKh2X4bS4c44SBnqrablrpsEwpnQvHOGGgz4w2XBxGS8NhtDQcRkvDYbQ0HEZLw2G0NBxGS8NhtDQcRkvDU1UtDf+JX0vDl2lLw2G0NBxGS8NhtDQcRkvDYbQ0HEZLw2G0NBxGS8NhtDTmZBjbzUUeHR1tpGa75ZeHbf5ztwZ63nS3Zvozvk1Yt27dtI8N2/znbs3JM6Pl5DBaGg6jpeEwWhoOo6XhMFoaDqOl4TBaGg6jpeEwWhqeN21peN60peHLtKXhMFoaDqOl4TBaGg6jpeEwWhoOo6XhMFoaDqOl4TBaGg5jAu3mVLebx93u/w3ifOw5OW86m3Zzquv8v0Gbj+0zo6XhMFoaDqOl4TBaGg6jpeEwWhoOo6XhMFoaDqOl4TBaGh3Nm167du3AjIN2O947V7Rb13y2nkt1sra1pJhue0l9Xyd7NmoOknY/n24fq9meNRExNt3jvkxbGg6jpeEwWhoOo6XhMFoaDqOl4TBaGg6jpeEwWhoOo6XRlzC2Gwet8+Ux5mbM1t/G7svYtMeQZ0cTz0md59Jj0zYwHEZLw2G0NBxGS8NhtDQcRkvDYbQ0HEZLw2G0NBxGS2PGZZQlLQOW9aEtNsd5bHqIeWzarEsOo6XhMFoaDqOl4TBaGg6jpeEwWhoOo6XhMFoaDqOl0bM/8Tsx13a6x2w4tHue6+rZ2LTlk+3zAh6btoHhMFoaDqOl4TBaGg6jpeEwWhoOo6XhMFoaDqOl4TBaGp3Om/6XpIe3cN8jwDPdNqwm1660G0duYIx5pmNv+yGFjsamOyFpvN04ZJNce3bUre/LtKXhMFoaTYZxZYP7du18tWvXb6zPaNYpX6YtjcbCqKY+m25Dq8kz46IG921DqJEwSjoJuE3SHk3sf4bax0g6R9Ip/a49RVtmrRvU79qSdqy7j543WNLRwFeBiyLiiV7vf4baJwDfBnYEbqleFP2sf7KkiyRdKmlRRGzuY+3jJF0o6RJJO0TE5n51lSQdRzn5LKlTs4lXz67ANRFxu6TXSHp39SQtaKAWUPqnknYCzgdWRMRlwNnAAkmHNVV3UhuOBK4GHgZ2Bm6VdJSkrftQ+2TgS8CzwJ7AnZK27eNUzu0pQ31vAY7q9qzcRBgFHCdpX2A1cCzwBeA8Sbs1UI8ongfuB0YlHQFcBpwIrJa0oom6kxwA3BkRN0bEWcAtwArgMGjusilpd+Ac4BMRcW1EnAH8GXh9E/Wm8QTlRbgn8H7gdZL26PQE1MQP6B7gd8BHgR9GxHnAqZRXzZsbqNfqEWAf4Ergqog4EzgJWN6HS/avgO0l7Q8QEV8Gfgl8RdLCBi/Z/wa+FhH3SNqqCv0i4PDWjRruQ/4R+AVwAfAU5URwGx2+ie15AyPiWcor8xDgkKrv9CglpCO9rgev/BopIq6LiHOBbwB/lTQ/In5POUvV7mDP4ClgE3C8pJGqPVdQXpjLmyoaEf8EflLd3FyFfi3wPICkpdUlu7H+a0S8ABxM+RmvpZx4nqS8OLc4Y7XCKGm/qtO6taStWhq3ErgR2ABcIenTwIeBu+rUm6421XG0HPhzwJHAUklnA+8C1vSqdksbWo/5aeAqYClwmqQDq4ceAXred5tUe2P1faLOpmqbU4FrgJ7+VqO1dssbljuA8yh9148BfwBOB7bd4h1HRFdfwHuAhyivyu8C5wILJm2zN3Aape+0X7e1uqx9KSUcdwBv7FXtat/7tvx7q+r7xNDqocDXge8D36OE8cAma0+xzWcpV6d7e3ns7WoDS4B1wCnV7QXAbh3tv8tGbQ3cBBxd3X4vcDlwCbDTFNvP6+EPpNPar+pxEN8OvAjcOEUg51XfR4A3AB8E9u5H7UnbfQB4sMcngC057oUTz1E3NepcphdUP3Ao75p/BGxDORMi6ciWNw29vkzNVHtJS+3/9KqopB0ol6BPAi9LugEgIv5X9U8n+mWbIuJPUd5Z/6UftVu22xH4KXBCRGzpp/Jr1W457vnV/f/tqlCNV8rxwK3AMROvEsqZYBWln/A+YPdenpWS1N6D0lEfAW4Gbpj0+MHVE7cd1aW7j7UPoXRZ5s/icW/bdY0ajduuKr4SOLbl/p/R0rdoKBCzVntSOxZR3qnfUN0+iNJt2NW1O//qerHQiNgoaRXlEnxB9fu1lygjMM93u9/stSe14++SlgOXVxPV5lFeHE+7dudqrVwbEf+Q9E3K2/jlwEbg9Ij4W539Zq89qR3PSHoAeBtwfEQ86drd6dknvavfPUX08cMBSWrvDPwA+FREPODaNfbZqzDOZZK2i+oXz65dY38Oo2XhOTCWhsNoaTiMlobDaGk4jJaGw2hpOIyWhsNoaTiMlobDaGk4jJaGw2hpOIyWhsNoaTiMlobDaGk4jJaGwzgFSZ+v1gdC0sXVYpjd7muhpJslPSTpQUlLqvsvr+57QNJqSQt71f5B5TDOICI+FxF319jFlcDtEbE/ZaL7g9X9dwEHRMRBlCXlLqjX0sHnMFaqJYgflnQ3sF/L/ddXq3khaZ2kL0q6V9K4pMMk3SHpEUlnTbHPBZTFUr8FEBEvR8Rz1b/vjIhN1ab3Aa9t+BDTcxgBSYdTFks6lLLC2RFtNn8sIpZQFse8nrIQ6puAi6fYdh/KsoDfkfQbSddV69ZM9hHgx90fwXBwGItjgNUR8WKUxTdvbbPtxGO/Be6PiBciYgOwcYp+33zKMsrXRsShlFVmz2/dQNKFlPUUV/XgOAaaw/iKLZ2z+1L1fXPLvyduT16h43Hg8Yi4v7p9M9Ua3wCSzqAsNfeh8Jxhh7Hyc+AUSdtLejXwjl7sNCKeAh6TNNEHfStlORYkLQU+A7wzIl7sRb1BV2utnWEREb+WdBNlPer1lP5gr3wcWCVpG+BR4Mzq/qspy/fdVa1EfF+Uv5IwZ3lFCUvDl2lLw2G0NBxGS8NhtDQcRkvDYbQ0HEZLw2G0NP4PoWkW0iyOZO8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAADTCAYAAADpu3N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAJ2ElEQVR4nO3dbYxcZRnG8f/VljfBUuyiAbVbiLZ8INiWRakENJGigiIgMb6QIGpaIoqKBiEYI0ggCBoRlIiofKAkmGIjmogFtQETIW61KVIsCraCiLQi+FIKKb398Jylk3V3drczZ+6ZneuXTDpz5nTOPTPXOeeZeeZ5VhGBWaYZ2QWYOYSWziG0dA6hpXMILZ1DaOlmTWXlgYGBmD9/fk2l2HS3bt26bRFx8OjlE4ZQ0nJgOcC8efMYHh6uoTzrB5K2jLV8wtNxRNwYEUMRMXTwwf8XYrOWuU1o6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQjjJ//nwkjXvxDzjab0q/oukHW7ZsodngL0kdrKY/+Eho6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCSzdhCCUtlzQsaXjr1q2dqKmrDQ4ONu1bdp/z1Gkqk2QODQ3FdB/8Lqlp33G3PW4vkbQuIoZGL/fp2NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NL1dAibDc+cLt1k/TAEtaeHfDYbnjldhmb2wxDUnj4S2vTgEFo6h9DSOYSWziG0dA6hpXMILZ1DaOkcQkvnEFo6D/m0dP5Ts5bOp2NL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xBaur4MYbOxvIODg7Vss9k0w9Nh7HArenrc8Z6aaCxvHTZv3jzufdNh7HAr+vJIaN3FIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NI5hJbOIbR0Hnds6Tzu2NL5dGzpHEJL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xB2gWZjkicaBz0dxjP35bjjbtNsTHIr/7dXxjP7SGjpHEJL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJLN6Vxx+vXr++ZfspW+mP7QbN5uzv9XmoqczdLivHWl9TxeaAzttlLmr0+e3pfi/Wsi4ih0ct9OrZ0DqGlcwgtnUNo6RxCS+cQWjqH0NI5hJbOIbR0DqGl60gIm/VTtnJxH3A9Oj2WuSN9x+7jzVHHe9LKe+m+Y+taDqGlcwgtnUNo6RxCS+cQWjqH0NI5hJbOIbR0DqGlm3C6YEnLgeUdqMX6lPuOpzH3HZtNkkNo6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6dr2p2ZHxqqOd59ND83e5z3Vtr5j6z7d1p/vvmPrWg6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpZvquOP/SNo0xW0MANumWlgN+rKOcfp5B4Bt7e4DnoQxf0Qwpb7jPSFpeKz+wk5zHd1VQyOfji2dQ2jpOhHCGzuwjclwHbt1Qw0vqb1NaDYRn44tXe0hVML3ANZbOnEknNuBbVgPqzWEkk4Gfizp0Dq3M4k6jpd0nqTTM+toJKkrmkLdUEdtBUg6DvgGcGlEPFHXdiZRx0nA94ADgNurHSOjjlMkXSrpSklzI2JXUh0nSrpE0uWS9o+IXdlNpjr3glcC34qIOyW9WtJp1Rsxu8ZtvkTFgcBFwIURcRXwcWC2pCWdqKGhljcB1wObgIOAOyS9WdJeHa7jFOCrwNPAa4E1kvbJHkJZZwgFnChpAbAaOAH4MnCBpFfVuF0AongWuB8YlHQMcBXwdmC1pAvrrqHBkcCaiLg1Is4FbgcuBJZAZ06Jkg4BzgM+FRE3RMTZwJ+A19W97YnU+eTXAr8HPgb8MCIuAM4E3gq8pcbtjvYIcDhwLXBdRJwDnAys6OCp+TfAfpKOAIiIrwG/Ar4uaU6HTs3/Bb4ZEWslzayCPxc4unGljDZibRuMiKcpe9oiYFHVDnqUEs6BurY7YqSdExE3RcT5wLeBv0iaFREPUo5GB9RdR+VJYCewTNJAVdc1lJ10RScKiIh/AT+vbu6qgr8eeBZA0juqU3PH26ptmQZE0kLgFcAw5Qm+CBARN0p6gbK3XSPpQeDDwLJ2bHeiOoAXJc2oXthngFOBJyTNA95DCWYtJM1seB2eknQdcHl139qIeIBylK61PTaqjh3VvyPb3FmtcybwFeBtwJ/rrGfMGlttk0o6A7gC+Gt1GQZurva8kXUOA46lNIZ/FBFT/U1iu+q4knL0WwB8JiI21lDHgoh4uLo+MyJeVDV/iqTFlCPfHEr43gicVgWy9jrGWOcLlIPCVuCjdbwekxIRe3wB9gJuA46rbr8XuJqyxx84xvozWtleG+t4WU11vAvYDtzasGxm43OnNEVeD3wQOKzTdYxa7/3AQ8DCOuqY7KUdbcLZ1YsK5VPwT4C9gQ9A+Xqi4QNAnaeeiepY2lDHc+3euKT9gU8AnwZekHQLQJQj4azY3dbaGRF/jPJJue2nvonqaFjvAOAXwElRw5lpStqw1y0D7gCOH9njKHv5SmAf4H3AIXXvTd1QB3Ao5XQ/AKwCbhl1/xsoAdmXqimUVMci4HxgVqePemNd2tEm3JfyNcxR1ZO9p1r+S2BFVO2SunVLHQ31zKX8bu+5iDhL0lGUI/W9EfFUv9XRTMufjiNih6SVlFPtxdV3Yc9TekyebfXxe62Ohnr+IWkFcHU1OGwGcEKn3/huqaOZtnxFExH/lPQdYCPl098O4KyI+Hs7Hr/X6mioZ5ukDcA7gWUR8bd+rmM8bf9ltaSZlK+iUjrou6kOSQcBPwA+GxEb+r2O8fjn/TWTtG9UXxK7jrE5hJYu/QeNZg6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA7hGCR9SdLnquuXSTqxhceaI2mVpD9IekjS0mr51dWyDZJWS5rTrvp7jUM4gYj4YkTc3cJDXAvcGRFHUAa/P1Qtvws4MiKOAh4GLm6t0t7lEFaqKXQ3SbobWNiw/OZq1iokbZZ0haRfSxqWtETSzyQ9IuncMR5zNmVy0O8CRMQLEfFMdX1NROysVr0PeE3NT7FrOYSApKMpkwMtBs4Ajmmy+mMRsRS4F7iZMvHnscBlY6x7OGXGq+9L+p2km6q5Ykb7CPDTPX8Gvc0hLI4HVkfE9ihTyd3RZN2R+x4A7o+If0fEVmDHGO26WZQpgW+IiMWU2VIvalxB0iWUeQJXtuF59CSHcLfJjn19vvp3V8P1kdujZ7R4HHg8Iu6vbq+imqcaQNLZlGncPhR9PPbWISzuAU6XtJ+klwPvbseDRsSTwGPVDLJQZkLdCGV6XuDzwKkRsb0d2+tVbZmLptdFxG8l3UaZw3kLpb3XLp8EVkraG3gUOKdafj1lyrq7qum174sys3/f8QwMls6nY0vnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOn+B7gnX/LPMZn/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAADTCAYAAAAh15mqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAO00lEQVR4nO2dfZRdVXnGfw8JBBECCQlV1Ez8AqwQwExZIAQbSvkoH5VIAW0rWtoQ25SylApov0RNFyAtQiMVaol8tI0LmhbFWkFtaS3QNeGjrSC0uJKCLW2MaCuKNOTtH+8eezuZmUzuvefe2bnPb6275u5zztzn7HOfe86793n3PooIjKmVXfq9A8Z0gg1sqsYGNlVjA5uqsYFN1djApmpm9kJk3rx5sXDhwl5ImZ2Q9evXfyMi5o+3rjEDS1oOLAdYsGABIyMjTUmZnRxJGyda11gIERHXR8RwRAzPnz/uj8eYjnEMbKrGBjZVYwObqrGBTdXYwKZqbGBTNTawqRob2FSNDWyqxgY2VWMDd5GFCxciadyXk5maoSfZaIPCxo0bmWiQrKQe781g4DOwqRob2FSNDWyqxgY2VWMDm6qxgU3V2MCmamxgUzU2sKkaG9hUTWMGlrRc0oikkU2bNjUlUw1DQ0MT5klM9nIOxeSoFxNcDw8PxyBMbCJpwlyI6fSZtSFpfUQMj7fOIYSpGhvYVI0NbKrGBjZVYwObqrGBTdXYwKZqbGBTNTawqZqBNPCgDH8fhHoO5LD6QRn+Pgj1HMgzsNl5sIFN1djApmpsYFM1NrCpGhvYVI0NbKrGBjZVYwObqrGBTdV4WL2pmsYMHBHXR8RwRAzPnz+/KRkz4DiEMFVjA5uqsYFN1djApmpsYFM1NrCpGhvYVI0NbKrGBjZVYwObqrGBd5DJ5loYGhrqut72Hk2ws8zv0C4DOS9EJ0w210ITbNiwYdL1O8v8Du3iM7CpGhvYVI0NbKrGBjZVYwObqrGBTdXYwKZqbGBTNTawqRob2FSN54UwVeN5IUzVOIQwVWMDm6qxgU3V2MCmamxgUzU2sKkaG9hUjQ1sqsYGNlVjA5uqsYErZ7J5Iyabp2Ky/6tprgnPC1E525s3op3/q2muCZ+BTdXYwKZqbGBTNTawqRob2FSNDWyqxgY2VWMDm6qxgU3V2MCmanoyL8RDDz1UzX337T2ToonnYNTEZM8I6cf3qV4870FSTKQjqafPnOiXZk1Mdny2d+yaOLaS1kfE8HjrHEKYqrGBTdXYwKZqbGBTNTawqRob2FSNDWyqxgY2VWMDm6qxgU3VTHsDb+/eezuvQc9naJJezzcx7XMhnLfQezrJhWj3c7fzf86FMDsnNrCpGhvYVI0NbKrGBjZVYwObqrGBTdXYwKZqbGBTNTawqZrGHjEgaTmwvKnPNwacC2HGwbkQxvQIG9hUjQ1sqsYGNlVjA5uqsYFN1djApmpsYFM1NrCpGhvYVE1juRBTZXQegcnWm52D7X3X7dD3XAgz/WgqF6KD/XEuhNk5sYFN1djApmpsYFM1NrCpGhvYVI0NbKrGBjZVYwObqrGBTdX0al6I70jaDHyjKb0pMM/6U9efLGehzXyGTuo/YUJMT3IhACSNTHQ/2/rWbxeHEKZqbGBTNb008PU91LL+gOj3LAY2pgkcQpiqsYFN1djABgB1e7Baj5iWBq71YLaDpFmSZvVR/w2SFvRr0GKn9Z9WBpY0JGkesGuf9I+TtLiHem8B1gJ3Slomad9eaRf9E4HrgNm91G3R77z+ETEtXsAZwP3AXcCHgGU91j8B+Bfg6JZlalDvNcBXgCNL3f8ceA/w2h7V91Tgn4DDS3mXHh/vrtS/7/NCAEiaC/wmsAL4JvAjwNsl7R0RN/ZA/03AtcDyiPiypBcDW8rq7zckuzewOSLuK/vwJPALwKmS/jAivt2Q7miIdgKwR0Q8WOr7gXL1+wxwZ0R8ryn9wj50of7TwsDAVuAJ4NGI+Lakp4FngJ+XtDki7mhYfxHwLWBE0iuBy8lj84SkL0bEX3RbMCLWS3pC0luB2yNipIT+HySPRWN1joiQdCGwRdJIWfwnwGPASmAWcGsT2pJeHBHPlvo+1mn9+xoDS3oZQER8C9gM3KScBeW/gL8jzwaHqdDUfkTEtcCdwJ+W1xeAK4ENwCmS9u6GvqSjJB0v6aiy6AvAUcASSbMiYgS4EThXUtdPLpKGJS2V9MaI2BoR7wYeAO6IiI9ExA3ANcDbJHW9HSLpJOACSS8qx3M9ebVtu/59M/BoA0LS/mXRhcB/Ar8HPzD1/cDRwOwogVMX9ZdKepeki4veZWT8/cmI+HhE3FvKQ2V9R/rly7sJOBN4r6TrI+IW8kfyZuCtZdNZwPNAt+t7KnADcC5woaSVZdUvlbqPshcZxnVb/2TyynZvRHyvHM9Pkieun6Td+vcycB/TgLgXWDpm+auATwCfBfYDfga4B5jbZf2fAB4Bzicvmze1rNu15f0y4Iud6pMniluAd5byHsBfAX9UymeTZ557gIcpDasu1vew8rmHlvIZwLXjbPdO8qx4cJf1Xwd8DXhXKe8LHAK8uqX+a9qpfz/Muy+Z2HxVKe8PnAb8LBl3ziK7dm4hz8CHdVn/FcDfAseX8ouAvx77pZFXhK59mcCvAueNWfYl4GMt5R8G5jdwzIeBFS3lBcDfA6/k//JhXk0m3BzSgP4h5JV1BXAKGTqtBe4Gru6k/j03cNnR04EvA+8uZ7jLgRHyEjejbDOLbCV3W3s+cHJ5v2t5fR44dsx2l3T6ZQJ7trw/hTzbH9CybB/gNmBRQ8d5r5b3e7TUeXfg08C+Zdlryt/dG9Q/GPhdsoG2oix7aTn2x7Wt0ZRJx6nMUDnbzS7l04FngfeW8gzyEnJRQ/oLyxe3zZcErKb0/wJv7JLe6eUss5YMWWaS3UT/ARzYst0fA8c0UN+x+kNlucrr08AcMkz7LDCnIf1PFf055NXvjDHb3QgsaVenJ91okk4BriB7FuZKuiwi7pA0HBGPStolIl6QdCfZndWU/r3APpI+GBEPS9o1Iv6HvBO1h6RzgA9LWhIR/9aB3gFkGHQWefk+lux3fR/ZOFkn6TryDHwY0LbWFPWPBk6UtDoiHi8t/GeBq4HXA+dGxDMN6i8h6391RKxr2W4ZeWZ+sm2xJs52Y35h+5OB+Y+S8e9K8iy0uKzfpfx9O/AQLWenXuiXba4g4+B7gNd3QXMRsLal/AbyRs3vkFeaE8h48OPd0Jui/q8V/QVl2e3A47SENA3r/3rRf3lZ9g4ybOyojdELA88Efp9sOIw2GJYD/06JMYGlZIOtq63fKegvKuULyO6sg7qkuRvZAPzFlmWLgavoIN7rgv4Vo/pky7/rP54d0F9C6YXoSKvBgzhqlt3J/s8PjVn/K8DNpbIvp8ut7ynq30I2Fg8HXtGh3hHkpfqYUj6RjO/OadnmEmBNQ8d7IPUbuZEh6VjgYklvJi+ZFwJnS2rtML+dzDPYEhFPRcSmPuk/HxEPRkTbcVi5KXMH2dNws6QVwFfJ7qKTJF1QNv162b6r6ZMDrd/AL/E4sp/3IvL27DXAm8j483FgFXAQGQM9QOnKqVGfbM3PIjvhzyrLDif7N1eSV5bjgAfJ7rKNlJsJXarrQOtHNBBCAOcBK8v7IfIGxY1kS3wOGY9+jIx5m+g077k+cDGZArpnKR9M3qQ4v5R3JW8U7Nft+g66fhOVGT2zzSnl+WQPw9WlIruV5Xs3dDB7rg+cTHYbHQrMLMsWk532i7ulY/1tX12PgSNiDRn7vK/k824C/obsWjk+Ip4v2zWS79pL/dEMtch0y++QDcODJe0ZEeuBzwEvdKpj/Un2ofxa2vtnjf8AOElHAD9FxkirIuKbki4H/jUiVrctOA30JR0IzCX7MLdGxAst664gs7meIzvn30Pe4dvQiab1J9mfDg08MyK2tJRnRN5RE3kH5izgJODPyMyvoyPinzvc577plztHq8jW9NfJL3FNZP7y6DZLybP9AcDqiHikXT3rT2Gf2jVwye88j+ywfioibi7Lx5rqbPL26cMR8Vjnu9wf/ZLgfQtwTeSwo7eQ47m+D1w5NiQZux+dMuj6E9FWDFwu0dcA68g7WBdJWgUQEVtas+kjYm1EfKrL5u2X/mzgteX9OnLEyG6UZGxJR5a8C2gm9ht0/W1ps9V5DHBDS/klZMLyh1uW/Rjw2w21evuiD/w42WG/pJRnAG8jx4/NIkOWlzZRZ+tPsE9tVmRxqcjclmUvIbuvRju051ASRxo4kH3RJ29LryQTv49tWf4lGkiKsf72X22lU0aOqH2K7CY5oix7WtJq4IdK+RlyZHHX6Zd+RDwn6VYypr5U0kFkDLgf0NgweOtPzA434iTtFqUvVdJnyJzWM4uBLiGHhbyDHAfZfhfHNNUf3QcyceV8ssvooxHxYBNa1t/OvuzId1wSz7eW95cC95EDH19GjiQ9lDTTVxrY177rj7M/M8gfytZe6Fl/nH2YqoHHmOcKsk/16FJ+HTnSdnM01Gndb30zPZmSgceY5yPkMJTTogf9fNNB30xfptQP3GKeq8gY87TI/tYZTe7cdNE305cp38iQtAA4EDh91DzRch+8afqtb6YnO9qIU0REv8zTb30z/dihW8mj3VL9Mk+/9aeCpN+SdFF5f5mk4zv4rH0k3Sbpq5IeVZkUUNKVZdk/SFonaZ9u7X9tTKsZ2nc2IuI3IuLuDj7io8DnIuIgsovw0bL8LnIE9yJymNSlne1pvdjAXUDS+5Vz3d5Nxumjy9dIOrO83yBplaR7JY0on03xl8o5gleM85mzyWFQnwCIiOcjZ+wkIj7f0gNzHzn2bCCxgTtE+UyNc8jBjMvI+W4n4smIOIocIbKGnGr1SOCycbZ9FbAJuFHSg5L+QDmT+lh+Duj6BNy1YAN3zhJgXUR8NzKxe7KZxUfX/SNwf0T8d+SQp+fGiWNnkjPaXBcRh5NTQV3SuoGk95OPQmhkNvUasIG7w1S7ckaft7GV///sja1s+7iHp8hE/ftL+TbS0ABIOpecZ/mnm8r5qAEbuHPuAc5QTpu/FznXccdExNPAk8oxaJD5zY/AD2Z7v5jsE/9uN/RqZbo85KVaIuIBSWvJiQk3kvFtt/hl4NaS/fU1cgZ1yMmiZwF35fA/7ouIbRqCg4CfVm+qxiGEqRob2FSNDWyqxgY2VWMDm6qxgU3V2MCmamxgUzX/C+LCBm0bIpexAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAADTCAYAAADpu3N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAJ3klEQVR4nO3de4xcZR3G8e/TlptgKXbRgNotRIE/CHJZFCSgiRQVFAGJ8UKCqGmJKCoahGCMIIEgaERQYkXlD0qCKTaiiQioBEyEuNUGBAQFW0FEiki9QCGlP/94z8pmmM7uXM78ZnaeTzLp7pnT8/5m5jmXmXfedxURmGWal12AmUNo6RxCS+cQWjqH0NI5hJZuQTsrj42NxdKlS2sqxea6tWvXPhkRuzcunzGEkpYDywGWLFnC5ORkDeXZKJC0odnyGU/HEbEyIiYiYmL33V8SYrOu+ZrQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4hbLB06VIkbfPmL3D0XlvfohkFGzZsoNXgL0l9rGY0+Eho6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCSzdjCCUtlzQpaXLjxo39qGmgjY+Pt+xbdp9z+9TOJJkTExMx1we/S2rZdzxo2x0mktZGxETjcp+OLZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILd1Qh7DV8My50k02Co9xqId8thqeOVeGZo7CYxzqI6HNDQ6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpfOQT0vnPzVr6Xw6tnQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaUbyRC2Gss7Pj5eS5utphmeK+OHOzXU4447NdOfk63D+vXrt3nfXBk/3KmRPBLaYHEILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ3HHVs6jzu2dD4dWzqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NI5hAOg1ZjkVuOgW/2/YRrPPJLjjgdNqzHJ3fy/YRnP7COhpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILV1b447XrVs3NP2UnfbHjopW83b3+7VUO3M3S4ptrS+p7/NAZ7Q5TFo9P53e12U9ayNionG5T8eWziG0dA6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dH0JYat+ym5u7gOuR7//NnNf+o7dx5ujjtekm9fSfcc2sBxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCSzfjdMGSlgPL+1CLjSj3Hc9h7js2myWH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NL17E/NTo1V3dZ9Nje0ep071bO+Yxs8g9af775jG1gOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVrd9zxfyQ90Mb2x4AnOymsh0a6hmn9vC+podd9wLPQ9EsEbfUdt0vSZLO+wn5yDYNTw7b4dGzpHEJLV3cIV9a8/dlwDcUg1NBUrdeEZrPh07GlqzWESvgMwIZP3UfCxTVv3+aA2kIo6Vjgx5L2rKuNWdRwpKQzJJ2YVUMjSamXQNntN1NLQZKOAL4BnB8Rj9XRxixqOAb4HrALcEO1U2TUcZyk8yVdLGlxRGztc/tHSzpP0oWSdo6IrYN2mVTXXvFK4FsRcZOkV0s6oXoxFtbU3v+p2BU4Bzg7Ii4BPg4slHRw3e031PIm4ErgAWA34EZJb5a0XZ/aPw74KvAU8FrgZkk7DNqQybpCKOBoSfsAa4CjgC8DZ0l6VU1tAhDFJuAuYFzSocAlwNuBNZLOrrP9BvsDN0fEdRFxOnADcDZwMNR7apS0B3AG8KmIuCoiTgX+BLyurjY7VdeTcBvwe+BjwA8j4izgZOCtwFtqarPRQ8DewOXAFRFxGnAssKKPp+bfADtJ2g8gIr4G/Ar4uqRFNZ+a/wt8MyJukzS/Cvxi4JDpKw3CNWItBUTEU5S97kDgwOpa6GFKOMfqaHPK1PVORFwdEWcC3wb+ImlBRNxLORrtUmcN0zwObAGWSRqr6rqMsoOuqLPhiPgX8PPq161V4NcBmwAkvaM6Nff1GrWZrqcBkbQv8ApgkvJgXwCIiJWSnqfseZdJuhf4MLCs2zZnqgF4QdK86gl+GjgeeEzSEuA9lGDWQtL8ac/BE5KuAC6s7rstIu6hHKVruS5raH9z9e9UW1uqdU4GvgK8DfhzHXW0o6tuO0knARcBf61uk8A11V44tc5ewGGUC+MfRUQ730fsVQ0XU45++wCfiYj7ellD1cY+EfFg9fP8iHhB1bwpkg6iHPkWUcL3RuCEKpC1td9knS9QDgQbgY/W8Tx0JCI6ugHbAdcDR1S/vxe4lLLX79pk/XmdttXDGl7W6xqq7b4LeAa4btqy+dMfN+Uy5PXAB4G9+tV+w3rvB+4H9q3jeej01u014cLqiYXyLvgnwPbAB6B8RDHtTUBdHwvMVMPh02p4tteNS9oZ+ATwaeB5SdcCRDkSLogXr7m2RMQfo7xT7tkpcKb2p623C/AL4Jjo8dmoa13ugcuAG4Ejp/Y+yp6+CtgBeB+wR5170YDUsCfldD8GrAaubbj/DZSg7Eh1CdTn9g8EzgQWZB/1mt26vSbckfIxzAHVA7+9Wv5LYEVU1yh1GoQaGupZTPnu3rMRcYqkAyhH6jsi4om53n4nunp3HBGbJa2inGrPrT4Pe47SY7KpB/UNRQ0N9fxD0grg0mpQ2DzgqH4FILv9TnT9EU1E/FPSd4D7KO8ANwOnRMTfu932MNXQUM+Tku4G3gksi4i/jVL77erpN6slzad8LJX2AeiA1LAb8APgsxFx96i13y5/vb8mknaM6sPiUWy/HQ6hpUvvvDZzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVzCJuQ9CVJn6t+vkDS0V1sa5Gk1ZL+IOl+SYdXyy+tlt0taY2kRb2qf9g4hDOIiC9GxK1dbOJy4KaI2I8yCP7+avktwP4RcQDwIHBud5UOL4ewUk2p+4CkW4F9py2/pprFCknrJV0k6deSJiUdLOlnkh6SdHqTbS6kTBD6XYCIeD4inq5+vjkitlSr3gm8puaHOLAcQkDSIZTJgg4CTgIObbH6IxFxOHAHcA1l8s/DgAuarLs3ZQas70v6naSrq7ljGn0E+Gnnj2C4OYTFkcCaiHgmypRyN7ZYd+q+e4C7IuLfEbER2Nzkum4BZWrgqyLiIMrsqedMX0HSeZR5A1f14HEMJYfwRbMd+/pc9e/WaT9P/d44o8WjwKMRcVf1+2qq+aoBJJ1KmdbtQzHCY28dwuJ24ERJO0l6OfDuXmw0Ih4HHqlmkoUyM+p9UKbrBT4PHB8Rz/SivWHV9Vw0c0FE/FbS9ZQ5nTdQrvd65ZPAKknbAw8Dp1XLr6RMXXdLNc32nVFm+B85noHB0vl0bOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILd3/AClZX/IOfJImAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAADTCAYAAADpu3N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAJxklEQVR4nO3dbYxcZRnG8f/VljeppdhFA2p3IdrygdS2LAqSooktKigCEuMLCaKmJaKoaBCCMYIEgkUjghIrKh8oCQZsRBMRUAmYCHGrDQgVFGwFESki+AKlaXv74ZwNm3E7uzM7c+4zM9cvmezMmbNn7pm5zsvMc55nFBGYZZqVXYCZQ2jpHEJL5xBaOofQ0jmElm5OKzMPDQ3FyMhIl0qxfrdx48anI+KgxulThlDSamA1wMKFCxkbG+tCeTYIJG2dbPqUu+OIWBcRoxExetBB/xdisxnzMaGlcwgtnUNo6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUPYYGRkBEl7vPgEjs5r6SyaQbB161aadf6SVGE1g8FbQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOkcQkvnEFq6KUMoabWkMUlj27Ztq6KmWhseHm7atuw259aplUEyR0dHo987v0tq2nZct+X2EkkbI2K0cbp3x5bOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NI5hJaup0PYrHtmvzSTDcJz7Okun826Z/ZL18xBeI49vSW0/uAQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQWjp3+bR0/qlZS+fdsaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVzCC3dQIawWV/e4eHhrjxms2GG+6X/cLt6ut9xu6b6Odlu2LJlyx7v65f+w+0ayC2h1YtDaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOnc79jSud+xpfPu2NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NI5hJbOIayBZn2Sm/WDbvZ/vdSfeSD7HddNsz7JM/m/XunP7C2hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILV1L/Y43bdrUM+2U7bbHDopm43ZX/V6qlbGbJcWe5pdU+TjQGY/ZS5q9Pu3eN8N6NkbEaON0744tnUNo6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6SoJYbN2yplc3AbcHVX/NnMlbcdu483RjfdkJu+l246tthxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCSzflcMGSVgOrK6jFBpTbjvuY247NpskhtHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQd+6nZ8b6qe7rP+kOz97ldHWs7tvqpW3u+246tthxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS9dqv+P/SHqoi/UMAU93cfmtqls90GJNzdp5O9QG3Eo9k55E0FLbcbdJGpusbTFL3eqB+tXUiXq8O7Z0DqGlq1sI12UX0KBu9UD9appxPbU6JrTBVLctoQ2gWoVQnT5v3HpCrUIILMguwKpXmxBKOgH4saRDsmsBkLRC0tmSTsmuZTKSavPewczqqcUTkXQs8A3gooh4ogb1HA98D5gL3FyuIKkknSjpIkmXSVoQEbuT61kp6UJJl0jaPyJ2t3s4VYsQAq8EvhURt0p6taSTyxd9XpVFqHAAcD5wXkRcDnwcmCdpeZW1NNT1JuBq4CHgQOAWSW+WtFdSPScCXwWeAV4L3CZpn3a7YtYlhAJWSloEbACOA74MnCvpVVUVEYXngHuBYUlHAZcDbwc2SDqvqloaHAHcFhE3RMRZwM3AecByqHbXLOlg4GzgUxFxTUScAfwJeF27y6xLCO8Efg98DPhhRJwLnAa8FXhLQj2PAIcBVwJXRcSZwAnAmqRd82+A/SQdDhARXwN+BXxd0vyKd83/Bb4ZEXdKml2uAAuAIyfO1MqKUYsQRsQzFGvTUmBpeczzKEU4h6qqY/yYJiKujYhzgG8Df5E0JyIeoNgCza2qngmeBHYCqyQNlTVeQbHirqmykIj4F/Dz8ubucgXYBDwHIOkd5a552itGx4YBmS5Ji4FXAGMUT2IXQESsk7SDYo26QtIDwIeBVVXWA+ySNKt8EZ8FTgKekLQQeA9FMLtO0uwJr81Tkq4CLinvuzMi7qfYYlfS5NVQz/by7/hj7yznOQ34CvA24M/TXnaVzXaSTgUuBf5aXsaA68q1a3yeQ4GjKQ54fxQRXTt/cZr1XEax9VsEfCYiHuxWPeXjLYqIh8vrsyNil8rxVyQto9jyzacI3xuBk8tAVlbPJPN8gWKDsQ34aMuvUURUcgH2Am4Eji1vvxdYS7F2HzDJ/LNqVs/LKniN3gU8D9wwYdrsia8HxeHJ64EPAodm1dMw3/uBzcDidh6n6mPCeeULCMWn4J8AewMfgOKriAkH/lVsoqeq55gJ9bzQzUIk7Q98Avg0sEPS9QBRbAnnxEvHWDsj4o9RfFKe9i6v0/VMmG8u8Avg+Gh3r9XttbthjVkF3AKsGF+rKNbo9cA+wPuAgwe4nkModv1DwE3A9Q33v6EMxr6Uh1LJ9SwFzgHmzORxqj4m3Jfia5gl5RO6q5z+S2BNlMceg1pPQ20LKM7VeyEiTpe0hGKrfXdEPNVP9VT66TgitktaT7GrvaD83utFihaT56qspY71NNT2D0lrgLVl57JZwHEZAex2PZV/RRMR/5T0HeBBik9624HTI+LvVddSx3omioinJd0HvBNYFRF/68d6Us+sljSb4uum1Mb4cTWs50DgB8BnI+K+fq3Hp/fXnKR9o/xyuA66UY9DaOlq0XZsg80htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4hnISkL0n6XHn9YkkrZ7Cs+ZJukvQHSZslHVNOX1tOu0/SBknzO1V/r3EIpxARX4yIO2awiCuBWyPicIrO65vL6bcDR0TEEuBh4IKZVdq7HMJSOfTtQ5LuABZPmH5dOdoUkrZIulTSryWNSVou6WeSHpF01iTLnEcx4Od3ASJiR0Q8W16/LSJ2lrPeA7ymy0+xthxCQNKRFIP6LANOBY5qMvtjEXEMcDdwHcVgnkcDF08y72EUI1V9X9LvJF1bjvHS6CPAT9t/Br3NISysADZExPNRDAt3S5N5x++7H7g3Iv4dEduA7ZMc182hGNL3mohYRjHK6fkTZ5B0IcX4fus78Dx6kkP4kun2fX2x/Lt7wvXx240jWjwOPB4R95a3b6IcZxpA0hkUw699KAa4761DWLgLOEXSfpJeDry7EwuNiCeBx8rRYKEYwfRBKIbVBT4PnBQRz3fi8XpV5WPR1FFE/FbSjRRjL2+lON7rlE8C6yXtDTwKnFlOv5pi+Lnby6Gy74liZP6B4xEYLJ13x5bOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NL9DxK7X/JhQeARAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAADTCAYAAADpu3N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAALXklEQVR4nO3de4xcZR3G8e/TVqiUewoahbaKXAQiIAtqEIzWaJVLFAFrvF/SGsVLhKho4t16Q2OJqCESSRCxBoNBCCggXkAg2QWUKKLBtAEStd4QuYilP/9437Xjsjtld+ec39md55NsunPmdM5vZp45c877nvddRQRmmRZkF2DmEFo6h9DSOYSWziG0dA6hpVs0nZWXLl0aK1asaKgUm+/Gxsb+EhF7TVy+3RBKWgOsAVi2bBmjo6MNlGfDQNKmyZZv9+s4Is6LiJGIGNlrr8eE2GzWfExo6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQTrBixQokTfrjizeaMa2raIbBpk2bmGrwl6SWqxkO3hNaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0m03hJLWSBqVNLp58+Y2auqs5cuXT9mvvL0f9ztPTdOZJHNkZCTm++B3SVP2HXfxcecSSWMRMTJxub+OLZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILd2cDuEwDM8chuc4p4d8DsPwzGF4jnN6T2jzg0No6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6Tzk09L5T81aOn8dWzqH0NI5hJbOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NINZQj7jeVdvnx5I9vsN9XwfBk/PFNzetzxTPUby9uUjRs3TnnffBk/PFNDuSe0bnEILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ3HHVs6jzu2dP46tnQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVzCDug35jkfuOg+/2/uTSeeSjHHXdNvzHJs/l/c2U8s/eEls4htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHTTGnd82223zZl+ypn2xw6LfvN2t/1eajpzN0uKqdaX1Po80BnbnEv6vT4zvW+W9YxFxMjE5f46tnQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVrJYT9+iln8+M+4Ga0/beZW+k7dh9vjibek9m8l+47ts5yCC2dQ2jpHEJL5xBaOofQ0jmEls4htHQOoaVzCC3ddqcLlrQGWNNCLTak3Hc8j7nv2OxxcggtnUNo6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgt3cD+1Oz4WNWp7rP5od/7PFMD6zu27ulaf777jq2zHEJL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJLN91xx/+SdGeD9SwF/tLg40/HvKilXz/vDPqAZ/uaTHoRwbT6jpsmaXSyvsUMrqW9Ovx1bOkcQkvXtRCel11AD9fyWI3U0aljQhtOXdsT2hByCC2dQ/g4adADK2aoK3UASBpIfhzC7ZC0M0D24BpJO3WhjlrL02otWwcRxE6HUNI+khZL2qXebnUvIOkk4HxJ35H0cknL2tx+Tx3HA1+XtEHSMZKekFFHreUo4OeSPg2DCWJnQyhpFXAJ8HXgy5L2bXMvIOkA4GvAOcCNwDHAGZIObKuGWscq4GzgG8CdwHuBXdusYYLNwG+AfSWthxJEmPlOopMhlPQCypv/PmA98CdgZb2vrZoXA9dHxA0RsR74HuUNWCtpnzYKkPRE4FTgkxHxs4j4CPAI8IY2tj9JPQuAh4C/A+cDiyV9XNKhkvab6U6iUyFUsRA4CvhURPwiIm6lvPkvgG2fuhb8FniGpHfU7d4CXAlsAQ4Yr7fJAiLiIeDTwBWSxi82+TWw2/g69fVqRURsjYg/UfaE/wE+CjwX+DGwd61n2pnqVAgpjeePAl8Fru15gX8KLPnfSmUPMfiNS0fXY67nR8QjwIeAoyStBoiIMeBvwOvq7UYOD2odz5d0dET8ISLui4gt9e67gB3qeq8EVjb5Yeh5TZ7Ts3gh8BRgX+Bg4DbgVTCznURnQijpOOD9kl4B7BYR99ZAAmwFVtT1Xg98rGfPMKjtvxS4DDgeuFDS2yl7w2uBVZLeXVe9F1ggacdBbn+KOjZIOn38DL1aWLd/KvBZ4K4GPwy9tVws6V31rm9TPog/oByjvo3y1fykGW0oItJ/gBdRrlM7E7gC+BKwuuf+/YANwGpgDDhogNsWsCNwAXBaXXYEcA1wOrBPre9WyonSJuCwBl6Dyeo4HLi6vi5L6rKXUg5PfgIc3ND70a+WM4D9gS8DL6n3LQIWz3h72QGsT+KtwOn19+XA6ymd5avrsiXAn4HRBl/4DwCfAnautw8FrgPW1ttPqB+GvRt+LSbWcQjlmOud9fb+wO3AIS28L5PVch3whp51Fsx6O9kBrE/kTcAtwB719l41iGdTDniXUE4KGglg3ebLKE0yhwGL6rIjKcdgR7b4WvSr43DK1/EuibWMjNcyqO104pgwIi6gHHt9SNJuEbEZuB54NjASEQ8AJ0TEbwa97fGD+oi4EvgX8B7gUEk7RzkRuQp4tM9DtFmHIuLRiLg/sZbRWsvgtlfT3RpNMb+cpKMpbWIC1kXE3yR9DrgbOBcGdzZaG5z3pHy9b41tJ0BI+jywC/Bw3fYZwDERsXEQ2+5iHdm1ZIRwUWxrbkDSwoh4tH76RoDTgFXA94G1lCf7+wFu/2RgHeUs917Ki35BRPyzZ50XAs+itAee29AeuBN1dKGWVkMo6WWUk5Ax4J6IuLAunxjMVwMB/DIiBja6r/a5fgs4JyJukPQqSmPrv4EvRMR9E9b/v7rmWx1dqaW1Y8L6dXsOcCmwEThT0jqAiNjS2+4XERsi4ruDDGCPXSlnmNRaLqc0/r6m1vncesEANHss2JU60mtp88RkB+AnEXFRRFxMae9a3XM1xhZJKyV9pqkCIuI/lDbIkyUdG6V1/3pKi/+xtQF6GeVMfWDHoF2tozO1tHGqH9uaGS4D9uxZ9uT65MYbRPcAljVcx2JKI/R5wHE9y68DDmjx9ehEHV2oZaBdX/1ExJikeyin90fXZX+UdC7wpHr775QrNJqs42FJF1GOOc+SdBDl+Gdv4L6+/3ke1tGFWlo5MZG0Q5QLApB0ObA7cEoN4QcpneBvouztWzlTkrQD5RrBtZSmh/VRrthpVVfqyKyl8RBKWhDbLno8C7gJOBl4KuXauMMogfx1o4VMXd9CSvjbukSs03Vk1NJoCCcE8POUNr9j6u1nAjsBf42GGmBtbmgshBMCeDal8/vEaKi9y+auxppoegL4Rcox34lRmmFauxLY5oZG2wlVRqcdCJw0HsDo6ZM0g3ZOTBQR4QDaVDwhkqXrxPWENtwcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DOAlJH5N0Zv39E5JePIvH2l3SJZJ+K+kOSc+ry79Ql/1K0qWSdh9U/XONQ7gdEfGRiLhmFg+xHrgqIg6iXDt5R11+NXBoRDwL+B1w1uwqnbscwkrShyXdKekaykUX48svkHRK/X2jpHWSbpQ0KunZkn4o6a46i9fEx9wVOI4yoSQR8UhE/KP+/qOey9puoky8NJQcQkDSkZQZv46gXPV9VJ/V746I5wE/p8xadQplnO4nJln36ZQZtL4p6VZJ35C0ZJL13kKZa2coOYTFscClEfFglFkHLuuz7vh9twM3R8T9UebOeXiS47pFlPl0vhYRRwAPAB/sXUHShymzv140gOcxJzmE2zzey4n+Xf/d2vP7+O2Joxfvocw0cXO9fQkllABIeiNwAvDatgZ4dZFDWPwMeKWkJ6r8uYoTB/GgEfFH4G5tm/F/JWW+5/FZ+T9AueD3wUFsb65qbdxxl0XELZI2UGYd2EQ53huUdwEX1eGUfwDeXJd/hTIb6tV1JrabIuIxJzfDwBe1Wjp/HVs6h9DSOYSWziG0dA6hpXMILZ1DaOkcQkv3X0jAMSa73NuZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKsAAADTCAYAAAD+meO1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAO6klEQVR4nO2dfbRcVXnGfw9JuIgQkpBQRc2NX4AVApiUBYZgQykf5aMSKaBtRUsbYptSllIB7Zeo6SJIRTBSoTYRQtu4oGlRrBXUltYGum4ItBWEFldSsKWNiLaiSEPe/vHuS6fDvcO9M2fOmTf3/a01K7P3nJzn7DnP3efdnyMzI0kisEfTF5AkEyXNmoQhzZqEIc2ahCHNmoQhzZqEYXo/Tjp37lxbsGBBP06dTAG2bNnyLTOb155fmVklrQBWAMyfP5+RkZGqTp1MMSRtHyu/sjDAzK43s8VmtnjevOf9USRJz2TMmoQhzZqEIc2ahCHNmoQhzZqEIc2ahCHNmoQhzZqEIc2ahCHNmoQhzdolCxYsQNKYr5zE0x/6MutqKrB9+3bGW2wpqearmRpkzZqEIc2ahCHNmoQhzZqEIc2ahCHNmoQhzZqEIc2ahCHNmoQhzZqEoTKzSlohaUTSyI4dO6o6bUiGh4fHnTfwQq+cVzA+6sdmwosXL7bdfZMLSePODRjE80ZC0hYzW9yen2FAEoY0axKGNGsShjRrEoY0axKGNGsShjRrEoY0axKGNGsShilh1qmwbHoqlHFKLMWeCsump0IZp0TNmuwepFmTMKRZkzCkWZMwpFmTMKRZkzCkWZMwpFmTMKRZkzCkWZMw5FLsJAz5E+5JGDIMSMKQZk3CkGZNwpBmTcKQZk3CkGZNwpBmTcKQZk3CkGZNwpBmTcKQZu1Ap7X4w8PDfdHstMX77rL+v1umxL4B3dJpLX6/2LZt27if7S7r/7sla9YkDGnWJAxp1iQMadYkDGnWJAxp1iQMadYkDGnWJAxp1iQMadYkDLlvQBKG3DcgCUOGAUkY0qxJGNKsSRjSrEkY0qxJGNKsSRjSrEkY0qxJGNKsSRjSrEkY0qyB6LSnQKd9DDr9v0j7EeS+AYHotKdAL/8vyn4EWbMmYUizJmFIsyZhSLMmYUizJmFIsyZhSLMmYUizJmFIsyZhSLMmYejLvgH33XdfmHHobsfbpwqdfleh7nupfuyZL8nGO6+k2vfpb0IzEp2+n24/6/F6tpjZ4vb8DAOSMKRZkzCkWZMwpFmTMKRZkzCkWZMwpFmTMKRZkzCkWZMwpFmTMAyUWTuNQ/fyyjH+/tBpXkU/5g0M1NyAHMNvhn7ck17uZc4NSMKTZk3CkGZNwpBmTcKQZk3CkGZNwpBmTcKQZk3CkGZNwpBmTcJQ2TbtklYAK6o6X5K0k3MDkpwbkCRVk2ZNwpBmTcKQZk3CkGZNwpBmTcKQZk3CkGZNwpBmTcKQZk3CUPtPuI+uNR/vs2T3oNN97pba5wYkg8egzdfIuQFJeNKsSRjSrEkY0qxJGNKsSRjSrEkY0qxJGNKsSRjSrEkY0qxJGPq1b8D3JD3Udshc4FtV6U2CJnTDlbXTOP4ExvirLu+Yk0T6MjdgTCFpZKzx3t1RdyqVtU7dDAOSMKRZkzDUadbra9RqWncqlbU23dpi1iTplQwDkjCkWZMwpFmnEKp6UVTNDKRZo3+pnZA0JGmoZs03SJpf98K4qss6UGaVNCxpLjCjZt3jJS2qQectwEbgdknLJe1fg+ZJwHXAzH5rtelWX1YzG4gXcCZwD3AH8CFgeU26JwL/AixpyVMfdF4DfA04upT1z4H3AK/tY9lOA/4JOLKk96jpO+1LWWvfN2AsJM0BfhtYCXwb+DHg7ZL2M7N1fdR9E3AtsMLMvirpxcDO8vEPK5bbD3jCzO4u2o8CvwScJukPzey7VYqVUOpEYG8z21rK9oHy5PoccLuZ/aBKzRZm0YeyDoRZgV3AI8CDZvZdSY8DTwK/KOkJM7utT7oLge8AI5JeCVyBfyePSPqymf1FVUJmtkXSI5LeCtxqZiMlNP8gXvZKy2hmJukiYKekkZL9J8BDwCpgCLi5Sk1JLzazp0rZHqq6rI3GrJJeBmBm3wGeAG6U75DxX8Df4TXAESpUrW9m1wK3A39aXl8CrgS2AadK2q8XXUnHSDpB0jEl60vAMcBSSUNmNgKsA86TVEnFIWmxpGWS3mhmu8zs3cC9wG1m9hEzuwG4BnibpMraBpJOBi6U9KLynW3Bn5CVlbUxs44G/pIOLFkXAf8JfByeM/A9wBJgppVgqALdZZLeJemSonM5Hid/2sw+aWabS3q4fN6Vbrl5NwJnAe+VdL2ZbcD/EN4MvLUcOgQ8A/RcPkmnATcA5wEXSVpVPvqVUs5R9sXDraq+01Pwp9JmM/tB+c4+jVdAP01VZa0j4B4n8N8MLGvLfxXwKeDzwAHAzwF3AXMq0v0p4AHgAvxxeGPLZzNa3i8HvtytLl4JbADeWdJ7A38F/FFJn4PXMncB91MaQD2W7YhyrsNL+kzg2jGOeyde6x1a0Xf6OuAbwLtKen/gMODVLWVdX0VZmzDq/vhE3atK+kDgdODn8XhxCO9q2YDXrEdUpPsK4G+BE0r6RcBft980vIbv+WYCvw6c35b3FeATLekfBeZVVL7FwMqW9Hzg74FX8n9zQF6NTzo5rML7eRj+NFwJnIqHOhuBO4Grqyxr7WYtF34G8FXg3aUGuwIYwR9h08oxQ3hLtirNecAp5f2M8voicFzbcZd2ezOBfVren4rX3ge15M0CbgEWVliufVve791Svr2AzwL7l7zXlH/36oPuocBH8cbTypL30vL9Hl9ZWWs06HCpzWa2GPYp4L0lPQ1/VFxcse6CcuOed5OAtZT+VeCNPeqcUWqUjXi4MR3vrvkP4OCW4/4YOLaisrVrDpd8lddngdl4OPV5YHbFup8purPxJ9eZbcetA5ZWdS9r6bqSdCqwBm/hz5F0uZndJmmxmT0oaQ8ze1bS7XhXUtW6m4FZkj5oZvdLmmFm/4OP6uwt6Vzgw5KWmtm/daFzEB66nI0/jo/D+zjfhzcmNkm6Dq9ZjwAmrTEBzSXASZLWmtnDpcX9FHA18HrgPDN7sg+6S/GyXm1mm1qOW47XuI/2qvkcVdZi4/wVHogH1j+Ox6ur8NpmUfl8j/Lv24H7aKmF+qlbjlmDx613Aa/vQWshsLEl/QZ8kOP38CfGiXhM98ledCag+RtFc37JuxV4mJZQpE+6v1l0X17y3oGHdZU04p7TqsGs04HfxwP+0UB/BfDvlNgQWIY3pior3AvoLizpC/GupEN61NoTb5T9ckveIuAqKozZJqi5ZlQTb4lX8scxSd2llN6ASrX7aNJRg+yF9zd+qO3zXwNuKoV/OdW1iieiuwFvwB0JvKJLnaPwR++xJX0SHqOd23LMpcD6Cr/T2jWb1G1/9WVQQNJxwCWS3ow/Bi8CzpHU2jF9Kz7+vtPMHjOzHTXrPmNmW81s0jFVGdC4DW/x3yRpJfB1vNvmZEkXlkO/WY7veZpcE5pN6o5J1e4Hjsf7US/GhzKvAd6Ex40PA6uBQ/C45l5K10oEXbyFPYR3cp9d8o7E+xRX4U+I44GteBfVdkonfQ/lql2zSd2O19QHs54PrCrvh/HO/nV4C3k2Hkd+Ao9Rq+ycrk0XuASfxrhPSR+Kd/hfUNIz8A74AyosX+2aTerWZdbRmmt2Sc/DW/pXl4LtWfL3i6oLnIJ33xwOTC95i/BO8UW9nn9QNJvUHetVecxqZuvxeOZ9ZT7qDuBv8C6PE8zsmXJcpfM369AdnYFlPnXwe3hj7VBJ+5jZFuALwLM9FWQANJvU7XhN5S+lu/+ssX/wStJRwM/gcc9qM/u2pCuAfzWztV0LNqAr6WBgDt5vuMvMnm35bA0+g+lpvPP7PfiI2LZutJrUbFJ3wtfXo1mnm9nOlvQ085Eo4aMbZwMnA3+Gz3RaYmb/3OM116ZbRmFW4y3db+I3cb35fNvRY5bhtfdBwFoze6D7kjWj2aTupK6xW7OWOYzn4x3Ej5nZTSW/3Ujn4EOO95tZ+zaYA6tbJiZvAK4xX/LyFnxN0Q+BK9vDiXb9bmhCs0ndydJVzFoet9cAm/ARoIslrQYws52tM8HNbKOZfaYio9atOxN4bXm/CV+5sCdlMrGko8v8A6gufmtCs0ndidNlC/FY4IaW9EvwCbgfbsn7CeB3q2wN1q0L/CTeIb60pKcBb8PXLg3h4cZLKy5j7ZpN6k7qGrss2KJSsDkteS/Bu45GO5BnUyZUVPiF1qqLD9muwicsH9eS/xUqnBzStGaTupN5dTVF0Hyl5mN498VRJe9xSWuBHynpJ/EVqpVRt66ZPS3pZjz2vUzSIXgcdwBQaddbk5pN6k6GSTewJO1ppc9S0ufwOZpnFdNcii9feAe+1q77roYB0R3VxidyXIB33XzMzLZWqTEImk3qToRJmbVMkt5V3l8G3I0vrnsZvmrxcNxAX6v0IhvSHeM6puF/DLv6qdO0ZpO6nZiwWdsMswbvu1xS0q/DV3A+YRV3EjelmwweEzJrm2E+gi+TON363NfWlG4ymEyon7XFMFfhseHp5v2a0/p5cU3pJoPJhAcFJM0HDgbOGDWMtYwd94umdJPBY7INLJmZ1W2YpnSTwWJSw62jXUJ1G6Yp3RdC0u9Iuri8v1zSCT2ca5akWyR9XdKDKpu5Sbqy5P2DpE2SZlV1/dEYqJ2vI2Nmv2Vmd/Zwio8BXzCzQ/CuuAdL/h34qt+F+PKcy3q70rikWSeJpPfL9x69E4+lR/PXSzqrvN8mabWkzZJG5Hv6/6V8f9aVY5xzJr785lMAZvaM+S6KmNkXW3o/7sbXPk1J0qyTQP67A+fiC+eW4/uPjsejZnYMvlphPb715dHA5WMc+ypgB7BO0lZJfyDfqbqdXwAq2+A4GmnWybEU2GRm3zeflNxpB+fRz/4RuMfM/tt8qc3TY8Sd0/GdTa4zsyPxbX8ubT1A0vvxLeQr3a06EmnWyTPR7pPR3yTYxf//fYJdPH97/MfwieT3lPQtuHkBkHQevqftz1Y97yESadbJcRdwpnwr8n3xfWV7xsweBx6Vr4ECn5P7ADy3g/YleD/z96vQi8qg/ABGCMzsXkkb8Q3ktuPxaFX8KnBzmfX0DXyHavCNeoeAO3yJGXeb2fMaaVOB/FXsJAwZBiRhSLMmYUizJmFIsyZhSLMmYUizJmFIsyZhSLMmYfhfKTxEIXJCFp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAADTCAYAAADpu3N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAJ2ElEQVR4nO3dbYwdZRnG8f/VljfBUuxWA2p3IdrygSCURamkaCJFBUVAYnwhQdS0RBQVTYVgjCCBYNGIoMSK2g+UBFNsrCYioBIwEeJWGxBqUbAVRKQVqS9QmtLbDzMrx3X3bHfPnLnPy/VLTro7Z/bMPWevmXn2PPM8VURglmlGdgFmDqGlcwgtnUNo6RxCS+cQWrpZU1l5YGAghoaG2lSK9boNGzZsj4h5Y5dPGkJJy4BlAPPnz2dkZKQN5Vk/kLR1vOWTXo4jYlVEDEfE8Lx5/xdis5a5TWjpHEJL5xBaOofQ0jmEls4htHQOoaVzCC2dQ2jpHEJL5xCOMTQ0hKRxH755oz2mdBdNP9i6dSsTDf6SVHM1/cFnQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOkcQkvnEFq6SUMoaZmkEUkj27Ztq6OmjjU4ODhhv/JkD/c7T0xTmSRzeHg4en3wu6QJ+4478XW7iaQNETE8drkvx5bOIbR0DqGlcwgtnUNo6RxCS+cQWjqH0NI5hJauq0PYD8Mzm+1jr+xnVw/57Ifhmc32EXpjP7v6TGi9wSG0dA6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dB7yaen8X81aOl+OLZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOn6MoTNxvIODg62ZZvNphruhbHDrejqccfTNdlY3nbYsmXLhM/1wtjhVvTlmdA6i0No6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6Tzu2NJ53LGl8+XY0jmEls4htHQOoaVzCC2dQ2jpHEJL5xBaOofQ0jmEls4h7ADNxiRPNg66F8Yz9+W4407TbExyKz/bLeOZfSa0dA6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpZvSuOONGzd2TT9lK/2x/aDZvN11/y41lbmbJcVE60uqfR7ojG12k2bvz3Sfa7GeDRExPHa5L8eWziG0dA6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dLWEsFk/ZSsP9wG3R91jmWvpO3Yfb452/E5a+V2679g6lkNo6RxCS+cQWjqH0NI5hJbOIbR0DqGlcwgtnUNo6SadLljSMmBZDbVYn3LfcQ9z37HZXnIILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILV1l/9Xs6FjViZ6z3tDs9zxdlfUdW+fptP589x1bx3IILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILd1Uxx3/S9LmaW5rANg+zZ9tt06treW6mvXzttAHPN26xr2JYEp9x62QNDJev2En6NTa+qUuX44tnUNo6eoM4aoatzVVnVpbX9RVW5vQbCK+HFu6WkOoqu8Lt55Q95lwbs3bsy5QWwglnQr8UNJhdW1zb0haIukCSWdm19KMpI5sOlVRVy07JulE4GvAZRHxRB3b3BuSTgG+AxwE3FoeKB1B0mmSLpN0laS5EbEnuyYASSdLulTSFZIOjIg9rTaz6jq6Xg58IyJuk/RKSWeUb/Lsmrb/P1Q4GLgYWBERVwMfBWZLWpRRUyNJbwCuBzYDhwDrJb1R0j7JdZ0GfBl4Gng1cLuk/VodgllXCAWcLGkBsA44CfgicJGkV9RUw39FYQdwHzAo6XjgauCtwDpJK+quaYyjgNsj4uaIOB+4FVgBLIKcS7OkQ4ELgE9ExA0RcS7wB+A1rb52XTtzF/Bb4CPA9yPiIuBs4M3Am2qqYTyPAEcA1wLXRcR5wKnA8uRL86+AAyQdCRARXwF+AXxV0pykS/O/ga9HxF2SZpYHwlzguMaVpnOA1BLCiHia4qg5BjimbOM8ShHOgTpqaDTahomIGyPiQuCbwJ8kzYqIBynOPAfVXVeDJ4HdwFJJAwARcQ3Fgbw8o6CI+Afw0/LbPeWBsBHYASDpbeWlecoHSGXTgIyStBB4GTBCUewLABGxStIuiiPnGkkPAh8EllZdw97UBbwgaUb5pj0DnA48IWk+8C6KYNZG0syG9+opSdcBV5TP3RURD1CcuWvt4hpT187y39EadpfrnA18CXgL8Mcpb6PKbjtJZwFXAn8uHyPA6vIoGl3ncOAEiobtDyJiuvcnVl3XVRRnvwXApyLioXbXVW53QUQ8XH49MyJeUDnfiqRjKc58cyjC93rgjDKQtdc1zjqfoziRbAM+PO33LCIqeQD7ALcAJ5bfvxtYSXE0HzzO+jOq2nbFdb2kjrrKbb0DeBa4uWHZzMb3h6K58lrg/cDh2XWNWe+9wCZgYSvbq7pNOLt8w6D4K/hHwL7A+6D46KGhwV/nZWWyuhY31PVcHQVJOhD4GPBJYJekmwCiOBPOihfbVrsj4vdR/KU85Utd1XU1rHcQ8DPglGj1albxEbQUWA8sGT16KI7gNcB+wHuAQ+s603RBXYdRNAEGgLXATWOef10ZiP0pm04dUtcxwIXArCq2V3WbcH+Kj2GOLgu/u1z+c2B5lG2MunVqXY0kzaW4T++5iDhH0tEUZ+97IuKpXq6r0r+OI2KnpDUUl9pLys+5nqfoMdlR5bZ6oa5GEfE3ScuBleVgshnASZkBrKuuyj+iiYi/S/oW8BDFX3Y7gXMi4q9Vb6sX6moUEdsl3Q+8HVgaEX/JrgnaX1db76yWNJPiY6WO6Hwf1cF1HQJ8D/h0RNyfXc+odtfl2/s7jKT9o/xQuJO0sy6H0NJ15I2S1l8cQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOkcQkvnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOkcwnFI+oKkz5RfXy7p5BZea46ktZJ+J2mTpMXl8pXlsvslrZM0p6r6u41DOImI+HxE3NnCS1wL3BYRR1IMZt9ULr8DOCoijgYeBi5prdLu5RCWyilwN0u6E1jYsHx1OesUkrZIulLSLyWNSFok6SeSHpF0/jivOZtiQtBvA0TEroh4pvz69ojYXa56L/CqNu9ix3IIAUnHUUzucyxwFnB8k9Ufi4jFwD3AaorJPk8ALh9n3SMoZqz6rqTfSLqxnOtlrA8BP57+HnQ3h7CwBFgXEc9GMV3c+ibrjj73AHBfRPwzIrYBO8dp182imOL3hog4lmK204sbV5B0KcU8f2sq2I+u5BC+aG/Hvj5f/run4evR78fOaPE48HhE3Fd+v5Zy3mkASedSTMP2gejjsbcOYeFu4ExJB0h6KfDOKl40Ip4EHitniYViJtOHoJheF/gscHpEPFvF9rpV5XPRdKOI+LWkWyjmYN5K0d6ryseBNZL2BR4FziuXX08xLd0d5RTa90YxU3/f8QwMls6XY0vnEFo6h9DSOYSWziG0dA6hpXMILZ1DaOn+A8QyX/K7p3n+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 244.8x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_idx = []\n",
    "results = []\n",
    "for i, mdl in mdls.iterrows():\n",
    "    \n",
    "    print(i, end=', ')\n",
    "    hypers = mdl.to_dict()\n",
    "\n",
    "    try:\n",
    "        if __name__ == \"__main__\":\n",
    "            assert numpyro.__version__.startswith('0.2.4')\n",
    "            parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "        #     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "        #     parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "        #     parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "        #     parser.add_argument(\"--num-data\", nargs='?', default=100, type=int)\n",
    "        #     parser.add_argument(\"--num-dimensions\", nargs='?', default=20, type=int)\n",
    "        #     parser.add_argument(\"--active-dimensions\", nargs='?', default=3, type=int)\n",
    "        #     parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "            parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "            parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "            parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "            parser.add_argument(\"--num-data\", nargs='?', default=63, type=int)\n",
    "            parser.add_argument(\"--num-dimensions\", nargs='?', default=145, type=int)\n",
    "            parser.add_argument(\"--active-dimensions\", nargs='?', default=15, type=int)\n",
    "            parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "            #args = parser.parse_args() \n",
    "            args = parser.parse_args(args=[])\n",
    "\n",
    "            numpyro.set_platform(args.device)\n",
    "            numpyro.set_host_device_count(args.num_chains)\n",
    "\n",
    "            fig = main(args, hypers)\n",
    "            results_idx.append(i)\n",
    "            results.append(fig)\n",
    "            fig.show()\n",
    "\n",
    "    except RuntimeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'expected_sparsity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-36c6ab8891d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mnumpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_host_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-036ad941efb2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, hypers)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# do inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrng_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# compute the mean and square root variance of each coefficient theta_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-86f87e277a40>\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(model, args, rng_key, X, Y, hypers)\u001b[0m\n\u001b[1;32m    205\u001b[0m     mcmc = MCMC(kernel, args.num_warmup, args.num_samples, num_chains=args.num_chains,\n\u001b[1;32m    206\u001b[0m                 progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True)\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nMCMC elapsed time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             states_flat, last_state = self._single_chain_mcmc(rng_key, init_state, init_params,\n\u001b[0;32m-> 1197\u001b[0;31m                                                               args, kwargs, collect_fields)\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36m_single_chain_mcmc\u001b[0;34m(self, rng_key, init_state, init_params, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minit_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             init_state = self.sampler.init(rng_key, self.num_warmup, init_params,\n\u001b[0;32m-> 1070\u001b[0;31m                                            model_args=args, model_kwargs=kwargs)\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m                                                               \u001b[0mparam_as_improper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                                                               \u001b[0mmodel_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                                                               model_kwargs=model_kwargs)\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnot_jax_tracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdevice_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36mfind_valid_initial_params\u001b[0;34m(rng_key, model, init_strategy, param_as_improper, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# Handle possible vectorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0minit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_valid_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0minit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_find_valid_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36m_find_valid_params\u001b[0;34m(rng_key_)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find_valid_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprototype_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng_key_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Early return if valid params found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_jax_tracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/infer/util.py\u001b[0m in \u001b[0;36mbody_fn\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# Use `block` to not record sample primitives in `init_loc_fn`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mseeded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubstitute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitute_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mmodel_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeded_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mconstrained_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/handlers.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpyro/primitives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-86f87e277a40>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X, Y, hypers)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# read off dimensions P and N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# S ??? - like a sparsity coeff?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expected_sparsity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# sample variables from p. 18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'expected_sparsity'"
     ]
    }
   ],
   "source": [
    "hypers = {#'expected_sparsity': max(1.0,args.num_dimensions // 10),\n",
    "          'alpha1': 0.40097142738801805, \n",
    "          'alpha2': 0.47483035520083294, \n",
    "          'alpha3': 19.09608142822879, \n",
    "          'alpha_obs': 0.9711468316345567, \n",
    "          'beta1': 1.2402045085927398, \n",
    "          'beta2': 0.332604268922102, \n",
    "          'beta_obs': 0.24564582519281306, \n",
    "          'c': 29.7980082293205}\n",
    "\n",
    "# hypers = {'expected_sparsity': max(1.0, args.num_dimensions / 10),\n",
    "#           'alpha1': 3.0, \n",
    "#           'beta1': 1.0,\n",
    "#           'alpha2': 3.0, \n",
    "#           'beta2': 1.0,\n",
    "#           'alpha3': 1.0, \n",
    "#           'c': 1.0,\n",
    "#           'alpha_obs': 50.0, \n",
    "#           'beta_obs': 1.0}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        assert numpyro.__version__.startswith('0.2.4')\n",
    "        parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "    #     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "    #     parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "    #     parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "    #     parser.add_argument(\"--num-data\", nargs='?', default=100, type=int)\n",
    "    #     parser.add_argument(\"--num-dimensions\", nargs='?', default=20, type=int)\n",
    "    #     parser.add_argument(\"--active-dimensions\", nargs='?', default=3, type=int)\n",
    "    #     parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "        parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "        parser.add_argument(\"--num-warmup\", nargs='?', default=500, type=int)\n",
    "        parser.add_argument(\"--num-chains\", nargs='?', default=1, type=int)\n",
    "        parser.add_argument(\"--num-data\", nargs='?', default=252, type=int)\n",
    "        parser.add_argument(\"--num-dimensions\", nargs='?', default=49, type=int)\n",
    "        parser.add_argument(\"--active-dimensions\", nargs='?', default=5, type=int)\n",
    "        parser.add_argument(\"--device\", default='cpu', type=str, help='use \"cpu\" or \"gpu\".')\n",
    "\n",
    "        #args = parser.parse_args() \n",
    "        args = parser.parse_args(args=[])\n",
    "\n",
    "        numpyro.set_platform(args.device)\n",
    "        numpyro.set_host_device_count(args.num_chains)\n",
    "        \n",
    "        main(args, hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
